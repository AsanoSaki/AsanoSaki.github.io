<!DOCTYPE html>
<html lang="zh-CN">
    <head>
  <!-- 元数据 -->
  <meta charset="utf-8">
  <link rel="icon" href="/images/favicon.ico">
  
  <title>动手学深度学习笔记(李沐)-现代循环神经网络 | AsanoSaki</title>
  <meta name="author" content="AsanoSaki" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="robots" content="index,follow" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <meta name="format-detection" content="telphone=no, email=no" />
  
    <meta name="keywords" content="AI" />
  
  <meta name="description" content="动手学深度学习笔记(李沐)-现代循环神经网络">
<meta property="og:type" content="article">
<meta property="og:title" content="动手学深度学习笔记(李沐)-现代循环神经网络">
<meta property="og:url" content="https://asanosaki.github.io/posts/7592.html">
<meta property="og:site_name" content="AsanoSaki">
<meta property="og:description" content="动手学深度学习笔记(李沐)-现代循环神经网络">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://asanosaki.github.io/images/favicon.ico">
<meta property="article:published_time" content="2023-04-11T04:58:00.000Z">
<meta property="article:modified_time" content="2023-05-21T09:56:38.075Z">
<meta property="article:author" content="AsanoSaki">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://asanosaki.github.io/images/favicon.ico">
  
  <!-- 站点验证相关 -->
  
    
    
    
  
  <!-- 样式表文件 -->
  <link rel="stylesheet" id="kratos-css" href="/css/kratosr.min.css" media="all"></script>
  
    <link rel="stylesheet" id="darkmode-css" href="/css/kr-color-dark.min.css" media="(prefers-color-scheme: dark)"></script>
    <script src="/js/kr-dark.min.js"></script>
  
  
    <link rel="stylesheet" id="highlight-css" href="/css/highlight/light.min.css" media="all"></script>
  
  
  <link rel="stylesheet" id="fontawe-css" href="/vendors/font-awesome@4.7.0/css/font-awesome.min.css" media="all"></script>
  <link rel="stylesheet" id="nprogress-css" href="/vendors/nprogress@0.2.0/nprogress.css" media="all"></script>
  
  
    <link rel="stylesheet" href="/vendors/aplayer@1.10.1/dist/APlayer.min.css"></script>
  
  
    <link rel="stylesheet" href="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"></script>
  
  <!-- 不得不预先加载的一些JS文件 -->
  <script src="/vendors/jquery@3.6.0/dist/jquery.min.js"></script>
  
    <script src="/vendors/qrcode_js@1.0.0/qrcode.min.js"></script>
  
  
  <style>
    
      .kratos-cover.kratos-cover-2 {
        background-image: url('https://z4a.net/images/2023/02/23/background03.jpg');
      }
    
    
      @media(min-width:768px) {
        body.custom-background {
          background-image: url('https://z4a.net/images/2023/02/23/background02.jpg');
        }
      }
    
  </style>
  
<meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="AsanoSaki" type="application/atom+xml">
</head>


    <body class="custom-background">
        <div id="kratos-wrapper">
    <div id="kratos-page">
        <div id="kratos-header">
            <header id="kratos-desktop-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="nav-header">
                        <nav id="kratos-menu-wrap">
                            <ul id="kratos-primary-menu" class="sf-menu">
                                
                                    
                                        <li>
                                            
                                                <a href="/">
                                            
                                                
                                                    <i class="fa fa-home"></i>
                                                
                                                Home
                                            </a>
                                            
                                        </li>
                                    
                                        <li>
                                            
                                                <a href="/archives/">
                                            
                                                
                                                    <i class="fa fa-file"></i>
                                                
                                                Archives
                                            </a>
                                            
                                        </li>
                                    
                                        <li>
                                            
                                                <a>
                                            
                                                
                                                    <i class="fa fa-paw"></i>
                                                
                                                Friends
                                            </a>
                                            
                                                <ul class="sub-menu">
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://angels-d.github.io">
                                                                
                                                                Angels-D
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="http://syh521.cn">
                                                                
                                                                SYH
                                                            </a>
                                                        </li>
                                                    
                                                </ul>
                                            
                                        </li>
                                    
                                        <li>
                                            
                                                <a>
                                            
                                                
                                                    <i class="fa fa-link"></i>
                                                
                                                Links
                                            </a>
                                            
                                                <ul class="sub-menu">
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://github.com/AsanoSaki">
                                                                
                                                                GitHub
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://gitee.com/asanosaki">
                                                                
                                                                Gitee
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://git.acwing.com/AsanoSaki">
                                                                
                                                                AcGit
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a href="https://asanosaki.github.io">
                                                                
                                                                BLOG
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://asanosaki.blog.csdn.net">
                                                                
                                                                CSDN
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.acwing.com/user/myspace/index/82581">
                                                                
                                                                AcWing
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.luogu.com.cn/user/459347">
                                                                
                                                                LuoGu
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://codeforces.com/profile/AsanoSaki">
                                                                
                                                                CodeForces
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://leetcode.cn/u/asanosaki">
                                                                
                                                                LeetCode
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://space.bilibili.com/12300056">
                                                                
                                                                Bilibili
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.youtube.com/@AsanoSaki0417">
                                                                
                                                                YouTube
                                                            </a>
                                                        </li>
                                                    
                                                </ul>
                                            
                                        </li>
                                    
                                        <li>
                                            
                                                <a>
                                            
                                                
                                                    <i class="fa fa-heart"></i>
                                                
                                                Favorite
                                            </a>
                                            
                                                <ul class="sub-menu">
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.cnki.net">
                                                                
                                                                CNKI
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.runoob.com">
                                                                
                                                                Runoob
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://wallhaven.cc">
                                                                
                                                                Wallhaven
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="http://www.flysheep6.com">
                                                                
                                                                Flysheep
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://thrift.apache.org">
                                                                
                                                                Thrift
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://developer.mozilla.org/zh-CN">
                                                                
                                                                MDN
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://v5.bootcss.com">
                                                                
                                                                Bootstrap
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://zh-hans.react.dev">
                                                                
                                                                React
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.nextjs.cn">
                                                                
                                                                Next.js
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://docs.djangoproject.com/zh-hans/4.2">
                                                                
                                                                Django
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://springdoc.cn/docs">
                                                                
                                                                Spring
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://hub.docker.com">
                                                                
                                                                DockerHub
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://fontawesome.com.cn">
                                                                
                                                                FontAwesome
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.online-convert.com">
                                                                
                                                                File-Convert
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://pytorch.org">
                                                                
                                                                PyTorch
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai">
                                                                
                                                                D2L
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://board.xcpcio.com">
                                                                
                                                                XCPC-Board
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://kr-demo.candinya.com/posts/Kratos-Rebirth-Manual">
                                                                
                                                                Kratos-MNL
                                                            </a>
                                                        </li>
                                                    
                                                </ul>
                                            
                                        </li>
                                    
                                
                            </ul>
                        </nav>
                    </div>
                </div>
            </header>
            <header id="kratos-mobile-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="color-logo"><a href="/">AsanoSaki</a></div>
                    <div class="nav-toggle">
                        <a class="kratos-nav-toggle js-kratos-nav-toggle">
                            <i></i>
                        </a>
                    </div>
                </div>
            </header>
        </div>
        <div class="kratos-start kratos-hero-2">
            <!-- <div class="kratos-overlay"></div> -->
            <div class="kratos-cover kratos-cover-2 text-center">
                <div class="desc desc2 animate-box">
                    <a href="/">
                        <h2>AsanoSaki</h2> <br />
                        <span>In summer, the sea breeze tastes like ice cream.</span>
                    </a>
                </div>
            </div>
        </div>

        <div id="kratos-blog-post">
            <div class="container">
                <div id="main" class="row">
                    

        

            <section class="col-md-8">

        

            <article itemscope itemtype="https://schema.org/Article">
    
    <link itemprop="mainEntityOfPage" href="https://asanosaki.github.io/posts/7592.html">
    <div class="kratos-hentry kratos-post-inner clearfix">
        <header class="kratos-entry-header">
            
                <h1 class="kratos-entry-title text-center" itemprop="name headline">动手学深度学习笔记(李沐)-现代循环神经网络</h1>
            
            
            <ul class="kratos-post-meta text-center">
                <li><time datetime="2023-04-11T04:58:00.000Z" itemprop="datePublished"><i class="fa fa-calendar"></i> 2023-04-11</time></li>
                <li itemprop="author" itemscope itemtype="https://schema.org/Person">
                    <i class="fa fa-user"></i> Author <span itemprop="name">AsanoSaki</span>
                </li>
                <li>
                    <i class="fa fa-edit"></i> 
                    
                    
                        ~35.32K
                    
                    words
                </li>
                
            </ul>
        </header>
        <div class="kratos-post-content">
            
            <div id="expire-alert" class="alert alert-warning hidden" role="alert">
                <div class="icon"><i class="fa fa-warning"></i></div>
                <div class="text"><p>本文最后编辑于 <time datetime="1684662998075"></time> 前，其中的内容可能需要更新。</p></div>
            </div>
            
            
            
                <div class="kratos-post-inner-toc toc-div-class" >
                    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E9%97%A8%E6%8E%A7%E5%BE%AA%E7%8E%AF%E5%8D%95%E5%85%83%EF%BC%88GRU%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">1. 门控循环单元（GRU）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E9%97%A8%E6%8E%A7%E5%BE%AA%E7%8E%AF%E5%8D%95%E5%85%83%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 门控循环单元的从零开始实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E9%97%A8%E6%8E%A7%E5%BE%AA%E7%8E%AF%E5%8D%95%E5%85%83%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.2.</span> <span class="toc-text">1.2 门控循环单元的简洁实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%EF%BC%88LSTM%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">2. 长短期记忆网络（LSTM）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 长短期记忆网络的从零开始实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 长短期记忆网络的简洁实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%B7%B1%E5%BA%A6%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">3.</span> <span class="toc-text">3. 深度循环神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%8F%8C%E5%90%91%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">4.</span> <span class="toc-text">4. 双向循环神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">5.</span> <span class="toc-text">5. 机器翻译与数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E7%BC%96%E7%A0%81%E5%99%A8-%E8%A7%A3%E7%A0%81%E5%99%A8%E6%9E%B6%E6%9E%84"><span class="toc-number">6.</span> <span class="toc-text">6. 编码器-解码器架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E5%BA%8F%E5%88%97%E5%88%B0%E5%BA%8F%E5%88%97%E5%AD%A6%E4%B9%A0%EF%BC%88seq2seq%EF%BC%89"><span class="toc-number">7.</span> <span class="toc-text">7. 序列到序列学习（seq2seq）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E6%9D%9F%E6%90%9C%E7%B4%A2"><span class="toc-number">8.</span> <span class="toc-text">8. 束搜索</span></a></li></ol>
                </div>
            
            <hr />
            <div itemprop="articleBody"><blockquote>
<p>李沐动手学深度学习（PyTorch）课程学习笔记第九章：现代循环神经网络。</p>
</blockquote>
<span id="more"></span>
<h2 id="1-门控循环单元（GRU）">1. 门控循环单元（GRU）</h2>
<p>在<a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/bptt.html">通过时间反向传播</a>中，我们讨论了如何在循环神经网络中计算梯度，以及矩阵连续乘积可以导致梯度消失或梯度爆炸的问题。下面我们简单思考一下这种梯度异常在实践中的意义，我们可能会遇到以下的情况：</p>
<ul>
<li>早期观测值对预测所有未来观测值具有非常重要的意义。考虑一个极端情况，其中第一个观测值包含一个校验和，目标是在序列的末尾辨别校验和是否正确。在这种情况下，第一个词元的影响至关重要。我们希望有某些机制能够<strong>在一个记忆元里存储重要的早期信息</strong>。如果没有这样的机制，我们将不得不给这个观测值指定一个非常大的梯度，因为它会影响所有后续的观测值。</li>
<li>一些词元没有相关的观测值。例如，在对网页内容进行情感分析时，可能有一些辅助 HTML 代码与网页传达的情绪无关。我们希望有一些机制来<strong>跳过隐状态表示中的此类词元</strong>。</li>
<li>序列的各个部分之间存在逻辑中断。例如，书的章节之间可能会有过渡存在，或者证券的熊市和牛市之间可能会有过渡存在。在这种情况下，最好有一种方法来<strong>重置我们的内部状态表示</strong>。</li>
</ul>
<p>在学术界已经提出了许多方法来解决这类问题。其中最早的方法是<strong>长短期记忆</strong>（long-short-term memory，LSTM），我们将在下一节中讨论。<strong>门控循环单元</strong>（gated recurrent unit，GRU）是一个稍微简化的变体，通常能够提供同等的效果，并且计算的速度明显更快。由于门控循环单元更简单，我们从它开始解读。</p>
<p>门控循环单元与普通的循环神经网络之间的关键区别在于：前者支持<strong>隐状态的门控</strong>。这意味着模型有专门的机制来确定应该何时更新隐状态，以及应该何时重置隐状态。这些机制是可学习的，并且能够解决了上面列出的问题。例如，如果第一个词元非常重要，模型将学会在第一次观测之后不更新隐状态。同样，模型也可以学会跳过不相关的临时观测。最后，模型还将学会在需要的时候重置隐状态。下面我们将详细讨论各类门控。</p>
<p>我们首先介绍<strong>重置门</strong>（reset gate）和<strong>更新门</strong>（update gate）。我们把它们设计成 <code>(0, 1)</code> 区间中的向量，这样我们就可以进行<strong>凸组合</strong>。重置门允许我们<strong>控制可能还想记住</strong>的过去状态的数量；更新门将允许我们<strong>控制新状态中有多少个是旧状态的副本</strong>。</p>
<p>我们从构造这些门控开始。重置门和更新门的输入是由当前时间步的输入和前一时间步的隐状态给出。两个门的输出是由使用 Sigmoid 激活函数的两个全连接层给出。门控循环单元的数学表达详见：<a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_recurrent-modern/gru.html">门控循环单元（GRU）</a>。</p>
<h3 id="1-1-门控循环单元的从零开始实现">1.1 门控循环单元的从零开始实现</h3>
<p>为了更好地理解门控循环单元模型，我们从零开始实现它。首先，我们读取上一章中使用的时间机器数据集：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">batch_size, num_steps = <span class="number">32</span>, <span class="number">35</span></span><br><span class="line">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br></pre></td></tr></table></figure>
<p>下一步是初始化模型参数。我们从标准差为0.01的高斯分布中提取权重，并将偏置项设为0，超参数 <code>num_hiddens</code> 定义隐藏单元的数量，实例化与更新门、重置门、候选隐状态和输出层相关的所有权重和偏置：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_params</span>(<span class="params">vocab_size, num_hiddens, device</span>):</span><br><span class="line">    num_inputs = num_outputs = vocab_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">normal</span>(<span class="params">shape</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.randn(size=shape, device=device) * <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">three</span>():</span><br><span class="line">        <span class="keyword">return</span> (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device))</span><br><span class="line"></span><br><span class="line">    W_xz, W_hz, b_z = three()  <span class="comment"># 更新门参数</span></span><br><span class="line">    W_xr, W_hr, b_r = three()  <span class="comment"># 重置门参数</span></span><br><span class="line">    W_xh, W_hh, b_h = three()  <span class="comment"># 候选隐状态参数</span></span><br><span class="line">    <span class="comment"># 输出层参数</span></span><br><span class="line">    W_hq = normal((num_hiddens, num_outputs))</span><br><span class="line">    b_q = torch.zeros(num_outputs, device=device)</span><br><span class="line">    <span class="comment"># 附加梯度</span></span><br><span class="line">    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> params</span><br></pre></td></tr></table></figure>
<p>现在我们将定义隐状态的初始化函数 <code>init_gru_state</code>。与从零开始实现 RNN 中定义的 <code>init_rnn_state</code> 函数一样，此函数返回一个形状为 <code>(批量大小, 隐藏单元个数)</code> 的张量，张量的值全部为零：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_gru_state</span>(<span class="params">batch_size, num_hiddens, device</span>):</span><br><span class="line">    <span class="keyword">return</span> (torch.zeros((batch_size, num_hiddens), device=device),)</span><br></pre></td></tr></table></figure>
<p>现在我们准备定义门控循环单元模型，模型的架构与基本的循环神经网络单元是相同的，只是权重更新公式更为复杂：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gru</span>(<span class="params">inputs, state, params</span>):</span><br><span class="line">    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params</span><br><span class="line">    H, = state</span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="keyword">for</span> X <span class="keyword">in</span> inputs:</span><br><span class="line">        Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z)  <span class="comment"># @为矩阵乘法，相当于torch.mm</span></span><br><span class="line">        R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r)</span><br><span class="line">        H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h)</span><br><span class="line">        H = Z * H + (<span class="number">1</span> - Z) * H_tilda</span><br><span class="line">        Y = H @ W_hq + b_q</span><br><span class="line">        outputs.append(Y)</span><br><span class="line">    <span class="keyword">return</span> torch.cat(outputs, dim=<span class="number">0</span>), (H,)</span><br></pre></td></tr></table></figure>
<p>训练和预测的工作方式与从零开始实现 RNN 完全相同。训练结束后，我们分别打印输出训练集的困惑度，以及前缀 <code>time traveler</code> 和 <code>traveler</code> 的预测序列上的困惑度：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">num_hiddens, num_epochs, lr = <span class="number">256</span>, <span class="number">500</span>, <span class="number">1</span></span><br><span class="line">net = d2l.RNNModelScratch(<span class="built_in">len</span>(vocab), num_hiddens, device, get_params, init_gru_state, gru)</span><br><span class="line">train(net, train_iter, vocab, lr, num_epochs, device)  <span class="comment"># 与从零开始实现RNN的train函数相同，此处不再实现</span></span><br></pre></td></tr></table></figure>
<h3 id="1-2-门控循环单元的简洁实现">1.2 门控循环单元的简洁实现</h3>
<p>高级 API 包含了前文介绍的所有配置细节，所以我们可以直接实例化门控循环单元模型。这段代码的运行速度要快得多，因为它使用的是编译好的运算符而不是 Python 来处理之前阐述的许多细节：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RNNModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, rnn_layer, vocab_size, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(RNNModel, self).__init__(**kwargs)</span><br><span class="line">        self.rnn = rnn_layer</span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.num_hiddens = self.rnn.hidden_size</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.rnn.bidirectional:</span><br><span class="line">            self.num_directions = <span class="number">1</span></span><br><span class="line">            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.num_directions = <span class="number">2</span></span><br><span class="line">            self.linear = nn.Linear(self.num_hiddens * <span class="number">2</span>, self.vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, state</span>):</span><br><span class="line">        X = F.one_hot(inputs.T.long(), self.vocab_size)</span><br><span class="line">        X = X.to(torch.float32)</span><br><span class="line">        Y, state = self.rnn(X, state)</span><br><span class="line">        output = self.linear(Y.reshape((-<span class="number">1</span>, Y.shape[-<span class="number">1</span>])))</span><br><span class="line">        <span class="keyword">return</span> output, state</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">begin_state</span>(<span class="params">self, device, batch_size=<span class="number">1</span></span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(self.rnn, nn.LSTM):</span><br><span class="line">            <span class="keyword">return</span> torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device),</span><br><span class="line">                    torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device))</span><br><span class="line"></span><br><span class="line">gru_layer = nn.GRU(<span class="built_in">len</span>(vocab), num_hiddens)</span><br><span class="line">net = RNNModel(gru_layer, <span class="built_in">len</span>(vocab))</span><br><span class="line">net = net.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params">net, train_iter, loss_function, optimizer, device, use_random_iter</span>):</span><br><span class="line">    state = <span class="literal">None</span></span><br><span class="line">    train_loss = []</span><br><span class="line">    <span class="keyword">for</span> X, Y <span class="keyword">in</span> tqdm(train_iter):</span><br><span class="line">        <span class="keyword">if</span> state <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> use_random_iter:</span><br><span class="line">            state = net.begin_state(batch_size=X.shape[<span class="number">0</span>], device=device)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module) <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(state, <span class="built_in">tuple</span>):</span><br><span class="line">                state.detach_()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> s <span class="keyword">in</span> state:</span><br><span class="line">                    s.detach_()</span><br><span class="line">        y = Y.T.reshape(-<span class="number">1</span>)</span><br><span class="line">        X, y = X.to(device), y.to(device)</span><br><span class="line">        loss_function.to(device)</span><br><span class="line">        y_hat, state = net(X, state)</span><br><span class="line">        loss = loss_function(y_hat, y.long()).mean()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        d2l.grad_clipping(net, <span class="number">1</span>)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        train_loss.append(loss)</span><br><span class="line">    <span class="keyword">return</span> math.exp(<span class="built_in">sum</span>(train_loss) / <span class="built_in">len</span>(train_loss))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, train_iter, vocab, lr, num_epochs, device, use_random_iter=<span class="literal">False</span></span>):</span><br><span class="line">    loss_function = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = torch.optim.SGD(net.parameters(), lr)</span><br><span class="line">    pred = <span class="keyword">lambda</span> prefix: d2l.predict_ch8(prefix, <span class="number">50</span>, net, vocab, device)</span><br><span class="line"></span><br><span class="line">    writer = SummaryWriter(<span class="string">&#x27;../logs/GRU_train_log&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        ppl = train_epoch(net, train_iter, loss_function, optimizer, device, use_random_iter)</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(pred(<span class="string">&#x27;time traveller&#x27;</span>))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Perplexity: <span class="subst">&#123;ppl:<span class="number">.1</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;train_loss&#x27;</span>, ppl, epoch + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(pred(<span class="string">&#x27;time traveller&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(pred(<span class="string">&#x27;traveller&#x27;</span>))</span><br><span class="line">    writer.close()</span><br><span class="line"></span><br><span class="line">train(net, train_iter, vocab, lr, num_epochs, device)</span><br><span class="line"><span class="comment"># Perplexity: 1.0</span></span><br><span class="line"><span class="comment"># time travelleryou can show black is white by argument said filby</span></span><br><span class="line"><span class="comment"># travelleryou can show black is white by argument said filby</span></span><br></pre></td></tr></table></figure>
<h2 id="2-长短期记忆网络（LSTM）">2. 长短期记忆网络（LSTM）</h2>
<p>长期以来，隐变量模型存在着长期信息保存和短期输入缺失的问题。解决这一问题的最早方法之一是长短期存储器（long short-term memory，LSTM）。它有许多与门控循环单元一样的属性。</p>
<p>可以说，长短期记忆网络的设计灵感来自于计算机的逻辑门。长短期记忆网络引入了记忆元（memory cell），或简称为单元（cell）。有些文献认为记忆元是隐状态的一种特殊类型，它们与隐状态具有相同的形状，其设计目的是用于记录附加的信息。为了控制记忆元，我们需要许多门。其中一个门用来从单元中输出条目，我们将其称为<strong>输出门</strong>（output gate）。另外一个门用来决定何时将数据读入单元，我们将其称为<strong>输入门</strong>（input gate）。我们还需要一种机制来重置单元的内容，由<strong>遗忘门</strong>（forget gate）来管理，这种设计的动机与门控循环单元相同，能够通过专用机制决定什么时候记忆或忽略隐状态中的输入。</p>
<p>长短期记忆网络的数学表达详见：<a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_recurrent-modern/lstm.html">长短期记忆网络（LSTM）</a>。</p>
<h3 id="2-1-长短期记忆网络的从零开始实现">2.1 长短期记忆网络的从零开始实现</h3>
<p>现在，我们从零开始实现长短期记忆网络，我们首先加载时光机器数据集：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">batch_size, num_steps = <span class="number">32</span>, <span class="number">35</span></span><br><span class="line">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br></pre></td></tr></table></figure>
<p>接下来，我们需要定义和初始化模型参数。如前所述，超参数 <code>num_hiddens</code> 定义隐藏单元的数量。我们按照标准差0.01的高斯分布初始化权重，并将偏置项设为0：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_lstm_params</span>(<span class="params">vocab_size, num_hiddens, device</span>):</span><br><span class="line">    num_inputs = num_outputs = vocab_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">normal</span>(<span class="params">shape</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.randn(size=shape, device=device) * <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">three</span>():</span><br><span class="line">        <span class="keyword">return</span> (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device))</span><br><span class="line"></span><br><span class="line">    W_xi, W_hi, b_i = three()  <span class="comment"># 输入门参数</span></span><br><span class="line">    W_xf, W_hf, b_f = three()  <span class="comment"># 遗忘门参数</span></span><br><span class="line">    W_xo, W_ho, b_o = three()  <span class="comment"># 输出门参数</span></span><br><span class="line">    W_xc, W_hc, b_c = three()  <span class="comment"># 候选记忆元参数</span></span><br><span class="line">    <span class="comment"># 输出层参数</span></span><br><span class="line">    W_hq = normal((num_hiddens, num_outputs))</span><br><span class="line">    b_q = torch.zeros(num_outputs, device=device)</span><br><span class="line">    <span class="comment"># 附加梯度</span></span><br><span class="line">    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q]</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> params</span><br></pre></td></tr></table></figure>
<p>在初始化函数中，长短期记忆网络的隐状态需要返回一个额外的记忆元，单元的值为0，形状为 <code>(批量大小, 隐藏单元数)</code>。因此，我们得到以下的状态初始化：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_lstm_state</span>(<span class="params">batch_size, num_hiddens, device</span>):</span><br><span class="line">    <span class="keyword">return</span> (torch.zeros((batch_size, num_hiddens), device=device),</span><br><span class="line">            torch.zeros((batch_size, num_hiddens), device=device))</span><br></pre></td></tr></table></figure>
<p>实际模型的定义与我们前面讨论的一样：提供三个门和一个额外的记忆元。请注意，只有隐状态 <code>H</code> 才会传递到输出层，而记忆元 <code>C</code> 不直接参与输出计算：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lstm</span>(<span class="params">inputs, state, params</span>):</span><br><span class="line">    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] = params</span><br><span class="line">    (H, C) = state</span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="keyword">for</span> X <span class="keyword">in</span> inputs:</span><br><span class="line">        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)</span><br><span class="line">        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)</span><br><span class="line">        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)</span><br><span class="line">        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)</span><br><span class="line">        C = F * C + I * C_tilda</span><br><span class="line">        H = O * torch.tanh(C)</span><br><span class="line">        Y = (H @ W_hq) + b_q</span><br><span class="line">        outputs.append(Y)</span><br><span class="line">    <span class="keyword">return</span> torch.cat(outputs, dim=<span class="number">0</span>), (H, C)</span><br></pre></td></tr></table></figure>
<p>让我们通过实例化从零实现 RNN 章节中引入的 <code>RNNModelScratch</code> 类来训练一个长短期记忆网络，就如我们在上一节中所做的一样：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">num_hiddens, num_epochs, lr = <span class="number">256</span>, <span class="number">500</span>, <span class="number">1</span></span><br><span class="line">net = d2l.RNNModelScratch(<span class="built_in">len</span>(vocab), num_hiddens, device, get_lstm_params, init_lstm_state, lstm)</span><br><span class="line">train(net, train_iter, vocab, lr, num_epochs, device)  <span class="comment"># 与从零开始实现RNN的train函数相同，此处不再实现</span></span><br></pre></td></tr></table></figure>
<h3 id="2-2-长短期记忆网络的简洁实现">2.2 长短期记忆网络的简洁实现</h3>
<p>使用高级 API，我们可以直接实例化 LSTM 模型：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RNNModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, rnn_layer, vocab_size, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(RNNModel, self).__init__(**kwargs)</span><br><span class="line">        self.rnn = rnn_layer</span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.num_hiddens = self.rnn.hidden_size</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.rnn.bidirectional:</span><br><span class="line">            self.num_directions = <span class="number">1</span></span><br><span class="line">            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.num_directions = <span class="number">2</span></span><br><span class="line">            self.linear = nn.Linear(self.num_hiddens * <span class="number">2</span>, self.vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, state</span>):</span><br><span class="line">        X = F.one_hot(inputs.T.long(), self.vocab_size)</span><br><span class="line">        X = X.to(torch.float32)</span><br><span class="line">        Y, state = self.rnn(X, state)</span><br><span class="line">        output = self.linear(Y.reshape((-<span class="number">1</span>, Y.shape[-<span class="number">1</span>])))</span><br><span class="line">        <span class="keyword">return</span> output, state</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">begin_state</span>(<span class="params">self, device, batch_size=<span class="number">1</span></span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(self.rnn, nn.LSTM):</span><br><span class="line">            <span class="keyword">return</span> torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device),</span><br><span class="line">                    torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device))</span><br><span class="line"></span><br><span class="line">lstm_layer = nn.LSTM(<span class="built_in">len</span>(vocab), num_hiddens)</span><br><span class="line">net = RNNModel(lstm_layer, <span class="built_in">len</span>(vocab))</span><br><span class="line">net = net.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params">net, train_iter, loss_function, optimizer, device, use_random_iter</span>):</span><br><span class="line">    state = <span class="literal">None</span></span><br><span class="line">    train_loss = []</span><br><span class="line">    <span class="keyword">for</span> X, Y <span class="keyword">in</span> tqdm(train_iter):</span><br><span class="line">        <span class="keyword">if</span> state <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> use_random_iter:</span><br><span class="line">            state = net.begin_state(batch_size=X.shape[<span class="number">0</span>], device=device)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module) <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(state, <span class="built_in">tuple</span>):</span><br><span class="line">                state.detach_()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> s <span class="keyword">in</span> state:</span><br><span class="line">                    s.detach_()</span><br><span class="line">        y = Y.T.reshape(-<span class="number">1</span>)</span><br><span class="line">        X, y = X.to(device), y.to(device)</span><br><span class="line">        loss_function.to(device)</span><br><span class="line">        y_hat, state = net(X, state)</span><br><span class="line">        loss = loss_function(y_hat, y.long()).mean()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        d2l.grad_clipping(net, <span class="number">1</span>)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        train_loss.append(loss)</span><br><span class="line">    <span class="keyword">return</span> math.exp(<span class="built_in">sum</span>(train_loss) / <span class="built_in">len</span>(train_loss))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, train_iter, vocab, lr, num_epochs, device, use_random_iter=<span class="literal">False</span></span>):</span><br><span class="line">    loss_function = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = torch.optim.SGD(net.parameters(), lr)</span><br><span class="line">    pred = <span class="keyword">lambda</span> prefix: d2l.predict_ch8(prefix, <span class="number">50</span>, net, vocab, device)</span><br><span class="line"></span><br><span class="line">    writer = SummaryWriter(<span class="string">&#x27;../logs/LSTM_train_log&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        ppl = train_epoch(net, train_iter, loss_function, optimizer, device, use_random_iter)</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(pred(<span class="string">&#x27;time traveller&#x27;</span>))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Perplexity: <span class="subst">&#123;ppl:<span class="number">.1</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;train_loss&#x27;</span>, ppl, epoch + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(pred(<span class="string">&#x27;time traveller&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(pred(<span class="string">&#x27;traveller&#x27;</span>))</span><br><span class="line">    writer.close()</span><br><span class="line"></span><br><span class="line">train(net, train_iter, vocab, lr, num_epochs, device)</span><br><span class="line"><span class="comment"># Perplexity: 1.0</span></span><br><span class="line"><span class="comment"># time traveller for so it will be convenient to speak of himwas e</span></span><br><span class="line"><span class="comment"># travelleryou can show black is white by argument said filby</span></span><br></pre></td></tr></table></figure>
<h2 id="3-深度循环神经网络">3. 深度循环神经网络</h2>
<p>到目前为止，我们只讨论了具有一个单向隐藏层的循环神经网络。其中，隐变量和观测值与具体的函数形式的交互方式是相当随意的。只要交互类型建模具有足够的灵活性，这就不是一个大问题。然而，对一个单层来说，这可能具有相当的挑战性。之前在线性模型中，我们通过添加更多的层来解决这个问题。而在循环神经网络中，我们首先需要确定如何添加更多的层，以及在哪里添加额外的非线性，因此这个问题有点棘手。</p>
<p>事实上，我们可以将多层循环神经网络堆叠在一起，通过对几个简单层的组合，产生了一个灵活的机制。特别是，数据可能与不同层的堆叠有关。例如，我们可能希望保持有关金融市场状况（熊市或牛市）的宏观数据可用，而微观数据只记录较短期的时间动态。</p>
<p>深度循环神经网络的数学表达详见：<a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_recurrent-modern/deep-rnn.html">深度循环神经网络</a>。</p>
<p>实现多层循环神经网络所需的许多逻辑细节在高级 API 中都是现成的。简单起见，我们仅示范使用此类内置函数的实现方式。以长短期记忆网络模型为例，该代码与上一节中使用的代码非常相似，实际上唯一的区别是我们指定了层的数量，而不是使用单一层这个默认值。像往常一样，我们从加载数据集开始：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">batch_size, num_steps = <span class="number">32</span>, <span class="number">35</span></span><br><span class="line">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br></pre></td></tr></table></figure>
<p>像选择超参数这类架构决策也跟上一节中的决策非常相似。因为我们有不同的词元，所以输入和输出都选择相同数量，即 <code>vocab_size</code>。隐藏单元的数量仍然是256。唯一的区别是，我们现在通过 <code>num_layers</code> 的值来设定隐藏层数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">num_inputs, num_hiddens, num_layers = <span class="built_in">len</span>(vocab), <span class="number">256</span>, <span class="number">2</span></span><br><span class="line">lstm_layer = nn.LSTM(input_size=num_inputs, hidden_size=num_hiddens, num_layers=num_layers)</span><br><span class="line">net = d2l.RNNModel(lstm_layer, <span class="built_in">len</span>(vocab))  <span class="comment"># 同上节的RNNModel</span></span><br><span class="line">net = net.to(device)</span><br></pre></td></tr></table></figure>
<p>最后和上一节一样训练模型看看效果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">num_epochs, lr = <span class="number">500</span>, <span class="number">2</span></span><br><span class="line">train(net, train_iter, vocab, lr * <span class="number">1.0</span>, num_epochs, device)  <span class="comment"># 同上节的train</span></span><br><span class="line"><span class="comment"># Perplexity: 1.0</span></span><br><span class="line"><span class="comment"># time traveller for so it will be convenient to speak of himwas e</span></span><br><span class="line"><span class="comment"># traveller with a slight accession ofcheerfulness really thi</span></span><br></pre></td></tr></table></figure>
<h2 id="4-双向循环神经网络">4. 双向循环神经网络</h2>
<p>在双向循环神经网络中，每个时间步的隐状态由当前时间步的前后数据同时决定，通过反向更新的隐藏层来利用反向时间信息，通常用来对序列抽取特征、填空，而<strong>不是预测未来</strong>。</p>
<p>双向循环神经网络的数学表达详见：<a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_recurrent-modern/bi-rnn.html">双向循环神经网络</a>。</p>
<p>由于双向循环神经网络使用了过去的和未来的数据，所以我们不能盲目地将这一语言模型应用于任何预测任务。尽管模型产出的困惑度是合理的，该模型预测未来词元的能力却可能存在严重缺陷。我们用下面的示例代码引以为戒，以防在错误的环境中使用它们：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">batch_size, num_steps = <span class="number">32</span>, <span class="number">35</span></span><br><span class="line">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过设置“bidirective=True”来定义双向LSTM模型</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">num_inputs, num_hiddens, num_layers = <span class="built_in">len</span>(vocab), <span class="number">256</span>, <span class="number">2</span></span><br><span class="line">lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers, bidirectional=<span class="literal">True</span>)</span><br><span class="line">net = d2l.RNNModel(lstm_layer, <span class="built_in">len</span>(vocab))</span><br><span class="line">net = net.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">num_epochs, lr = <span class="number">500</span>, <span class="number">1</span></span><br><span class="line">train(net, train_iter, vocab, lr, num_epochs, device)</span><br><span class="line"><span class="comment"># Perplexity: 1.1</span></span><br><span class="line"><span class="comment"># time travellerererererererererererererererererererererererererer</span></span><br><span class="line"><span class="comment"># travellerererererererererererererererererererererererererer</span></span><br></pre></td></tr></table></figure>
<h2 id="5-机器翻译与数据集">5. 机器翻译与数据集</h2>
<p>语言模型是自然语言处理的关键，而机器翻译是语言模型最成功的基准测试。因为机器翻译正是将输入序列转换成输出序列的<strong>序列转换模型</strong>（sequence transduction）的核心问题。</p>
<p>与语言模型那一节中的语料库是单一语言的语言模型问题存在不同，机器翻译的数据集是由源语言和目标语言的文本序列对组成的。因此，我们需要一种完全不同的方法来预处理机器翻译数据集，而不是复用语言模型的预处理程序。</p>
<p>首先，下载一个由双语句子对组成的“英-法”数据集，数据集中的每一行都是制表符分隔的文本序列对，序列对由英文文本序列和翻译后的法语文本序列组成。请注意，每个文本序列可以是一个句子，也可以是包含多个句子的一个段落。在这个将英语翻译成法语的机器翻译问题中，英语是源语言（source language），法语是目标语言（target language）。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">d2l.DATA_HUB[<span class="string">&#x27;fra-eng&#x27;</span>] = (d2l.DATA_URL + <span class="string">&#x27;fra-eng.zip&#x27;</span>, <span class="string">&#x27;94646ad1522d915e7b0f9296181140edcf86a4f5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_data_nmt</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;载入“英语-法语”数据集&quot;&quot;&quot;</span></span><br><span class="line">    data_dir = d2l.download_extract(<span class="string">&#x27;fra-eng&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(data_dir, <span class="string">&#x27;fra.txt&#x27;</span>), <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">return</span> f.read()</span><br><span class="line"></span><br><span class="line">raw_text = read_data_nmt()</span><br><span class="line"><span class="built_in">print</span>(raw_text[:<span class="number">75</span>])</span><br><span class="line"><span class="comment"># Go.    Va !</span></span><br><span class="line"><span class="comment"># Hi.    Salut !</span></span><br><span class="line"><span class="comment"># Run!    Cours !</span></span><br><span class="line"><span class="comment"># Run!    Courez !</span></span><br><span class="line"><span class="comment"># Who?    Qui ?</span></span><br><span class="line"><span class="comment"># Wow!    Ça alors !</span></span><br></pre></td></tr></table></figure>
<p>下载数据集后，原始文本数据需要经过几个预处理步骤。例如，我们用空格代替不间断空格（non-breaking space），使用小写字母替换大写字母，并在单词和标点符号之间插入空格：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_nmt</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;预处理“英语-法语”数据集&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">no_space</span>(<span class="params">char, prev_char</span>):</span><br><span class="line">        <span class="keyword">return</span> char <span class="keyword">in</span> <span class="built_in">set</span>(<span class="string">&#x27;,.!?&#x27;</span>) <span class="keyword">and</span> prev_char != <span class="string">&#x27; &#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用空格替换不间断空格，使用小写字母替换大写字母</span></span><br><span class="line">    text = text.replace(<span class="string">&#x27;\u202f&#x27;</span>, <span class="string">&#x27; &#x27;</span>).replace(<span class="string">&#x27;\xa0&#x27;</span>, <span class="string">&#x27; &#x27;</span>).lower()</span><br><span class="line">    <span class="comment"># 在单词和标点符号之间插入空格</span></span><br><span class="line">    out = [<span class="string">&#x27; &#x27;</span> + char <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> no_space(char, text[i - <span class="number">1</span>]) <span class="keyword">else</span> char <span class="keyword">for</span> i, char <span class="keyword">in</span> <span class="built_in">enumerate</span>(text)]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(out)</span><br><span class="line"></span><br><span class="line">text = preprocess_nmt(raw_text)</span><br><span class="line"><span class="built_in">print</span>(text[:<span class="number">80</span>])</span><br><span class="line"><span class="comment"># go .    va !</span></span><br><span class="line"><span class="comment"># hi .    salut !</span></span><br><span class="line"><span class="comment"># run !    cours !</span></span><br><span class="line"><span class="comment"># run !    courez !</span></span><br><span class="line"><span class="comment"># who ?    qui ?</span></span><br><span class="line"><span class="comment"># wow !    ça alors !</span></span><br></pre></td></tr></table></figure>
<p>与之前的字符级词元化不同，在机器翻译中，我们更喜欢单词级词元化（最先进的模型可能使用更高级的词元化技术）。下面的 <code>tokenize_nmt</code> 函数对前 <code>num_examples</code> 个文本序列对进行词元化，其中每个词元要么是一个词，要么是一个标点符号。此函数返回两个词元列表：<code>source</code> 和 <code>target</code>，<code>source[i]</code> 是源语言（这里是英语）第 <code>i</code> 个文本序列的词元列表，<code>target[i]</code> 是目标语言（这里是法语）第 <code>i</code> 个文本序列的词元列表。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_nmt</span>(<span class="params">text, num_examples=<span class="literal">None</span></span>):  <span class="comment"># num_examples限制数据集的数量</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;词元化“英语-法语”数据集&quot;&quot;&quot;</span></span><br><span class="line">    source, target = [], []</span><br><span class="line">    <span class="keyword">for</span> i, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(text.split(<span class="string">&#x27;\n&#x27;</span>)):</span><br><span class="line">        <span class="keyword">if</span> num_examples <span class="keyword">and</span> i &gt; num_examples:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        parts = line.split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(parts) == <span class="number">2</span>:</span><br><span class="line">            source.append(parts[<span class="number">0</span>].split(<span class="string">&#x27; &#x27;</span>))</span><br><span class="line">            target.append(parts[<span class="number">1</span>].split(<span class="string">&#x27; &#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> source, target</span><br><span class="line"></span><br><span class="line">source, target = tokenize_nmt(text)</span><br><span class="line"><span class="built_in">print</span>(source[:<span class="number">3</span>], target[:<span class="number">3</span>])  <span class="comment"># [[&#x27;go&#x27;, &#x27;.&#x27;], [&#x27;hi&#x27;, &#x27;.&#x27;], [&#x27;run&#x27;, &#x27;!&#x27;]] [[&#x27;va&#x27;, &#x27;!&#x27;], [&#x27;salut&#x27;, &#x27;!&#x27;], [&#x27;cours&#x27;, &#x27;!&#x27;]]</span></span><br></pre></td></tr></table></figure>
<p>让我们绘制每个文本序列所包含的词元数量的直方图。在这个简单的“英-法”数据集中，大多数文本序列的词元数量少于20个：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_list_len_pair_hist</span>(<span class="params">legend, title, xlabel, ylabel, xlist, ylist</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;绘制列表长度对的直方图&quot;&quot;&quot;</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>), dpi=<span class="number">150</span>)</span><br><span class="line">    _, _, patches = plt.hist([[<span class="built_in">len</span>(l) <span class="keyword">for</span> l <span class="keyword">in</span> xlist], [<span class="built_in">len</span>(l) <span class="keyword">for</span> l <span class="keyword">in</span> ylist]], edgecolor=<span class="string">&#x27;r&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.xlabel(xlabel)</span><br><span class="line">    plt.ylabel(ylabel)</span><br><span class="line">    plt.legend(legend)</span><br><span class="line">    <span class="comment"># for patch in patches[1].patches:</span></span><br><span class="line">    <span class="comment">#     patch.set_hatch(&#x27;/&#x27;)  # 给第二个list对的条形设置填充效果</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">show_list_len_pair_hist([<span class="string">&#x27;source&#x27;</span>, <span class="string">&#x27;target&#x27;</span>], <span class="string">&#x27;The length of list&#x27;</span>, <span class="string">&#x27;# tokens per sequence&#x27;</span>, <span class="string">&#x27;count&#x27;</span>, source, target)</span><br></pre></td></tr></table></figure>
<p>由于机器翻译数据集由语言对组成，因此我们可以分别为源语言和目标语言构建两个词表。使用单词级词元化时，词表大小将明显大于使用字符级词元化时的词表大小。为了缓解这一问题，这里我们将出现次数少于2次的低频率词元视为相同的未知（<code>&lt;unk&gt;</code>）词元。除此之外，我们还指定了额外的特定词元，例如在小批量时用于将序列填充到相同长度的填充词元（<code>&lt;pad&gt;</code>），以及序列的开始词元（<code>&lt;bos&gt;</code>）和结束词元（<code>&lt;eos&gt;</code>）。这些特殊词元在自然语言处理任务中比较常用。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">src_vocab = d2l.Vocab(source, min_freq=<span class="number">2</span>, reserved_tokens=[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="string">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(src_vocab))  <span class="comment"># 10012</span></span><br></pre></td></tr></table></figure>
<p>回想一下，语言模型中的序列样本都有一个固定的长度，无论这个样本是一个句子的一部分还是跨越了多个句子的一个片断。这个固定长度是由语言模型中的 <code>num_steps</code>（时间步数或词元数量）参数指定的。在机器翻译中，每个样本都是由源和目标组成的文本序列对，其中的每个文本序列可能具有不同的长度。</p>
<p>为了提高计算效率，我们仍然可以通过<strong>截断</strong>（truncation）和<strong>填充</strong>（padding）方式实现一次只处理一个小批量的文本序列。假设同一个小批量中的每个序列都应该具有相同的长度 <code>num_steps</code>，那么如果文本序列的词元数目少于 <code>num_steps</code> 时，我们将继续在其末尾添加特定的 <code>&lt;pad&gt;</code> 词元，直到其长度达到 <code>num_steps</code>；反之，我们将截断文本序列时，只取其前 <code>num_steps</code> 个词元，并且丢弃剩余的词元。这样，每个文本序列将具有相同的长度，以便以相同形状的小批量进行加载。下面的 <code>truncate_pad</code> 函数将截断或填充文本序列：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">truncate_pad</span>(<span class="params">line, num_steps, padding_token</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;截断或填充文本序列&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(line) &gt; num_steps:</span><br><span class="line">        <span class="keyword">return</span> line[:num_steps]  <span class="comment"># 截断</span></span><br><span class="line">    <span class="keyword">return</span> line + [padding_token] * (num_steps - <span class="built_in">len</span>(line))  <span class="comment"># 填充</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(truncate_pad(src_vocab[source[<span class="number">0</span>]], <span class="number">10</span>, src_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]))  <span class="comment"># [47, 4, 1, 1, 1, 1, 1, 1, 1, 1]</span></span><br></pre></td></tr></table></figure>
<p>现在我们定义一个函数，可以将文本序列转换成小批量数据集用于训练。我们将特定的 <code>&lt;eos&gt;</code> 词元添加到所有序列的末尾，用于表示序列的结束。当模型通过一个词元接一个词元地生成序列进行预测时，生成的 <code>&lt;eos&gt;</code> 词元说明完成了序列输出工作。此外，我们还记录了每个文本序列的长度，统计长度时排除了填充词元，在稍后将要介绍的一些模型会需要这个长度信息。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_array_nmt</span>(<span class="params">lines, vocab, num_steps</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;将机器翻译的文本序列转换成小批量&quot;&quot;&quot;</span></span><br><span class="line">    lines = [vocab[l] <span class="keyword">for</span> l <span class="keyword">in</span> lines]</span><br><span class="line">    lines = [l + [vocab[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>]] <span class="keyword">for</span> l <span class="keyword">in</span> lines]</span><br><span class="line">    array = torch.tensor([truncate_pad(l, num_steps, vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]) <span class="keyword">for</span> l <span class="keyword">in</span> lines])</span><br><span class="line">    valid_len = (array != vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]).<span class="built_in">type</span>(torch.int32).<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> array, valid_len</span><br></pre></td></tr></table></figure>
<p>最后，我们定义 <code>load_data_nmt</code> 函数来返回数据迭代器，以及源语言和目标语言的两种词表：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_nmt</span>(<span class="params">batch_size, num_steps, num_examples=<span class="number">600</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;返回翻译数据集的迭代器和词表&quot;&quot;&quot;</span></span><br><span class="line">    text = preprocess_nmt(read_data_nmt())</span><br><span class="line">    source, target = tokenize_nmt(text, num_examples)</span><br><span class="line">    src_vocab = d2l.Vocab(source, min_freq=<span class="number">2</span>, reserved_tokens=[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="string">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class="line">    tgt_vocab = d2l.Vocab(target, min_freq=<span class="number">2</span>, reserved_tokens=[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="string">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class="line">    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)</span><br><span class="line">    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)</span><br><span class="line">    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)</span><br><span class="line">    data_iter = d2l.load_array(data_arrays, batch_size)</span><br><span class="line">    <span class="keyword">return</span> data_iter, src_vocab, tgt_vocab</span><br><span class="line"></span><br><span class="line">train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=<span class="number">2</span>, num_steps=<span class="number">8</span>)</span><br><span class="line"><span class="keyword">for</span> X, X_valid_len, Y, Y_valid_len <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;X:&#x27;</span>, X.<span class="built_in">type</span>(torch.int32))  <span class="comment"># X: tensor([[ 6, 18, 43,  4,  3,  1,  1,  1], [78,  9,  4,  3,  1,  1,  1,  1]], dtype=torch.int32)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;X的有效长度:&#x27;</span>, X_valid_len)  <span class="comment"># X的有效长度: tensor([5, 4])</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Y:&#x27;</span>, Y.<span class="built_in">type</span>(torch.int32))  <span class="comment"># Y: tensor([[ 6,  7, 40,  4,  3,  1,  1,  1], [ 0,  4,  3,  1,  1,  1,  1,  1]], dtype=torch.int32)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Y的有效长度:&#x27;</span>, Y_valid_len)  <span class="comment"># Y的有效长度: tensor([5, 3])</span></span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h2 id="6-编码器-解码器架构">6. 编码器-解码器架构</h2>
<p>正如我们在上一节中所讨论的，机器翻译是序列转换模型的一个核心问题，其输入和输出都是长度可变的序列。为了处理这种类型的输入和输出，我们可以设计一个包含两个主要组件的架构：第一个组件是一个<strong>编码器</strong>（encoder）：它接受一个<strong>长度可变</strong>的序列作为输入，并将其转换为具有<strong>固定形状</strong>的编码状态。第二个组件是<strong>解码器</strong>（decoder）：它将<strong>固定形状</strong>的编码状态映射到<strong>长度可变</strong>的序列。这被称为编码器-解码器（encoder-decoder）架构，示意图可见：<a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_recurrent-modern/encoder-decoder.html">编码器-解码器架构</a>。</p>
<p>由于“编码器-解码器”架构是形成后续章节中不同序列转换模型的基础，因此本节将把这个架构转换为接口方便后面的代码实现。</p>
<p>在编码器接口中，我们只指定长度可变的序列作为编码器的输入 <code>X</code>。任何继承这个 <code>Encoder</code> 基类的模型将完成代码实现：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;编码器-解码器架构的基本编码器接口&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, *args</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>
<p>在下面的解码器接口中，我们新增一个 <code>init_state</code> 函数，用于将编码器的输出（enc_outputs）转换为编码后的状态。注意，此步骤可能需要额外的输入，例如输入序列的有效长度。为了逐个地生成长度可变的词元序列，解码器在每个时间步都会将输入（例如在前一时间步生成的词元）和编码后的状态映射成当前时间步的输出词元：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;编码器-解码器架构的基本解码器接口&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_state</span>(<span class="params">self, enc_outputs, *args</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, state</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>
<p>总而言之，“编码器-解码器”架构包含了一个编码器和一个解码器，并且还拥有可选的额外的参数。在前向传播中，编码器的输出用于生成编码状态，这个状态又被解码器作为其输入的一部分：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderDecoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;编码器-解码器架构的基类&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, encoder, decoder, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(EncoderDecoder, self).__init__(**kwargs)</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, enc_X, dec_X, *args</span>):</span><br><span class="line">        enc_outputs = self.encoder(enc_X, *args)</span><br><span class="line">        dec_state = self.decoder.init_state(enc_outputs, *args)</span><br><span class="line">        <span class="keyword">return</span> self.decoder(dec_X, dec_state)</span><br></pre></td></tr></table></figure>
<h2 id="7-序列到序列学习（seq2seq）">7. 序列到序列学习（seq2seq）</h2>
<p>遵循编码器-解码器架构的设计原则，循环神经网络编码器使用长度可变的序列作为输入，将其转换为固定形状的隐状态。换言之，输入序列的信息被编码到循环神经网络编码器的隐状态中。为了连续生成输出序列的词元，独立的循环神经网络解码器是基于输入序列的编码信息和输出序列已经看见的或者生成的词元来预测下一个词元。在机器翻译中使用两个循环神经网络进行序列到序列学习的图示以及理论介绍可见：<a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_recurrent-modern/seq2seq.html">序列到序列学习（seq2seq）</a>。</p>
<p>在序列到序列学习中，特定的 <code>&lt;eos&gt;</code> 表示序列结束词元。一旦输出序列生成此词元，模型就会停止预测。在循环神经网络解码器的初始化时间步，有两个特定的设计决定：首先，特定的 <code>&lt;bos&gt;</code> 表示序列开始词元，它是解码器的输入序列的第一个词元。其次，使用循环神经网络编码器最终的隐状态来初始化解码器的隐状态。</p>
<p>从技术上讲，编码器将长度可变的输入序列转换成形状固定的上下文变量，并且将输入序列的信息在该上下文变量中进行编码。</p>
<p>现在，让我们实现循环神经网络编码器。注意，我们使用了嵌入层（embedding layer）来获得输入序列中每个词元的特征向量。嵌入层的权重是一个矩阵，其行数等于输入词表的大小（vocab_size），其列数等于特征向量的维度（embed_size）。另外，本文选择了一个多层门控循环单元来实现编码器。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2SeqEncoder</span>(d2l.Encoder):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;用于序列到序列学习的循环神经网络编码器&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_size, num_hiddens, num_layers, dropout=<span class="number">0.</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2SeqEncoder, self).__init__(**kwargs)</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embed_size)  <span class="comment"># 嵌入层</span></span><br><span class="line">        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, *args</span>):</span><br><span class="line">        X = self.embedding(X)  <span class="comment"># X.shape: (batch_size, num_steps, embed_size)</span></span><br><span class="line">        X = X.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)  <span class="comment"># 在循环神经网络模型中，第一个轴对应于时间步</span></span><br><span class="line">        output, state = self.rnn(X)  <span class="comment"># 如果未提及状态，则默认为0</span></span><br><span class="line">        <span class="comment"># output.shape: (num_steps, batch_size, num_hiddens)</span></span><br><span class="line">        <span class="comment"># state.shape: (num_layers, batch_size, num_hiddens)</span></span><br><span class="line">        <span class="keyword">return</span> output, state</span><br></pre></td></tr></table></figure>
<p>下面，我们实例化上述编码器的实现：我们使用一个两层门控循环单元编码器，其隐藏单元数为16。给定一小批量的输入序列 <code>X</code>（批量大小为4，时间步为7）。在完成所有时间步后，最后一层的隐状态的输出是一个张量（<code>output</code> 由编码器的循环层返回），其形状为 <code>(时间步数, 批量大小, 隐藏单元数)</code>。</p>
<p>由于这里使用的是门控循环单元，所以在最后一个时间步的多层隐状态的形状是 <code>(隐藏层的数量, 批量大小, 隐藏单元的数量)</code>。如果使用长短期记忆网络，<code>state</code> 中还将包含记忆单元信息。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">encoder = Seq2SeqEncoder(vocab_size=<span class="number">10</span>, embed_size=<span class="number">8</span>, num_hiddens=<span class="number">16</span>, num_layers=<span class="number">2</span>)</span><br><span class="line">encoder.<span class="built_in">eval</span>()</span><br><span class="line">X = torch.zeros((<span class="number">4</span>, <span class="number">7</span>), dtype=torch.long)</span><br><span class="line">output, state = encoder(X)</span><br><span class="line"><span class="built_in">print</span>(output.shape, state.shape)  <span class="comment"># torch.Size([7, 4, 16]) torch.Size([2, 4, 16])</span></span><br></pre></td></tr></table></figure>
<p>当实现解码器时，我们直接使用编码器最后一个时间步的隐状态来初始化解码器的隐状态。这就要求使用循环神经网络实现的编码器和解码器具有<strong>相同数量的层和隐藏单元</strong>。为了进一步包含经过编码的输入序列的信息，上下文变量在所有的时间步与解码器的输入进行拼接（concatenate）。为了预测输出词元的概率分布，在循环神经网络解码器的最后一层使用全连接层来变换隐状态。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2SeqDecoder</span>(d2l.Decoder):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;用于序列到序列学习的循环神经网络解码器&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embed_size, num_hiddens, num_layers, dropout=<span class="number">0.</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2SeqDecoder, self).__init__(**kwargs)</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)</span><br><span class="line">        self.dense = nn.Linear(num_hiddens, vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_state</span>(<span class="params">self, enc_outputs, *args</span>):</span><br><span class="line">        <span class="keyword">return</span> enc_outputs[<span class="number">1</span>]  <span class="comment"># enc_outputs[1]即为[output, state]中的state</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, state</span>):</span><br><span class="line">        X = self.embedding(X).permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)  <span class="comment"># X.shape: (num_steps, batch_size, embed_size)</span></span><br><span class="line">        context = state[-<span class="number">1</span>].repeat(X.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>)  <span class="comment"># 广播context，使其具有与X相同的num_steps</span></span><br><span class="line">        X_and_context = torch.cat((X, context), <span class="number">2</span>)  <span class="comment"># 因此RNN的输入维度为embed_size + num_hiddens</span></span><br><span class="line">        output, state = self.rnn(X_and_context, state)</span><br><span class="line">        output = self.dense(output).permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="comment"># output.shape: (batch_size, num_steps, vocab_size)</span></span><br><span class="line">        <span class="comment"># state.shape: (num_layers, batch_size, num_hiddens)</span></span><br><span class="line">        <span class="keyword">return</span> output, state</span><br></pre></td></tr></table></figure>
<p>下面，我们用与前面提到的编码器中相同的超参数来实例化解码器。如我们所见，解码器的输出形状变为 <code>(批量大小, 时间步数, 词表大小)</code>，其中张量的最后一个维度存储预测的词元分布。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">decoder = Seq2SeqDecoder(vocab_size=<span class="number">10</span>, embed_size=<span class="number">8</span>, num_hiddens=<span class="number">16</span>, num_layers=<span class="number">2</span>)</span><br><span class="line">decoder.<span class="built_in">eval</span>()</span><br><span class="line">state = decoder.init_state(encoder(X))</span><br><span class="line">output, state = decoder(X, state)</span><br><span class="line"><span class="built_in">print</span>(output.shape, state.shape)  <span class="comment"># torch.Size([4, 7, 10]) torch.Size([2, 4, 16])</span></span><br></pre></td></tr></table></figure>
<p>在每个时间步，解码器预测了输出词元的概率分布。类似于语言模型，可以使用 Softmax 来获得分布，并通过计算交叉熵损失函数来进行优化。回想一下我们将特定的填充词元添加到序列的末尾，因此不同长度的序列可以以相同形状的小批量加载。但是，我们应该将填充词元的预测排除在损失函数的计算之外。</p>
<p>为此，我们可以使用下面的 <code>sequence_mask</code> 函数通过<strong>零值化</strong>屏蔽不相关的项，以便后面任何不相关预测的计算都是与零的乘积，结果都等于零。例如，如果两个序列的有效长度（不包括填充词元）分别为1和2，则第一个序列的第一项和第二个序列的前两项之后的剩余项将被清除为零：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解析[None, :]和[:, None]</span></span><br><span class="line"><span class="built_in">print</span>(torch.arange(<span class="number">3</span>)[<span class="literal">None</span>, :])  <span class="comment"># tensor([[0, 1, 2]])，在第1维增加一维，同理[:, None]在第2维增加一维</span></span><br><span class="line"><span class="built_in">print</span>(torch.arange(<span class="number">3</span>)[<span class="literal">None</span>, :] &lt; torch.tensor([<span class="number">1</span>, <span class="number">2</span>])[:, <span class="literal">None</span>])</span><br><span class="line"><span class="comment"># tensor([[ True, False, False],</span></span><br><span class="line"><span class="comment">#         [ True,  True, False]])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sequence_mask</span>(<span class="params">X, valid_len, value=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;在序列中屏蔽不相关的项&quot;&quot;&quot;</span></span><br><span class="line">    maxlen = X.size(<span class="number">1</span>)</span><br><span class="line">    mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[<span class="literal">None</span>, :] &lt; valid_len[:, <span class="literal">None</span>]</span><br><span class="line">    X[~mask] = value</span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">X = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="built_in">print</span>(sequence_mask(X, torch.tensor([<span class="number">1</span>, <span class="number">2</span>])))</span><br><span class="line"><span class="comment"># tensor([[1, 0, 0],</span></span><br><span class="line"><span class="comment">#         [4, 5, 0]])</span></span><br></pre></td></tr></table></figure>
<p>现在，我们可以通过扩展 Softmax 交叉熵损失函数来遮蔽不相关的预测。最初，所有预测词元的掩码都设置为1。一旦给定了有效长度，与填充词元对应的掩码将被设置为0。最后，将所有词元的损失乘以掩码，以过滤掉损失中填充词元产生的不相关预测。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MaskedSoftmaxCELoss</span>(nn.CrossEntropyLoss):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;带遮蔽的softmax交叉熵损失函数&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># pred.shape: (batch_size, num_steps, vocab_size)</span></span><br><span class="line">    <span class="comment"># label.shape: (batch_size, num_steps)</span></span><br><span class="line">    <span class="comment"># valid_len.shape: (batch_size,)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, pred, label, valid_len</span>):</span><br><span class="line">        weights = torch.ones_like(label)</span><br><span class="line">        weights = sequence_mask(weights, valid_len)</span><br><span class="line">        self.reduction=<span class="string">&#x27;none&#x27;</span></span><br><span class="line">        unweighted_loss = <span class="built_in">super</span>(MaskedSoftmaxCELoss, self).forward(pred.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>), label)</span><br><span class="line">        weighted_loss = (unweighted_loss * weights).mean(dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> weighted_loss</span><br></pre></td></tr></table></figure>
<p>我们可以创建三个相同的序列来进行代码健全性检查，然后分别指定这些序列的有效长度为4、2和0。结果就是，第一个序列的损失应为第二个序列的两倍，而第三个序列的损失应为零。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss = MaskedSoftmaxCELoss()</span><br><span class="line"><span class="built_in">print</span>(loss(torch.ones(<span class="number">3</span>, <span class="number">4</span>, <span class="number">10</span>), torch.ones((<span class="number">3</span>, <span class="number">4</span>), dtype=torch.long), torch.tensor([<span class="number">4</span>, <span class="number">2</span>, <span class="number">0</span>])))  <span class="comment"># tensor([2.3026, 1.1513, 0.0000])</span></span><br></pre></td></tr></table></figure>
<p>在下面的循环训练过程中，特定的序列开始词元（<code>&lt;bos&gt;</code>）和原始的输出序列（不包括序列结束词元 <code>&lt;eos&gt;</code>）拼接在一起作为解码器的输入。这被称为<strong>强制教学</strong>（teacher forcing），因为原始的输出序列（词元的标签）被送入解码器。或者，将来自上一个时间步的预测得到的词元作为解码器的当前输入。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_seq2seq</span>(<span class="params">net, data_iter, lr, num_epochs, tgt_vocab, device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;训练序列到序列模型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">xavier_init_weights</span>(<span class="params">m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.GRU:</span><br><span class="line">            <span class="keyword">for</span> param <span class="keyword">in</span> m._flat_weights_names:</span><br><span class="line">                <span class="keyword">if</span> <span class="string">&quot;weight&quot;</span> <span class="keyword">in</span> param:</span><br><span class="line">                    nn.init.xavier_uniform_(m._parameters[param])</span><br><span class="line"></span><br><span class="line">    net.apply(xavier_init_weights)</span><br><span class="line">    net.to(device)</span><br><span class="line">    optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class="line">    loss_function = MaskedSoftmaxCELoss()</span><br><span class="line"></span><br><span class="line">    net.train()</span><br><span class="line">    writer = SummaryWriter(<span class="string">&#x27;../logs/seq2seq_train_log&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        timer = d2l.Timer()</span><br><span class="line">        num_tokens = <span class="number">0</span>  <span class="comment"># 词元数量</span></span><br><span class="line">        train_loss = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(data_iter):</span><br><span class="line">            X, X_valid_len, Y, Y_valid_len = [x.to(device) <span class="keyword">for</span> x <span class="keyword">in</span> batch]</span><br><span class="line">            bos = torch.tensor([tgt_vocab[<span class="string">&#x27;&lt;bos&gt;&#x27;</span>]] * Y.shape[<span class="number">0</span>], device=device).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            dec_input = torch.cat([bos, Y[:, :-<span class="number">1</span>]], <span class="number">1</span>)  <span class="comment"># 强制教学</span></span><br><span class="line">            Y_hat, _ = net(X, dec_input, X_valid_len)</span><br><span class="line">            loss = loss_function(Y_hat, Y, Y_valid_len).mean()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()  <span class="comment"># 损失函数的标量进行“反向传播”</span></span><br><span class="line">            d2l.grad_clipping(net, <span class="number">1</span>)</span><br><span class="line">            optimizer.step()</span><br><span class="line">            train_loss.append(loss)</span><br><span class="line">            num_tokens += Y_valid_len.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            train_loss = <span class="built_in">sum</span>(train_loss) / <span class="built_in">len</span>(train_loss)</span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;train_loss&#x27;</span>, train_loss, epoch + <span class="number">1</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;loss <span class="subst">&#123;train_loss:<span class="number">.3</span>f&#125;</span>, <span class="subst">&#123;num_tokens / timer.stop():<span class="number">.1</span>f&#125;</span> tokens/sec on <span class="subst">&#123;<span class="built_in">str</span>(device)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line"></span><br><span class="line">embed_size, num_hiddens, num_layers, dropout = <span class="number">32</span>, <span class="number">32</span>, <span class="number">2</span>, <span class="number">0.1</span></span><br><span class="line">batch_size, num_steps, lr, num_epochs = <span class="number">64</span>, <span class="number">10</span>, <span class="number">0.005</span>, <span class="number">300</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)</span><br><span class="line">encoder = Seq2SeqEncoder(<span class="built_in">len</span>(src_vocab), embed_size, num_hiddens, num_layers, dropout)</span><br><span class="line">decoder = Seq2SeqDecoder(<span class="built_in">len</span>(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)</span><br><span class="line">net = d2l.EncoderDecoder(encoder, decoder)</span><br><span class="line">train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)</span><br></pre></td></tr></table></figure>
<p>为了采用一个接着一个词元的方式预测输出序列，每个解码器当前时间步的输入都将来自于前一时间步的预测词元。与训练类似，序列开始词元（<code>&lt;bos&gt;</code>）在初始时间步被输入到解码器中，当输出序列的预测遇到序列结束词元（<code>&lt;eos&gt;</code>）时，预测就结束了。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_seq2seq</span>(<span class="params">net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;序列到序列模型的预测&quot;&quot;&quot;</span></span><br><span class="line">    net.<span class="built_in">eval</span>()  <span class="comment"># 在预测时将net设置为评估模式</span></span><br><span class="line">    src_tokens = src_vocab[src_sentence.lower().split(<span class="string">&#x27; &#x27;</span>)] + [src_vocab[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>]]</span><br><span class="line">    enc_valid_len = torch.tensor([<span class="built_in">len</span>(src_tokens)], device=device)</span><br><span class="line">    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>])</span><br><span class="line">    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=<span class="number">0</span>)  <span class="comment"># 添加批量维度</span></span><br><span class="line">    enc_outputs = net.encoder(enc_X, enc_valid_len)</span><br><span class="line">    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)</span><br><span class="line">    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab[<span class="string">&#x27;&lt;bos&gt;&#x27;</span>]], dtype=torch.long, device=device), dim=<span class="number">0</span>)  <span class="comment"># 添加批量维度</span></span><br><span class="line">    output_seq, attention_weight_seq = [], []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_steps):</span><br><span class="line">        Y, dec_state = net.decoder(dec_X, dec_state)</span><br><span class="line">        dec_X = Y.argmax(dim=<span class="number">2</span>)  <span class="comment"># 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入</span></span><br><span class="line">        pred = dec_X.squeeze(dim=<span class="number">0</span>).<span class="built_in">type</span>(torch.int32).item()</span><br><span class="line">        <span class="comment"># 保存注意力权重（稍后讨论）</span></span><br><span class="line">        <span class="keyword">if</span> save_attention_weights:</span><br><span class="line">            attention_weight_seq.append(net.decoder.attention_weights)</span><br><span class="line">        <span class="comment"># 一旦序列结束词元被预测，输出序列的生成就完成了</span></span><br><span class="line">        <span class="keyword">if</span> pred == tgt_vocab[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>]:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        output_seq.append(pred)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq</span><br></pre></td></tr></table></figure>
<p>我们可以通过与真实的标签序列进行比较来评估预测序列。虽然BLEU（bilingual evaluation understudy）最先是用于评估机器翻译的结果，但现在它已经被广泛用于测量许多应用的输出序列的质量。BLEU的详细介绍可见：<a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_recurrent-modern/seq2seq.html">序列到序列学习（seq2seq）</a>。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bleu</span>(<span class="params">pred_seq, label_seq, k</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算BLEU&quot;&quot;&quot;</span></span><br><span class="line">    pred_tokens, label_tokens = pred_seq.split(<span class="string">&#x27; &#x27;</span>), label_seq.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    len_pred, len_label = <span class="built_in">len</span>(pred_tokens), <span class="built_in">len</span>(label_tokens)</span><br><span class="line">    score = math.exp(<span class="built_in">min</span>(<span class="number">0</span>, <span class="number">1</span> - len_label / len_pred))</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, k + <span class="number">1</span>):</span><br><span class="line">        num_matches, label_subs = <span class="number">0</span>, collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len_label - n + <span class="number">1</span>):</span><br><span class="line">            label_subs[<span class="string">&#x27; &#x27;</span>.join(label_tokens[i: i + n])] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len_pred - n + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> label_subs[<span class="string">&#x27; &#x27;</span>.join(pred_tokens[i: i + n])] &gt; <span class="number">0</span>:</span><br><span class="line">                num_matches += <span class="number">1</span></span><br><span class="line">                label_subs[<span class="string">&#x27; &#x27;</span>.join(pred_tokens[i: i + n])] -= <span class="number">1</span></span><br><span class="line">        score *= math.<span class="built_in">pow</span>(num_matches / (len_pred - n + <span class="number">1</span>), math.<span class="built_in">pow</span>(<span class="number">0.5</span>, n))</span><br><span class="line">    <span class="keyword">return</span> score</span><br><span class="line"></span><br><span class="line">engs = [<span class="string">&#x27;go .&#x27;</span>, <span class="string">&quot;i lost .&quot;</span>, <span class="string">&#x27;he\&#x27;s calm .&#x27;</span>, <span class="string">&#x27;i\&#x27;m home .&#x27;</span>]</span><br><span class="line">fras = [<span class="string">&#x27;va !&#x27;</span>, <span class="string">&#x27;j\&#x27;ai perdu .&#x27;</span>, <span class="string">&#x27;il est calme .&#x27;</span>, <span class="string">&#x27;je suis chez moi .&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> eng, fra <span class="keyword">in</span> <span class="built_in">zip</span>(engs, fras):</span><br><span class="line">    translation, attention_weight_seq = predict_seq2seq(net, eng, src_vocab, tgt_vocab, num_steps, device)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;eng&#125;</span> =&gt; <span class="subst">&#123;translation&#125;</span>, bleu <span class="subst">&#123;bleu(translation, fra, k=<span class="number">2</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># go . =&gt; va !, bleu 1.000</span></span><br><span class="line"><span class="comment"># i lost . =&gt; j&#x27;ai perdu ., bleu 1.000</span></span><br><span class="line"><span class="comment"># he&#x27;s calm . =&gt; il est bon malade pas gagné pas en gagné pas, bleu 0.258</span></span><br><span class="line"><span class="comment"># i&#x27;m home . =&gt; je suis fainéante fainéante tomber ai ai homme paresseux ?, bleu 0.258</span></span><br></pre></td></tr></table></figure>
<h2 id="8-束搜索">8. 束搜索</h2>
<p>束搜索为预测输出序列的一个算法，详细介绍可见：<a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_recurrent-modern/beam-search.html">束搜索</a>。</p>
</div>
        </div>
        
        <footer class="kratos-entry-footer clearfix">
            
                <div class="post-like-donate text-center clearfix" id="post-like-donate">
                
                
                    <a class="share" href="javascript:;"><i class="fa fa-share-alt"></i> Share</a>
                    <div class="share-wrap" style="display: none;">
    <div class="share-group">
        <a href="javascript:;" class="share-plain qq" onclick="share('qq');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-qq"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain qzone" onclick="share('qzone');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-star"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain weixin pop style-plain" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-weixin"></i>
            </div>
            <div class="share-int">
                <div class="qrcode" id="wechat-qr"></div>
                <p>打开微信“扫一扫”，打开网页后点击屏幕右上角分享按钮</p>
            </div>
        </a>
        <a href="javascript:;" class="share-plain weibo" onclick="share('weibo');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-weibo"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain facebook style-plain" onclick="share('facebook');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-facebook"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain twitter style-plain" onclick="share('twitter');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-twitter"></i>
            </div>
        </a>
    </div>
    <script type="text/javascript">
        $(()=>{
            new QRCode("wechat-qr", {
                text: "https://asanosaki.github.io/posts/7592.html",
                width: 150,
                height: 150,
                correctLevel : QRCode.CorrectLevel.H
            });
        });
        function share(dest) {
            const qqBase        = "https://connect.qq.com/widget/shareqq/index.html?";
            const weiboBase     = "https://service.weibo.com/share/share.php?";
            const qzoneBase     = "https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?";
            const facebookBase  = "https://www.facebook.com/sharer/sharer.php?";
            const twitterBase   = "https://twitter.com/intent/tweet?";
            const hostUrl       = "https://asanosaki.github.io/posts/7592.html";
            const title         = "「动手学深度学习笔记(李沐)-现代循环神经网络」";
            const excerpt       = `李沐动手学深度学习（PyTorch）课程学习笔记第九章：现代循环神经网络。`;
            let _URL;
            switch (dest) {
                case "qq"       : _URL = qqBase+"url="+hostUrl+"&title="+title+"&desc=&summary="+excerpt+"&site=cxpy";     break;
                case "weibo"    : _URL = weiboBase+"url="+hostUrl+"&title="+title+excerpt;                                 break;
                case "qzone"    : _URL = qzoneBase+"url="+hostUrl+"&title="+title+"&desc=&summary="+excerpt+"&site=cxpy";  break;
                case "facebook" : _URL = facebookBase+"u="+hostUrl;                                                        break;
                case "twitter"  : _URL = twitterBase+"text="+title+excerpt+"&url="+hostUrl;                                break;
            }
            window.open(_URL);
        };
    </script>
</div>
                
                </div>
            
            <div class="footer-tag clearfix">
                <div class="pull-left">
                <i class="fa fa-tags"></i>
                    <a class="tag-none-link" href="/tags/AI/" rel="tag">AI</a>
                </div>
                <div class="pull-date">
                    <time datetime="2023-05-21T09:56:38.075Z" itemprop="dateModified">Last edited: 2023-05-21</time>
                </div>
            </div>
        </footer>
    </div>
    
        <nav class="navigation post-navigation clearfix" role="navigation">
            
            <div class="nav-previous clearfix">
                <a title=" 动手学深度学习笔记(李沐)-循环神经网络" href="/posts/11559.html">&lt; Previous</a>
            </div>
            
            
            <div class="nav-next clearfix">
                <a title=" 动手学深度学习笔记(李沐)-注意力机制" href="/posts/39408.html">Next &gt;</a>
            </div>
            
        </nav>
    
    
</article>

        

            </section>

        

                
            

<section id="kratos-widget-area" class="col-md-4 hidden-xs hidden-sm">
    <!-- 文章和页面根据splitter来分割，没有的话就从头开始设置为sticky -->
    
    
                <aside id="krw-about" class="widget widget-kratos-about clearfix">
    <div class="photo-background"></div>
    <div class="photo-wrapper clearfix">
        <div class="photo-wrapper-tip text-center">
            <img class="about-photo" src="/images/head.webp" loading="lazy" decoding="auto" />
        </div>
    </div>
    <div class="textwidget">
        <p class="text-center"></p>
    </div>
    <div class="site-meta">
        <a class="meta-item" href="/archives/">
            <span class="title">
                Articles
            </span>
            <span class="count">
                60
            </span>
        </a>
        <a class="meta-item" href="/categories/">
            <span class="title">
                Classifications
            </span>
            <span class="count">
                10
            </span>
        </a>
        <a class="meta-item" href="/tags/">
            <span class="title">
                Tags
            </span>
            <span class="count">
                10
            </span>
        </a>
    </div>
</aside>
            
                    <div class="sticky-area">
                
                    <aside id="krw-toc" class="widget widget-kratos-toc clearfix toc-div-class" >
    <div class="photo-background"></div>
    <h4 class="widget-title no-after">
        <i class="fa fa-compass"></i>
        Contents
        <span class="toc-progress-bar" role="progressbar" aria-label="阅读进度："></span>
    </h4>
    <div class="textwidget">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E9%97%A8%E6%8E%A7%E5%BE%AA%E7%8E%AF%E5%8D%95%E5%85%83%EF%BC%88GRU%EF%BC%89"><span class="toc-text">1. 门控循环单元（GRU）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E9%97%A8%E6%8E%A7%E5%BE%AA%E7%8E%AF%E5%8D%95%E5%85%83%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0"><span class="toc-text">1.1 门控循环单元的从零开始实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E9%97%A8%E6%8E%A7%E5%BE%AA%E7%8E%AF%E5%8D%95%E5%85%83%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"><span class="toc-text">1.2 门控循环单元的简洁实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%EF%BC%88LSTM%EF%BC%89"><span class="toc-text">2. 长短期记忆网络（LSTM）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0"><span class="toc-text">2.1 长短期记忆网络的从零开始实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"><span class="toc-text">2.2 长短期记忆网络的简洁实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%B7%B1%E5%BA%A6%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">3. 深度循环神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%8F%8C%E5%90%91%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">4. 双向循环神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">5. 机器翻译与数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E7%BC%96%E7%A0%81%E5%99%A8-%E8%A7%A3%E7%A0%81%E5%99%A8%E6%9E%B6%E6%9E%84"><span class="toc-text">6. 编码器-解码器架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E5%BA%8F%E5%88%97%E5%88%B0%E5%BA%8F%E5%88%97%E5%AD%A6%E4%B9%A0%EF%BC%88seq2seq%EF%BC%89"><span class="toc-text">7. 序列到序列学习（seq2seq）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E6%9D%9F%E6%90%9C%E7%B4%A2"><span class="toc-text">8. 束搜索</span></a></li></ol>
    </div>
</aside>
                
                
  <aside id="krw-categories" class="widget widget-kratos-categories clearfix">
    <h4 class="widget-title"><i class="fa fa-folder"></i>Contents</h4>
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AI/">AI</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Essay/">Essay</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network/">Network</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Others/">Others</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web/">Web</a><span class="category-list-count">7</span></li></ul>
  </aside>


            
                
  <aside id="krw-tags" class="widget widget-kratos-tags clearfix">
    <h4 class="widget-title"><i class="fa fa-tags"></i>Tags aggregation</h4>
      <div class="tag-clouds">
        <a href="/tags/AI/" style="font-size: 0.77em;">AI</a> <a href="/tags/C/" style="font-size: 0.6em;">C++</a> <a href="/tags/Essay/" style="font-size: 0.6em;">Essay</a> <a href="/tags/Hexo/" style="font-size: 0.63em;">Hexo</a> <a href="/tags/Linux/" style="font-size: 0.67em;">Linux</a> <a href="/tags/MySQL/" style="font-size: 0.6em;">MySQL</a> <a href="/tags/Network/" style="font-size: 0.6em;">Network</a> <a href="/tags/Others/" style="font-size: 0.7em;">Others</a> <a href="/tags/Python/" style="font-size: 0.8em;">Python</a> <a href="/tags/Web/" style="font-size: 0.73em;">Web</a>
      </div>
  </aside>

            
                
  <aside id="krw-posts" class="widget widget-kratos-posts">
  <h4 class="widget-title"><i class="fa fa-file"></i>Latest articles</h4>
  <div class="tab-content">
      <ul class="list-group">
        
        
          
          
            <a class="list-group-item" href="/posts/45720.html"><i class="fa  fa-book"></i> Django Channels、WS协议及同步与异步详解</a>
            
          
        
          
          
            <a class="list-group-item" href="/posts/60606.html"><i class="fa  fa-book"></i> Django使用SMTP发送邮件教程</a>
            
          
        
          
          
            <a class="list-group-item" href="/posts/54938.html"><i class="fa  fa-book"></i> Django学习笔记-实现聊天系统</a>
            
          
        
          
          
            <a class="list-group-item" href="/posts/65222.html"><i class="fa  fa-book"></i> Django、Nginx、uWSGI详解及配置示例</a>
            
          
        
          
          
            <a class="list-group-item" href="/posts/60167.html"><i class="fa  fa-book"></i> Django学习笔记-实现联机对战(下)</a>
            
          
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
      </ul>
  </div>
  </aside>

            
    </div>
</section>
        
        </div>
    </div>
</div>
<footer>
    <div id="footer"  class="ap-lrc"  >
        <div class="container">
            <div class="row">
                <div class="col-md-6 col-md-offset-3 footer-list text-center">
                    <ul class="kratos-social-icons">
                        <li><a target="_blank" rel="nofollow" href="https://weibo.com/u/1952449115"><i class="fa fa-weibo"></i></a></li>
                        <li><a href="mailto:mail@1195595343@qq.com"><i class="fa fa-envelope"></i></a></li>
                        
                        
                        
                        
                        
                        <li><a target="_blank" rel="nofollow" href="https://github.com/AsanoSaki"><i class="fa fa-github"></i></a></li>
                        
                    </ul>
                    <ul class="kratos-copyright">
                        <div>
                            <li>&copy; 2023 AsanoSaki Copyright.</li>
                            <li>This site is running<span id="span_dt">Loading...</span></li>
                        </div>
                        <div>
                            <li>Theme <a href="https://github.com/Candinya/Kratos-Rebirth" target="_blank">Kratos:Rebirth</a></li>
                            <li>Site built with&nbsp;<i class="fa fa-heart throb" style="color:#d43f57"></i>&nbsp;by AsanoSaki.</li>
                        </div>
                        <div>
                            <li>Powered by <a href="https://hexo.io" target="_blank" rel="nofollow">Hexo</a></li>
                            <li>Hosted on <a href="https://github.com/" target="_blank">Github Pages</a></li>
                        </div>
                        <div>
                            
                            
                        </div>
                    </ul>
                </div>
            </div>
        </div>
        <div class="kr-tool text-center">
            <div class="tool">
                
                    <div class="box search-box">
                        <a href="/search/">
                            <span class="fa fa-search"></span>
                        </a>
                    </div>
                
                
                    <div class="box theme-box" id="darkmode-switch">
                        <span class="fa fa-adjust"></span>
                    </div>
                
                
            </div>
            <div class="box gotop-box">
                <span class="fa fa-chevron-up"></span>
            </div>
        </div>
    </div>
</footer>
</div>
</div>

        <script defer src="/vendors/bootstrap@3.3.4/dist/js/bootstrap.min.js"></script>
<script defer src="/vendors/nprogress@0.2.0/nprogress.js"></script>
<script>
    if (!window.kr) {
        window.kr = {};
    }
    window.kr.notMobile = (!(navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i)));
    window.kr.siteRoot = "/";
</script>


    <script async src="/js/candy.min.js"></script>



    <script defer src="/vendors/aplayer@1.10.1/dist/APlayer.min.js"></script>
    


    <script defer src="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

<script defer src="/vendors/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script defer src="/js/kratosr.min.js"></script>
<script defer src="/js/pjax.min.js"></script>



<!-- Extra support for third-party plguins  -->


    </body>
</html>
<!DOCTYPE html>
<html lang="zh-CN">
    <head>
  <!-- 元数据 -->
  <meta charset="utf-8">
  <link rel="icon" href="/images/favicon.ico">
  
  <title>D2L学习笔记-PyTorch神经网络基础 | AsanoSaki</title>
  <meta name="author" content="AsanoSaki" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="robots" content="index,follow" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <meta name="format-detection" content="telphone=no, email=no" />
  
    <meta name="keywords" content="AI" />
  
  <meta name="description" content="D2L学习笔记-PyTorch神经网络基础">
<meta property="og:type" content="article">
<meta property="og:title" content="D2L学习笔记-PyTorch神经网络基础">
<meta property="og:url" content="https://asanosaki.github.io/posts/23526.html">
<meta property="og:site_name" content="AsanoSaki">
<meta property="og:description" content="D2L学习笔记-PyTorch神经网络基础">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://asanosaki.github.io/images/favicon.ico">
<meta property="article:published_time" content="2023-02-28T02:34:00.000Z">
<meta property="article:modified_time" content="2023-11-19T08:08:49.610Z">
<meta property="article:author" content="AsanoSaki">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://asanosaki.github.io/images/favicon.ico">
  
  <!-- 站点验证相关 -->
  
    
    
    
  
  <!-- 样式表文件 -->
  <link rel="stylesheet" id="kratos-css" href="/css/kratosr.min.css" media="all"></script>
  
    <link rel="stylesheet" id="darkmode-css" href="/css/kr-color-dark.min.css" media="(prefers-color-scheme: dark)"></script>
    <script src="/js/kr-dark.min.js"></script>
  
  
    <link rel="stylesheet" id="highlight-css" href="/css/highlight/light.min.css" media="all"></script>
  
  
  <link rel="stylesheet" id="fontawe-css" href="/vendors/font-awesome@4.7.0/css/font-awesome.min.css" media="all"></script>
  <link rel="stylesheet" id="nprogress-css" href="/vendors/nprogress@0.2.0/nprogress.css" media="all"></script>
  
  
    <link rel="stylesheet" href="/vendors/aplayer@1.10.1/dist/APlayer.min.css"></script>
  
  
    <link rel="stylesheet" href="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"></script>
  
  <!-- 不得不预先加载的一些JS文件 -->
  <script src="/vendors/jquery@3.6.0/dist/jquery.min.js"></script>
  
    <script src="/vendors/qrcode_js@1.0.0/qrcode.min.js"></script>
  
  
  <style>
    
      .kratos-cover.kratos-cover-2 {
        background-image: url('https://z4a.net/images/2023/02/23/background03.jpg');
      }
    
    
      @media(min-width:768px) {
        body.custom-background {
          background-image: url('https://z4a.net/images/2023/02/23/background02.jpg');
        }
      }
    
  </style>
  
<meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="AsanoSaki" type="application/atom+xml">
</head>


    <body class="custom-background">
        <div id="kratos-wrapper">
    <div id="kratos-page">
        <div id="kratos-header">
            <header id="kratos-desktop-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="nav-header">
                        <nav id="kratos-menu-wrap">
                            <ul id="kratos-primary-menu" class="sf-menu">
                                
                                    
                                        <li>
                                            
                                                <a href="/">
                                            
                                                
                                                    <i class="fa fa-home"></i>
                                                
                                                Home
                                            </a>
                                            
                                        </li>
                                    
                                        <li>
                                            
                                                <a href="/archives/">
                                            
                                                
                                                    <i class="fa fa-file"></i>
                                                
                                                Archives
                                            </a>
                                            
                                        </li>
                                    
                                        <li>
                                            
                                                <a>
                                            
                                                
                                                    <i class="fa fa-paw"></i>
                                                
                                                Friends
                                            </a>
                                            
                                                <ul class="sub-menu">
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://angels-d.github.io">
                                                                
                                                                Angels-D
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="http://syh521.cn">
                                                                
                                                                SYH
                                                            </a>
                                                        </li>
                                                    
                                                </ul>
                                            
                                        </li>
                                    
                                        <li>
                                            
                                                <a>
                                            
                                                
                                                    <i class="fa fa-link"></i>
                                                
                                                Links
                                            </a>
                                            
                                                <ul class="sub-menu">
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://github.com/AsanoSaki">
                                                                
                                                                GitHub
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://gitee.com/asanosaki">
                                                                
                                                                Gitee
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://git.acwing.com/AsanoSaki">
                                                                
                                                                AcGit
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a href="https://asanosaki.github.io">
                                                                
                                                                BLOG
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://asanosaki.blog.csdn.net">
                                                                
                                                                CSDN
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.acwing.com/user/myspace/index/82581">
                                                                
                                                                AcWing
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.luogu.com.cn/user/459347">
                                                                
                                                                LuoGu
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://codeforces.com/profile/AsanoSaki">
                                                                
                                                                CodeForces
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://leetcode.cn/u/asanosaki">
                                                                
                                                                LeetCode
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://space.bilibili.com/12300056">
                                                                
                                                                Bilibili
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.youtube.com/@AsanoSaki0417">
                                                                
                                                                YouTube
                                                            </a>
                                                        </li>
                                                    
                                                </ul>
                                            
                                        </li>
                                    
                                        <li>
                                            
                                                <a>
                                            
                                                
                                                    <i class="fa fa-heart"></i>
                                                
                                                Favorite
                                            </a>
                                            
                                                <ul class="sub-menu">
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.cnki.net">
                                                                
                                                                CNKI
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.runoob.com">
                                                                
                                                                Runoob
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://wallhaven.cc">
                                                                
                                                                Wallhaven
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="http://www.flysheep6.com">
                                                                
                                                                Flysheep
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://thrift.apache.org">
                                                                
                                                                Thrift
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://developer.mozilla.org/zh-CN">
                                                                
                                                                MDN
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://v5.bootcss.com">
                                                                
                                                                Bootstrap
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://zh-hans.react.dev">
                                                                
                                                                React
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.nextjs.cn">
                                                                
                                                                Next.js
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://docs.djangoproject.com/zh-hans/4.2">
                                                                
                                                                Django
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle">
                                                                
                                                                SpringBoot
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://hub.docker.com">
                                                                
                                                                DockerHub
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://fontawesome.com.cn">
                                                                
                                                                FontAwesome
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://www.online-convert.com">
                                                                
                                                                File-Convert
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://pytorch.org">
                                                                
                                                                PyTorch
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai">
                                                                
                                                                D2L
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://board.xcpcio.com">
                                                                
                                                                XCPC-Board
                                                            </a>
                                                        </li>
                                                    
                                                        <li>
                                                            <a target="_blank" rel="noopener" href="https://kr-demo.candinya.com/posts/Kratos-Rebirth-Manual">
                                                                
                                                                Kratos-MNL
                                                            </a>
                                                        </li>
                                                    
                                                </ul>
                                            
                                        </li>
                                    
                                
                            </ul>
                        </nav>
                    </div>
                </div>
            </header>
            <header id="kratos-mobile-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="color-logo"><a href="/">AsanoSaki</a></div>
                    <div class="nav-toggle">
                        <a class="kratos-nav-toggle js-kratos-nav-toggle">
                            <i></i>
                        </a>
                    </div>
                </div>
            </header>
        </div>
        <div class="kratos-start kratos-hero-2">
            <!-- <div class="kratos-overlay"></div> -->
            <div class="kratos-cover kratos-cover-2 text-center">
                <div class="desc desc2 animate-box">
                    <a href="/">
                        <h2>AsanoSaki</h2> <br />
                        <span>In summer, the sea breeze tastes like ice cream.</span>
                    </a>
                </div>
            </div>
        </div>

        <div id="kratos-blog-post">
            <div class="container">
                <div id="main" class="row">
                    

        

            <section class="col-md-8">

        

            <article itemscope itemtype="https://schema.org/Article">
    
    <link itemprop="mainEntityOfPage" href="https://asanosaki.github.io/posts/23526.html">
    <div class="kratos-hentry kratos-post-inner clearfix">
        <header class="kratos-entry-header">
            
                <h1 class="kratos-entry-title text-center" itemprop="name headline">D2L学习笔记-PyTorch神经网络基础</h1>
            
            
            <ul class="kratos-post-meta text-center">
                <li><time datetime="2023-02-28T02:34:00.000Z" itemprop="datePublished"><i class="fa fa-calendar"></i> 2023-02-28</time></li>
                <li itemprop="author" itemscope itemtype="https://schema.org/Person">
                    <i class="fa fa-user"></i> Author <span itemprop="name">AsanoSaki</span>
                </li>
                <li>
                    <i class="fa fa-edit"></i> 
                    
                    
                        ~10.97K
                    
                    words
                </li>
                
            </ul>
        </header>
        <div class="kratos-post-content">
            
            <div id="expire-alert" class="alert alert-warning hidden" role="alert">
                <div class="icon"><i class="fa fa-warning"></i></div>
                <div class="text"><p>本文最后编辑于 <time datetime="1700381329610"></time> 前，其中的内容可能需要更新。</p></div>
            </div>
            
            
            
                <div class="kratos-post-inner-toc toc-div-class" >
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">1. 层和块</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">2. 参数管理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">3. 自定义层</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">4. 读写文件</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">5. GPU</span></a></li></ol>
                </div>
            
            <hr />
            <div itemprop="articleBody"><blockquote>
<p>李沐动手学深度学习（PyTorch）课程学习笔记第四章：PyTorch 神经网络基础。</p>
</blockquote>
<span id="more"></span>
<h1>1. 层和块</h1>
<p>在构造自定义块之前，我们先回顾一下多层感知机（第三章第二节）的代码，下面的代码生成一个网络，其中包含一个具有256个单元和 ReLU 激活函数的全连接隐藏层，然后是一个具有10个隐藏单元且不带激活函数的全连接输出层：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">20</span>, <span class="number">256</span>), nn.ReLU(), nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">X = torch.rand(<span class="number">2</span>, <span class="number">20</span>)</span><br><span class="line"><span class="built_in">print</span>(net(X).shape)  <span class="comment"># torch.Size([2, 10])</span></span><br></pre></td></tr></table></figure>
<p>在这个例子中，我们通过实例化 <code>nn.Sequential</code> 来构建我们的模型，层的执行顺序是作为参数传递的。简而言之，<code>nn.Sequential</code> 定义了一种特殊的 <code>Module</code>，即在 PyTorch 中表示一个块的类，它维护了一个由 <code>Module</code> 组成的<strong>有序列表</strong>。注意，两个全连接层都是 <code>Linear</code> 类的实例，<code>Linear</code> 类本身就是 <code>Module</code> 的子类。另外，到目前为止，我们一直在通过 <code>net(X)</code> 调用我们的模型来获得模型的输出。这实际上是 <code>net.__call__(X)</code> 的简写。这个前向传播函数非常简单：它将列表中的每个块连接在一起，将每个块的输出作为下一个块的输入。</p>
<p>在下面的代码片段中，我们从零开始编写一个块。它包含一个多层感知机，其具有256个隐藏单元的隐藏层和一个10维输出层。注意，下面的 <code>MLP</code> 类继承了表示块的类。我们的实现只需要提供我们自己的构造函数（Python 中的 <code>__init__</code> 函数）和前向传播函数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="comment"># 模型参数声明层。这里，我们声明两个全连接的层</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 调用MLP的父类Module的构造函数来执行必要的初始化。</span></span><br><span class="line">        <span class="comment"># 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">20</span>, <span class="number">256</span>)  <span class="comment"># 隐藏层</span></span><br><span class="line">        self.out = nn.Linear(<span class="number">256</span>, <span class="number">10</span>)  <span class="comment"># 输出层</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义模型的前向传播，即如何根据输入X返回所需的模型输出</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义</span></span><br><span class="line">        <span class="keyword">return</span> self.out(F.relu(self.hidden(X)))</span><br></pre></td></tr></table></figure>
<p>接着我们实例化多层感知机的层，然后在每次调用前向传播函数时调用这些层：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = MLP()</span><br><span class="line"><span class="built_in">print</span>(net(X).shape)  <span class="comment"># torch.Size([2, 10])</span></span><br></pre></td></tr></table></figure>
<p>现在我们可以更仔细地看看 <code>Sequential</code> 类是如何工作的，回想一下 <code>Sequential</code> 的设计是为了把其他模块串起来。为了构建我们自己的简化的 <code>MySequential</code>，我们只需要定义两个关键函数：</p>
<ul>
<li>一种将块逐个追加到列表中的函数；</li>
<li>一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”。</li>
</ul>
<p>下面的 <code>MySequential</code> 类提供了与默认 <code>Sequential</code> 类相同的功能：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MySequential</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, *args</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">for</span> idx, module <span class="keyword">in</span> <span class="built_in">enumerate</span>(args):</span><br><span class="line">            <span class="comment"># 这里，module是Module子类的一个实例，我们把它保存在&#x27;Module&#x27;类的成员</span></span><br><span class="line">            <span class="comment"># 变量_modules中，_module的类型是OrderedDict</span></span><br><span class="line">            self._modules[<span class="built_in">str</span>(idx)] = module</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># OrderedDict保证了按照成员添加的顺序遍历它们</span></span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> self._modules.values():</span><br><span class="line">            X = block(X)</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">net = MySequential(nn.Linear(<span class="number">20</span>, <span class="number">256</span>), nn.ReLU(), nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line"><span class="built_in">print</span>(net(X).shape)  <span class="comment"># torch.Size([2, 10])</span></span><br></pre></td></tr></table></figure>
<p><code>Sequential</code> 类使模型构造变得简单，允许我们组合新的架构，而不必定义自己的类。然而，并不是所有的架构都是简单的顺序架构。当需要更强的灵活性时，我们需要定义自己的块。例如，我们可能希望在前向传播函数中执行 Python 的控制流。此外，我们可能希望执行任意的数学运算，而不是简单地依赖预定义的神经网络层：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FixedHiddenMLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 不计算梯度的随机权重参数，因此其在训练期间保持不变</span></span><br><span class="line">        self.rand_weight = torch.rand((<span class="number">20</span>, <span class="number">20</span>), requires_grad=<span class="literal">False</span>)</span><br><span class="line">        self.linear = nn.Linear(<span class="number">20</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        X = self.linear(X)</span><br><span class="line">        <span class="comment"># 使用创建的常量参数以及relu和mm函数</span></span><br><span class="line">        X = F.relu(torch.mm(X, self.rand_weight) + <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 复用全连接层，这相当于两个全连接层共享参数</span></span><br><span class="line">        X = self.linear(X)</span><br><span class="line">        <span class="comment"># 控制流</span></span><br><span class="line">        <span class="keyword">while</span> X.<span class="built_in">abs</span>().<span class="built_in">sum</span>() &gt; <span class="number">1</span>:</span><br><span class="line">            X /= <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> X.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<p>我们可以混合搭配各种组合块的方法。在下面的例子中，我们以一些想到的方法嵌套块：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NestMLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(nn.Linear(<span class="number">20</span>, <span class="number">64</span>), nn.ReLU(), nn.Linear(<span class="number">64</span>, <span class="number">32</span>), nn.ReLU())</span><br><span class="line">        self.linear = nn.Linear(<span class="number">32</span>, <span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> self.linear(self.net(X))</span><br><span class="line"></span><br><span class="line">chimera = nn.Sequential(NestMLP(), nn.Linear(<span class="number">16</span>, <span class="number">20</span>), FixedHiddenMLP())</span><br><span class="line"><span class="built_in">print</span>(chimera(X))  <span class="comment"># tensor(-0.2911, grad_fn=&lt;SumBackward0&gt;)</span></span><br></pre></td></tr></table></figure>
<h1>2. 参数管理</h1>
<p>我们首先看一下具有单隐藏层的多层感知机：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">4</span>, <span class="number">8</span>), nn.ReLU(), nn.Linear(<span class="number">8</span>, <span class="number">1</span>))</span><br><span class="line">X = torch.rand(size=(<span class="number">2</span>, <span class="number">4</span>))</span><br><span class="line"><span class="built_in">print</span>(net(X).shape)  <span class="comment"># torch.Size([2, 1])</span></span><br></pre></td></tr></table></figure>
<p>我们从已有模型中访问参数。当通过 <code>Sequential</code> 类定义模型时，我们可以通过索引来访问模型的任意层。这就像模型是一个列表一样，每层的参数都在其属性中。如下所示，我们可以检查第二个全连接层的参数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].state_dict())</span><br><span class="line"><span class="comment"># OrderedDict([(&#x27;weight&#x27;, tensor([[-0.1326,  0.1692, -0.0925, -0.1721,  0.0828, -0.0890, -0.0742, -0.2730]])), (&#x27;bias&#x27;, tensor([0.2011]))])</span></span><br></pre></td></tr></table></figure>
<p>这个全连接层包含两个参数，分别是该层的权重和偏置，每个参数都表示为参数类的一个实例。要对参数执行任何操作，首先我们需要访问底层的数值：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(net[<span class="number">2</span>].bias))  <span class="comment"># &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].bias)  <span class="comment"># Parameter containing: tensor([-0.2786], requires_grad=True)</span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].bias.data)  <span class="comment"># tensor([-0.1571])</span></span><br></pre></td></tr></table></figure>
<p>参数是复合的对象，包含值、梯度和额外信息。这就是我们需要显式参数值的原因。除了值之外，我们还可以访问每个参数的梯度。在上面这个网络中，由于我们还没有调用反向传播，所以参数的梯度处于初始状态：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].weight.grad == <span class="literal">None</span>)  <span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<p>当我们需要对所有参数执行操作时，逐个访问它们可能会很麻烦。下面，我们将通过演示来比较访问第一个全连接层的参数和访问所有层：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(*[(name, param.shape) <span class="keyword">for</span> name, param <span class="keyword">in</span> net[<span class="number">0</span>].named_parameters()])</span><br><span class="line"><span class="comment"># (&#x27;weight&#x27;, torch.Size([8, 4])) (&#x27;bias&#x27;, torch.Size([8]))</span></span><br><span class="line"><span class="built_in">print</span>(*[(name, param.shape) <span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters()])</span><br><span class="line"><span class="comment"># (&#x27;0.weight&#x27;, torch.Size([8, 4])) (&#x27;0.bias&#x27;, torch.Size([8])) (&#x27;2.weight&#x27;, torch.Size([1, 8])) (&#x27;2.bias&#x27;, torch.Size([1]))</span></span><br></pre></td></tr></table></figure>
<p>这为我们提供了另一种访问网络参数的方式，如下所示：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(net.state_dict()[<span class="string">&#x27;2.bias&#x27;</span>].data)  <span class="comment"># tensor([0.0992])</span></span><br></pre></td></tr></table></figure>
<p>现在让我们看看如果我们将多个块相互嵌套，参数命名约定是如何工作的：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">block1</span>():</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(nn.Linear(<span class="number">4</span>, <span class="number">8</span>), nn.ReLU(), nn.Linear(<span class="number">8</span>, <span class="number">4</span>), nn.ReLU())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">block2</span>():</span><br><span class="line">    net = nn.Sequential()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        <span class="comment"># 在这里嵌套</span></span><br><span class="line">        net.add_module(<span class="string">f&#x27;block <span class="subst">&#123;i&#125;</span>&#x27;</span>, block1())</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line">rgnet = nn.Sequential(block2(), nn.Linear(<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(rgnet)</span><br><span class="line"><span class="comment"># Sequential(</span></span><br><span class="line"><span class="comment">#   (0): Sequential(</span></span><br><span class="line"><span class="comment">#     (block 0): Sequential(</span></span><br><span class="line"><span class="comment">#       (0): Linear(in_features=4, out_features=8, bias=True)</span></span><br><span class="line"><span class="comment">#       (1): ReLU()</span></span><br><span class="line"><span class="comment">#       ...</span></span><br></pre></td></tr></table></figure>
<p>因为层是分层嵌套的，所以我们也可以像通过嵌套列表索引一样访问它们：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(rgnet[<span class="number">0</span>][<span class="number">1</span>][<span class="number">0</span>].bias.data)  <span class="comment"># tensor([ 0.4102,  0.1565,  0.1458,  0.0826,  0.2460, -0.0115, -0.4241,  0.1192])</span></span><br></pre></td></tr></table></figure>
<p>知道了如何访问参数后，现在我们看看如何正确地初始化参数。深度学习框架提供默认随机初始化，也允许我们创建自定义初始化方法。</p>
<p>让我们首先调用内置的初始化器。下面的代码将所有权重参数初始化为标准差为0.01的高斯随机变量，且将偏置参数设置为0：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_normal</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">        nn.init.zeros_(m.bias)</span><br><span class="line"></span><br><span class="line">net.apply(init_normal)</span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">0</span>].weight.data[<span class="number">0</span>], net[<span class="number">0</span>].bias.data[<span class="number">0</span>])  <span class="comment"># tensor([0.0037, 0.0052, 0.0020, 0.0028]) tensor(0.)</span></span><br></pre></td></tr></table></figure>
<p>我们还可以将所有参数初始化为给定的常数，比如初始化为1：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.init.constant_(m.weight, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>我们还可以对某些块应用不同的初始化方法。例如，下面我们使用 Xavier 初始化方法初始化第一个神经网络层，然后将第三个神经网络层初始化为常量值42：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_xavier</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.xavier_uniform_(m.weight)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_42</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        nn.init.constant_(m.weight, <span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">net[<span class="number">0</span>].apply(init_xavier)</span><br><span class="line">net[<span class="number">2</span>].apply(init_42)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">0</span>].weight.data[<span class="number">0</span>])  <span class="comment"># tensor([-0.7014,  0.1061,  0.2061,  0.2125])</span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].weight.data)  <span class="comment"># tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])</span></span><br></pre></td></tr></table></figure>
<p>有时，深度学习框架没有提供我们需要的初始化方法。在下面的例子中，我们先初始化为-10~10的均匀分布，然后将绝对值小于5的参数置零：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_init</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Init&quot;</span>, *[(name, param.shape) <span class="keyword">for</span> name, param <span class="keyword">in</span> m.named_parameters()][<span class="number">0</span>])</span><br><span class="line">        nn.init.uniform_(m.weight, -<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">        m.weight.data *= m.weight.data.<span class="built_in">abs</span>() &gt;= <span class="number">5</span></span><br><span class="line"></span><br><span class="line">net.apply(my_init)</span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">0</span>].weight[:<span class="number">2</span>])</span><br><span class="line"><span class="comment"># tensor([[-0.0000,  8.9053,  0.0000,  8.9382],</span></span><br><span class="line"><span class="comment">#         [-9.5017, -0.0000,  5.4470, -0.0000]], grad_fn=&lt;SliceBackward0&gt;)</span></span><br></pre></td></tr></table></figure>
<p>有时我们希望在多个层间共享参数：我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">shared = nn.Linear(<span class="number">8</span>, <span class="number">8</span>)  <span class="comment"># 我们需要给共享层一个名称，以便可以引用它的参数</span></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">4</span>, <span class="number">8</span>), nn.ReLU(), shared, nn.ReLU(),</span><br><span class="line">                    shared, nn.ReLU(), nn.Linear(<span class="number">8</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 检查参数是否相同</span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].weight.data[<span class="number">0</span>] == net[<span class="number">4</span>].weight.data[<span class="number">0</span>])  <span class="comment"># tensor([True, True, True, True, True, True, True, True])</span></span><br><span class="line">net[<span class="number">2</span>].weight.data[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">100</span></span><br><span class="line"><span class="comment"># 确保它们实际上是同一个对象，而不只是有相同的值</span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">2</span>].weight.data[<span class="number">0</span>] == net[<span class="number">4</span>].weight.data[<span class="number">0</span>])  <span class="comment"># tensor([True, True, True, True, True, True, True, True])</span></span><br></pre></td></tr></table></figure>
<p>这个例子表明第三个和第五个神经网络层的参数是绑定的。它们不仅值相等，而且由相同的张量表示。因此，如果我们改变其中一个参数，另一个参数也会改变。这里有一个问题：当参数绑定时，梯度会发生什么情况？答案是由于模型参数包含梯度，因此在反向传播期间第二个隐藏层（即第三个神经网络层）和第三个隐藏层（即第五个神经网络层）的梯度会加在一起。</p>
<h1>3. 自定义层</h1>
<p>我们构造一个没有任何参数的自定义层，下面的 <code>CenteredLayer</code> 类要从其输入中减去均值。要构建它，我们只需继承基础层类并实现前向传播功能：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CenteredLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> X - X.mean()</span><br><span class="line"></span><br><span class="line">layer = CenteredLayer()</span><br><span class="line"><span class="built_in">print</span>(layer(torch.FloatTensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])))  <span class="comment"># tensor([-2., -1.,  0.,  1.,  2.])</span></span><br></pre></td></tr></table></figure>
<p>下面我们继续定义具有参数的层，这些参数可以通过训练进行调整。让我们实现自定义版本的全连接层。回想一下，该层需要两个参数，一个用于表示权重，另一个用于表示偏置项。在此实现中，我们使用 ReLU 作为激活函数。该层需要输入参数：<code>in_units</code> 和 <code>units</code>，分别表示输入数和输出数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyLinear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_units, units</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.randn(in_units, units))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(units,))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        linear = torch.matmul(X, self.weight.data) + self.bias.data</span><br><span class="line">        <span class="keyword">return</span> F.relu(linear)</span><br><span class="line"></span><br><span class="line">linear = MyLinear(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(linear.weight.shape)  <span class="comment"># torch.Size([5, 3])</span></span><br></pre></td></tr></table></figure>
<h1>4. 读写文件</h1>
<p>加载和保存张量：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">4</span>)</span><br><span class="line">torch.save(x, <span class="string">&#x27;../save/x-file&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>将存储在文件中的数据读回内存：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x2 = torch.load(<span class="string">&#x27;../save/x-file&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(x2)  <span class="comment"># tensor([0, 1, 2, 3])</span></span><br></pre></td></tr></table></figure>
<p>存储一个张量列表，然后把它们读回内存：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = torch.zeros(<span class="number">4</span>)</span><br><span class="line">torch.save([x, y],<span class="string">&#x27;../save/x-files&#x27;</span>)</span><br><span class="line">x2, y2 = torch.load(<span class="string">&#x27;../save/x-files&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>((x2, y2))  <span class="comment"># (tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))</span></span><br></pre></td></tr></table></figure>
<p>我们可以写入或读取从字符串映射到张量的字典。当我们要读取或写入模型中的所有权重时，这很方便：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mydict = &#123;<span class="string">&#x27;x&#x27;</span>: x, <span class="string">&#x27;y&#x27;</span>: y&#125;</span><br><span class="line">torch.save(mydict, <span class="string">&#x27;../save/mydict&#x27;</span>)</span><br><span class="line">mydict2 = torch.load(<span class="string">&#x27;../save/mydict&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(mydict2)  <span class="comment"># &#123;&#x27;x&#x27;: tensor([0, 1, 2, 3]), &#x27;y&#x27;: tensor([0., 0., 0., 0.])&#125;</span></span><br></pre></td></tr></table></figure>
<p>深度学习框架提供了内置函数来保存和加载整个网络。需要注意的一个重要细节是，这将<strong>保存模型的参数</strong>而不是保存整个模型：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">20</span>, <span class="number">256</span>)</span><br><span class="line">        self.output = nn.Linear(<span class="number">256</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.output(F.relu(self.hidden(x)))</span><br><span class="line"></span><br><span class="line">net = MLP()</span><br><span class="line">X = torch.randn(size=(<span class="number">2</span>, <span class="number">20</span>))</span><br><span class="line">Y = net(X)</span><br><span class="line"></span><br><span class="line">torch.save(net.state_dict(), <span class="string">&#x27;../save/mlp.params&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了恢复模型，我们实例化了原始多层感知机模型的一个备份。这里我们不需要随机初始化模型参数，而是直接读取文件中存储的参数</span></span><br><span class="line">clone = MLP()</span><br><span class="line">clone.load_state_dict(torch.load(<span class="string">&#x27;../save/mlp.params&#x27;</span>))</span><br><span class="line">clone.<span class="built_in">eval</span>()</span><br><span class="line">Y_clone = clone(X)</span><br><span class="line"><span class="built_in">print</span>(Y_clone == Y)</span><br><span class="line"><span class="comment"># tensor([[True, True, True, True, True, True, True, True, True, True],</span></span><br><span class="line"><span class="comment">#         [True, True, True, True, True, True, True, True, True, True]])</span></span><br></pre></td></tr></table></figure>
<h1>5. GPU</h1>
<p>CUDA 的安装配置教程：<a href="/posts/15428.html">Anaconda与PyTorch安装教程</a></p>
<p>在 PyTorch 中，CPU 和 GPU 可以用 <code>torch.device('cpu')</code> 和 <code>torch.device('cuda')</code> 表示：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(torch.device(<span class="string">&#x27;cpu&#x27;</span>), torch.device(<span class="string">&#x27;cuda&#x27;</span>), torch.device(<span class="string">&#x27;cuda:0&#x27;</span>))  <span class="comment"># cpu cuda cuda:0</span></span><br></pre></td></tr></table></figure>
<p>我们可以查询可用 GPU 的数量：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.cuda.device_count())  <span class="comment"># 1</span></span><br></pre></td></tr></table></figure>
<p>我们可以查询张量所在的设备。默认情况下，张量是在 CPU 上创建的：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(x.device)  <span class="comment"># cpu</span></span><br></pre></td></tr></table></figure>
<p>需要注意的是，无论何时我们要对多个项进行操作，它们都必须在同一个设备上。例如，如果我们对两个张量求和，我们需要确保两个张量都位于同一个设备上，否则框架将不知道在哪里存储结果，甚至不知道在哪里执行计算。</p>
<p>有几种方法可以在 GPU 上存储张量。例如，我们可以在创建张量时指定存储设备：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = torch.ones(<span class="number">2</span>, <span class="number">3</span>, device=<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(X.device)  <span class="comment"># cuda:0</span></span><br></pre></td></tr></table></figure>
<p>数据在同一个 GPU 上我们才可以将它们相加：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Y = X.cuda(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(Y.device)  <span class="comment"># cuda:0</span></span><br><span class="line"><span class="built_in">print</span>((X + Y).device)  <span class="comment"># cuda:0</span></span><br></pre></td></tr></table></figure>
<p>类似地，神经网络模型可以指定设备。下面的代码将模型参数放在 GPU 上：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(nn.Linear(<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">net = net.to(device=<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(net(X))  <span class="comment"># tensor([[-0.0370], [-0.0370]], device=&#x27;cuda:0&#x27;, grad_fn=&lt;AddmmBackward0&gt;)</span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">0</span>].weight.data.device)  <span class="comment"># cuda:0</span></span><br></pre></td></tr></table></figure>
<p>总之，只要所有的数据和参数都在同一个设备上，我们就可以有效地学习模型。</p>
<p>下一章：<a href="/posts/25122.html">卷积神经网络</a>。</p>
</div>
        </div>
        
        <footer class="kratos-entry-footer clearfix">
            
                <div class="post-like-donate text-center clearfix" id="post-like-donate">
                
                
                    <a class="share" href="javascript:;"><i class="fa fa-share-alt"></i> Share</a>
                    <div class="share-wrap" style="display: none;">
    <div class="share-group">
        <a href="javascript:;" class="share-plain qq" onclick="share('qq');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-qq"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain qzone" onclick="share('qzone');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-star"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain weixin pop style-plain" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-weixin"></i>
            </div>
            <div class="share-int">
                <div class="qrcode" id="wechat-qr"></div>
                <p>打开微信“扫一扫”，打开网页后点击屏幕右上角分享按钮</p>
            </div>
        </a>
        <a href="javascript:;" class="share-plain weibo" onclick="share('weibo');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-weibo"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain facebook style-plain" onclick="share('facebook');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-facebook"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain twitter style-plain" onclick="share('twitter');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-twitter"></i>
            </div>
        </a>
    </div>
    <script type="text/javascript">
        $(()=>{
            new QRCode("wechat-qr", {
                text: "https://asanosaki.github.io/posts/23526.html",
                width: 150,
                height: 150,
                correctLevel : QRCode.CorrectLevel.H
            });
        });
        function share(dest) {
            const qqBase        = "https://connect.qq.com/widget/shareqq/index.html?";
            const weiboBase     = "https://service.weibo.com/share/share.php?";
            const qzoneBase     = "https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?";
            const facebookBase  = "https://www.facebook.com/sharer/sharer.php?";
            const twitterBase   = "https://twitter.com/intent/tweet?";
            const hostUrl       = "https://asanosaki.github.io/posts/23526.html";
            const title         = "「D2L学习笔记-PyTorch神经网络基础」";
            const excerpt       = `李沐动手学深度学习（PyTorch）课程学习笔记第四章：PyTorch 神经网络基础。`;
            let _URL;
            switch (dest) {
                case "qq"       : _URL = qqBase+"url="+hostUrl+"&title="+title+"&desc=&summary="+excerpt+"&site=cxpy";     break;
                case "weibo"    : _URL = weiboBase+"url="+hostUrl+"&title="+title+excerpt;                                 break;
                case "qzone"    : _URL = qzoneBase+"url="+hostUrl+"&title="+title+"&desc=&summary="+excerpt+"&site=cxpy";  break;
                case "facebook" : _URL = facebookBase+"u="+hostUrl;                                                        break;
                case "twitter"  : _URL = twitterBase+"text="+title+excerpt+"&url="+hostUrl;                                break;
            }
            window.open(_URL);
        };
    </script>
</div>
                
                </div>
            
            <div class="footer-tag clearfix">
                <div class="pull-left">
                <i class="fa fa-tags"></i>
                    <a class="tag-none-link" href="/tags/AI/" rel="tag">AI</a>
                </div>
                <div class="pull-date">
                    <time datetime="2023-11-19T08:08:49.610Z" itemprop="dateModified">Last edited: 2023-11-19</time>
                </div>
            </div>
        </footer>
    </div>
    
        <nav class="navigation post-navigation clearfix" role="navigation">
            
            <div class="nav-previous clearfix">
                <a title=" D2L学习笔记-多层感知机" href="/posts/46068.html">&lt; Previous</a>
            </div>
            
            
            <div class="nav-next clearfix">
                <a title=" D2L学习笔记-卷积神经网络" href="/posts/25122.html">Next &gt;</a>
            </div>
            
        </nav>
    
    
</article>

        

            </section>

        

                
            

<section id="kratos-widget-area" class="col-md-4 hidden-xs hidden-sm">
    <!-- 文章和页面根据splitter来分割，没有的话就从头开始设置为sticky -->
    
    
                <aside id="krw-about" class="widget widget-kratos-about clearfix">
    <div class="photo-background"></div>
    <div class="photo-wrapper clearfix">
        <div class="photo-wrapper-tip text-center">
            <img class="about-photo" src="/images/head.webp" loading="lazy" decoding="auto" />
        </div>
    </div>
    <div class="textwidget">
        <p class="text-center"></p>
    </div>
    <div class="site-meta">
        <a class="meta-item" href="/archives/">
            <span class="title">
                Articles
            </span>
            <span class="count">
                75
            </span>
        </a>
        <a class="meta-item" href="/categories/">
            <span class="title">
                Classifications
            </span>
            <span class="count">
                11
            </span>
        </a>
        <a class="meta-item" href="/tags/">
            <span class="title">
                Tags
            </span>
            <span class="count">
                11
            </span>
        </a>
    </div>
</aside>
            
                    <div class="sticky-area">
                
                    <aside id="krw-toc" class="widget widget-kratos-toc clearfix toc-div-class" >
    <div class="photo-background"></div>
    <h4 class="widget-title no-after">
        <i class="fa fa-compass"></i>
        Contents
        <span class="toc-progress-bar" role="progressbar" aria-label="阅读进度："></span>
    </h4>
    <div class="textwidget">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">1. 层和块</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">2. 参数管理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">3. 自定义层</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">4. 读写文件</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">5. GPU</span></a></li></ol>
    </div>
</aside>
                
                
  <aside id="krw-categories" class="widget widget-kratos-categories clearfix">
    <h4 class="widget-title"><i class="fa fa-folder"></i>Contents</h4>
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AI/">AI</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Essay/">Essay</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network/">Network</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Others/">Others</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web/">Web</a><span class="category-list-count">9</span></li></ul>
  </aside>


            
                
  <aside id="krw-tags" class="widget widget-kratos-tags clearfix">
    <h4 class="widget-title"><i class="fa fa-tags"></i>Tags aggregation</h4>
      <div class="tag-clouds">
        <a href="/tags/AI/" style="font-size: 0.77em;">AI</a> <a href="/tags/C/" style="font-size: 0.6em;">C++</a> <a href="/tags/Essay/" style="font-size: 0.6em;">Essay</a> <a href="/tags/Hexo/" style="font-size: 0.63em;">Hexo</a> <a href="/tags/Java/" style="font-size: 0.74em;">Java</a> <a href="/tags/Linux/" style="font-size: 0.66em;">Linux</a> <a href="/tags/MySQL/" style="font-size: 0.6em;">MySQL</a> <a href="/tags/Network/" style="font-size: 0.6em;">Network</a> <a href="/tags/Others/" style="font-size: 0.69em;">Others</a> <a href="/tags/Python/" style="font-size: 0.8em;">Python</a> <a href="/tags/Web/" style="font-size: 0.71em;">Web</a>
      </div>
  </aside>

            
                
  <aside id="krw-posts" class="widget widget-kratos-posts">
  <h4 class="widget-title"><i class="fa fa-file"></i>Latest articles</h4>
  <div class="tab-content">
      <ul class="list-group">
        
        
          
          
            <a class="list-group-item" href="/posts/54295.html"><i class="fa  fa-book"></i> SpringBoot学习笔记-创建菜单与游戏页面（上）</a>
            
          
        
          
          
            <a class="list-group-item" href="/posts/34589.html"><i class="fa  fa-book"></i> SpringBoot学习笔记-项目初始化</a>
            
          
        
          
          
            <a class="list-group-item" href="/posts/55162.html"><i class="fa  fa-book"></i> Web学习笔记-Vue3（用户动态页面设计）</a>
            
          
        
          
          
            <a class="list-group-item" href="/posts/54619.html"><i class="fa  fa-book"></i> Web学习笔记-Vue3（环境配置、概念、整体布局设计）</a>
            
          
        
          
          
            <a class="list-group-item" href="/posts/62501.html"><i class="fa  fa-book"></i> Java字符串与输入输出详解</a>
            
          
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
      </ul>
  </div>
  </aside>

            
    </div>
</section>
        
        </div>
    </div>
</div>
<footer>
    <div id="footer"  class="ap-lrc"  >
        <div class="container">
            <div class="row">
                <div class="col-md-6 col-md-offset-3 footer-list text-center">
                    <ul class="kratos-social-icons">
                        <li><a target="_blank" rel="nofollow" href="https://weibo.com/u/1952449115"><i class="fa fa-weibo"></i></a></li>
                        <li><a href="mailto:mail@1195595343@qq.com"><i class="fa fa-envelope"></i></a></li>
                        
                        
                        
                        
                        
                        <li><a target="_blank" rel="nofollow" href="https://github.com/AsanoSaki"><i class="fa fa-github"></i></a></li>
                        
                    </ul>
                    <ul class="kratos-copyright">
                        <div>
                            <li>&copy; 2023 AsanoSaki Copyright.</li>
                            <li>This site is running<span id="span_dt">Loading...</span></li>
                        </div>
                        <div>
                            <li>Theme <a href="https://github.com/Candinya/Kratos-Rebirth" target="_blank">Kratos:Rebirth</a></li>
                            <li>Site built with&nbsp;<i class="fa fa-heart throb" style="color:#d43f57"></i>&nbsp;by AsanoSaki.</li>
                        </div>
                        <div>
                            <li>Powered by <a href="https://hexo.io" target="_blank" rel="nofollow">Hexo</a></li>
                            <li>Hosted on <a href="https://github.com/" target="_blank">Github Pages</a></li>
                        </div>
                        <div>
                            
                            
                        </div>
                    </ul>
                </div>
            </div>
        </div>
        <div class="kr-tool text-center">
            <div class="tool">
                
                    <div class="box search-box">
                        <a href="/search/">
                            <span class="fa fa-search"></span>
                        </a>
                    </div>
                
                
                    <div class="box theme-box" id="darkmode-switch">
                        <span class="fa fa-adjust"></span>
                    </div>
                
                
            </div>
            <div class="box gotop-box">
                <span class="fa fa-chevron-up"></span>
            </div>
        </div>
    </div>
</footer>
</div>
</div>

        <script defer src="/vendors/bootstrap@3.3.4/dist/js/bootstrap.min.js"></script>
<script defer src="/vendors/nprogress@0.2.0/nprogress.js"></script>
<script>
    if (!window.kr) {
        window.kr = {};
    }
    window.kr.notMobile = (!(navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i)));
    window.kr.siteRoot = "/";
</script>


    <script async src="/js/candy.min.js"></script>



    <script defer src="/vendors/aplayer@1.10.1/dist/APlayer.min.js"></script>
    


    <script defer src="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

<script defer src="/vendors/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script defer src="/js/kratosr.min.js"></script>
<script defer src="/js/pjax.min.js"></script>



<!-- Extra support for third-party plguins  -->


    </body>
</html>
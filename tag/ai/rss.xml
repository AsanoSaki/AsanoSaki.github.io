<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>AsanoSaki • Posts by &#34;ai&#34; tag</title>
        <link>https://asanosaki.github.io</link>
        <description></description>
        <language>zh-CN</language>
        <pubDate>Sat, 19 Aug 2023 15:49:00 +0800</pubDate>
        <lastBuildDate>Sat, 19 Aug 2023 15:49:00 +0800</lastBuildDate>
        <category>Others</category>
        <category>AI</category>
        <category>Hexo</category>
        <category>Linux</category>
        <category>Python</category>
        <category>MySQL</category>
        <category>Web</category>
        <category>Essay</category>
        <category>C++</category>
        <category>Network</category>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/21781.html</guid>
            <title>DeepLabV3Plus核心代码详解</title>
            <link>https://asanosaki.github.io/posts/21781.html</link>
            <category>AI</category>
            <pubDate>Sat, 19 Aug 2023 15:49:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;本文记录 DeepLabV3+ 论文（Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation）的阅读笔记。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-Atrous-Spatial-Pyramid-Pooling&#34;&gt;1. Atrous Spatial Pyramid Pooling&lt;/h2&gt;
&lt;p&gt;ASPP（Atrous Spatial Pyramid Pooling），空洞空间金字塔池化。简单理解就是个至尊版池化层，其目的与普通的池化层一致，尽可能地去提取特征。&lt;/p&gt;
&lt;p&gt;ASPP 本质上由一个 1×1 的卷积层、三个 3×3 的空洞卷积层 &lt;code&gt;ASPP Conv&lt;/code&gt; 以及一个全局池化层 &lt;code&gt;ASPP Pooling&lt;/code&gt;。五个模块输出的特征图尺寸都与输入相同，因此最后将它们在通道维度上 Concat 起来然后再通过一个 1×1 的卷积层降维得到 ASPP 的输出。&lt;/p&gt;
&lt;h3 id=&#34;1-1-ASPP-Conv&#34;&gt;1.1 ASPP Conv&lt;/h3&gt;
&lt;p&gt;空洞卷积层与一般卷积层之间的差别在于膨胀率（dilation rate），膨胀率控制的是卷积时的 &lt;code&gt;padding&lt;/code&gt; 以及 &lt;code&gt;dilation&lt;/code&gt;。ASPP 应用了多个不同膨胀率的&lt;strong&gt;并行&lt;/strong&gt;空洞卷积。通过不同的填充与膨胀，可以在不改变输出图像尺寸的情况下获取不同尺度的感受野，提取多尺度的信息。注意卷积核尺寸始终保持 3×3 不变：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;ASPPConv&lt;/span&gt;(nn.Sequential):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_channels, out_channels, dilation&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        modules = [&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels, out_channels, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=dilation, dilation=dilation, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(out_channels),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(ASPPConv, self).__init__(*modules)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;1-2-ASPP-Pooling&#34;&gt;1.2 ASPP Pooling&lt;/h3&gt;
&lt;p&gt;ASPP Pooling 首先是一个 &lt;code&gt;AdaptiveAvgPool2d&lt;/code&gt; 层。所谓自适应均值池化，其自适应的地方在于不需要指定 &lt;code&gt;kernel size&lt;/code&gt; 和 &lt;code&gt;stride&lt;/code&gt;，只需指定最后的输出尺寸（此处为 1×1）。通过将各通道的特征图尺寸分别压缩至 1×1，从而提取各通道的特征，进而获取全局的特征。然后是一个 1×1 的卷积层，对上一步获取的特征进行进一步的提取，并降维。需要注意的是，在 ASPP Pooling 的网络结构部分，只是对特征进行了提取；而在 &lt;code&gt;forward&lt;/code&gt; 方法中，除了顺序执行网络的各层外，最终还将特征图从 1×1 上采样回原来的尺寸：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;ASPPPooling&lt;/span&gt;(nn.Sequential):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_channels, out_channels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(ASPPPooling, self).__init__(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.AdaptiveAvgPool2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels, out_channels, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(out_channels),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        size = x.shape[-&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:]  &lt;span class=&#34;comment&#34;&gt;# 记录输入的尺寸&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(ASPPPooling, self).forward(x)  &lt;span class=&#34;comment&#34;&gt;# 图像尺寸变为(1, 1)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; F.interpolate(x, size=size, mode=&lt;span class=&#34;string&#34;&gt;&amp;#x27;bilinear&amp;#x27;&lt;/span&gt;, align_corners=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 上采样为输入的尺寸&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;1-3-ASPP&#34;&gt;1.3 ASPP&lt;/h3&gt;
&lt;p&gt;我们将以上模块进行组合即可构建完整的 ASPP 模块：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;ASPP&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_channels, atrous_rates&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(ASPP, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out_channels = &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        modules = []  &lt;span class=&#34;comment&#34;&gt;# 五个分支输出图像大小均与原图相同&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# (n, 2048, h, w) -&amp;gt; (n, 256, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        modules.append(nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels, out_channels, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(out_channels),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        rate1, rate2, rate3 = &lt;span class=&#34;built_in&#34;&gt;tuple&lt;/span&gt;(atrous_rates)  &lt;span class=&#34;comment&#34;&gt;# 膨胀率&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        modules.append(ASPPConv(in_channels, out_channels, rate1))  &lt;span class=&#34;comment&#34;&gt;# (n, 2048, h, w) -&amp;gt; (n, 256, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        modules.append(ASPPConv(in_channels, out_channels, rate2))  &lt;span class=&#34;comment&#34;&gt;# (n, 2048, h, w) -&amp;gt; (n, 256, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        modules.append(ASPPConv(in_channels, out_channels, rate3))  &lt;span class=&#34;comment&#34;&gt;# (n, 2048, h, w) -&amp;gt; (n, 256, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        modules.append(ASPPPooling(in_channels, out_channels))  &lt;span class=&#34;comment&#34;&gt;# (n, 2048, h, w) -&amp;gt; (n, 256, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.convs = nn.ModuleList(modules)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.project = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt; * out_channels, out_channels, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(out_channels),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Dropout(&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 假设ASPP的输入为ResNet101中layer4的输出，即x.shape: (n, 2048, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        res = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; conv &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self.convs:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            res.append(conv(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        res = torch.cat(res, dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# (n, 256*5, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.project(res)  &lt;span class=&#34;comment&#34;&gt;# (n, 256, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; __name__ == &lt;span class=&#34;string&#34;&gt;&amp;#x27;__main__&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    aspp = ASPP(in_channels=&lt;span class=&#34;number&#34;&gt;2048&lt;/span&gt;, atrous_rates=[&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;12&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;18&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x = torch.randn(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2048&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;18&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(aspp(x).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([8, 256, 18, 32])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-空洞卷积ResNet&#34;&gt;2. 空洞卷积ResNet&lt;/h2&gt;
&lt;p&gt;本文以 ResNet50、101、152 为例，构建加入了空洞卷积的 ResNet 网络。ResNet 网络一共有四大层，我们记为 layer1、layer2、layer3 以及 layer4，默认情况下输出的 Feature Map 宽高尺寸比原图像小32倍，我们可以在第2~4层使用空洞卷积，假设在最后一层使用了空洞卷积，那么最后输出的 Feature Map 宽高尺寸比原图像小16倍：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;114&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;115&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;116&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;117&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;118&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;119&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;120&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;121&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;122&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;123&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;124&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;125&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;126&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;127&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;128&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;129&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;130&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;131&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;132&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;133&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;134&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;135&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;136&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;137&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;138&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;139&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;140&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;141&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;142&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;143&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;144&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;145&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;146&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;147&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;148&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;149&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;150&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;151&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;152&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;153&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;154&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;155&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;156&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;157&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;158&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;159&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;160&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;161&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;162&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;163&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;164&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;165&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;166&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.hub &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; load_state_dict_from_url&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model_urls = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;#x27;resnet50&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;https://download.pytorch.org/models/resnet50-19c8e357.pth&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;#x27;resnet101&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;https://download.pytorch.org/models/resnet101-5d3b4d8f.pth&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;#x27;resnet152&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;https://download.pytorch.org/models/resnet152-b121ed2d.pth&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;conv3x3&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;in_planes, out_planes, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, groups=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, dilation=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Conv2d(in_planes, out_planes, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=stride,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                     padding=dilation, groups=groups, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, dilation=dilation)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;conv1x1&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;in_planes, out_planes, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Conv2d(in_planes, out_planes, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=stride, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Bottleneck&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    expansion = &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, inplanes, planes, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, downsample=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, groups=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;params&#34;&gt;                 base_width=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, dilation=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, norm_layer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Bottleneck, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; norm_layer &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            norm_layer = nn.BatchNorm2d&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        width = &lt;span class=&#34;built_in&#34;&gt;int&lt;/span&gt;(planes * (base_width / &lt;span class=&#34;number&#34;&gt;64.&lt;/span&gt;)) * groups&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = conv1x1(inplanes, width)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bn1 = norm_layer(width)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv2 = conv3x3(width, width, stride, groups, dilation)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bn2 = norm_layer(width)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv3 = conv1x1(width, planes * self.expansion)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bn3 = norm_layer(planes * self.expansion)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.relu = nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.downsample = downsample&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.stride = stride&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        identity = x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.relu(self.bn1(self.conv1(x)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.relu(self.bn2(self.conv2(out)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.bn3(self.conv3(out))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; self.downsample &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            identity = self.downsample(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out += identity&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.relu(out)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;ResNet&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, block, layers, replace_stride_with_dilation=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;params&#34;&gt;                 num_classes=&lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;, groups=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, width_per_group=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, norm_layer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(ResNet, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; norm_layer &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            norm_layer = nn.BatchNorm2d&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self._norm_layer = norm_layer&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.inplanes = &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.dilation = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.groups = groups&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.base_width = width_per_group&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; replace_stride_with_dilation &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            replace_stride_with_dilation = [&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;]  &lt;span class=&#34;comment&#34;&gt;# 分别表示在layer2/3/4是否使用空洞卷积&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(replace_stride_with_dilation) != &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;raise&lt;/span&gt; ValueError(&lt;span class=&#34;string&#34;&gt;f&amp;quot;replace_stride_with_dilation should be None or a 3-element tuple, got &lt;span class=&#34;subst&#34;&gt;&amp;#123;replace_stride_with_dilation&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, self.inplanes, kernel_size=&lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bn1 = norm_layer(self.inplanes)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.relu = nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.maxpool = nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.layer1 = self._make_layer(block, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, layers[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.layer2 = self._make_layer(block, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, layers[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, dilate=replace_stride_with_dilation[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.layer3 = self._make_layer(block, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, layers[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, dilate=replace_stride_with_dilation[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.layer4 = self._make_layer(block, &lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;, layers[&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, dilate=replace_stride_with_dilation[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.avgpool = nn.AdaptiveAvgPool2d((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.fc = nn.Linear(&lt;span class=&#34;number&#34;&gt;512&lt;/span&gt; * block.expansion, num_classes)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; m &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self.modules():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(m, nn.Conv2d):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.init.kaiming_normal_(m.weight, mode=&lt;span class=&#34;string&#34;&gt;&amp;#x27;fan_out&amp;#x27;&lt;/span&gt;, nonlinearity=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(m, (nn.BatchNorm2d, nn.GroupNorm)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.init.constant_(m.weight, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.init.constant_(m.bias, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;_make_layer&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, block, planes, blocks, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, dilate=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        norm_layer = self._norm_layer&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        downsample = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        previous_dilation = self.dilation&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; dilate:  &lt;span class=&#34;comment&#34;&gt;# 如果使用空洞卷积那么就不对图像的尺寸进行下采样&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.dilation *= stride&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            stride = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; stride != &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; self.inplanes != planes * block.expansion:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            downsample = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                conv1x1(self.inplanes, planes * block.expansion, stride),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                norm_layer(planes * block.expansion),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        layers = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                            self.base_width, previous_dilation, norm_layer))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.inplanes = planes * block.expansion&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; _ &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, blocks):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            layers.append(block(self.inplanes, planes, groups=self.groups, base_width=self.base_width,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                dilation=self.dilation, norm_layer=norm_layer))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Sequential(*layers)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        dict_out = &amp;#123;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.relu(self.bn1(self.conv1(x)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.maxpool(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.layer1(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.layer2(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.layer3(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.layer4(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        dict_out[&lt;span class=&#34;string&#34;&gt;&amp;#x27;layer4&amp;#x27;&lt;/span&gt;] = x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.avgpool(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = torch.flatten(x, start_dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.fc(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; x, dict_out&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;get_resnet&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;arch, block, layers, pretrained, progress, replace_stride_with_dilation&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = ResNet(block, layers, replace_stride_with_dilation)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; pretrained:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        model.load_state_dict(state_dict)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;resnet50&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;pretrained=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, progress=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, replace_stride_with_dilation=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; get_resnet(&lt;span class=&#34;string&#34;&gt;&amp;#x27;resnet50&amp;#x27;&lt;/span&gt;, Bottleneck, [&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], pretrained, progress, replace_stride_with_dilation)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;resnet101&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;pretrained=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, progress=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, replace_stride_with_dilation=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; get_resnet(&lt;span class=&#34;string&#34;&gt;&amp;#x27;resnet101&amp;#x27;&lt;/span&gt;, Bottleneck, [&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;23&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], pretrained, progress, replace_stride_with_dilation)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;resnet152&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;pretrained=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, progress=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, replace_stride_with_dilation=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; get_resnet(&lt;span class=&#34;string&#34;&gt;&amp;#x27;resnet152&amp;#x27;&lt;/span&gt;, Bottleneck, [&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;36&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], pretrained, progress, replace_stride_with_dilation)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; __name__ == &lt;span class=&#34;string&#34;&gt;&amp;#x27;__main__&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net1 = resnet101(pretrained=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, replace_stride_with_dilation=[&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# 在layer4使用空洞卷积&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net2 = resnet101(pretrained=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, replace_stride_with_dilation=[&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# 在layer3与layer4使用空洞卷积&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x = torch.randn(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    out1, dict_out1 = net1(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    out2, dict_out2 = net2(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(dict_out1[&lt;span class=&#34;string&#34;&gt;&amp;#x27;layer4&amp;#x27;&lt;/span&gt;].shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([8, 2048, 14, 14])，有一层使用空洞卷积因此输出尺寸为输入的1/16&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(dict_out2[&lt;span class=&#34;string&#34;&gt;&amp;#x27;layer4&amp;#x27;&lt;/span&gt;].shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([8, 2048, 28, 28])，有两层使用空洞卷积因此输出尺寸为输入的1/8&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-IntermediateLayerGetter&#34;&gt;3. IntermediateLayerGetter&lt;/h2&gt;
&lt;p&gt;我们需要用到 ResNet 特征提取层提取出的特征，其中有浅层特征（layer1 的输出）与深层特征（layer4 的输出），两者的通道维度我们分别记作 &lt;code&gt;low_level_channels&lt;/code&gt; 与 &lt;code&gt;in_channels&lt;/code&gt;，越深层的特征蕴含的语义信息越丰富，但是目标的位置信息更为模糊，小目标的特征可能还会丢失。因此我们需要记录下这些特征，实现 &lt;code&gt;IntermediateLayerGetter&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; collections &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; OrderedDict&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; ResNet &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; resnet101&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;IntermediateLayerGetter&lt;/span&gt;(nn.ModuleDict):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, model, return_layers&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;set&lt;/span&gt;(return_layers).issubset([name &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; name, _ &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; model.named_children()]):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;raise&lt;/span&gt; ValueError(&lt;span class=&#34;string&#34;&gt;&amp;quot;return_layers are not present in model&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        origin_ret_layers = return_layers.copy()  &lt;span class=&#34;comment&#34;&gt;# 之后会删除return_layers的内容因此需要备份&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        layers = OrderedDict()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; name, module &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; model.named_children():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            layers[name] = module&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; name &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; return_layers:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;del&lt;/span&gt; return_layers[name]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; return_layers:  &lt;span class=&#34;comment&#34;&gt;# 到layer4结束，即layers中没有avgpool与fc层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;break&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(IntermediateLayerGetter, self).__init__(layers)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.return_layers = origin_ret_layers  &lt;span class=&#34;comment&#34;&gt;# &amp;#123;&amp;#x27;layer4&amp;#x27;: &amp;#x27;out&amp;#x27;, &amp;#x27;layer1&amp;#x27;: &amp;#x27;low_level&amp;#x27;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = OrderedDict()  &lt;span class=&#34;comment&#34;&gt;# 输出以字典形式返回&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; name, module &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self.named_children():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            x = module(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; name &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self.return_layers:  &lt;span class=&#34;comment&#34;&gt;# 记录下需要返回的中间层输出，映射为自定义的名称&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                out_name = self.return_layers[name]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                out[out_name] = x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; out&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; __name__ == &lt;span class=&#34;string&#34;&gt;&amp;#x27;__main__&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = resnet101(pretrained=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, replace_stride_with_dilation=[&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = IntermediateLayerGetter(model, &amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;layer4&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;out&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;layer1&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;low_level&amp;#x27;&lt;/span&gt;&amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x = torch.randn(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = model(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output[&lt;span class=&#34;string&#34;&gt;&amp;#x27;low_level&amp;#x27;&lt;/span&gt;].shape, output[&lt;span class=&#34;string&#34;&gt;&amp;#x27;out&amp;#x27;&lt;/span&gt;].shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([8, 256, 56, 56]) torch.Size([8, 2048, 14, 14])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;4-DeepLabV3Plus&#34;&gt;4. DeepLabV3Plus&lt;/h2&gt;
&lt;p&gt;ResNet 与 ASPP 均为 DeepLabV3 的 Encoder 部分，现在先介绍一下 Decoder 部分 &lt;code&gt;DeepLabHeadV3Plus&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;ResNet 提取出的浅层特征与深层特征的通道维度我们分别记作 &lt;code&gt;low_level_channels&lt;/code&gt; 与 &lt;code&gt;in_channels&lt;/code&gt;。先对浅层特征做一个投影，降低通道维度，将投影后的特征记作 &lt;code&gt;low_level_feature&lt;/code&gt;；接着将深层特征通过 ASPP，并上采样到与 &lt;code&gt;low_level_feature&lt;/code&gt; 相同的尺寸，将该特征记作 &lt;code&gt;output_feature&lt;/code&gt;；最后将这两个特征在通道维度上 Concat 起来后通过分类头将通道维度映射为分类数量：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; ResNet&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; IntermediateLayerGetter &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; IntermediateLayerGetter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; ASPP &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; ASPP&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;DeepLabHeadV3Plus&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_channels, low_level_channels, num_classes, aspp_dilate=[&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;12&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;18&lt;/span&gt;]&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(DeepLabHeadV3Plus, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 浅层特征的投影层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.project = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(low_level_channels, &lt;span class=&#34;number&#34;&gt;48&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;48&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 深层特征的ASPP层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.aspp = ASPP(in_channels, aspp_dilate)  &lt;span class=&#34;comment&#34;&gt;# aspp_dilate = [6, 12, 18]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 分类头&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.classifier = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(&lt;span class=&#34;number&#34;&gt;304&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, num_classes, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self._init_weight()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, feature&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# feature[&amp;#x27;low_level&amp;#x27;]: (n, 256, h/4, w/4), feature[&amp;#x27;out&amp;#x27;]: (n, 2048, h/16, w/16)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        low_level_feature = self.project(feature[&lt;span class=&#34;string&#34;&gt;&amp;#x27;low_level&amp;#x27;&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# (n, 256, h/4, w/4) -&amp;gt; (n, 48, h/4, w/4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        size = low_level_feature.shape[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:]  &lt;span class=&#34;comment&#34;&gt;# (h/4, w/4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output_feature = self.aspp(feature[&lt;span class=&#34;string&#34;&gt;&amp;#x27;out&amp;#x27;&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# (n, 2048, h/16, w/16) -&amp;gt; (n, 256, h/16, w/16)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output_feature = F.interpolate(output_feature, size=size, mode=&lt;span class=&#34;string&#34;&gt;&amp;#x27;bilinear&amp;#x27;&lt;/span&gt;, align_corners=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 上采样为与low_level_feature尺寸一致&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.classifier(torch.cat([low_level_feature, output_feature], dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# (n, 48+256, h/4, w/4) -&amp;gt; (n, num_classes, h/4, w/4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;_init_weight&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; m &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self.modules():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(m, nn.Conv2d):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.init.kaiming_normal_(m.weight)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(m, (nn.BatchNorm2d, nn.GroupNorm)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.init.constant_(m.weight, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.init.constant_(m.bias, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;空间金字塔池化模块能够通过使用滤波器（卷积）或池化操作以多种比率（rate）和多个有效感受野（fields-of-view）探测传入特征，对&lt;strong&gt;多尺度&lt;/strong&gt;的上下文信息进行编码；Encoder-Decoder 结构的模块能够通过逐渐恢复空间信息来捕获更清晰的对象边界。DeepLabV3Plus 结合了这两者的优点，通过添加了一个简单而有效的解码器模块来扩展  DeepLabv3，以细化分割结果，尤其是沿对象边界的分割结果。&lt;/p&gt;
&lt;p&gt;此外还可将深度可分离卷积应用于 ASPP 和解码器模块，从而形成更快、更强的编码器-解码器网络，该部分代码在下一节中介绍。&lt;/p&gt;
&lt;p&gt;最后我们组合所有的模块即可构建完整的 &lt;code&gt;DeepLabV3Plus&lt;/code&gt;，注意最后需要对 Decoder 的分类头输出进行上采样，恢复到原始的输入图像大小：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;DeepLabV3Plus&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, backbone, classifier&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(DeepLabV3Plus, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.backbone = backbone&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.classifier = classifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# (n, c, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        input_shape = x.shape[-&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:]  &lt;span class=&#34;comment&#34;&gt;# (h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        features = self.backbone(x)  &lt;span class=&#34;comment&#34;&gt;# features[&amp;#x27;low_level&amp;#x27;]: (n, 256, h/4, w/4), feature[&amp;#x27;out&amp;#x27;]: (n, 2048, h/16, w/16)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.classifier(features)  &lt;span class=&#34;comment&#34;&gt;# (n, num_classes, h/4, w/4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.interpolate(x, size=input_shape, mode=&lt;span class=&#34;string&#34;&gt;&amp;#x27;bilinear&amp;#x27;&lt;/span&gt;, align_corners=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# (n, num_classes, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;get_deeplabv3plus_model&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;args&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; args[&lt;span class=&#34;string&#34;&gt;&amp;#x27;output_stride&amp;#x27;&lt;/span&gt;] == &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        replace_stride_with_dilation = [&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        aspp_dilate = [&lt;span class=&#34;number&#34;&gt;12&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;24&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;36&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:  &lt;span class=&#34;comment&#34;&gt;# output_stride == 16&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        replace_stride_with_dilation = [&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        aspp_dilate = [&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;12&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;18&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    return_layers = &amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;layer4&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;out&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;layer1&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;low_level&amp;#x27;&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    backbone = ResNet.__dict__[args[&lt;span class=&#34;string&#34;&gt;&amp;#x27;backbone&amp;#x27;&lt;/span&gt;]](&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, replace_stride_with_dilation)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    backbone = IntermediateLayerGetter(backbone, return_layers)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    in_channels = &lt;span class=&#34;number&#34;&gt;2048&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    low_level_channels = &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    classifier = DeepLabHeadV3Plus(in_channels, low_level_channels, args[&lt;span class=&#34;string&#34;&gt;&amp;#x27;num_classes&amp;#x27;&lt;/span&gt;], aspp_dilate)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = DeepLabV3Plus(backbone, classifier)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; __name__ == &lt;span class=&#34;string&#34;&gt;&amp;#x27;__main__&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    args = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;string&#34;&gt;&amp;#x27;num_classes&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;string&#34;&gt;&amp;#x27;output_stride&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;string&#34;&gt;&amp;#x27;backbone&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;resnet101&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;string&#34;&gt;&amp;#x27;device&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = get_deeplabv3plus_model(args)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model.to(args[&lt;span class=&#34;string&#34;&gt;&amp;#x27;device&amp;#x27;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.randn(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;, device=args[&lt;span class=&#34;string&#34;&gt;&amp;#x27;device&amp;#x27;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = model(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([8, 4, 224, 224])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pred = output.detach().&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].cpu().numpy()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred.shape)  &lt;span class=&#34;comment&#34;&gt;# (8, 224, 224)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, :&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# [0 0 0 3 3 3 2 1 1 1]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;5-AtrousSeparableConvolution&#34;&gt;5. AtrousSeparableConvolution&lt;/h2&gt;
&lt;p&gt;深度可分离卷积，将标准卷积分解为 Depth-wise 卷积与 Point-wise 卷积，大大降低了计算复杂度。我们在其中结合空洞卷积即可构建空洞可分离卷积：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;AtrousSeparableConvolution&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_channels, out_channels, kernel_size,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;params&#34;&gt;                 stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, dilation=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(AtrousSeparableConvolution, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.sepconv = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=bias),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels, out_channels, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, bias=bias),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self._init_weight()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.sepconv(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;_init_weight&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; m &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self.modules():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(m, nn.Conv2d):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.init.kaiming_normal_(m.weight)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(m, (nn.BatchNorm2d, nn.GroupNorm)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.init.constant_(m.weight, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.init.constant_(m.bias, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;convert_to_separable_conv&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;module&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    new_module = module&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(module, nn.Conv2d) &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; module.kernel_size[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] &amp;gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        new_module = AtrousSeparableConvolution(module.in_channels,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                                module.out_channels,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                                module.kernel_size,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                                module.stride,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                                module.padding,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                                module.dilation,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                                module.bias)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; name, child &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; module.named_children():  &lt;span class=&#34;comment&#34;&gt;# 递归修改每一层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        new_module.add_module(name, convert_to_separable_conv(child))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; new_module&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; __name__ == &lt;span class=&#34;string&#34;&gt;&amp;#x27;__main__&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    args = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;string&#34;&gt;&amp;#x27;num_classes&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;string&#34;&gt;&amp;#x27;output_stride&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;string&#34;&gt;&amp;#x27;backbone&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;resnet101&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;string&#34;&gt;&amp;#x27;device&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;string&#34;&gt;&amp;#x27;separable_conv&amp;#x27;&lt;/span&gt;: &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = get_deeplabv3plus_model(args)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; args[&lt;span class=&#34;string&#34;&gt;&amp;#x27;separable_conv&amp;#x27;&lt;/span&gt;]:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        convert_to_separable_conv(model.classifier)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# print(model)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model.to(args[&lt;span class=&#34;string&#34;&gt;&amp;#x27;device&amp;#x27;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.randn(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;, device=args[&lt;span class=&#34;string&#34;&gt;&amp;#x27;device&amp;#x27;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = model(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([8, 4, 224, 224])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pred = output.detach().&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].cpu().numpy()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred.shape)  &lt;span class=&#34;comment&#34;&gt;# (8, 224, 224)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, :&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# [0 0 0 3 3 3 2 1 1 1]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/23991.html</guid>
            <title>KMeans聚类与PCA主成分分析</title>
            <link>https://asanosaki.github.io/posts/23991.html</link>
            <category>AI</category>
            <pubDate>Wed, 09 Aug 2023 10:03:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;介绍二维数据与高维数据的 K-Means 聚类算法以及高维数据的 PCA 主成分分析方法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-二维数据K-Means聚类&#34;&gt;1. 二维数据K-Means聚类&lt;/h2&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.cluster &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; KMeans, MiniBatchKMeans&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.decomposition &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; PCA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 以center为中心产生随机分布的数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;get_random_data&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;center, data_num, data_dim=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, fix_seed=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; fix_seed:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        np.random.seed(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 产生-2~2的随机数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    offset = np.random.rand(data_num, data_dim) * &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt; - &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; center + offset&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;centers = [[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;]]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;center_num = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(centers)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_num = &lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;  &lt;span class=&#34;comment&#34;&gt;# 每个center产生的样本数量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.zeros([data_num * center_num, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, center &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(centers):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    data[i * data_num:(i + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) * data_num] = get_random_data(center, data_num)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 显示数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(data.shape)  &lt;span class=&#34;comment&#34;&gt;# (1500, 2)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], s=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, color=&lt;span class=&#34;string&#34;&gt;&amp;#x27;c&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ---------- KMeans聚类 ----------&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;kms = KMeans(n_clusters=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, init=&lt;span class=&#34;string&#34;&gt;&amp;#x27;k-means++&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 聚出3类&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;kms.fit(data)  &lt;span class=&#34;comment&#34;&gt;# 模型拟合&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;centers = kms.cluster_centers_  &lt;span class=&#34;comment&#34;&gt;# 计算聚类中心&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;labels = kms.labels_  &lt;span class=&#34;comment&#34;&gt;# 聚类后每个样本的类别标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ---------- MiniBatchKMeans聚类 ----------&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# mbk = MiniBatchKMeans(init=&amp;#x27;k-means++&amp;#x27;, n_clusters=3, batch_size=32, random_state=0)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# mbk.fit(data)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# centers = mbk.cluster_centers_&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# labels = mbk.labels_&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.figure(figsize=(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], s=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, c=labels, cmap=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Accent&amp;#x27;&lt;/span&gt;, alpha=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 画出聚类后带标签的样本&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(centers[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], centers[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], marker=&lt;span class=&#34;string&#34;&gt;&amp;#x27;*&amp;#x27;&lt;/span&gt;, s=&lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;, c=[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], cmap=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Accent&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 画出聚类中心&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-主成分分析PCA&#34;&gt;2. 主成分分析PCA&lt;/h2&gt;
&lt;p&gt;PCA（Principal Component Analysis）是一种常见的数据分析方式，常用于高维数据的&lt;strong&gt;降维&lt;/strong&gt;，可用于提取数据的&lt;strong&gt;主要特征分量&lt;/strong&gt;。PCA 通常用于降低大型数据集的维数，使数据集中的指标数量变少，并且保留原数据集中指标的大部分信息。总而言之：减少数据指标数量，保留尽可能多的信息。&lt;/p&gt;
&lt;p&gt;PCA 优点在于数据降维，便于提取数据的主要特征，使得数据更容易使用，减少计算开销，去除噪音等；PCA 适用于结构化数据，不仅能将数据压缩，也使得降维之后的数据特征&lt;strong&gt;相互独立&lt;/strong&gt;。PCA 缺点在于不一定需要，有可能损失有用信息，只针对训练集保留主要信息，可能造成过拟合。&lt;/p&gt;
&lt;p&gt;PCA 的步骤主要分为五步：&lt;strong&gt;标准化&lt;/strong&gt;连续初始变量的范围、计算&lt;strong&gt;协方差矩阵&lt;/strong&gt;以识别相关性、计算协方差矩阵的&lt;strong&gt;特征向量&lt;/strong&gt;和&lt;strong&gt;特征值&lt;/strong&gt;以识别主成分、创建特征向量来决定保留那些主成分、沿主成分轴重铸数据。&lt;/p&gt;
&lt;p&gt;我们随机生成具有 &lt;code&gt;y = 0.5x&lt;/code&gt; 的二维数据，并在 Y 轴方向上添加少量随机噪音。通过使用 PCA 法拟合数据，其中最重要的是&lt;strong&gt;分量&lt;/strong&gt;和&lt;strong&gt;解释方差&lt;/strong&gt;，对于这些数字的概念，让我们将其可视化为输入数据上的向量，使用&lt;strong&gt;分量来定义向量的方向&lt;/strong&gt;，使用&lt;strong&gt;解释方差来定义向量的平方长度&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这些向量代表数据的主轴，向量的长度表明该轴在描述数据分布方面的重要性，更准确的说，它是投影时数据方差的度量到那个轴。每个数据点在主轴上的投影是数据的主成分。这种从数据轴到主轴的变换被称为 Affine transformation，基本上由平移，旋转和均匀缩放组成。&lt;/p&gt;
&lt;p&gt;代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;f&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    rs = np.random.RandomState(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; x / &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; + rs.randn(*x.shape) / &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;rs = np.random.RandomState(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = rs.randn(&lt;span class=&#34;number&#34;&gt;200&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] = f(data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# plt.scatter(data[:, 0], data[:, 1], s=5, color=&amp;#x27;c&amp;#x27;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# plt.axis(&amp;#x27;equal&amp;#x27;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# plt.show()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pca = PCA(n_components=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pca.fit(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_pca = pca.transform(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pca.components_)  &lt;span class=&#34;comment&#34;&gt;# PCA分量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pca.explained_variance_)  &lt;span class=&#34;comment&#34;&gt;# PCA解释方差&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;draw_vector&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;v0, v1, ax=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(v0, v1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ax = ax &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; plt.gca()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    arrowprops = &lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(arrowstyle=&lt;span class=&#34;string&#34;&gt;&amp;#x27;-&amp;gt;&amp;#x27;&lt;/span&gt;, linewidth=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, shrinkA=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, shrinkB=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ax.annotate(&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;#x27;&lt;/span&gt;, v1, v0, arrowprops=arrowprops)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 将分量和解释方差可视化为输入数据上的向量，使用分量来定义向量的方向，使用解释方差来定义向量的平方长度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], s=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, color=&lt;span class=&#34;string&#34;&gt;&amp;#x27;c&amp;#x27;&lt;/span&gt;, alpha=&lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; length, vector &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(pca.explained_variance_, pca.components_):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    v = vector * &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt; * np.sqrt(length)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    draw_vector(pca.mean_, pca.mean_ + v)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.axis(&lt;span class=&#34;string&#34;&gt;&amp;#x27;equal&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-高维数据PCA后聚类&#34;&gt;3. 高维数据PCA后聚类&lt;/h2&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 产生高维数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hd_centers = [&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hd_center_num = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(hd_centers)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hd_data_num = &lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hd_data = np.zeros([hd_data_num * hd_center_num, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, center &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(hd_centers):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hd_data[i * hd_data_num:(i + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) * hd_data_num] = get_random_data(center, hd_data_num, data_dim=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(hd_data.shape)  &lt;span class=&#34;comment&#34;&gt;# (1500, 10)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ---------- PCA主成分分析降维 ----------&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pca = PCA(n_components=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 降成二维&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pca.fit(hd_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pca_data = pca.transform(hd_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pca_data.shape)  &lt;span class=&#34;comment&#34;&gt;# (1500, 2)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(pca_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], pca_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], s=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, color=&lt;span class=&#34;string&#34;&gt;&amp;#x27;c&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ---------- KMeans聚类 ----------&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;kms = KMeans(n_clusters=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, init=&lt;span class=&#34;string&#34;&gt;&amp;#x27;k-means++&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;kms.fit(pca_data)  &lt;span class=&#34;comment&#34;&gt;# 模型拟合&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;centers = kms.cluster_centers_  &lt;span class=&#34;comment&#34;&gt;# 计算聚类中心&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;labels = kms.labels_  &lt;span class=&#34;comment&#34;&gt;# 聚类后每个样本的类别标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.figure(figsize=(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(pca_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], pca_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], s=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, c=labels, cmap=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Accent&amp;#x27;&lt;/span&gt;, alpha=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 画出聚类后带标签的样本&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(centers[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], centers[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], marker=&lt;span class=&#34;string&#34;&gt;&amp;#x27;*&amp;#x27;&lt;/span&gt;, s=&lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;, c=[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], cmap=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Accent&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 画出聚类中心&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;4-高维数据聚类并计算与中心的相似度&#34;&gt;4. 高维数据聚类并计算与中心的相似度&lt;/h2&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 产生高维数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hd_centers = [&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hd_center_num = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(hd_centers)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hd_data_num = &lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hd_data = np.zeros([hd_data_num * hd_center_num, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, center &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(hd_centers):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hd_data[i * hd_data_num:(i + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) * hd_data_num] = get_random_data(center, hd_data_num, data_dim=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(hd_data.shape)  &lt;span class=&#34;comment&#34;&gt;# (1500, 10)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 对原始高维数据聚类&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;kms = KMeans(n_clusters=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, init=&lt;span class=&#34;string&#34;&gt;&amp;#x27;k-means++&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;kms.fit(hd_data)  &lt;span class=&#34;comment&#34;&gt;# 模型拟合&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;centers = kms.cluster_centers_  &lt;span class=&#34;comment&#34;&gt;# 计算聚类中心&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;labels = kms.labels_  &lt;span class=&#34;comment&#34;&gt;# 聚类后每个样本的类别标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(centers.shape)  &lt;span class=&#34;comment&#34;&gt;# (3, 10)，3个聚类中心的高维向量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(labels[:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# [1 1 1 1 1 1 1 1 1 1]，第1类的标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(labels[&lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;510&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# [2 2 2 2 2 2 2 2 2 2]，第2类的标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(labels[&lt;span class=&#34;number&#34;&gt;1490&lt;/span&gt;:])  &lt;span class=&#34;comment&#34;&gt;# [0 0 0 0 0 0 0 0 0 0]，第3类的标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 计算每个向量分别与3个聚类中心的余弦相似度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;CosineSimilarity&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x, y&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    normalized_x = x / np.linalg.norm(x, axis=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, keepdims=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    normalized_y = y / np.linalg.norm(y, axis=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, keepdims=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; np.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(normalized_x * normalized_y, axis=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_cnt = hd_data_num * hd_center_num&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;true_cnt = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(hd_data):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    score_0 = CosineSimilarity(data, centers[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    score_1 = CosineSimilarity(data, centers[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    score_2 = CosineSimilarity(data, centers[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    max_idx = np.argmax([score_0, score_1, score_2])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;ID: &lt;span class=&#34;subst&#34;&gt;&amp;#123;i&amp;#125;&lt;/span&gt;, Score0: &lt;span class=&#34;subst&#34;&gt;&amp;#123;score_0:&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;f&amp;#125;&lt;/span&gt;, Score1: &lt;span class=&#34;subst&#34;&gt;&amp;#123;score_1:&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;f&amp;#125;&lt;/span&gt;, Score2: &lt;span class=&#34;subst&#34;&gt;&amp;#123;score_2:&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;f&amp;#125;&lt;/span&gt;, Pred_label: &lt;span class=&#34;subst&#34;&gt;&amp;#123;max_idx&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; i &amp;lt; &lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; max_idx == &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            true_cnt = true_cnt + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; i &amp;lt; &lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; max_idx == &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            true_cnt = true_cnt + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; max_idx == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            true_cnt = true_cnt + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ID: 0, Score0: 0.85, Score1: 0.98, Score2: 0.85, Pred_label: 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ID: 1, Score0: 0.84, Score1: 0.92, Score2: 0.79, Pred_label: 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ID: 2, Score0: 0.87, Score1: 0.93, Score2: 0.90, Pred_label: 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ID: 500, Score0: 0.85, Score1: 0.78, Score2: 0.99, Pred_label: 2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ID: 501, Score0: 0.85, Score1: 0.75, Score2: 0.98, Pred_label: 2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ID: 502, Score0: 0.83, Score1: 0.71, Score2: 0.98, Pred_label: 2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ID: 1000, Score0: 0.99, Score1: 0.81, Score2: 0.87, Pred_label: 0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ID: 1001, Score0: 0.98, Score1: 0.77, Score2: 0.83, Pred_label: 0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ID: 1002, Score0: 0.99, Score1: 0.76, Score2: 0.87, Pred_label: 0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;All: &lt;span class=&#34;subst&#34;&gt;&amp;#123;data_cnt&amp;#125;&lt;/span&gt;, True: &lt;span class=&#34;subst&#34;&gt;&amp;#123;true_cnt&amp;#125;&lt;/span&gt;, Acc: &lt;span class=&#34;subst&#34;&gt;&amp;#123;true_cnt / data_cnt:&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# All: 1500, True: 1499, Acc: 1.00&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/21944.html</guid>
            <title>分割图像的着色与相似度匹配</title>
            <link>https://asanosaki.github.io/posts/21944.html</link>
            <category>AI</category>
            <pubDate>Tue, 08 Aug 2023 14:14:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;介绍图像分割后产生的 Mask 灰度图的着色以及相似度匹配计算。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-分割图像着色&#34;&gt;1. 分割图像着色&lt;/h2&gt;
&lt;p&gt;以 SAM 分割为例，我们分割出来产生的 &lt;code&gt;masks&lt;/code&gt; 为一个 List，长度为分割出来的类别数，List 中的每个元素为一个 Dict，记录了分割目标的面积、边界框等信息，其中的 &lt;code&gt;segmentation&lt;/code&gt; 字段为分割出来的二值图，宽高与原图一致，目标像素点为 True，否则为 False。&lt;/p&gt;
&lt;p&gt;我们实现两种方式分别对分割出来的 &lt;code&gt;masks&lt;/code&gt; 以及保存下来的若干张分割图像进行合并与上色。灰度图像和伪彩色图像都对应一个索引表，这个索引表又叫调色板。图像的像素值就是索引，灰度图的索引表为：&lt;/p&gt;
&lt;table&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;像素值&lt;/th&gt;
            &lt;th&gt;R&lt;/th&gt;
            &lt;th&gt;G&lt;/th&gt;
            &lt;th&gt;B&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;0&lt;/td&gt;
            &lt;td&gt;0&lt;/td&gt;
            &lt;td&gt;0&lt;/td&gt;
            &lt;td&gt;0&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;2&lt;/td&gt;
            &lt;td&gt;2&lt;/td&gt;
            &lt;td&gt;2&lt;/td&gt;
            &lt;td&gt;2&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;3&lt;/td&gt;
            &lt;td&gt;3&lt;/td&gt;
            &lt;td&gt;3&lt;/td&gt;
            &lt;td&gt;3&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;...&lt;/td&gt;
            &lt;td&gt;...&lt;/td&gt;
            &lt;td&gt;...&lt;/td&gt;
            &lt;td&gt;...&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;255&lt;/td&gt;
            &lt;td&gt;255&lt;/td&gt;
            &lt;td&gt;255&lt;/td&gt;
            &lt;td&gt;255&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;索引表不同的像素值对应的 RGB 值就是该像素的颜色，灰度图像的索引表中的 RGB 值都与像素值相同。同理，只要修改这些 RGB 数值，就可以显示伪彩色图像了。注意调色板的索引从0-255，因此，调色板的每个索引对应的 RGB 值都要进行设置。&lt;/p&gt;
&lt;p&gt;代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;96&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; PIL &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Image&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 调色板&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;_palette = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;color_num = &lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;  &lt;span class=&#34;comment&#34;&gt;# 不同的颜色数量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(color_num // &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    _palette.append([(&lt;span class=&#34;number&#34;&gt;255&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    _palette.append([(&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;255&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    _palette.append([(&lt;span class=&#34;number&#34;&gt;33&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;133&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;233&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    _palette.append([(&lt;span class=&#34;number&#34;&gt;68&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;218&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;138&lt;/span&gt; + i * &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(color_num, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# 补上后面的灰度值索引&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    _palette.append([i, i, i])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;color_palette = np.array(_palette, dtype=&lt;span class=&#34;string&#34;&gt;&amp;#x27;uint8&amp;#x27;&lt;/span&gt;).reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# print(color_palette.shape)  # (256, 3)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 给mask上色&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;colorize_mask&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;mask&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mask = Image.fromarray(mask.astype(np.uint8))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mask = mask.convert(mode=&lt;span class=&#34;string&#34;&gt;&amp;#x27;P&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mask.putpalette(color_palette)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# mask = mask.convert(mode=&amp;#x27;RGB&amp;#x27;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; mask&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 给mask上色并保存&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;save_colorize_mask&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;mask, output_dir, file_name&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    save_mask = colorize_mask(mask)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    save_mask.save(os.path.join(output_dir, file_name))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 显示SAM分割出来的masks&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;show_origin_masks&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;masks&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(masks) == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    sorted_masks = &lt;span class=&#34;built_in&#34;&gt;sorted&lt;/span&gt;(masks, key=(&lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; x: x[&lt;span class=&#34;string&#34;&gt;&amp;#x27;area&amp;#x27;&lt;/span&gt;]), reverse=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 按面积从大到小排序&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# ax = plt.gca()  # 在原本的图片上绘制&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# ax.set_autoscale_on(False)  # 在原本的图片上绘制&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    img = np.ones((sorted_masks[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;string&#34;&gt;&amp;#x27;segmentation&amp;#x27;&lt;/span&gt;].shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], sorted_masks[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;string&#34;&gt;&amp;#x27;segmentation&amp;#x27;&lt;/span&gt;].shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# img.shape: (1080, 1920, 4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    img[:, :, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;] = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; mask &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; sorted_masks:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        m = mask[&lt;span class=&#34;string&#34;&gt;&amp;#x27;segmentation&amp;#x27;&lt;/span&gt;]  &lt;span class=&#34;comment&#34;&gt;# (1080, 1920)的True or False矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        color_mask = np.concatenate([np.random.random(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), [&lt;span class=&#34;number&#34;&gt;0.35&lt;/span&gt;]])  &lt;span class=&#34;comment&#34;&gt;# 第4维表示透明度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        img[m] = color_mask&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# ax.imshow(img)  # 在原本的图片上绘制&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.axis(&lt;span class=&#34;string&#34;&gt;&amp;#x27;off&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.imshow(img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 显示目录img_masks_path中的masks&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;show_img_masks&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;masks_dir, height, width, threshold&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mask = np.zeros((height, width))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    img_mask_names = os.listdir(masks_dir)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; idx, img_mask_name &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(img_mask_names):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        img_mask = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(os.path.join(masks_dir, img_mask_name))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        img_mask = np.asarray(img_mask, dtype=np.bool_)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; np.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(img_mask) &amp;lt; threshold:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;continue&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        mask[img_mask] = idx + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Image.fromarray(mask).show()  &lt;span class=&#34;comment&#34;&gt;# 上色前的mask&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mask = colorize_mask(mask)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mask.show()  &lt;span class=&#34;comment&#34;&gt;# 上色后的mask&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 读取原始图像&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;image = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../images/people.jpg&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;width, height = image.size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;image.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 读取SAM分割的若干masks图像进行合并上色显示&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;masks_dir = &lt;span class=&#34;string&#34;&gt;&amp;#x27;../images/people_sam/&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;threshold = &lt;span class=&#34;number&#34;&gt;200&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_img_masks(masks_dir, height, width, threshold)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 展示上色前后的mask&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_mask_path = &lt;span class=&#34;string&#34;&gt;&amp;#x27;../images/test_mask.png&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_mask = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(test_mask_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_mask.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_mask = np.array(test_mask, dtype=np.uint8)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(test_mask.shape)  &lt;span class=&#34;comment&#34;&gt;# (1080, 1920)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mask_gray = Image.fromarray(test_mask, &lt;span class=&#34;string&#34;&gt;&amp;#x27;P&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mask_gray.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mask_color = colorize_mask(test_mask)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mask_color.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(np.unique(mask_color)))  &lt;span class=&#34;comment&#34;&gt;# [0, 1, 2, 3, 4, 5, 6, ..., 44]，可以看成类别&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-分割图相似度匹配&#34;&gt;2. 分割图相似度匹配&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;区域相似度&lt;/strong&gt;（Region Similarity）：为了测量基于区域的分割相似度，即错误像素的数量，我们使用 Jaccard 索引 𝒥 表示， 𝒥 定义为预测的分割输出 Mask 和真值 Mask 之间的交并比 IoU（Intersection over Union），Jaccard 索引提供了关于错误分类像素的直观的信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;边沿精度&lt;/strong&gt;（Contour Accuracy）：边沿精度即计算 F-score，F-score 评估的是预测 Mask 的边界是否与真值 Mask 的边界对应。首先应提取预测 Mask 和真值 Mask 的边界元素坐标，将边界上的元素置为 True，非边界的元素置为 False。F-score 被定义为&lt;strong&gt;精度&lt;/strong&gt;和&lt;strong&gt;召回率&lt;/strong&gt;的调和平均数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;精度&lt;/strong&gt;（Precision，P，也称查准率）：分母应是&lt;strong&gt;预测&lt;/strong&gt; Mask 的边界元素总数，分子则是在预测 Mask 为边界的那些元素中真正属于真值的。换句话说，预测 Mask 假设有100个元素为边界元素，但实际上可能只有70个存在于真值图的对应位置上，即70个真值的正样本被正确（True）预测为 Positive，属于 True Positive（TP），所以此时的查准率为70%，剩下的30个元素是错误（False）预测为 Positive，属于 False Positive（FP）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;召回率&lt;/strong&gt;（Recall，R，也称查全率）：分母是&lt;strong&gt;真值&lt;/strong&gt; Mask 的边界元素总数，分子表示多少个本质的正样本被预测出来。例如真值 Mask 的边界有140个元素，但实际的预测 Mask 中只有70个真值的正样本被正确（True）预测为 Positive（TP），还有70个被错误（False）预测为 Negative（False Negative），那么此时的 Recall 为50%。&lt;/p&gt;
&lt;p&gt;J &amp;amp; F 指标的计算代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;114&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;115&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;116&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;117&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;118&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;119&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;120&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;121&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;122&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;123&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;124&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;125&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;126&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;127&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;128&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;129&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;130&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;131&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;132&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;133&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;134&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;135&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;136&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;137&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;138&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;139&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;140&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;141&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;142&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;143&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;144&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;145&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;146&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;147&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;148&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;149&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;150&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;151&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;152&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;153&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;154&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;155&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;156&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;157&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;158&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;159&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;160&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;161&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;162&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;163&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;164&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;165&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;166&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;167&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;168&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;169&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;170&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;171&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;172&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;173&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;174&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; math&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; PIL &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Image&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; skimage.morphology &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; binary_dilation, disk&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;db_eval_iou&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;annotation, segmentation&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    Compute region similarity as the Jaccard Index.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    Arguments:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        annotation   (ndarray): binary annotation   map.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        segmentation (ndarray): binary segmentation map.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    Return:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        jaccard (float): region similarity&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    annotation = annotation.astype(np.bool_)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    segmentation = segmentation.astype(np.bool_)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; np.isclose(np.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(annotation), &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; np.isclose(np.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(segmentation), &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; np.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;((annotation &amp;amp; segmentation)) / np.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;((annotation | segmentation), dtype=np.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;db_eval_boundary&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;foreground_mask, gt_mask, bound_th=&lt;span class=&#34;number&#34;&gt;0.008&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    Compute mean, recall and decay from per-frame evaluation.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    Calculates precision/recall for boundaries between foreground_mask and&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    gt_mask using morphological operators to speed it up.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    Arguments:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        foreground_mask (ndarray): binary segmentation image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        gt_mask         (ndarray): binary annotated image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    Returns:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        F (float): boundaries F-measure&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        P (float): boundaries precision&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        R (float): boundaries recall&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; np.atleast_3d(foreground_mask).shape[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;] == &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    bound_pix = bound_th &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; bound_th &amp;gt;= &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        np.ceil(bound_th * np.linalg.norm(foreground_mask.shape))  &lt;span class=&#34;comment&#34;&gt;# np.linalg.norm计算范数，默认为L2范数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# Get the pixel boundaries of both masks&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fg_boundary = seg2bmap(foreground_mask)  &lt;span class=&#34;comment&#34;&gt;# 将边界置为True&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    gt_boundary = seg2bmap(gt_mask)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fg_dil = binary_dilation(fg_boundary, disk(bound_pix))  &lt;span class=&#34;comment&#34;&gt;# 二值化膨胀&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    gt_dil = binary_dilation(gt_boundary, disk(bound_pix))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# Get the intersection&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    gt_match = gt_boundary * fg_dil  &lt;span class=&#34;comment&#34;&gt;# 计算GT中与FG边缘匹配的像素&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fg_match = fg_boundary * gt_dil  &lt;span class=&#34;comment&#34;&gt;# 计算FG中与GT边缘匹配的像素&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# Area of the intersection&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    n_fg = np.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(fg_boundary)  &lt;span class=&#34;comment&#34;&gt;# FG边缘像素数量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    n_gt = np.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(gt_boundary)  &lt;span class=&#34;comment&#34;&gt;# GT边缘像素数量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#% Compute precision and recall&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; n_fg == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; n_gt &amp;gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        precision = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        recall = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; n_fg &amp;gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; n_gt == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        precision = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        recall = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; n_fg == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; n_gt == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        precision = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        recall = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        precision = np.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(fg_match) / &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(n_fg)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        recall = np.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(gt_match) / &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(n_gt)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# Compute F measure&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; precision + recall == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        F_score = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        F_score = &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; * precision * recall / (precision + recall)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; F_score&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;seg2bmap&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;seg, width=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, height=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    From a segmentation, compute a binary boundary map with 1 pixel wide&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    boundaries.  The boundary pixels are offset by 1/2 pixel towards the&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    origin from the actual segment boundary.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    Arguments:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        seg     : Segments labeled from 1..k.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        width      :	Width of desired bmap  &amp;lt;= seg.shape[1]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        height  :    Height of desired bmap &amp;lt;= seg.shape[0]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    Returns:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;        bmap (ndarray):    Binary boundary map.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    seg = seg.astype(np.bool_)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    seg[seg &amp;gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; np.atleast_3d(seg).shape[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;] == &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    width = seg.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; width &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; width&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    height = seg.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; height &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; height&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    h,w = seg.shape[:&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ar1 = &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(width) / &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(height)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ar2 = &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(w) / &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(h)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; (width &amp;gt; w | height &amp;gt; h | &lt;span class=&#34;built_in&#34;&gt;abs&lt;/span&gt;(ar1 - ar2) &amp;gt; &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;),\&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;string&#34;&gt;&amp;#x27;Can&amp;#x27;&lt;/span&gt;&lt;span class=&#34;string&#34;&gt;&amp;#x27;t convert %dx%d seg to %dx%d bmap.&amp;#x27;&lt;/span&gt;%(w, h, width, height)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    e = np.zeros_like(seg)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    s = np.zeros_like(seg)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    se = np.zeros_like(seg)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    e[:, :-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] = seg[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    s[:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, :] = seg[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:, :]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    se[:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, :-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] = seg[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    b = seg^e | seg^s | seg^se&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    b[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, :] = seg[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, :]^e[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, :]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    b[:, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] = seg[:, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]^s[:, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    b[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; w == width &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; h == height:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        bmap = b&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        bmap = np.zeros((height, width))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; x &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(w):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(h):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; b[y, x]:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    j = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; + math.floor((y - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) + height / h)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    i = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; + math.floor((x - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) + width / h)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    bmap[j, i] = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; bmap&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;database_path = &lt;span class=&#34;string&#34;&gt;&amp;#x27;../data/mask_database/&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_path = &lt;span class=&#34;string&#34;&gt;&amp;#x27;../data/mask_test/&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;database_img_name_list = os.listdir(database_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_img_name_list = os.listdir(test_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; test_img_name &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; test_img_name_list:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_img = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(test_path + test_img_name)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    h, w = test_img.size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_img = np.asarray(test_img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    best_iou, best_F, best_iou_dbname, best_F_dbname = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; database_img_name &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; database_img_name_list:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        database_img = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(database_path + database_img_name).resize((h, w))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        database_img = np.asarray(database_img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        iou = db_eval_iou(test_img, database_img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        F_score = db_eval_boundary(test_img, database_img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; iou &amp;gt; best_iou:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            best_iou = iou&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            best_iou_dbname = database_img_name&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; F_score &amp;gt; best_F:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            best_F = F_score&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            best_F_dbname = database_img_name&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;[&lt;span class=&#34;subst&#34;&gt;&amp;#123;test_img_name&amp;#125;&lt;/span&gt;] best iou: &lt;span class=&#34;subst&#34;&gt;&amp;#123;best_iou:&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;f&amp;#125;&lt;/span&gt; (&lt;span class=&#34;subst&#34;&gt;&amp;#123;best_iou_dbname&amp;#125;&lt;/span&gt;), best F: &lt;span class=&#34;subst&#34;&gt;&amp;#123;best_F:&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;f&amp;#125;&lt;/span&gt; (&lt;span class=&#34;subst&#34;&gt;&amp;#123;best_F_dbname&amp;#125;&lt;/span&gt;)&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# [0_70.png] best iou: 0.7433 (0_9_156_197_151.png), best F: 0.2681 (0_2_152_212_77.png)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# [0_71.png] best iou: 0.9399 (0_3_140_238_157.png), best F: 0.7001 (0_3_140_238_157.png)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# [0_72.png] best iou: 0.7066 (0_10_190_185_95.png), best F: 0.2735 (0_7_93_244_223.png)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# [0_75.png] best iou: 0.9089 (0_5_241_130_227.png), best F: 0.5160 (0_5_241_130_227.png)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# [0_77.png] best iou: 0.5177 (0_18_252_79_113.png), best F: 0.2171 (0_1_245_116_182.png)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# [0_78.png] best iou: 0.7393 (0_4_251_231_252.png), best F: 0.2872 (0_9_156_197_151.png)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/6828.html</guid>
            <title>DeAOT视频追踪论文阅读笔记</title>
            <link>https://asanosaki.github.io/posts/6828.html</link>
            <category>AI</category>
            <pubDate>Tue, 08 Aug 2023 13:58:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;本文记录 DeAOT 视频追踪论文的阅读笔记。&lt;br&gt;
涉及的相关知识点为：AOT（Associating Objects with Transformers for Video Object Segmentation）、DeAOT（Decoupling Features in Hierarchical Propagation for Video Object Segmentation）、FPN（Feature Pyramid Networks for Object Detection）、Depth-wise Convolution、DropPath、GroupNorm。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-相关知识&#34;&gt;1. 相关知识&lt;/h2&gt;
&lt;h3 id=&#34;1-1-深度可分离卷积&#34;&gt;1.1 深度可分离卷积&lt;/h3&gt;
&lt;p&gt;Depth-wise（DW）卷积与 Point-wise（PW）卷积，合起来被称作 Depth-wise Separable Convolution（深度可分离卷积），该结构和常规卷积操作类似，可用来提取特征，但相比于常规卷积操作，其&lt;strong&gt;参数量和运算成本较低&lt;/strong&gt;。所以在一些轻量级网络中会碰到这种结构，如 MobileNet。&lt;/p&gt;
&lt;p&gt;Depth-wise Convolution 的一个卷积核负责一个通道，即一个通道只被一个单通道的卷积核卷积，而常规卷积每个卷积核是同时操作输入图片的每个通道，即每个卷积核的通道数与图片的通道数相同。&lt;/p&gt;
&lt;p&gt;Depth-wise Convolution 完成后的 Feature Map 数量与输入层的通道数相同，无法扩展 Feature Map。而且这种运算对输入层的每个通道&lt;strong&gt;独立&lt;/strong&gt;进行卷积运算，没有有效地利用不同通道在相同空间位置上的特征信息。因此需要Point-wise Convolution 来将这些 Feature Map 进行组合生成新的 Feature Map。&lt;/p&gt;
&lt;p&gt;Depth-wise Convolution 代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Depth-wise卷积，输出维度和输入维度相同&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;DWConv2d&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_channels, dropout=&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 当groups=in_channels时，是在做Depth-wise Conv&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv = nn.Conv2d(in_channels, in_channels, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, groups=in_channels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.dropout = nn.Dropout2d(p=dropout, inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# x.shape: (bsz, c, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.dropout(self.conv(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; out  &lt;span class=&#34;comment&#34;&gt;# out.shape: (bsz, c, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dwconv2d = DWConv2d(in_channels=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.randn(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(dwconv2d(x).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 3, 10, 10])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Point-wise Convolution 的运算与常规卷积运算非常相似，它的卷积核的尺寸为 1 × 1 × M，M 为输入图像的通道数。所以这里的卷积运算会将上一步的 Feature Map &lt;strong&gt;在深度方向上进行加权组合&lt;/strong&gt;，生成新的 Feature Map。有几个卷积核就有几个输出 Feature Map。&lt;/p&gt;
&lt;p&gt;Point-wise Convolution 代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Point-wise卷积，输出维度可以改变&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;PWConv2d&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_channels, out_channels, dropout=&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv = nn.Conv2d(in_channels, out_channels, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.dropout = nn.Dropout2d(p=dropout, inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# x.shape: (bsz, c, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.dropout(self.conv(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; out  &lt;span class=&#34;comment&#34;&gt;# out.shape: (bsz, c&amp;#x27;, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pwconv2d = PWConv2d(in_channels=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.randn(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pwconv2d(x).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 4, 10, 10])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Depth-wise 卷积对每个输入通道独立执行空间卷积，而 Point-wise 卷积用于组合 Depth-wise 卷积的输出。将两者组合起来即为深度可分离卷积神经网络：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;DepthwiseSeparableConv2d&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_channels, out_channels, dropout=&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.dwconv2d = DWConv2d(in_channels, dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.pwconv2d = PWConv2d(in_channels, out_channels, dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# x.shape: (bsz, c, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.pwconv2d(self.dwconv2d(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; out  &lt;span class=&#34;comment&#34;&gt;# out.shape: (bsz, c&amp;#x27;, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;depthwiseseparableconv2d = DepthwiseSeparableConv2d(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.randn(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(depthwiseseparableconv2d(x).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 4, 10, 10])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;1-2-DropPath&#34;&gt;1.2 DropPath&lt;/h3&gt;
&lt;p&gt;DropPath 是一种针对&lt;strong&gt;分支&lt;/strong&gt;网络而提出的网络正则化方法，作用是将深度学习网络中的多分支结构随机删除。DropPath 作用的是网络分支，而 DropOut 作用的是 Feature Map，DropConnect 作用的是参数。&lt;/p&gt;
&lt;p&gt;简单来说，DropPath 的输出是随机将一个 batch 中所有的神经元均设置为0；而在 DropOut 中，是在每个 batch 中随机选择神经元设置为0。&lt;/p&gt;
&lt;p&gt;DropPath 代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;DropPath&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, drop_prob=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, batch_dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(DropPath, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.drop_prob = drop_prob  &lt;span class=&#34;comment&#34;&gt;# 丢弃率，假设是0.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.batch_dim = batch_dim  &lt;span class=&#34;comment&#34;&gt;# batch在第几维，假设是0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.drop_path(x, self.drop_prob)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;drop_path&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x, drop_prob&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# x.shape: (hw, bsz, c)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 丢弃率为0或者不是在训练时直接返回x&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; drop_prob == &lt;span class=&#34;number&#34;&gt;0.&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; self.training:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        keep_prob = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; - drop_prob  &lt;span class=&#34;comment&#34;&gt;# 保持率，0.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        shape = [&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; _ &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(x.ndim)]  &lt;span class=&#34;comment&#34;&gt;# [1, 1, 1]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        shape[self.batch_dim] = x.shape[self.batch_dim]  &lt;span class=&#34;comment&#34;&gt;# [bsz, 1, 1]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)  &lt;span class=&#34;comment&#34;&gt;# 0~1之间的均匀分布&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        random_tensor.floor_()  &lt;span class=&#34;comment&#34;&gt;# 下取整，随机出来的大于等于0.5的数都为1，确定保留哪些batch&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = x.div(keep_prob) * random_tensor  &lt;span class=&#34;comment&#34;&gt;# 除以keep_prob是为了让训练和测试时的期望保持一致&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;droppath = DropPath(drop_prob=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, batch_dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;a = torch.randn(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(droppath(a))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[-0.6209, -5.4889, -1.9857],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [ 0.1626,  6.0644,  0.8875]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[ 0.0000, -0.0000,  0.0000],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [ 0.0000, -0.0000,  0.0000]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[-0.1041,  0.4921,  0.3389],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [-2.0490, -0.0399, -0.1521]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;1-3-Group-Normalization&#34;&gt;1.3 Group Normalization&lt;/h3&gt;
&lt;p&gt;BN 全名是 Batch Normalization，见名知意，其是一种归一化方式，而且是以 batch 的维度做归一化，那么问题就来了，此归一化方式如果使用过小的 batch size 会导致其性能下降，一般来说每个 GPU 上的 batch size 设为32最合适，但是对于一些其他深度学习任务 batch size 往往只有1或2，比如目标检测，图像分割，视频分类上，输入的图像数据很大，较大的 batch size 显存吃不消。&lt;/p&gt;
&lt;p&gt;另外，Batch Normalization 是在 batch 这个维度上做 Normalization，但是这个维度并&lt;strong&gt;不是固定不变的&lt;/strong&gt;，比如训练和测试时一般不一样，一般都是训练的时候在训练集上通过&lt;strong&gt;滑动平均&lt;/strong&gt;预先计算好平均（mean），和方差（variance）参数，在测试的时候，不再计算这些值，而是直接调用这些预计算好的参数来用。但是，当训练数据和测试数据分布有差别时，训练机上预计算好的数据并不能代表测试数据，这就导致在训练、验证、测试这三个阶段存在 inconsistency（不一致性）。&lt;/p&gt;
&lt;p&gt;Group Normalization（GN）首先将 channel 分为许多组（group），对每一组做归一化，即先将 feature 的维度由 &lt;code&gt;[N, C, H, W]&lt;/code&gt; reshape 为 &lt;code&gt;[N, G, C/G, H, W]&lt;/code&gt;，归一化的维度为 &lt;code&gt;[C/G, H, W]&lt;/code&gt;。事实上，GN 的极端情况就是 LN（Layer Normalization）和 IN（Instance Normalization），分别对应 &lt;code&gt;G = 1&lt;/code&gt; 和 &lt;code&gt;G = C&lt;/code&gt;，作者在论文中给出 G 设为32较好。&lt;/p&gt;
&lt;p&gt;Group Normalization 代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 自己实现GN&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;GroupNorm&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, num_channels, num_groups=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, eps=&lt;span class=&#34;number&#34;&gt;1e-5&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(GroupNorm, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.gamma = nn.Parameter(torch.ones(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, num_groups, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.beta = nn.Parameter(torch.zeros(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, num_groups, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.num_groups = num_groups&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.eps = eps&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# x.shape: (N, C, H, W)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        N, C, H, W = x.size()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        G = self.num_groups&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; C % G == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = x.view(N, G, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        mean = x.mean(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, keepdim=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        std = x.std(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, keepdim=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.gamma * (x - mean) / (std + self.eps) + self.beta&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = x.view(N, C, H, W)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.randn(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gn = GroupNorm(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_gn = gn(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x_gn)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[[-0.1165, -0.5803,  0.7635],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [-0.2374, -1.3281,  1.4988]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [[ 0.0982, -0.3936, -1.3941],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [-0.5678,  1.2321,  1.0253]]]], grad_fn=&amp;lt;ViewBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x_gn.mean((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)))  &lt;span class=&#34;comment&#34;&gt;# tensor([[-4.9671e-09,  9.9341e-09]], grad_fn=&amp;lt;MeanBackward1&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x_gn.var((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)))  &lt;span class=&#34;comment&#34;&gt;# tensor([[1.0000, 1.0000]], grad_fn=&amp;lt;VarBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 使用torch.nn中的GN&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch_gn = nn.GroupNorm(num_groups=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, num_channels=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_torch_gn = torch_gn(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x_torch_gn)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[[-0.1277, -0.6357,  0.8363],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [-0.2601, -1.4548,  1.6419]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [[ 0.1076, -0.4312, -1.5272],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [-0.6220,  1.3497,  1.1232]]]], grad_fn=&amp;lt;NativeGroupNormBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x_torch_gn.mean((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)))  &lt;span class=&#34;comment&#34;&gt;# tensor([[-2.9802e-08,  1.9868e-08]], grad_fn=&amp;lt;MeanBackward1&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x_torch_gn.var((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)))  &lt;span class=&#34;comment&#34;&gt;# tensor([[1.2000, 1.2000]], grad_fn=&amp;lt;VarBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;1-4-FPN特征金字塔网络&#34;&gt;1.4 FPN特征金字塔网络&lt;/h3&gt;
&lt;p&gt;目标的多尺度一直是目标检测算法极为棘手的问题。像 Fast R-CNN，YOLO 这些只是利用深层网络进行检测的算法，是很难把小目标物体检测好的。因为小目标物体本身的像素就比较少，随着下采样的累积，它的特征更容易被丢失。&lt;/p&gt;
&lt;p&gt;特征金字塔网络（Feature Pyramid Network，FPN）是一个在特征尺度的金字塔操作，它是通过将&lt;strong&gt;自底向上&lt;/strong&gt;（Bottom-up）和&lt;strong&gt;自顶向下&lt;/strong&gt;（Top-down）的特征图进行&lt;strong&gt;融合&lt;/strong&gt;来实现特征金字塔操作的。FPN 提供的是一个特征融合的机制，并没有引入太多的参数，实现了以增加极小计算代价的情况下提升对多尺度目标的检测能力。&lt;/p&gt;
&lt;p&gt;自底向上即是卷积网络的前向过程，我们可以选择不同的骨干网络，例如 ResNet-50 或者 ResNet-101。前向网络的返回值依次是 C2、C3、C4、C5，是每次池化之后得到的 Feature Map。&lt;/p&gt;
&lt;p&gt;通过自底向上路径，FPN 得到了四组 Feature Map。浅层的 Feature Map，例如 C2 含有更多的底层信息（纹理，颜色等），而深层的 Feature Map 如 C5 含有更多的语义信息。为了将这四组倾向不同特征的 Feature Map 组合起来，FPN 使用了自顶向下及&lt;strong&gt;横向连接&lt;/strong&gt;的策略，最终得到 P2、P3、P4、P5 四个输出。&lt;/p&gt;
&lt;p&gt;最后，FPN 在 P2、P3、P4、P5 之后均接了一个 3*3 Conv 操作，该卷积操作是为了减轻上采样的&lt;strong&gt;混叠效应&lt;/strong&gt;（aliasing effect）。&lt;/p&gt;
&lt;p&gt;FPN 和 U-Net 最大的不同是它的多个层级的都会有各自的输出层，而每个输出层都有不同尺度的感受野。一个比较粗暴的方式是每一层都预测所有的样本，而另一个更好的选择是根据一些可能存在的先验知识选择一个最好的层。&lt;/p&gt;
&lt;p&gt;FPN 代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;114&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;115&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;116&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;117&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;118&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;119&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;120&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;121&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;122&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;123&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;124&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;125&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;126&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; math&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn.functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Bottleneck&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    expansion = &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;  &lt;span class=&#34;comment&#34;&gt;# 残差块第3个卷积层的通道膨胀倍率&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_channels, channels, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, downsample=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Bottleneck, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bn1 = nn.BatchNorm2d(channels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv2 = nn.Conv2d(channels, channels, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=stride, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bn2 = nn.BatchNorm2d(channels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv3 = nn.Conv2d(channels, self.expansion * channels, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bn3 = nn.BatchNorm2d(self.expansion * channels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.relu = nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.downsample = downsample&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.stride = stride&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        residual = x  &lt;span class=&#34;comment&#34;&gt;# 将原始输入暂存为shortcut的输出&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; self.downsample &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:  &lt;span class=&#34;comment&#34;&gt;# 如果需要下采样，那么shortcut后：H/2，W/2。C：out_channel -&amp;gt; 4 * out_channel&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            residual = self.downsample(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.relu(self.bn1(self.conv1(x)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.relu(self.bn2(self.conv2(out)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.bn3(self.conv3(out))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out += residual  &lt;span class=&#34;comment&#34;&gt;# 残差连接&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.relu(out)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; out&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;FPN&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, block, layers&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(FPN, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.inchannels = &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bn1 = nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.relu = nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.maxpool = nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# Bottom-up layers&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.layer1 = self._make_layer(block, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, layers[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.layer2 = self._make_layer(block, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, layers[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.layer3 = self._make_layer(block, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, layers[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.layer4 = self._make_layer(block, &lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;, layers[&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# Top layer&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.toplayer = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;2048&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# Reduce channels&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# Lateral layers&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.latlayer1 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1024&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.latlayer2 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.latlayer3 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# Smooth layers&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.smooth1 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.smooth2 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.smooth3 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; m &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self.modules():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(m, nn.Conv2d):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                n = m.kernel_size[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] * m.kernel_size[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] * m.out_channels&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                m.weight.data.normal_(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, math.sqrt(&lt;span class=&#34;number&#34;&gt;2.&lt;/span&gt; / n))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(m, nn.BatchNorm2d):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                m.weight.data.fill_(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                m.bias.data.zero_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;_make_layer&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, block, channel, block_num, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        downsample = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; stride != &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; self.inchannels != channel * block.expansion:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            downsample = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.Conv2d(self.inchannels, block.expansion * channel, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=stride, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                nn.BatchNorm2d(block.expansion * channel)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        layers = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        layers.append(block(self.inchannels, channel, stride, downsample))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.inchannels = channel * block.expansion&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, block_num):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            layers.append(block(self.inchannels, channel))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Sequential(*layers)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;_upsample_add&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x, y&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# 将x上采样成y的size后与y相加&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        _, _, H, W = y.size()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; F.interpolate(x, size=(H, W), mode=&lt;span class=&#34;string&#34;&gt;&amp;#x27;bilinear&amp;#x27;&lt;/span&gt;) + y&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# (bsz, 3, h, w)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# Bottom-up&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.conv1(x)  &lt;span class=&#34;comment&#34;&gt;# (bsz, 64, h/2, w/2)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.bn1(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = self.relu(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        c1 = self.maxpool(x)  &lt;span class=&#34;comment&#34;&gt;# (bsz, 64, h/4, w/4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        c2 = self.layer1(c1)  &lt;span class=&#34;comment&#34;&gt;# (bsz, 256, h/4, w/4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        c3 = self.layer2(c2)  &lt;span class=&#34;comment&#34;&gt;# (bsz, 512, h/8, w/8)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        c4 = self.layer3(c3)  &lt;span class=&#34;comment&#34;&gt;# (bsz, 1024, h/16, w/16)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        c5 = self.layer4(c4)  &lt;span class=&#34;comment&#34;&gt;# (bsz, 2048, h/32, w/32)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# Top-down&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p5 = self.toplayer(c5)  &lt;span class=&#34;comment&#34;&gt;# (bsz, 256, h/32, w/32)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p4 = self._upsample_add(p5, self.latlayer1(c4))  &lt;span class=&#34;comment&#34;&gt;# (bsz, 256, h/16, w/16)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p3 = self._upsample_add(p4, self.latlayer2(c3))  &lt;span class=&#34;comment&#34;&gt;# (bsz, 256, h/8, w/8)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p2 = self._upsample_add(p3, self.latlayer3(c2))  &lt;span class=&#34;comment&#34;&gt;# (bsz, 256, h/4, w/4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# Smooth&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p4 = self.smooth1(p4)  &lt;span class=&#34;comment&#34;&gt;# (bsz, 256, h/16, w/16)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p3 = self.smooth2(p3)  &lt;span class=&#34;comment&#34;&gt;# (bsz, 256, h/8, w/8)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p2 = self.smooth3(p2)  &lt;span class=&#34;comment&#34;&gt;# (bsz, 256, h/4, w/4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; p2, p3, p4, p5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;FPN101&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; FPN(Bottleneck, [&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;fpn_101 = FPN101()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.randn(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output_p2, output_p3, output_p4, output_p5 = fpn_101(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output_p2.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 256, 64, 64])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output_p3.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 256, 32, 32])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output_p4.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 256, 16, 16])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output_p5.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 256, 8, 8])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-半监督VOS与AOT模型&#34;&gt;2. 半监督VOS与AOT模型&lt;/h2&gt;
&lt;h3 id=&#34;2-1-VOS与AOT简介&#34;&gt;2.1 VOS与AOT简介&lt;/h3&gt;
&lt;p&gt;视频对象分割（VOS）旨在识别和分割给定视频中的一个或多个感兴趣的对象，半监督 VOS 需要算法在给定一帧或多帧的&lt;strong&gt;对象注释掩码&lt;/strong&gt;的情况下跟踪和分割整个视频序列中的对象。&lt;/p&gt;
&lt;p&gt;此前最先进的方法学习用单个正目标解码特征，因此必须在多目标场景下单独匹配和分割每个目标，消耗多倍的计算资源。我们提出 Associating Objects with Transformers（AOT）方法来&lt;strong&gt;统一匹配和解码多个对象&lt;/strong&gt;。AOT 采用 Identification 机制将&lt;strong&gt;多个目标&lt;/strong&gt;关联到&lt;strong&gt;同一高维嵌入空间&lt;/strong&gt;中。因此可以像处理单个对象一样高效地同时处理多个对象的匹配和分割解码。&lt;/p&gt;
&lt;p&gt;AOT 方法将&lt;strong&gt;分层传播&lt;/strong&gt;引入到 VOS 中。分层传播可以逐渐将 ID 信息从过去的帧传播到当前帧，并将当前帧的特征从 object-agnostic（对象不可知）转移到 object-specific（对象特定）。&lt;/p&gt;
&lt;h3 id=&#34;2-2-ID-机制&#34;&gt;2.2 ID 机制&lt;/h3&gt;
&lt;p&gt;ID 机制为每个目标分配唯一的 ID 信息，并将任意数量（要求小于预定义的大量）目标的 mask 嵌入到同一高维空间中。因此，网络可以学习所有目标之间的关联或相关性。此外，可以利用分配的 ID 信息直接解码多对象分割。&lt;/p&gt;
&lt;p&gt;我们初始化一个身份库（ID Bank），其中存储 M 个具有 C 维的识别向量。为了嵌入多个不同的目标掩码，每个目标将被&lt;strong&gt;随机&lt;/strong&gt;分配一个不同的识别向量。&lt;/p&gt;
&lt;h3 id=&#34;2-3-Long-Short-Term-Transformer（LSTT）&#34;&gt;2.3 Long Short-Term Transformer（LSTT）&lt;/h3&gt;
&lt;p&gt;本文设计长短期 Transformer（LSTT）用于构建&lt;strong&gt;分层对象匹配和传播&lt;/strong&gt;。每个 LSTT 块都利用&lt;strong&gt;长期注意力&lt;/strong&gt;来匹配&lt;strong&gt;第一帧&lt;/strong&gt;的嵌入，并利用&lt;strong&gt;短期注意力&lt;/strong&gt;来匹配&lt;strong&gt;多个附近帧&lt;/strong&gt;的嵌入。与仅利用一个注意力层的方法相比，我们发现分层注意力结构在&lt;strong&gt;关联多个对象&lt;/strong&gt;方面更有效。&lt;/p&gt;
&lt;p&gt;LSTT 首先采用自注意力层，负责学习&lt;strong&gt;当前帧内目标之间&lt;/strong&gt;的关联或相关性。此外，LSTT 还引入了长期注意力和短期注意力，前者用于聚合来自长期&lt;strong&gt;记忆帧的目标信息&lt;/strong&gt;，后者能够从邻近的短期帧学习&lt;strong&gt;时间平滑性&lt;/strong&gt;。所有注意力模块都是以&lt;strong&gt;多头注意力&lt;/strong&gt;的形式实现的，即多个注意力模块后跟串联和线性投影。&lt;/p&gt;
&lt;p&gt;长期注意力负责将目标的信息从过去的记忆帧（包含参考帧和存储的预测帧）聚合到当前帧。由于当前帧和过去帧之间的时间间隔是可变的并且可以是长期的，因此&lt;strong&gt;时间平滑性难以保证&lt;/strong&gt;。因此，长期注意力采用&lt;strong&gt;非局部&lt;/strong&gt;注意力。&lt;/p&gt;
&lt;p&gt;短期注意力用于聚合每个当前帧位置的时空邻域中的信息。直观上，多个连续视频帧之间的图像变化始终是&lt;strong&gt;平滑且连续&lt;/strong&gt;的。因此，连续帧中的目标匹配和传播可以&lt;strong&gt;限制在小的时空邻域内&lt;/strong&gt;，从而比非局部过程具有更好的效率。&lt;/p&gt;
&lt;h2 id=&#34;三、DeAOT&#34;&gt;三、DeAOT&lt;/h2&gt;
&lt;p&gt;本文重点是为&lt;strong&gt;半监督视频对象分割&lt;/strong&gt;（VOS）开发一种更有效的分层传播方法。在 AOT 方法中 object-specific 信息的增加将不可避免地导致深层传播层中 object-agnostic 的视觉信息的丢失。为了解决这样的问题并进一步促进视觉嵌入的学习，本文提出了一种&lt;strong&gt;分层传播中的解耦特征&lt;/strong&gt;（DeAOT）方法。DeAOT 通过在两个&lt;strong&gt;独立&lt;/strong&gt;的分支中处理 object-agnostic 和 object-specific 的嵌入来解耦它们的分层传播。其次，为了补偿双分支传播的额外计算，设计了一种用于构造分层传播的有效模块 GPM（门控传播模块），它是通过&lt;strong&gt;单头注意力&lt;/strong&gt;精心设计的。&lt;/p&gt;
&lt;h3 id=&#34;3-1-分层双分支传播&#34;&gt;3.1 分层双分支传播&lt;/h3&gt;
&lt;p&gt;DeAOT 在两个&lt;strong&gt;并行分支&lt;/strong&gt;中传播对象的视觉特征（visual features）和掩码（mask features）特征。具体来说，视觉分支负责匹配对象、收集过去的视觉信息并提炼对象特征。为了重新识别对象，ID 分支&lt;strong&gt;重用&lt;/strong&gt;视觉分支计算的&lt;strong&gt;匹配图&lt;/strong&gt;（注意力图），将 ID 嵌入（由 AOT 中的 ID 机制编码）从过去的帧传播到当前帧。两个分支共享相同的具有 L 个传播层的层次结构。&lt;/p&gt;
&lt;h3 id=&#34;3-2-门控传播模块GPM&#34;&gt;3.2 门控传播模块GPM&lt;/h3&gt;
&lt;p&gt;门控传播函数首先通过使用&lt;strong&gt;条件门&lt;/strong&gt;来增强基于注意力的传播，此外，我们利用 Depth-wise 卷积以&lt;strong&gt;轻量级&lt;/strong&gt;方式增强局部空间上下文的建模。&lt;/p&gt;
&lt;p&gt;门控传播模块由三种门控传播组成：自传播、长期传播、短期传播。与 LSTT 相比，GPM 去掉了前馈模块，进一步节省了计算量和参数。所有传播过程都采用门控传播函数。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/6211.html</guid>
            <title>Kaggle项目实战</title>
            <link>https://asanosaki.github.io/posts/6211.html</link>
            <category>AI</category>
            <pubDate>Tue, 30 May 2023 09:45:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;记录 Kaggle 中的一些经典竞赛，也当做自己的练手小项目。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-实战Kaggle比赛：预测房价&#34;&gt;1. 实战Kaggle比赛：预测房价&lt;/h2&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;114&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;115&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;116&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;117&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;118&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;119&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;120&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;121&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;122&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;123&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;124&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;125&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;126&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;127&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;128&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;129&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;130&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;131&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;132&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;133&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;134&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;135&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;136&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;137&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;138&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;139&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;140&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;141&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;142&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;143&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;144&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;145&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;146&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;147&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;148&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;149&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;150&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;151&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;152&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;153&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;154&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;155&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;156&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;157&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;158&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;159&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;160&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;161&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;162&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;163&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;164&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;165&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;166&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;167&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;168&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;169&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;170&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;171&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;172&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;173&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;174&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;175&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 比赛链接：https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; hashlib&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tarfile&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; zipfile&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; requests&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; pandas &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;DATA_HUB = &lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;DATA_URL = &lt;span class=&#34;string&#34;&gt;&amp;#x27;http://d2l-data.s3-accelerate.amazonaws.com/&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;download&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;name, cache_dir=os.path.join(&lt;span class=&#34;params&#34;&gt;&lt;span class=&#34;string&#34;&gt;&amp;#x27;..&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;data&amp;#x27;&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;下载一个DATA_HUB中的文件，返回本地文件名&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; name &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; DATA_HUB, &lt;span class=&#34;string&#34;&gt;f&amp;quot;&lt;span class=&#34;subst&#34;&gt;&amp;#123;name&amp;#125;&lt;/span&gt; 不存在于 &lt;span class=&#34;subst&#34;&gt;&amp;#123;DATA_HUB&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    url, sha1_hash = DATA_HUB[name]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    os.makedirs(cache_dir, exist_ok=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fname = os.path.join(cache_dir, url.split(&lt;span class=&#34;string&#34;&gt;&amp;#x27;/&amp;#x27;&lt;/span&gt;)[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; os.path.exists(fname):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        sha1 = hashlib.sha1()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(fname, &lt;span class=&#34;string&#34;&gt;&amp;#x27;rb&amp;#x27;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                data = f.read(&lt;span class=&#34;number&#34;&gt;1048576&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; data:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    &lt;span class=&#34;keyword&#34;&gt;break&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                sha1.update(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; sha1.hexdigest() == sha1_hash:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; fname  &lt;span class=&#34;comment&#34;&gt;# 命中缓存&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;正在从&lt;span class=&#34;subst&#34;&gt;&amp;#123;url&amp;#125;&lt;/span&gt;下载&lt;span class=&#34;subst&#34;&gt;&amp;#123;fname&amp;#125;&lt;/span&gt;...&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    r = requests.get(url, stream=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, verify=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(fname, &lt;span class=&#34;string&#34;&gt;&amp;#x27;wb&amp;#x27;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        f.write(r.content)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; fname&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;download_extract&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;name, folder=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;下载并解压zip/tar文件&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fname = download(name)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    base_dir = os.path.dirname(fname)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    data_dir, ext = os.path.splitext(fname)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; ext == &lt;span class=&#34;string&#34;&gt;&amp;#x27;.zip&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        fp = zipfile.ZipFile(fname, &lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; ext &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; (&lt;span class=&#34;string&#34;&gt;&amp;#x27;.tar&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;.gz&amp;#x27;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        fp = tarfile.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(fname, &lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;只有zip/tar文件可以被解压缩&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fp.extractall(base_dir)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; os.path.join(base_dir, folder) &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; folder &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; data_dir&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;download_all&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;下载DATA_HUB中的所有文件&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; name &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; DATA_HUB:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        download(name)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 下载并缓存Kaggle房屋数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;DATA_HUB[&lt;span class=&#34;string&#34;&gt;&amp;#x27;kaggle_house_train&amp;#x27;&lt;/span&gt;] = (DATA_URL + &lt;span class=&#34;string&#34;&gt;&amp;#x27;kaggle_house_pred_train.csv&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;585e9cc93e70b39160e7921475f9bcd7d31219ce&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;DATA_HUB[&lt;span class=&#34;string&#34;&gt;&amp;#x27;kaggle_house_test&amp;#x27;&lt;/span&gt;] = (DATA_URL + &lt;span class=&#34;string&#34;&gt;&amp;#x27;kaggle_house_pred_test.csv&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 使用pandas分别加载包含训练数据和测试数据的两个CSV文件&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_data = pd.read_csv(download(&lt;span class=&#34;string&#34;&gt;&amp;#x27;kaggle_house_train&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = pd.read_csv(download(&lt;span class=&#34;string&#34;&gt;&amp;#x27;kaggle_house_test&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练数据集包括1460个样本，每个样本80个特征和1个标签，而测试数据集包含1459个样本，每个样本80个特征&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(train_data.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(test_data.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 看看前四个和最后两个特征，以及相应标签（房价）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(train_data.iloc[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 在每个样本中，第一个特征是ID，这有助于模型识别每个训练样本。虽然这很方便，但它不携带任何用于预测的信息。因此，在将数据提供给模型之前，我们将其从数据集中删除&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;all_features = pd.concat((train_data.iloc[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], test_data.iloc[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:]))  &lt;span class=&#34;comment&#34;&gt;# train数据的最后一列为label&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 在开始建模之前，我们需要对数据进行预处理。首先，我们将所有缺失的值替换为相应特征的平均值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 若无法获得测试数据，则可根据训练数据计算均值和标准差&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;numeric_features = all_features.dtypes[all_features.dtypes != &lt;span class=&#34;string&#34;&gt;&amp;#x27;object&amp;#x27;&lt;/span&gt;].index  &lt;span class=&#34;comment&#34;&gt;# 数值类型特征的下标&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;all_features[numeric_features] = all_features[numeric_features].apply(&lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; x: (x - x.mean()) / (x.std()))  &lt;span class=&#34;comment&#34;&gt;# 将所有数值特征的均值变成0，方差变成1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;all_features[numeric_features] = all_features[numeric_features].fillna(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 接下来，我们处理离散值。这包括诸如“MSZoning”之类的特征。我们用独热编码替换它们，pandas软件包会自动为我们实现这一点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# dummy_na=True将&amp;#x27;na&amp;#x27;（缺失值）视为有效的特征值，并为其创建指示符特征&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;all_features = pd.get_dummies(all_features, dummy_na=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(all_features.shape)  &lt;span class=&#34;comment&#34;&gt;# (2919, 331)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 通过values属性，我们可以从pandas格式中提取NumPy格式，并将其转换为张量表示用于训练&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;n_train = train_data.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_labels = torch.tensor(train_data.SalePrice.values.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), dtype=torch.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = nn.MSELoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;in_features = train_features.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Linear(in_features, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.Dropout(&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.Linear(&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 房价就像股票价格一样，我们关心的是相对数量，而不是绝对数量，我们更关心相对误差，即：(真实值-预测值)/真实值，解决这个问题的一种方法是用价格预测的对数来衡量差异&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;log_rmse&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, features, labels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 为了在取对数时进一步稳定该值，将小于1的值设置为1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    clipped_preds = torch.clamp(net(features), &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;inf&amp;#x27;&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# 将inf变成1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    rmse = torch.sqrt(loss_function(torch.log(clipped_preds), torch.log(labels)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; rmse.item()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;load_array&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;data_arrays, batch_size, is_train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    dataset = data.TensorDataset(*data_arrays)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; data.DataLoader(dataset, batch_size, shuffle=is_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_ls, test_ls = [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_iter = load_array((train_features, train_labels), batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)  &lt;span class=&#34;comment&#34;&gt;# 这里使用的是Adam优化算法&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; train_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss = loss_function(net(X), y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_ls.append(log_rmse(net, train_features, train_labels))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; test_labels &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            test_ls.append(log_rmse(net, test_features, test_labels))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; train_ls, test_ls&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# K折交叉验证，有助于模型选择和超参数调整，首先需要定义一个函数，在K折交叉验证过程中返回第i折的数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;get_k_fold_data&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;k, i, X, y&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; k &amp;gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fold_size = X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] // k  &lt;span class=&#34;comment&#34;&gt;# 每一折的大小&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    X_train, y_train = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; j &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(k):  &lt;span class=&#34;comment&#34;&gt;# 分成k份&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        idx = &lt;span class=&#34;built_in&#34;&gt;slice&lt;/span&gt;(j * fold_size, (j + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) * fold_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X_part, y_part = X[idx, :], y[idx]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; j == i:  &lt;span class=&#34;comment&#34;&gt;# 将第i折的数据作为验证数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            X_valid, y_valid = X_part, y_part&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; X_train &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            X_train, y_train = X_part, y_part&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            X_train = torch.cat([X_train, X_part], &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            y_train = torch.cat([y_train, y_part], &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X_train, y_train, X_valid, y_valid&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;k_fold&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_l_sum, valid_l_sum = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(k):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        data = get_k_fold_data(k, i, X_train, y_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_l_sum += train_ls[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_l_sum += valid_ls[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;折&lt;span class=&#34;subst&#34;&gt;&amp;#123;i + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&amp;#125;&lt;/span&gt;，训练log rmse: &lt;span class=&#34;subst&#34;&gt;&amp;#123;&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(train_ls[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]):f&amp;#125;&lt;/span&gt;，验证log rmse: &lt;span class=&#34;subst&#34;&gt;&amp;#123;&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(valid_ls[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]):f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; train_l_sum / k, valid_l_sum / k&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;k, num_epochs, lr, weight_decay, batch_size = &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;250&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1e-3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;k&amp;#125;&lt;/span&gt;-折验证: 平均训练log rmse: &lt;span class=&#34;subst&#34;&gt;&amp;#123;&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(train_l):f&amp;#125;&lt;/span&gt;，&amp;#x27;&lt;/span&gt;&lt;span class=&#34;string&#34;&gt;f&amp;#x27;平均验证log rmse: &lt;span class=&#34;subst&#34;&gt;&amp;#123;&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(valid_l):f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 使用所有数据对其进行训练&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train_and_pred&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_ls, _ = train(net, train_features, train_labels, &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, num_epochs, lr, weight_decay, batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;训练log rmse: &lt;span class=&#34;subst&#34;&gt;&amp;#123;&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(train_ls[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]):f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 将网络应用于测试集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    preds = net(test_features).detach().numpy()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 将其重新格式化以导出到Kaggle，将预测保存在CSV文件中可以简化将结果上传到Kaggle的过程&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_data[&lt;span class=&#34;string&#34;&gt;&amp;#x27;SalePrice&amp;#x27;&lt;/span&gt;] = pd.Series(preds.reshape(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    submission = pd.concat([test_data[&lt;span class=&#34;string&#34;&gt;&amp;#x27;Id&amp;#x27;&lt;/span&gt;], test_data[&lt;span class=&#34;string&#34;&gt;&amp;#x27;SalePrice&amp;#x27;&lt;/span&gt;]], axis=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    submission.to_csv(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../data/submission.csv&amp;#x27;&lt;/span&gt;, index=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/39408.html</guid>
            <title>动手学深度学习笔记(李沐)-注意力机制</title>
            <link>https://asanosaki.github.io/posts/39408.html</link>
            <category>AI</category>
            <pubDate>Sun, 21 May 2023 17:57:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;李沐动手学深度学习（PyTorch）课程学习笔记第十章：注意力机制。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-注意力提示&#34;&gt;1. 注意力提示&lt;/h2&gt;
&lt;p&gt;注意力机制（Attention Mechanism）是人们在机器学习模型中嵌入的一种特殊结构，用来自动学习和计算&lt;strong&gt;输入数据对输出数据的贡献&lt;/strong&gt;大小。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;非自主性提示&lt;/strong&gt;是基于环境中物体的突出性和易见性。想象一下，假如我们面前有五个物品：一份报纸、一篇研究论文、一杯咖啡、一本笔记本和一本书，所有纸制品都是黑白印刷的，但咖啡杯是红色的。换句话说，这个咖啡杯在这种视觉环境中是突出和显眼的，不由自主地引起人们的注意，所以我们会把视力最敏锐的地方放到咖啡上。喝咖啡后，我们会变得兴奋并想读书，所以转过头，重新聚焦眼睛，然后看看书，与咖啡杯是由于突出性导致的选择不同，此时选择书是受到了&lt;strong&gt;认知和意识&lt;/strong&gt;的控制，因此注意力在基于&lt;strong&gt;自主性提示&lt;/strong&gt;去辅助选择时将更为谨慎。受试者的主观意愿推动，选择的力量也就更强大。自主性的与非自主性的注意力提示解释了人类的注意力的方式，下面来看看如何通过这两种注意力提示，用神经网络来设计注意力机制的框架。&lt;/p&gt;
&lt;p&gt;首先，考虑一个相对简单的状况，即只使用非自主性提示。要想将选择偏向于感官输入，则可以简单地使用参数化的全连接层，甚至是非参数化的最大汇聚层或平均汇聚层。&lt;/p&gt;
&lt;p&gt;因此，“是否包含自主性提示”将注意力机制与全连接层或汇聚层区别开来。在注意力机制的背景下，自主性提示被称为&lt;strong&gt;查询&lt;/strong&gt;（query）。给定任何查询，注意力机制通过注意力汇聚（attention pooling）将选择引导至感官输入（sensory inputs，例如中间特征表示）。在注意力机制中，这些感官输入被称为&lt;strong&gt;值&lt;/strong&gt;（value）。更通俗的解释，每个值都与一个&lt;strong&gt;键&lt;/strong&gt;（key）配对，这可以想象为感官输入的非自主提示。可以通过设计注意力汇聚的方式，便于给定的查询（自主性提示）与键（非自主性提示）进行匹配，这将引导得出最匹配的值（感官输入）。&lt;/p&gt;
&lt;p&gt;平均汇聚层可以被视为输入的加权平均值，其中各输入的权重是一样的。实际上，注意力汇聚得到的是加权平均的总和值，其中权重是在给定的查询和不同的键之间计算得出的。为了可视化注意力权重，需要定义一个 &lt;code&gt;show_heatmaps&lt;/code&gt; 函数，其输入 &lt;code&gt;matrices&lt;/code&gt; 的形状是 &lt;code&gt;(要显示的行数, 要显示的列数, 查询的数目, 键的数目)&lt;/code&gt;。下面使用一个简单的例子进行演示，在本例子中，仅当查询和键相同时，注意力权重为1，否则为0：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;show_heatmaps&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;matrices, xlabel, ylabel, titles=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, figsize=(&lt;span class=&#34;params&#34;&gt;&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;&lt;/span&gt;), cmap=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Reds&amp;#x27;&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;显示矩阵热图&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    d2l.use_svg_display()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_rows, num_cols = matrices.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], matrices.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize, sharex=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, sharey=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, squeeze=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, (row_axes, row_matrices) &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(axes, matrices)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; j, (ax, matrix) &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(row_axes, row_matrices)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; i == num_rows - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                ax.set_xlabel(xlabel)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; j == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                ax.set_ylabel(ylabel)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; titles:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                ax.set_title(titles[j])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fig.colorbar(pcm, ax=axes, shrink=&lt;span class=&#34;number&#34;&gt;0.6&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention_weights = torch.eye(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;).reshape((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_heatmaps(attention_weights, xlabel=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Keys&amp;#x27;&lt;/span&gt;, ylabel=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Queries&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;此外可以使用 Plotly 绘制热力图：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; plotly.graph_objects &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; go&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;show_plotly_heatmaps&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, y=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, z=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, colorscale=&lt;span class=&#34;string&#34;&gt;&amp;#x27;reds&amp;#x27;&lt;/span&gt;, width=&lt;span class=&#34;number&#34;&gt;600&lt;/span&gt;, height=&lt;span class=&#34;number&#34;&gt;600&lt;/span&gt;, title=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, xtitle=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, ytitle=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    heatmap_fig = go.Figure(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        data=[&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            go.Heatmap(x=x, y=y, z=z, colorscale=colorscale)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    heatmap_fig.update_layout(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        autosize=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, width=width, height=height,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        title=title,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        xaxis=&lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(title=xtitle), yaxis=&lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(title=ytitle),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        showlegend=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    heatmap_fig.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention_weights = torch.eye(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_plotly_heatmaps(z=attention_weights, title=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Attention Weights Heatmap&amp;#x27;&lt;/span&gt;, xtitle=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Keys&amp;#x27;&lt;/span&gt;, ytitle=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Queries&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-注意力汇聚：Nadaraya-Watson核回归&#34;&gt;2. 注意力汇聚：Nadaraya-Watson核回归&lt;/h2&gt;
&lt;p&gt;上节介绍了框架下的注意力机制的主要成分：查询（自主提示）和键（非自主提示）之间的交互形成了注意力汇聚；注意力汇聚有选择地聚合了值（感官输入）以生成最终的输出。本节将介绍注意力汇聚的更多细节，以便从宏观上了解注意力机制在实践中的运作方式。具体来说，1964年提出的 Nadaraya-Watson 核回归模型是一个简单但完整的例子，可以用于演示具有注意力机制的机器学习，其理论介绍可见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_attention-mechanisms/nadaraya-waston.html&#34;&gt;注意力汇聚：Nadaraya-Watson核回归&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;首先生成一个非线性函数的人工数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;n_train = &lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;  &lt;span class=&#34;comment&#34;&gt;# 训练样本数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_train, _ = torch.sort(torch.rand(n_train) * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 排序后的训练样本&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;f&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; * torch.sin(x) + x**&lt;span class=&#34;number&#34;&gt;0.8&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_train = f(x_train) + torch.normal(&lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, (n_train,))  &lt;span class=&#34;comment&#34;&gt;# 训练样本的输出&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_test = torch.arange(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 测试样本&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_truth = f(x_test)  &lt;span class=&#34;comment&#34;&gt;# 测试样本的真实输出&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;n_test = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(x_test)  &lt;span class=&#34;comment&#34;&gt;# 测试样本数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(n_test)  &lt;span class=&#34;comment&#34;&gt;# 50&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;函数 &lt;code&gt;plot_kernel_reg&lt;/code&gt; 将绘制所有的训练样本（样本由圆圈表示），不带噪声项的真实数据生成函数（标记为 &lt;code&gt;Truth&lt;/code&gt;），以及学习得到的预测函数（标记为 &lt;code&gt;Pred&lt;/code&gt;）。先使用最简单的估计器来解决回归问题，即基于平均汇聚来计算所有训练样本输出值的平均值：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;plot_kernel_reg&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;y_hat&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fig = go.Figure(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        data=[&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            go.Scatter(x=x_test, y=y_truth, mode=&lt;span class=&#34;string&#34;&gt;&amp;#x27;lines&amp;#x27;&lt;/span&gt;, name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Truth&amp;#x27;&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            go.Scatter(x=x_test, y=y_hat, mode=&lt;span class=&#34;string&#34;&gt;&amp;#x27;lines&amp;#x27;&lt;/span&gt;, name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Pred&amp;#x27;&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            go.Scatter(x=x_train, y=y_train, mode=&lt;span class=&#34;string&#34;&gt;&amp;#x27;markers&amp;#x27;&lt;/span&gt;, name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Sample&amp;#x27;&lt;/span&gt;, opacity=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fig.update_layout(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        autosize=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, width=&lt;span class=&#34;number&#34;&gt;1200&lt;/span&gt;, height=&lt;span class=&#34;number&#34;&gt;800&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        xaxis=&lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(title=&lt;span class=&#34;string&#34;&gt;&amp;#x27;x&amp;#x27;&lt;/span&gt;), yaxis=&lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(title=&lt;span class=&#34;string&#34;&gt;&amp;#x27;y&amp;#x27;&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        showlegend=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fig.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# d2l.plot(x_test, [y_truth, y_hat], &amp;#x27;x&amp;#x27;, &amp;#x27;y&amp;#x27;, legend=[&amp;#x27;Truth&amp;#x27;, &amp;#x27;Pred&amp;#x27;],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#          xlim=[0, 5], ylim=[-1, 5])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# d2l.plt.plot(x_train, y_train, &amp;#x27;o&amp;#x27;, alpha=0.5)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_hat = torch.repeat_interleave(y_train.mean(), n_test)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plot_kernel_reg(y_hat)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;显然，平均汇聚忽略了输入，Nadaraya-Watson 核回归根据输入的位置对输出进行加权，是一个非参数模型。接下来，我们将基于这个非参数的注意力汇聚模型来绘制预测结果。从绘制的结果会发现新的模型预测线是平滑的，并且比平均汇聚的预测更接近真实。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# X_repeat.shape: (n_test, n_train)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 每一行都包含着相同的测试输入（例如：同样的查询）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X_repeat = x_test.repeat_interleave(n_train).reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, n_train))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# x_train包含着键，attention_weights.shape: (n_test, n_train)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 每一行都包含着要在给定的每个查询的值（y_train）之间分配的注意力权重&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention_weights = nn.functional.softmax(-(X_repeat - x_train)**&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; / &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# y_hat的每个元素都是值的加权平均值，其中的权重是注意力权重&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_hat = torch.matmul(attention_weights, y_train)  &lt;span class=&#34;comment&#34;&gt;# y_hat.shape: torch.Size([50])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plot_kernel_reg(y_hat)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;非参数的 Nadaraya-Watson 核回归具有一致性（consistency）的优点：如果有足够的数据，此模型会收敛到最优结果。尽管如此，我们还是可以轻松地将可学习的参数集成到注意力汇聚中。&lt;/p&gt;
&lt;p&gt;为了更有效地计算小批量数据的注意力，我们可以利用深度学习开发框架中提供的批量矩阵乘法：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = torch.ones((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = torch.ones((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.bmm(X, Y).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 1, 6])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在注意力机制的背景中，我们可以使用小批量矩阵乘法来计算小批量数据中的加权平均值：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;weights = torch.ones((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)) * &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;values = torch.arange(&lt;span class=&#34;number&#34;&gt;20.0&lt;/span&gt;).reshape((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.bmm(weights.unsqueeze(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), values.unsqueeze(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[ 4.5000]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[14.5000]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义 Nadaraya-Watson 核回归的带参数版本为：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;NWKernelRegression&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.w = nn.Parameter(torch.rand((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,), requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, queries, keys, values&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# queries和attention_weights的形状为: (查询个数, “键-值”对个数)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        queries = queries.repeat_interleave(keys.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]).reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, keys.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.attention_weights = nn.functional.softmax(-((queries - keys) * self.w)**&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; / &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# values的形状为: (查询个数, “键-值”对个数)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.bmm(self.attention_weights.unsqueeze(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), values.unsqueeze(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)).reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来，将训练数据集变换为键和值用于训练注意力模型。在带参数的注意力汇聚模型中，任何一个训练样本的输入都会和除自己以外的所有训练样本的“键-值”对进行计算，从而得到其对应的预测输出：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# X_tile.shape: (n_train, n_train)，每一行都包含着相同的训练输入&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X_tile = x_train.repeat(n_train, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Y_tile.shape: (n_train, n_train)，每一行都包含着相同的训练输出&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y_tile = y_train.repeat(n_train, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# keys.shape: (n_train, n_train-1)，将对角线元素筛去&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;keys = X_tile[(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; - torch.eye(n_train)).&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(torch.&lt;span class=&#34;built_in&#34;&gt;bool&lt;/span&gt;)].reshape((n_train, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# values.shape: (n_train, n_train-1)，将对角线元素筛去&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;values = Y_tile[(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; - torch.eye(n_train)).&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(torch.&lt;span class=&#34;built_in&#34;&gt;bool&lt;/span&gt;)].reshape((n_train, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;训练带参数的注意力汇聚模型时，使用平方损失函数和随机梯度下降：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;net = NWKernelRegression()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = nn.MSELoss(reduction=&lt;span class=&#34;string&#34;&gt;&amp;#x27;none&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = torch.optim.SGD(net.parameters(), lr=&lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss = loss_function(net(x_train, keys, values), y_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;epoch &lt;span class=&#34;subst&#34;&gt;&amp;#123;epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&amp;#125;&lt;/span&gt;, loss &lt;span class=&#34;subst&#34;&gt;&amp;#123;&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(loss.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()):&lt;span class=&#34;number&#34;&gt;.6&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;训练完带参数的注意力汇聚模型后可以发现：在尝试拟合带噪声的训练数据时，预测结果绘制的线不如之前非参数模型的平滑，因为与非参数的注意力汇聚模型相比，带参数的模型加入可学习的参数后，曲线在注意力权重较大的区域变得更不平滑。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# keys.shape: (n_test, n_train)，每一行包含着相同的训练输入（例如，相同的键）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;keys = x_train.repeat(n_test, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# value.shape: (n_test, n_train)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;values = y_train.repeat(n_test, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_hat = net(x_test, keys, values).detach()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plot_kernel_reg(y_hat)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-注意力评分函数&#34;&gt;3. 注意力评分函数&lt;/h2&gt;
&lt;p&gt;在上一节中使用了高斯核来对查询和键之间的关系建模。高斯核的指数部分可以视为注意力评分函数（attention scoring function），简称&lt;strong&gt;评分函数&lt;/strong&gt;（scoring function），然后把这个函数的输出结果输入到 Softmax 函数中进行运算。通过上述步骤，将得到与键对应的值的概率分布（即注意力权重）。最后，注意力汇聚的输出就是基于这些注意力权重的值的加权和。&lt;/p&gt;
&lt;p&gt;选择不同的注意力评分函数会导致不同的注意力汇聚操作。本节将介绍两个流行的评分函数，稍后将用他们来实现更复杂的注意力机制。&lt;/p&gt;
&lt;p&gt;正如上面提到的，Softmax 操作用于输出一个概率分布作为注意力权重。在某些情况下，并非所有的值都应该被纳入到注意力汇聚中。例如，为了在机器翻译中高效处理小批量数据集，某些文本序列被填充了没有意义的特殊词元。为了仅将有意义的词元作为值来获取注意力汇聚，可以指定一个有效序列长度（即词元的个数），以便在计算 Softmax 时过滤掉超出指定范围的位置。下面的 &lt;code&gt;masked_softmax&lt;/code&gt; 函数实现了这样的掩蔽 Softmax 操作（masked softmax operation），其中任何超出有效长度的位置都被掩蔽并置为0。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; math&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;masked_softmax&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, valid_lens&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;通过在最后一个轴上掩蔽元素来执行softmax操作&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# X: 3D张量，valid_lens: 1D或2D张量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; valid_lens &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.functional.softmax(X, dim=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        shape = X.shape&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; valid_lens.dim() == &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            valid_lens = torch.repeat_interleave(valid_lens, shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# [a, b] -&amp;gt; [a, a, ..., b, b, ...]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            valid_lens = valid_lens.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = d2l.sequence_mask(X.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, shape[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]), valid_lens, value=-&lt;span class=&#34;number&#34;&gt;1e6&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.functional.softmax(X.reshape(shape), dim=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;为了演示此函数是如何工作的，考虑由两个2*4矩阵表示的样本，这两个样本的有效长度分别为2和3。经过掩蔽 Softmax 操作，超出有效长度的值都被掩蔽为0：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(masked_softmax(torch.rand(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;), torch.tensor([&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;])))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[0.3292, 0.6708, 0.0000, 0.0000],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [0.5249, 0.4751, 0.0000, 0.0000]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[0.3104, 0.4577, 0.2318, 0.0000],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [0.3227, 0.3408, 0.3365, 0.0000]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;同样，也可以使用二维张量，为矩阵样本中的每一行指定有效长度：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(masked_softmax(torch.rand(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;), torch.tensor([[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;]])))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[1.0000, 0.0000, 0.0000, 0.0000],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [0.4203, 0.2752, 0.3045, 0.0000]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[0.4234, 0.5766, 0.0000, 0.0000],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [0.2979, 0.1618, 0.2246, 0.3157]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来将介绍加性注意力与缩放点积注意力，其理论分析可见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_attention-mechanisms/attention-scoring-functions.html&#34;&gt;注意力评分函数&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;一般来说，当查询和键是不同长度的矢量时，可以使用加性注意力作为评分函数。将查询和键连结起来后输入到一个多层感知机（MLP）中，感知机包含一个隐藏层，其隐藏单元数是一个超参数。通过使用 &lt;code&gt;tanh&lt;/code&gt; 作为激活函数，并且禁用偏置项：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;AdditiveAttention&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;加性注意力&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, key_size, query_size, num_hiddens, dropout, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(AdditiveAttention, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.W_k = nn.Linear(key_size, num_hiddens, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.W_q = nn.Linear(query_size, num_hiddens, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.w_v = nn.Linear(num_hiddens, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.dropout = nn.Dropout(dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, queries, keys, values, valid_lens&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        queries, keys = self.W_q(queries), self.W_k(keys)  &lt;span class=&#34;comment&#34;&gt;# (2, 1, 8), (2, 10, 8)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 维度扩展后使用广播方式进行求和&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 扩展后的queries.shape: (batch_size, 查询的个数, 1, num_hidden)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 扩展后的key.shape: (batch_size, 1, “键-值”对的个数, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        features = queries.unsqueeze(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;) + keys.unsqueeze(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        features = torch.tanh(features)  &lt;span class=&#34;comment&#34;&gt;# (2, 1, 10, 8)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# self.w_v仅有一个输出，因此从形状中移除最后那个大小为1的维度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# scores.shape: (batch_size, 查询的个数, “键-值”对的个数)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        scores = self.w_v(features).squeeze(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# (2, 1, 10, 1) -&amp;gt; (2, 1, 10)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.attention_weights = masked_softmax(scores, valid_lens)  &lt;span class=&#34;comment&#34;&gt;# (2, 1, 10)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# values.shape: (batch_size, “键-值”对的个数, 值的维度)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.bmm(self.dropout(self.attention_weights), values)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;queries, keys = torch.normal(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;)), torch.ones((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# values的小批量，两个值矩阵是相同的&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;values = torch.arange(&lt;span class=&#34;number&#34;&gt;40&lt;/span&gt;, dtype=torch.float32).reshape(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;).repeat(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;valid_lens = torch.tensor([&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention = AdditiveAttention(key_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, query_size=&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, num_hiddens=&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, dropout=&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(attention(queries, keys, values, valid_lens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=&amp;lt;BmmBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;尽管加性注意力包含了可学习的参数，但由于本例子中每个键都是相同的，所以注意力权重是均匀的，由指定的有效长度决定：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# show_plotly_heatmaps函数在第一节中定义&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_plotly_heatmaps(z=attention.attention_weights.detach().reshape((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)), height=&lt;span class=&#34;number&#34;&gt;300&lt;/span&gt;, xtitle=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Keys&amp;#x27;&lt;/span&gt;, ytitle=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Queries&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;使用点积可以得到计算效率更高的评分函数，但是点积操作要求查询和键具有相同的长度，为了演示 &lt;code&gt;DotProductAttention&lt;/code&gt; 类，我们使用与先前加性注意力例子中相同的键、值和有效长度。对于点积操作，我们令查询的特征维度与键的特征维度大小相同：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;DotProductAttention&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;缩放点积注意力&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, dropout, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(DotProductAttention, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.dropout = nn.Dropout(dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# queries.shape: (batch_size, 查询的个数, d)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# keys.shape: (batch_size, “键-值”对的个数, d)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# values.shape: (batch_size, “键-值”对的个数, 值的维度)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# valid_lens.shape: (batch_size,)或者(batch_size, 查询的个数)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, queries, keys, values, valid_lens=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        d = queries.shape[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        scores = torch.bmm(queries, keys.transpose(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)) / math.sqrt(d)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.attention_weights = masked_softmax(scores, valid_lens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.bmm(self.dropout(self.attention_weights), values)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;queries = torch.normal(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention = DotProductAttention(dropout=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(attention(queries, keys, values, valid_lens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[10.0000, 11.0000, 12.0000, 13.0000]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;与加性注意力演示相同，由于键包含的是相同的元素，而这些元素无法通过任何查询进行区分，因此获得了均匀的注意力权重。&lt;/p&gt;
&lt;h2 id=&#34;4-Bahdanau注意力（使用注意力的seq2seq）&#34;&gt;4. Bahdanau注意力（使用注意力的seq2seq）&lt;/h2&gt;
&lt;p&gt;Bahdanau 注意力模型的原理可见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_attention-mechanisms/bahdanau-attention.html&#34;&gt;Bahdanau 注意力&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下面看看如何定义 Bahdanau 注意力，实现循环神经网络编码器-解码器。其实，我们只需重新定义解码器即可。为了更方便地显示学习的注意力权重，以下 &lt;code&gt;AttentionDecoder&lt;/code&gt; 类定义了带有注意力机制解码器的基本接口：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; sys&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;sys.path.append(&lt;span class=&#34;string&#34;&gt;&amp;quot;..&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; util.functions &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_seq2seq, predict_seq2seq, bleu, show_plotly_heatmaps&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;AttentionDecoder&lt;/span&gt;(d2l.Decoder):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;带有注意力机制解码器的基本接口&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(AttentionDecoder, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;meta&#34;&gt;    @property&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;attention_weights&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;raise&lt;/span&gt; NotImplementedError&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来，让我们在接下来的 &lt;code&gt;Seq2SeqAttentionDecoder&lt;/code&gt; 类中实现带有 Bahdanau 注意力的循环神经网络解码器。首先，初始化解码器的状态，需要下面的输入：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;编码器在所有时间步的最终层隐状态，将作为注意力的键和值；&lt;/li&gt;
&lt;li&gt;上一时间步的编码器全层隐状态，将作为初始化解码器的隐状态；&lt;/li&gt;
&lt;li&gt;编码器有效长度（排除在注意力池中填充词元）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在每个解码时间步骤中，解码器上一个时间步的最终层隐状态将用作查询。因此，注意力输出和输入嵌入都连结为循环神经网络解码器的输入。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Seq2SeqAttentionDecoder&lt;/span&gt;(&lt;span class=&#34;title class_ inherited__&#34;&gt;AttentionDecoder&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, vocab_size, embed_size, num_hiddens, num_layers, dropout=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Seq2SeqAttentionDecoder, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.attention = d2l.AdditiveAttention(num_hiddens, num_hiddens, num_hiddens, dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.embedding = nn.Embedding(vocab_size, embed_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.dense = nn.Linear(num_hiddens, vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_state&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, enc_outputs, enc_valid_lens, *args&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# outputs.shape: (batch_size, num_steps, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# hidden_state.shape: (num_layers, batch_size, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs, hidden_state = enc_outputs&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (outputs.permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), hidden_state, enc_valid_lens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X, state&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# enc_outputs.shape: (batch_size, num_steps, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# hidden_state.shape: (num_layers, batch_size, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        enc_outputs, hidden_state, enc_valid_lens = state&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = self.embedding(X).permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# X.shape: (num_steps, batch_size, embed_size)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs, self._attention_weights = [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; x &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; X:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# query.shape: (batch_size, 1, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            query = torch.unsqueeze(hidden_state[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# context.shape: (batch_size, 1, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            context = self.attention(query, enc_outputs, enc_outputs, enc_valid_lens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 在特征维度上连结&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            x = torch.cat((context, torch.unsqueeze(x, dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)), dim=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 将x变形为(1, batch_size, embed_size + num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            out, hidden_state = self.rnn(x.permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), hidden_state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            outputs.append(out)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self._attention_weights.append(self.attention.attention_weights)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 全连接层变换后，outputs的形状为(num_steps, batch_size, vocab_size)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs = self.dense(torch.cat(outputs, dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; outputs.permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), [enc_outputs, hidden_state, enc_valid_lens]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;meta&#34;&gt;    @property&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;attention_weights&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self._attention_weights&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来，使用包含7个时间步的4个序列输入的小批量测试 Bahdanau 注意力解码器：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;encoder = d2l.Seq2SeqEncoder(vocab_size=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, embed_size=&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, num_hiddens=&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, num_layers=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;encoder.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;decoder = Seq2SeqAttentionDecoder(vocab_size=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, embed_size=&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, num_hiddens=&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, num_layers=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;decoder.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.zeros((&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;), dtype=torch.long)  &lt;span class=&#34;comment&#34;&gt;# (batch_size, num_steps)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;state = decoder.init_state(encoder(X), &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output, state = decoder(X, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output.shape, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(state), state[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].shape, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(state[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]), state[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# torch.Size([4, 7, 10]) 3 torch.Size([4, 7, 16]) 2 torch.Size([4, 16])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们在这里指定超参数，实例化一个带有 Bahdanau 注意力的编码器和解码器，并对这个模型进行机器翻译训练：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;embed_size, num_hiddens, num_layers, dropout = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, num_steps, lr, num_epochs = &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.005&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;300&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;encoder = d2l.Seq2SeqEncoder(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(src_vocab), embed_size, num_hiddens, num_layers, dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;decoder = Seq2SeqAttentionDecoder(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = d2l.EncoderDecoder(encoder, decoder)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device, &lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/Bahdanau_seq2seq_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;模型训练后，我们用它将几个英语句子翻译成法语并计算它们的 BLEU 分数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;engs = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;go .&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;i lost .&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;he\&amp;#x27;s calm .&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;i\&amp;#x27;m home .&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;fras = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;va !&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;j\&amp;#x27;ai perdu .&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;il est calme .&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;je suis chez moi .&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; eng, fra &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(engs, fras):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    translation, dec_attention_weight_seq = predict_seq2seq(net, eng, src_vocab, tgt_vocab, num_steps, device, &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;eng&amp;#125;&lt;/span&gt; =&amp;gt; &lt;span class=&#34;subst&#34;&gt;&amp;#123;translation&amp;#125;&lt;/span&gt;, bleu &lt;span class=&#34;subst&#34;&gt;&amp;#123;bleu(translation, fra, k=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;):&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;训练结束后，下面通过可视化注意力权重会发现每个查询都会在键值对上分配不同的权重，这说明在每个解码步中，输入序列的不同部分被选择性地聚集在注意力池中：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;attention_weights = torch.cat([step[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; dec_attention_weight_seq], &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;).reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, num_steps))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 加上一个包含序列结束词元&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_plotly_heatmaps(z=attention_weights[:, :&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(engs[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].split()) + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].cpu().detach(), xtitle=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Keys&amp;#x27;&lt;/span&gt;, ytitle=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Queries&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;5-多头注意力&#34;&gt;5. 多头注意力&lt;/h2&gt;
&lt;p&gt;在实践中，当给定相同的查询、键和值的集合时，我们希望模型可以基于相同的注意力机制学习到不同的行为，然后将不同的行为作为知识组合起来，捕获序列内各种范围的依赖关系（例如，短距离依赖和长距离依赖关系）。因此，允许注意力机制组合使用查询、键和值的不同&lt;strong&gt;子空间表示&lt;/strong&gt;（representation subspaces）可能是有益的。&lt;/p&gt;
&lt;p&gt;为此，与其只使用单独一个注意力汇聚，我们可以用独立学习得到的 &lt;code&gt;h&lt;/code&gt; 组不同的&lt;strong&gt;线性投影&lt;/strong&gt;（linear projections）来变换查询、键和值。然后，这 &lt;code&gt;h&lt;/code&gt; 组变换后的查询、键和值将并行地送到注意力汇聚中。最后，将这 &lt;code&gt;h&lt;/code&gt; 个注意力汇聚的输出拼接在一起，并且通过另一个可以学习的线性投影进行变换，以产生最终输出。这种设计被称为&lt;strong&gt;多头注意力&lt;/strong&gt;（multihead attention）。对于 &lt;code&gt;h&lt;/code&gt; 个注意力汇聚输出，每一个注意力汇聚都被称作一个&lt;strong&gt;头&lt;/strong&gt;（head）。基于这种设计，每个头都可能会关注输入的不同部分，可以表示比简单加权平均值更复杂的函数。&lt;/p&gt;
&lt;p&gt;多头注意力模型的原理可见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_attention-mechanisms/multihead-attention.html&#34;&gt;多头注意力&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在实现过程中通常选择缩放点积注意力作为每一个注意力头：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;MultiHeadAttention&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;多头注意力&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, key_size, query_size, value_size, num_hiddens, num_heads, dropout, bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(MultiHeadAttention, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.num_heads = num_heads&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.attention = d2l.DotProductAttention(dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, queries, keys, values, valid_lens&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# queries/keys/values的形状: (batch_size, 查询或者“键-值”对的个数, query_size/key_size/value_size)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# valid_lens的形状: (batch_size,)或(batch_size, 查询的个数)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 经过变换后，输出的queries/keys/values的形状: (batch_size * num_heads, 查询或者“键-值”对的个数, num_hiddens / num_heads)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        queries = transpose_qkv(self.W_q(queries), self.num_heads)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        keys = transpose_qkv(self.W_k(keys), self.num_heads)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        values = transpose_qkv(self.W_v(values), self.num_heads)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; valid_lens &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 在轴0，将每一项（标量或者矢量）复制num_heads次&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            valid_lens = torch.repeat_interleave(valid_lens, repeats=self.num_heads, dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# output的形状: (batch_size * num_heads, 查询的个数, num_hiddens / num_heads)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.attention(queries, keys, values, valid_lens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# output_concat的形状: (batch_size, 查询的个数, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output_concat = transpose_output(output, self.num_heads)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.W_o(output_concat)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;为了能够使多个头并行计算，上面的 &lt;code&gt;MultiHeadAttention&lt;/code&gt; 类将使用下面定义的两个转置函数。具体来说，&lt;code&gt;transpose_output&lt;/code&gt; 函数反转了 &lt;code&gt;transpose_qkv&lt;/code&gt; 函数的操作：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;transpose_qkv&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, num_heads&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;为了多注意力头的并行计算而变换形状&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 输入X的形状: (batch_size, 查询或者“键-值”对的个数, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    X = X.reshape(X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], X.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], num_heads, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# (batch_size, 查询或者“键-值”对的个数, num_heads, num_hiddens/num_heads)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    X = X.permute(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# (batch_size, num_heads, 查询或者“键-值”对的个数, num_hiddens/num_heads)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, X.shape[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], X.shape[&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# (batch_size*num_heads, 查询或者“键-值”对的个数, num_hiddens/num_heads)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;transpose_output&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, num_heads&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;逆转transpose_qkv函数的操作&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 输入X的形状: (batch_size*num_heads, 查询或者“键-值”对的个数, num_hiddens/num_heads)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    X = X.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, num_heads, X.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], X.shape[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# (batch_size, num_heads, 查询或者“键-值”对的个数, num_hiddens/num_heads)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    X = X.permute(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# (batch_size, 查询或者“键-值”对的个数, num_heads, num_hiddens/num_heads)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X.reshape(X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], X.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# (batch_size, 查询或者“键-值”对的个数, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下面使用键和值相同的小例子来测试我们编写的 &lt;code&gt;MultiHeadAttention&lt;/code&gt; 类。多头注意力输出的形状是 &lt;code&gt;(batch_size, num_queries, num_hiddens)&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;num_hiddens, num_heads = &lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, num_queries = &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_kvpairs, valid_lens = &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, torch.tensor([&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.ones((batch_size, num_queries, num_hiddens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = torch.ones((batch_size, num_kvpairs, num_hiddens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(attention(X, Y, Y, valid_lens).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 4, 100])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;6-自注意力和位置编码&#34;&gt;6. 自注意力和位置编码&lt;/h2&gt;
&lt;p&gt;在深度学习中，经常使用卷积神经网络（CNN）或循环神经网络（RNN）对序列进行编码。想象一下，有了注意力机制之后，我们将词元序列输入注意力池化中，以便同一组词元同时充当查询、键和值。具体来说，每个查询都会关注所有的键-值对并生成一个注意力输出。当查询、键和值来自同一组输入时被称为&lt;strong&gt;自注意力&lt;/strong&gt;（self-attention），也被称为&lt;strong&gt;内部注意力&lt;/strong&gt;（intra-attention）。本节将使用自注意力进行序列编码，以及如何使用序列的顺序作为补充信息。&lt;/p&gt;
&lt;p&gt;自注意力模型的原理可见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_attention-mechanisms/self-attention-and-positional-encoding.html&#34;&gt;自注意力和位置编码&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下面的代码片段是基于多头注意力对一个张量完成自注意力的计算，张量的形状为 &lt;code&gt;(批量大小, 时间步的数目或词元序列的长度, h)&lt;/code&gt;，输出与输入的张量形状相同：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; util.functions &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; show_plotly_heatmaps&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_hiddens, num_heads = &lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention = d2l.MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;attention.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, num_queries, valid_lens = &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, torch.tensor([&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.ones((batch_size, num_queries, num_hiddens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(attention(X, X, X, valid_lens).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 4, 100])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在处理词元序列时，循环神经网络是逐个的重复地处理词元的，而自注意力则因为并行计算而放弃了顺序操作。为了使用序列的顺序信息，通过在输入表示中添加&lt;strong&gt;位置编码&lt;/strong&gt;（positional encoding）来注入绝对的或相对的位置信息。位置编码可以通过学习得到也可以直接固定得到。接下来描述的是基于正弦函数和余弦函数的固定位置编码。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;PositionalEncoding&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;位置编码&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, num_hiddens, dropout, max_len=&lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(PositionalEncoding, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.dropout = nn.Dropout(dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 创建一个足够长的P&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.P = torch.zeros((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, max_len, num_hiddens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = torch.arange(max_len, dtype=torch.float32).reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) /\&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            torch.&lt;span class=&#34;built_in&#34;&gt;pow&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;10000&lt;/span&gt;, torch.arange(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, num_hiddens, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, dtype=torch.float32) / num_hiddens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.P[:, :, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;::&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;] = torch.sin(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.P[:, :, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;::&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;] = torch.cos(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = X + self.P[:, :X.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], :].to(X.device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.dropout(X)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在位置嵌入矩阵 &lt;code&gt;P&lt;/code&gt; 中，行代表词元在序列中的位置，列代表位置编码的不同维度。从下面的例子中可以看到位置嵌入矩阵的第6列和第7列的频率高于第8列和第9列。第6列和第7列之间的偏移量（第8列和第9列相同）是由于正弦函数和余弦函数的交替：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;encoding_dim, num_steps = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;60&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pos_encoding = PositionalEncoding(encoding_dim, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pos_encoding.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = pos_encoding(torch.zeros((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, num_steps, encoding_dim)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;P = pos_encoding.P[:, :X.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], :]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.plot(torch.arange(num_steps), P[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, :, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;].T, xlabel=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Row (position)&amp;#x27;&lt;/span&gt;, figsize=(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         legend=[&lt;span class=&#34;string&#34;&gt;&amp;quot;Col %d&amp;quot;&lt;/span&gt; % d &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; d &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; torch.arange(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过绘制热力图可以看到，位置编码通过使用三角函数在编码维度上降低频率：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;P = P[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, :, :]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_plotly_heatmaps(z=P, xtitle=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Column (encoding dimension)&amp;#x27;&lt;/span&gt;, ytitle=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Row (position)&amp;#x27;&lt;/span&gt;, colorscale=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Blues&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;7-Transformer&#34;&gt;7. Transformer&lt;/h2&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/7592.html</guid>
            <title>动手学深度学习笔记(李沐)-现代循环神经网络</title>
            <link>https://asanosaki.github.io/posts/7592.html</link>
            <category>AI</category>
            <pubDate>Tue, 11 Apr 2023 12:58:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;李沐动手学深度学习（PyTorch）课程学习笔记第九章：现代循环神经网络。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-门控循环单元（GRU）&#34;&gt;1. 门控循环单元（GRU）&lt;/h2&gt;
&lt;p&gt;在&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/bptt.html&#34;&gt;通过时间反向传播&lt;/a&gt;中，我们讨论了如何在循环神经网络中计算梯度，以及矩阵连续乘积可以导致梯度消失或梯度爆炸的问题。下面我们简单思考一下这种梯度异常在实践中的意义，我们可能会遇到以下的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;早期观测值对预测所有未来观测值具有非常重要的意义。考虑一个极端情况，其中第一个观测值包含一个校验和，目标是在序列的末尾辨别校验和是否正确。在这种情况下，第一个词元的影响至关重要。我们希望有某些机制能够&lt;strong&gt;在一个记忆元里存储重要的早期信息&lt;/strong&gt;。如果没有这样的机制，我们将不得不给这个观测值指定一个非常大的梯度，因为它会影响所有后续的观测值。&lt;/li&gt;
&lt;li&gt;一些词元没有相关的观测值。例如，在对网页内容进行情感分析时，可能有一些辅助 HTML 代码与网页传达的情绪无关。我们希望有一些机制来&lt;strong&gt;跳过隐状态表示中的此类词元&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;序列的各个部分之间存在逻辑中断。例如，书的章节之间可能会有过渡存在，或者证券的熊市和牛市之间可能会有过渡存在。在这种情况下，最好有一种方法来&lt;strong&gt;重置我们的内部状态表示&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在学术界已经提出了许多方法来解决这类问题。其中最早的方法是&lt;strong&gt;长短期记忆&lt;/strong&gt;（long-short-term memory，LSTM），我们将在下一节中讨论。&lt;strong&gt;门控循环单元&lt;/strong&gt;（gated recurrent unit，GRU）是一个稍微简化的变体，通常能够提供同等的效果，并且计算的速度明显更快。由于门控循环单元更简单，我们从它开始解读。&lt;/p&gt;
&lt;p&gt;门控循环单元与普通的循环神经网络之间的关键区别在于：前者支持&lt;strong&gt;隐状态的门控&lt;/strong&gt;。这意味着模型有专门的机制来确定应该何时更新隐状态，以及应该何时重置隐状态。这些机制是可学习的，并且能够解决了上面列出的问题。例如，如果第一个词元非常重要，模型将学会在第一次观测之后不更新隐状态。同样，模型也可以学会跳过不相关的临时观测。最后，模型还将学会在需要的时候重置隐状态。下面我们将详细讨论各类门控。&lt;/p&gt;
&lt;p&gt;我们首先介绍&lt;strong&gt;重置门&lt;/strong&gt;（reset gate）和&lt;strong&gt;更新门&lt;/strong&gt;（update gate）。我们把它们设计成 &lt;code&gt;(0, 1)&lt;/code&gt; 区间中的向量，这样我们就可以进行&lt;strong&gt;凸组合&lt;/strong&gt;。重置门允许我们&lt;strong&gt;控制可能还想记住&lt;/strong&gt;的过去状态的数量；更新门将允许我们&lt;strong&gt;控制新状态中有多少个是旧状态的副本&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我们从构造这些门控开始。重置门和更新门的输入是由当前时间步的输入和前一时间步的隐状态给出。两个门的输出是由使用 Sigmoid 激活函数的两个全连接层给出。门控循环单元的数学表达详见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-modern/gru.html&#34;&gt;门控循环单元（GRU）&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;1-1-门控循环单元的从零开始实现&#34;&gt;1.1 门控循环单元的从零开始实现&lt;/h3&gt;
&lt;p&gt;为了更好地理解门控循环单元模型，我们从零开始实现它。首先，我们读取上一章中使用的时间机器数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; math&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tqdm &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tqdm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, num_steps = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;35&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下一步是初始化模型参数。我们从标准差为0.01的高斯分布中提取权重，并将偏置项设为0，超参数 &lt;code&gt;num_hiddens&lt;/code&gt; 定义隐藏单元的数量，实例化与更新门、重置门、候选隐状态和输出层相关的所有权重和偏置：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;get_params&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;vocab_size, num_hiddens, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_inputs = num_outputs = vocab_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;normal&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;shape&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.randn(size=shape, device=device) * &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;three&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_xz, W_hz, b_z = three()  &lt;span class=&#34;comment&#34;&gt;# 更新门参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_xr, W_hr, b_r = three()  &lt;span class=&#34;comment&#34;&gt;# 重置门参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_xh, W_hh, b_h = three()  &lt;span class=&#34;comment&#34;&gt;# 候选隐状态参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 输出层参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_hq = normal((num_hiddens, num_outputs))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    b_q = torch.zeros(num_outputs, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 附加梯度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; params:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        param.requires_grad_(&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; params&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在我们将定义隐状态的初始化函数 &lt;code&gt;init_gru_state&lt;/code&gt;。与从零开始实现 RNN 中定义的 &lt;code&gt;init_rnn_state&lt;/code&gt; 函数一样，此函数返回一个形状为 &lt;code&gt;(批量大小, 隐藏单元个数)&lt;/code&gt; 的张量，张量的值全部为零：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_gru_state&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size, num_hiddens, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (torch.zeros((batch_size, num_hiddens), device=device),)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在我们准备定义门控循环单元模型，模型的架构与基本的循环神经网络单元是相同的，只是权重更新公式更为复杂：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;gru&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;inputs, state, params&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    H, = state&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    outputs = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; inputs:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z)  &lt;span class=&#34;comment&#34;&gt;# @为矩阵乘法，相当于torch.mm&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        H = Z * H + (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; - Z) * H_tilda&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y = H @ W_hq + b_q&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs.append(Y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.cat(outputs, dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;), (H,)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;训练和预测的工作方式与从零开始实现 RNN 完全相同。训练结束后，我们分别打印输出训练集的困惑度，以及前缀 &lt;code&gt;time traveler&lt;/code&gt; 和 &lt;code&gt;traveler&lt;/code&gt; 的预测序列上的困惑度：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_hiddens, num_epochs, lr = &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = d2l.RNNModelScratch(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab), num_hiddens, device, get_params, init_gru_state, gru)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, vocab, lr, num_epochs, device)  &lt;span class=&#34;comment&#34;&gt;# 与从零开始实现RNN的train函数相同，此处不再实现&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;1-2-门控循环单元的简洁实现&#34;&gt;1.2 门控循环单元的简洁实现&lt;/h3&gt;
&lt;p&gt;高级 API 包含了前文介绍的所有配置细节，所以我们可以直接实例化门控循环单元模型。这段代码的运行速度要快得多，因为它使用的是编译好的运算符而不是 Python 来处理之前阐述的许多细节：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;RNNModel&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, rnn_layer, vocab_size, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(RNNModel, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.rnn = rnn_layer&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.vocab_size = vocab_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.num_hiddens = self.rnn.hidden_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; self.rnn.bidirectional:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.num_directions = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.num_directions = &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.linear = nn.Linear(self.num_hiddens * &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, self.vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, inputs, state&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = F.one_hot(inputs.T.long(), self.vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = X.to(torch.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y, state = self.rnn(X, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.linear(Y.reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, Y.shape[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output, state&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;begin_state&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, device, batch_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(self.rnn, nn.LSTM):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gru_layer = nn.GRU(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab), num_hiddens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = RNNModel(gru_layer, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train_epoch&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, loss_function, optimizer, device, use_random_iter&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    state = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_loss = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, Y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(train_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; state &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; use_random_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            state = net.begin_state(batch_size=X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(net, nn.Module) &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(state, &lt;span class=&#34;built_in&#34;&gt;tuple&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                state.detach_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; s &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; state:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    s.detach_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y = Y.T.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X, y = X.to(device), y.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss_function.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y_hat, state = net(X, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(y_hat, y.long()).mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        d2l.grad_clipping(net, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss.append(loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; math.exp(&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loss))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, vocab, lr, num_epochs, device, use_random_iter=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer = torch.optim.SGD(net.parameters(), lr)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pred = &lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; prefix: d2l.predict_ch8(prefix, &lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, net, vocab, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/GRU_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ppl = train_epoch(net, train_iter, loss_function, optimizer, device, use_random_iter)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; (epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt; == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;Perplexity: &lt;span class=&#34;subst&#34;&gt;&amp;#123;ppl:&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_loss&amp;#x27;&lt;/span&gt;, ppl, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.close()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, vocab, lr, num_epochs, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Perplexity: 1.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# time travelleryou can show black is white by argument said filby&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# travelleryou can show black is white by argument said filby&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-长短期记忆网络（LSTM）&#34;&gt;2. 长短期记忆网络（LSTM）&lt;/h2&gt;
&lt;p&gt;长期以来，隐变量模型存在着长期信息保存和短期输入缺失的问题。解决这一问题的最早方法之一是长短期存储器（long short-term memory，LSTM）。它有许多与门控循环单元一样的属性。&lt;/p&gt;
&lt;p&gt;可以说，长短期记忆网络的设计灵感来自于计算机的逻辑门。长短期记忆网络引入了记忆元（memory cell），或简称为单元（cell）。有些文献认为记忆元是隐状态的一种特殊类型，它们与隐状态具有相同的形状，其设计目的是用于记录附加的信息。为了控制记忆元，我们需要许多门。其中一个门用来从单元中输出条目，我们将其称为&lt;strong&gt;输出门&lt;/strong&gt;（output gate）。另外一个门用来决定何时将数据读入单元，我们将其称为&lt;strong&gt;输入门&lt;/strong&gt;（input gate）。我们还需要一种机制来重置单元的内容，由&lt;strong&gt;遗忘门&lt;/strong&gt;（forget gate）来管理，这种设计的动机与门控循环单元相同，能够通过专用机制决定什么时候记忆或忽略隐状态中的输入。&lt;/p&gt;
&lt;p&gt;长短期记忆网络的数学表达详见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-modern/lstm.html&#34;&gt;长短期记忆网络（LSTM）&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;2-1-长短期记忆网络的从零开始实现&#34;&gt;2.1 长短期记忆网络的从零开始实现&lt;/h3&gt;
&lt;p&gt;现在，我们从零开始实现长短期记忆网络，我们首先加载时光机器数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; math&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tqdm &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tqdm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, num_steps = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;35&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来，我们需要定义和初始化模型参数。如前所述，超参数 &lt;code&gt;num_hiddens&lt;/code&gt; 定义隐藏单元的数量。我们按照标准差0.01的高斯分布初始化权重，并将偏置项设为0：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;get_lstm_params&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;vocab_size, num_hiddens, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_inputs = num_outputs = vocab_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;normal&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;shape&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.randn(size=shape, device=device) * &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;three&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_xi, W_hi, b_i = three()  &lt;span class=&#34;comment&#34;&gt;# 输入门参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_xf, W_hf, b_f = three()  &lt;span class=&#34;comment&#34;&gt;# 遗忘门参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_xo, W_ho, b_o = three()  &lt;span class=&#34;comment&#34;&gt;# 输出门参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_xc, W_hc, b_c = three()  &lt;span class=&#34;comment&#34;&gt;# 候选记忆元参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 输出层参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_hq = normal((num_hiddens, num_outputs))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    b_q = torch.zeros(num_outputs, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 附加梯度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; params:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        param.requires_grad_(&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; params&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在初始化函数中，长短期记忆网络的隐状态需要返回一个额外的记忆元，单元的值为0，形状为 &lt;code&gt;(批量大小, 隐藏单元数)&lt;/code&gt;。因此，我们得到以下的状态初始化：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_lstm_state&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size, num_hiddens, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (torch.zeros((batch_size, num_hiddens), device=device),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            torch.zeros((batch_size, num_hiddens), device=device))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;实际模型的定义与我们前面讨论的一样：提供三个门和一个额外的记忆元。请注意，只有隐状态 &lt;code&gt;H&lt;/code&gt; 才会传递到输出层，而记忆元 &lt;code&gt;C&lt;/code&gt; 不直接参与输出计算：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;lstm&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;inputs, state, params&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] = params&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    (H, C) = state&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    outputs = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; inputs:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        C = F * C + I * C_tilda&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        H = O * torch.tanh(C)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y = (H @ W_hq) + b_q&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs.append(Y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.cat(outputs, dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;), (H, C)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;让我们通过实例化从零实现 RNN 章节中引入的 &lt;code&gt;RNNModelScratch&lt;/code&gt; 类来训练一个长短期记忆网络，就如我们在上一节中所做的一样：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_hiddens, num_epochs, lr = &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = d2l.RNNModelScratch(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab), num_hiddens, device, get_lstm_params, init_lstm_state, lstm)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, vocab, lr, num_epochs, device)  &lt;span class=&#34;comment&#34;&gt;# 与从零开始实现RNN的train函数相同，此处不再实现&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;2-2-长短期记忆网络的简洁实现&#34;&gt;2.2 长短期记忆网络的简洁实现&lt;/h3&gt;
&lt;p&gt;使用高级 API，我们可以直接实例化 LSTM 模型：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;RNNModel&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, rnn_layer, vocab_size, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(RNNModel, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.rnn = rnn_layer&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.vocab_size = vocab_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.num_hiddens = self.rnn.hidden_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; self.rnn.bidirectional:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.num_directions = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.num_directions = &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.linear = nn.Linear(self.num_hiddens * &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, self.vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, inputs, state&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = F.one_hot(inputs.T.long(), self.vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = X.to(torch.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y, state = self.rnn(X, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.linear(Y.reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, Y.shape[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output, state&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;begin_state&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, device, batch_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(self.rnn, nn.LSTM):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lstm_layer = nn.LSTM(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab), num_hiddens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = RNNModel(lstm_layer, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train_epoch&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, loss_function, optimizer, device, use_random_iter&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    state = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_loss = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, Y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(train_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; state &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; use_random_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            state = net.begin_state(batch_size=X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(net, nn.Module) &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(state, &lt;span class=&#34;built_in&#34;&gt;tuple&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                state.detach_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; s &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; state:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    s.detach_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y = Y.T.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X, y = X.to(device), y.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss_function.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y_hat, state = net(X, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(y_hat, y.long()).mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        d2l.grad_clipping(net, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss.append(loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; math.exp(&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loss))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, vocab, lr, num_epochs, device, use_random_iter=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer = torch.optim.SGD(net.parameters(), lr)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pred = &lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; prefix: d2l.predict_ch8(prefix, &lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, net, vocab, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/LSTM_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ppl = train_epoch(net, train_iter, loss_function, optimizer, device, use_random_iter)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; (epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt; == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;Perplexity: &lt;span class=&#34;subst&#34;&gt;&amp;#123;ppl:&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_loss&amp;#x27;&lt;/span&gt;, ppl, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.close()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, vocab, lr, num_epochs, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Perplexity: 1.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# time traveller for so it will be convenient to speak of himwas e&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# travelleryou can show black is white by argument said filby&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-深度循环神经网络&#34;&gt;3. 深度循环神经网络&lt;/h2&gt;
&lt;p&gt;到目前为止，我们只讨论了具有一个单向隐藏层的循环神经网络。其中，隐变量和观测值与具体的函数形式的交互方式是相当随意的。只要交互类型建模具有足够的灵活性，这就不是一个大问题。然而，对一个单层来说，这可能具有相当的挑战性。之前在线性模型中，我们通过添加更多的层来解决这个问题。而在循环神经网络中，我们首先需要确定如何添加更多的层，以及在哪里添加额外的非线性，因此这个问题有点棘手。&lt;/p&gt;
&lt;p&gt;事实上，我们可以将多层循环神经网络堆叠在一起，通过对几个简单层的组合，产生了一个灵活的机制。特别是，数据可能与不同层的堆叠有关。例如，我们可能希望保持有关金融市场状况（熊市或牛市）的宏观数据可用，而微观数据只记录较短期的时间动态。&lt;/p&gt;
&lt;p&gt;深度循环神经网络的数学表达详见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-modern/deep-rnn.html&#34;&gt;深度循环神经网络&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;实现多层循环神经网络所需的许多逻辑细节在高级 API 中都是现成的。简单起见，我们仅示范使用此类内置函数的实现方式。以长短期记忆网络模型为例，该代码与上一节中使用的代码非常相似，实际上唯一的区别是我们指定了层的数量，而不是使用单一层这个默认值。像往常一样，我们从加载数据集开始：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; math&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tqdm &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tqdm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, num_steps = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;35&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;像选择超参数这类架构决策也跟上一节中的决策非常相似。因为我们有不同的词元，所以输入和输出都选择相同数量，即 &lt;code&gt;vocab_size&lt;/code&gt;。隐藏单元的数量仍然是256。唯一的区别是，我们现在通过 &lt;code&gt;num_layers&lt;/code&gt; 的值来设定隐藏层数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_inputs, num_hiddens, num_layers = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab), &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lstm_layer = nn.LSTM(input_size=num_inputs, hidden_size=num_hiddens, num_layers=num_layers)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = d2l.RNNModel(lstm_layer, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab))  &lt;span class=&#34;comment&#34;&gt;# 同上节的RNNModel&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = net.to(device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后和上一节一样训练模型看看效果：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;num_epochs, lr = &lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, vocab, lr * &lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;, num_epochs, device)  &lt;span class=&#34;comment&#34;&gt;# 同上节的train&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Perplexity: 1.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# time traveller for so it will be convenient to speak of himwas e&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# traveller with a slight accession ofcheerfulness really thi&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;4-双向循环神经网络&#34;&gt;4. 双向循环神经网络&lt;/h2&gt;
&lt;p&gt;在双向循环神经网络中，每个时间步的隐状态由当前时间步的前后数据同时决定，通过反向更新的隐藏层来利用反向时间信息，通常用来对序列抽取特征、填空，而&lt;strong&gt;不是预测未来&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;双向循环神经网络的数学表达详见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-modern/bi-rnn.html&#34;&gt;双向循环神经网络&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;由于双向循环神经网络使用了过去的和未来的数据，所以我们不能盲目地将这一语言模型应用于任何预测任务。尽管模型产出的困惑度是合理的，该模型预测未来词元的能力却可能存在严重缺陷。我们用下面的示例代码引以为戒，以防在错误的环境中使用它们：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 加载数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, num_steps = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;35&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 通过设置“bidirective=True”来定义双向LSTM模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_inputs, num_hiddens, num_layers = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab), &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers, bidirectional=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = d2l.RNNModel(lstm_layer, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_epochs, lr = &lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, vocab, lr, num_epochs, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Perplexity: 1.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# time travellerererererererererererererererererererererererererer&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# travellerererererererererererererererererererererererererer&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;5-机器翻译与数据集&#34;&gt;5. 机器翻译与数据集&lt;/h2&gt;
&lt;p&gt;语言模型是自然语言处理的关键，而机器翻译是语言模型最成功的基准测试。因为机器翻译正是将输入序列转换成输出序列的&lt;strong&gt;序列转换模型&lt;/strong&gt;（sequence transduction）的核心问题。&lt;/p&gt;
&lt;p&gt;与语言模型那一节中的语料库是单一语言的语言模型问题存在不同，机器翻译的数据集是由源语言和目标语言的文本序列对组成的。因此，我们需要一种完全不同的方法来预处理机器翻译数据集，而不是复用语言模型的预处理程序。&lt;/p&gt;
&lt;p&gt;首先，下载一个由双语句子对组成的“英-法”数据集，数据集中的每一行都是制表符分隔的文本序列对，序列对由英文文本序列和翻译后的法语文本序列组成。请注意，每个文本序列可以是一个句子，也可以是包含多个句子的一个段落。在这个将英语翻译成法语的机器翻译问题中，英语是源语言（source language），法语是目标语言（target language）。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.DATA_HUB[&lt;span class=&#34;string&#34;&gt;&amp;#x27;fra-eng&amp;#x27;&lt;/span&gt;] = (d2l.DATA_URL + &lt;span class=&#34;string&#34;&gt;&amp;#x27;fra-eng.zip&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;94646ad1522d915e7b0f9296181140edcf86a4f5&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;read_data_nmt&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;载入“英语-法语”数据集&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    data_dir = d2l.download_extract(&lt;span class=&#34;string&#34;&gt;&amp;#x27;fra-eng&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(os.path.join(data_dir, &lt;span class=&#34;string&#34;&gt;&amp;#x27;fra.txt&amp;#x27;&lt;/span&gt;), &lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;, encoding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;utf-8&amp;#x27;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; f.read()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;raw_text = read_data_nmt()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(raw_text[:&lt;span class=&#34;number&#34;&gt;75&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Go.    Va !&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Hi.    Salut !&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Run!    Cours !&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Run!    Courez !&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Who?    Qui ?&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Wow!    Ça alors !&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下载数据集后，原始文本数据需要经过几个预处理步骤。例如，我们用空格代替不间断空格（non-breaking space），使用小写字母替换大写字母，并在单词和标点符号之间插入空格：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;preprocess_nmt&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;text&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;预处理“英语-法语”数据集&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;no_space&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;char, prev_char&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; char &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;set&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;,.!?&amp;#x27;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; prev_char != &lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 使用空格替换不间断空格，使用小写字母替换大写字母&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    text = text.replace(&lt;span class=&#34;string&#34;&gt;&amp;#x27;\u202f&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;).replace(&lt;span class=&#34;string&#34;&gt;&amp;#x27;\xa0&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;).lower()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 在单词和标点符号之间插入空格&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    out = [&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt; + char &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; i &amp;gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; no_space(char, text[i - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]) &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; char &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, char &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(text)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;#x27;&lt;/span&gt;.join(out)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;text = preprocess_nmt(raw_text)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(text[:&lt;span class=&#34;number&#34;&gt;80&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# go .    va !&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# hi .    salut !&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# run !    cours !&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# run !    courez !&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# who ?    qui ?&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# wow !    ça alors !&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;与之前的字符级词元化不同，在机器翻译中，我们更喜欢单词级词元化（最先进的模型可能使用更高级的词元化技术）。下面的 &lt;code&gt;tokenize_nmt&lt;/code&gt; 函数对前 &lt;code&gt;num_examples&lt;/code&gt; 个文本序列对进行词元化，其中每个词元要么是一个词，要么是一个标点符号。此函数返回两个词元列表：&lt;code&gt;source&lt;/code&gt; 和 &lt;code&gt;target&lt;/code&gt;，&lt;code&gt;source[i]&lt;/code&gt; 是源语言（这里是英语）第 &lt;code&gt;i&lt;/code&gt; 个文本序列的词元列表，&lt;code&gt;target[i]&lt;/code&gt; 是目标语言（这里是法语）第 &lt;code&gt;i&lt;/code&gt; 个文本序列的词元列表。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;tokenize_nmt&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;text, num_examples=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# num_examples限制数据集的数量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;词元化“英语-法语”数据集&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    source, target = [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, line &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(text.split(&lt;span class=&#34;string&#34;&gt;&amp;#x27;\n&amp;#x27;&lt;/span&gt;)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; num_examples &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; i &amp;gt; num_examples:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;break&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        parts = line.split(&lt;span class=&#34;string&#34;&gt;&amp;#x27;\t&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(parts) == &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            source.append(parts[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].split(&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            target.append(parts[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].split(&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; source, target&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;source, target = tokenize_nmt(text)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(source[:&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], target[:&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# [[&amp;#x27;go&amp;#x27;, &amp;#x27;.&amp;#x27;], [&amp;#x27;hi&amp;#x27;, &amp;#x27;.&amp;#x27;], [&amp;#x27;run&amp;#x27;, &amp;#x27;!&amp;#x27;]] [[&amp;#x27;va&amp;#x27;, &amp;#x27;!&amp;#x27;], [&amp;#x27;salut&amp;#x27;, &amp;#x27;!&amp;#x27;], [&amp;#x27;cours&amp;#x27;, &amp;#x27;!&amp;#x27;]]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;让我们绘制每个文本序列所包含的词元数量的直方图。在这个简单的“英-法”数据集中，大多数文本序列的词元数量少于20个：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;show_list_len_pair_hist&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;legend, title, xlabel, ylabel, xlist, ylist&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;绘制列表长度对的直方图&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.figure(figsize=(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;), dpi=&lt;span class=&#34;number&#34;&gt;150&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    _, _, patches = plt.hist([[&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(l) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; l &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; xlist], [&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(l) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; l &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; ylist]], edgecolor=&lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;, alpha=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.title(title)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.xlabel(xlabel)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.ylabel(ylabel)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.legend(legend)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# for patch in patches[1].patches:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#     patch.set_hatch(&amp;#x27;/&amp;#x27;)  # 给第二个list对的条形设置填充效果&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_list_len_pair_hist([&lt;span class=&#34;string&#34;&gt;&amp;#x27;source&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;target&amp;#x27;&lt;/span&gt;], &lt;span class=&#34;string&#34;&gt;&amp;#x27;The length of list&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;# tokens per sequence&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;count&amp;#x27;&lt;/span&gt;, source, target)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;由于机器翻译数据集由语言对组成，因此我们可以分别为源语言和目标语言构建两个词表。使用单词级词元化时，词表大小将明显大于使用字符级词元化时的词表大小。为了缓解这一问题，这里我们将出现次数少于2次的低频率词元视为相同的未知（&lt;code&gt;&amp;lt;unk&amp;gt;&lt;/code&gt;）词元。除此之外，我们还指定了额外的特定词元，例如在小批量时用于将序列填充到相同长度的填充词元（&lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;），以及序列的开始词元（&lt;code&gt;&amp;lt;bos&amp;gt;&lt;/code&gt;）和结束词元（&lt;code&gt;&amp;lt;eos&amp;gt;&lt;/code&gt;）。这些特殊词元在自然语言处理任务中比较常用。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;src_vocab = d2l.Vocab(source, min_freq=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, reserved_tokens=[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;pad&amp;gt;&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;bos&amp;gt;&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;eos&amp;gt;&amp;#x27;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(src_vocab))  &lt;span class=&#34;comment&#34;&gt;# 10012&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;回想一下，语言模型中的序列样本都有一个固定的长度，无论这个样本是一个句子的一部分还是跨越了多个句子的一个片断。这个固定长度是由语言模型中的 &lt;code&gt;num_steps&lt;/code&gt;（时间步数或词元数量）参数指定的。在机器翻译中，每个样本都是由源和目标组成的文本序列对，其中的每个文本序列可能具有不同的长度。&lt;/p&gt;
&lt;p&gt;为了提高计算效率，我们仍然可以通过&lt;strong&gt;截断&lt;/strong&gt;（truncation）和&lt;strong&gt;填充&lt;/strong&gt;（padding）方式实现一次只处理一个小批量的文本序列。假设同一个小批量中的每个序列都应该具有相同的长度 &lt;code&gt;num_steps&lt;/code&gt;，那么如果文本序列的词元数目少于 &lt;code&gt;num_steps&lt;/code&gt; 时，我们将继续在其末尾添加特定的 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; 词元，直到其长度达到 &lt;code&gt;num_steps&lt;/code&gt;；反之，我们将截断文本序列时，只取其前 &lt;code&gt;num_steps&lt;/code&gt; 个词元，并且丢弃剩余的词元。这样，每个文本序列将具有相同的长度，以便以相同形状的小批量进行加载。下面的 &lt;code&gt;truncate_pad&lt;/code&gt; 函数将截断或填充文本序列：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;truncate_pad&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;line, num_steps, padding_token&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;截断或填充文本序列&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(line) &amp;gt; num_steps:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; line[:num_steps]  &lt;span class=&#34;comment&#34;&gt;# 截断&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; line + [padding_token] * (num_steps - &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(line))  &lt;span class=&#34;comment&#34;&gt;# 填充&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(truncate_pad(src_vocab[source[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]], &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, src_vocab[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;pad&amp;gt;&amp;#x27;&lt;/span&gt;]))  &lt;span class=&#34;comment&#34;&gt;# [47, 4, 1, 1, 1, 1, 1, 1, 1, 1]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在我们定义一个函数，可以将文本序列转换成小批量数据集用于训练。我们将特定的 &lt;code&gt;&amp;lt;eos&amp;gt;&lt;/code&gt; 词元添加到所有序列的末尾，用于表示序列的结束。当模型通过一个词元接一个词元地生成序列进行预测时，生成的 &lt;code&gt;&amp;lt;eos&amp;gt;&lt;/code&gt; 词元说明完成了序列输出工作。此外，我们还记录了每个文本序列的长度，统计长度时排除了填充词元，在稍后将要介绍的一些模型会需要这个长度信息。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;build_array_nmt&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;lines, vocab, num_steps&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;将机器翻译的文本序列转换成小批量&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    lines = [vocab[l] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; l &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; lines]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    lines = [l + [vocab[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;eos&amp;gt;&amp;#x27;&lt;/span&gt;]] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; l &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; lines]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    array = torch.tensor([truncate_pad(l, num_steps, vocab[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;pad&amp;gt;&amp;#x27;&lt;/span&gt;]) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; l &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; lines])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    valid_len = (array != vocab[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;pad&amp;gt;&amp;#x27;&lt;/span&gt;]).&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(torch.int32).&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; array, valid_len&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后，我们定义 &lt;code&gt;load_data_nmt&lt;/code&gt; 函数来返回数据迭代器，以及源语言和目标语言的两种词表：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;load_data_nmt&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size, num_steps, num_examples=&lt;span class=&#34;number&#34;&gt;600&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;返回翻译数据集的迭代器和词表&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    text = preprocess_nmt(read_data_nmt())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    source, target = tokenize_nmt(text, num_examples)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    src_vocab = d2l.Vocab(source, min_freq=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, reserved_tokens=[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;pad&amp;gt;&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;bos&amp;gt;&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;eos&amp;gt;&amp;#x27;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    tgt_vocab = d2l.Vocab(target, min_freq=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, reserved_tokens=[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;pad&amp;gt;&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;bos&amp;gt;&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;eos&amp;gt;&amp;#x27;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    data_iter = d2l.load_array(data_arrays, batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; data_iter, src_vocab, tgt_vocab&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, num_steps=&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, X_valid_len, Y, Y_valid_len &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; train_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;X:&amp;#x27;&lt;/span&gt;, X.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(torch.int32))  &lt;span class=&#34;comment&#34;&gt;# X: tensor([[ 6, 18, 43,  4,  3,  1,  1,  1], [78,  9,  4,  3,  1,  1,  1,  1]], dtype=torch.int32)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;X的有效长度:&amp;#x27;&lt;/span&gt;, X_valid_len)  &lt;span class=&#34;comment&#34;&gt;# X的有效长度: tensor([5, 4])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Y:&amp;#x27;&lt;/span&gt;, Y.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(torch.int32))  &lt;span class=&#34;comment&#34;&gt;# Y: tensor([[ 6,  7, 40,  4,  3,  1,  1,  1], [ 0,  4,  3,  1,  1,  1,  1,  1]], dtype=torch.int32)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Y的有效长度:&amp;#x27;&lt;/span&gt;, Y_valid_len)  &lt;span class=&#34;comment&#34;&gt;# Y的有效长度: tensor([5, 3])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;break&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;6-编码器-解码器架构&#34;&gt;6. 编码器-解码器架构&lt;/h2&gt;
&lt;p&gt;正如我们在上一节中所讨论的，机器翻译是序列转换模型的一个核心问题，其输入和输出都是长度可变的序列。为了处理这种类型的输入和输出，我们可以设计一个包含两个主要组件的架构：第一个组件是一个&lt;strong&gt;编码器&lt;/strong&gt;（encoder）：它接受一个&lt;strong&gt;长度可变&lt;/strong&gt;的序列作为输入，并将其转换为具有&lt;strong&gt;固定形状&lt;/strong&gt;的编码状态。第二个组件是&lt;strong&gt;解码器&lt;/strong&gt;（decoder）：它将&lt;strong&gt;固定形状&lt;/strong&gt;的编码状态映射到&lt;strong&gt;长度可变&lt;/strong&gt;的序列。这被称为编码器-解码器（encoder-decoder）架构，示意图可见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-modern/encoder-decoder.html&#34;&gt;编码器-解码器架构&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;由于“编码器-解码器”架构是形成后续章节中不同序列转换模型的基础，因此本节将把这个架构转换为接口方便后面的代码实现。&lt;/p&gt;
&lt;p&gt;在编码器接口中，我们只指定长度可变的序列作为编码器的输入 &lt;code&gt;X&lt;/code&gt;。任何继承这个 &lt;code&gt;Encoder&lt;/code&gt; 基类的模型将完成代码实现：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Encoder&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;编码器-解码器架构的基本编码器接口&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Encoder, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X, *args&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;raise&lt;/span&gt; NotImplementedError&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在下面的解码器接口中，我们新增一个 &lt;code&gt;init_state&lt;/code&gt; 函数，用于将编码器的输出（enc_outputs）转换为编码后的状态。注意，此步骤可能需要额外的输入，例如输入序列的有效长度。为了逐个地生成长度可变的词元序列，解码器在每个时间步都会将输入（例如在前一时间步生成的词元）和编码后的状态映射成当前时间步的输出词元：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Decoder&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;编码器-解码器架构的基本解码器接口&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Decoder, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_state&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, enc_outputs, *args&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;raise&lt;/span&gt; NotImplementedError&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X, state&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;raise&lt;/span&gt; NotImplementedError&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;总而言之，“编码器-解码器”架构包含了一个编码器和一个解码器，并且还拥有可选的额外的参数。在前向传播中，编码器的输出用于生成编码状态，这个状态又被解码器作为其输入的一部分：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;EncoderDecoder&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;编码器-解码器架构的基类&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, encoder, decoder, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(EncoderDecoder, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.encoder = encoder&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.decoder = decoder&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, enc_X, dec_X, *args&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        enc_outputs = self.encoder(enc_X, *args)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        dec_state = self.decoder.init_state(enc_outputs, *args)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.decoder(dec_X, dec_state)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;7-序列到序列学习（seq2seq）&#34;&gt;7. 序列到序列学习（seq2seq）&lt;/h2&gt;
&lt;p&gt;遵循编码器-解码器架构的设计原则，循环神经网络编码器使用长度可变的序列作为输入，将其转换为固定形状的隐状态。换言之，输入序列的信息被编码到循环神经网络编码器的隐状态中。为了连续生成输出序列的词元，独立的循环神经网络解码器是基于输入序列的编码信息和输出序列已经看见的或者生成的词元来预测下一个词元。在机器翻译中使用两个循环神经网络进行序列到序列学习的图示以及理论介绍可见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-modern/seq2seq.html&#34;&gt;序列到序列学习（seq2seq）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在序列到序列学习中，特定的 &lt;code&gt;&amp;lt;eos&amp;gt;&lt;/code&gt; 表示序列结束词元。一旦输出序列生成此词元，模型就会停止预测。在循环神经网络解码器的初始化时间步，有两个特定的设计决定：首先，特定的 &lt;code&gt;&amp;lt;bos&amp;gt;&lt;/code&gt; 表示序列开始词元，它是解码器的输入序列的第一个词元。其次，使用循环神经网络编码器最终的隐状态来初始化解码器的隐状态。&lt;/p&gt;
&lt;p&gt;从技术上讲，编码器将长度可变的输入序列转换成形状固定的上下文变量，并且将输入序列的信息在该上下文变量中进行编码。&lt;/p&gt;
&lt;p&gt;现在，让我们实现循环神经网络编码器。注意，我们使用了嵌入层（embedding layer）来获得输入序列中每个词元的特征向量。嵌入层的权重是一个矩阵，其行数等于输入词表的大小（vocab_size），其列数等于特征向量的维度（embed_size）。另外，本文选择了一个多层门控循环单元来实现编码器。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; collections&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; math&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Seq2SeqEncoder&lt;/span&gt;(d2l.Encoder):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;用于序列到序列学习的循环神经网络编码器&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, vocab_size, embed_size, num_hiddens, num_layers, dropout=&lt;span class=&#34;number&#34;&gt;0.&lt;/span&gt;, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Seq2SeqEncoder, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.embedding = nn.Embedding(vocab_size, embed_size)  &lt;span class=&#34;comment&#34;&gt;# 嵌入层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X, *args&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = self.embedding(X)  &lt;span class=&#34;comment&#34;&gt;# X.shape: (batch_size, num_steps, embed_size)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = X.permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 在循环神经网络模型中，第一个轴对应于时间步&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output, state = self.rnn(X)  &lt;span class=&#34;comment&#34;&gt;# 如果未提及状态，则默认为0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# output.shape: (num_steps, batch_size, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# state.shape: (num_layers, batch_size, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output, state&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下面，我们实例化上述编码器的实现：我们使用一个两层门控循环单元编码器，其隐藏单元数为16。给定一小批量的输入序列 &lt;code&gt;X&lt;/code&gt;（批量大小为4，时间步为7）。在完成所有时间步后，最后一层的隐状态的输出是一个张量（&lt;code&gt;output&lt;/code&gt; 由编码器的循环层返回），其形状为 &lt;code&gt;(时间步数, 批量大小, 隐藏单元数)&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;由于这里使用的是门控循环单元，所以在最后一个时间步的多层隐状态的形状是 &lt;code&gt;(隐藏层的数量, 批量大小, 隐藏单元的数量)&lt;/code&gt;。如果使用长短期记忆网络，&lt;code&gt;state&lt;/code&gt; 中还将包含记忆单元信息。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;encoder = Seq2SeqEncoder(vocab_size=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, embed_size=&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, num_hiddens=&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, num_layers=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;encoder.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.zeros((&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;), dtype=torch.long)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output, state = encoder(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output.shape, state.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([7, 4, 16]) torch.Size([2, 4, 16])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;当实现解码器时，我们直接使用编码器最后一个时间步的隐状态来初始化解码器的隐状态。这就要求使用循环神经网络实现的编码器和解码器具有&lt;strong&gt;相同数量的层和隐藏单元&lt;/strong&gt;。为了进一步包含经过编码的输入序列的信息，上下文变量在所有的时间步与解码器的输入进行拼接（concatenate）。为了预测输出词元的概率分布，在循环神经网络解码器的最后一层使用全连接层来变换隐状态。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Seq2SeqDecoder&lt;/span&gt;(d2l.Decoder):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;用于序列到序列学习的循环神经网络解码器&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, vocab_size, embed_size, num_hiddens, num_layers, dropout=&lt;span class=&#34;number&#34;&gt;0.&lt;/span&gt;, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Seq2SeqDecoder, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.embedding = nn.Embedding(vocab_size, embed_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.dense = nn.Linear(num_hiddens, vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_state&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, enc_outputs, *args&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; enc_outputs[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]  &lt;span class=&#34;comment&#34;&gt;# enc_outputs[1]即为[output, state]中的state&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X, state&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = self.embedding(X).permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# X.shape: (num_steps, batch_size, embed_size)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        context = state[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].repeat(X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 广播context，使其具有与X相同的num_steps&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X_and_context = torch.cat((X, context), &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 因此RNN的输入维度为embed_size + num_hiddens&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output, state = self.rnn(X_and_context, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.dense(output).permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# output.shape: (batch_size, num_steps, vocab_size)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# state.shape: (num_layers, batch_size, num_hiddens)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output, state&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下面，我们用与前面提到的编码器中相同的超参数来实例化解码器。如我们所见，解码器的输出形状变为 &lt;code&gt;(批量大小, 时间步数, 词表大小)&lt;/code&gt;，其中张量的最后一个维度存储预测的词元分布。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;decoder = Seq2SeqDecoder(vocab_size=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, embed_size=&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, num_hiddens=&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, num_layers=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;decoder.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;state = decoder.init_state(encoder(X))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output, state = decoder(X, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output.shape, state.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([4, 7, 10]) torch.Size([2, 4, 16])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在每个时间步，解码器预测了输出词元的概率分布。类似于语言模型，可以使用 Softmax 来获得分布，并通过计算交叉熵损失函数来进行优化。回想一下我们将特定的填充词元添加到序列的末尾，因此不同长度的序列可以以相同形状的小批量加载。但是，我们应该将填充词元的预测排除在损失函数的计算之外。&lt;/p&gt;
&lt;p&gt;为此，我们可以使用下面的 &lt;code&gt;sequence_mask&lt;/code&gt; 函数通过&lt;strong&gt;零值化&lt;/strong&gt;屏蔽不相关的项，以便后面任何不相关预测的计算都是与零的乘积，结果都等于零。例如，如果两个序列的有效长度（不包括填充词元）分别为1和2，则第一个序列的第一项和第二个序列的前两项之后的剩余项将被清除为零：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 解析[None, :]和[:, None]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.arange(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)[&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, :])  &lt;span class=&#34;comment&#34;&gt;# tensor([[0, 1, 2]])，在第1维增加一维，同理[:, None]在第2维增加一维&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.arange(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)[&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, :] &amp;lt; torch.tensor([&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])[:, &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[ True, False, False],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [ True,  True, False]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;sequence_mask&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, valid_len, value=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;在序列中屏蔽不相关的项&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    maxlen = X.size(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, :] &amp;lt; valid_len[:, &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    X[~mask] = value&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.tensor([[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(sequence_mask(X, torch.tensor([&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[1, 0, 0],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [4, 5, 0]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在，我们可以通过扩展 Softmax 交叉熵损失函数来遮蔽不相关的预测。最初，所有预测词元的掩码都设置为1。一旦给定了有效长度，与填充词元对应的掩码将被设置为0。最后，将所有词元的损失乘以掩码，以过滤掉损失中填充词元产生的不相关预测。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;MaskedSoftmaxCELoss&lt;/span&gt;(nn.CrossEntropyLoss):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;带遮蔽的softmax交叉熵损失函数&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# pred.shape: (batch_size, num_steps, vocab_size)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# label.shape: (batch_size, num_steps)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# valid_len.shape: (batch_size,)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, pred, label, valid_len&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        weights = torch.ones_like(label)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        weights = sequence_mask(weights, valid_len)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.reduction=&lt;span class=&#34;string&#34;&gt;&amp;#x27;none&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        unweighted_loss = &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(MaskedSoftmaxCELoss, self).forward(pred.permute(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), label)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        weighted_loss = (unweighted_loss * weights).mean(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; weighted_loss&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以创建三个相同的序列来进行代码健全性检查，然后分别指定这些序列的有效长度为4、2和0。结果就是，第一个序列的损失应为第二个序列的两倍，而第三个序列的损失应为零。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;loss = MaskedSoftmaxCELoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(loss(torch.ones(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;), torch.ones((&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;), dtype=torch.long), torch.tensor([&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])))  &lt;span class=&#34;comment&#34;&gt;# tensor([2.3026, 1.1513, 0.0000])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在下面的循环训练过程中，特定的序列开始词元（&lt;code&gt;&amp;lt;bos&amp;gt;&lt;/code&gt;）和原始的输出序列（不包括序列结束词元 &lt;code&gt;&amp;lt;eos&amp;gt;&lt;/code&gt;）拼接在一起作为解码器的输入。这被称为&lt;strong&gt;强制教学&lt;/strong&gt;（teacher forcing），因为原始的输出序列（词元的标签）被送入解码器。或者，将来自上一个时间步的预测得到的词元作为解码器的当前输入。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train_seq2seq&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, data_iter, lr, num_epochs, tgt_vocab, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;训练序列到序列模型&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;xavier_init_weights&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;m&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.Linear:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.init.xavier_uniform_(m.weight)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.GRU:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; m._flat_weights_names:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;weight&amp;quot;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; param:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.init.xavier_uniform_(m._parameters[param])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.apply(xavier_init_weights)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer = torch.optim.Adam(net.parameters(), lr=lr)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function = MaskedSoftmaxCELoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/seq2seq_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        timer = d2l.Timer()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        num_tokens = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;  &lt;span class=&#34;comment&#34;&gt;# 词元数量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; batch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(data_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            X, X_valid_len, Y, Y_valid_len = [x.to(device) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; x &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; batch]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            bos = torch.tensor([tgt_vocab[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;bos&amp;gt;&amp;#x27;&lt;/span&gt;]] * Y.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], device=device).reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            dec_input = torch.cat([bos, Y[:, :-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]], &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 强制教学&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            Y_hat, _ = net(X, dec_input, X_valid_len)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss = loss_function(Y_hat, Y, Y_valid_len).mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss.backward()  &lt;span class=&#34;comment&#34;&gt;# 损失函数的标量进行“反向传播”&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            d2l.grad_clipping(net, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_loss.append(loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            num_tokens += Y_valid_len.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; (epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt; == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_loss = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_loss&amp;#x27;&lt;/span&gt;, train_loss, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;loss &lt;span class=&#34;subst&#34;&gt;&amp;#123;train_loss:&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;f&amp;#125;&lt;/span&gt;, &lt;span class=&#34;subst&#34;&gt;&amp;#123;num_tokens / timer.stop():&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;f&amp;#125;&lt;/span&gt; tokens/sec on &lt;span class=&#34;subst&#34;&gt;&amp;#123;&lt;span class=&#34;built_in&#34;&gt;str&lt;/span&gt;(device)&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.close()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;embed_size, num_hiddens, num_layers, dropout = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, num_steps, lr, num_epochs = &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.005&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;300&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;encoder = Seq2SeqEncoder(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(src_vocab), embed_size, num_hiddens, num_layers, dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;decoder = Seq2SeqDecoder(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = d2l.EncoderDecoder(encoder, decoder)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;为了采用一个接着一个词元的方式预测输出序列，每个解码器当前时间步的输入都将来自于前一时间步的预测词元。与训练类似，序列开始词元（&lt;code&gt;&amp;lt;bos&amp;gt;&lt;/code&gt;）在初始时间步被输入到解码器中，当输出序列的预测遇到序列结束词元（&lt;code&gt;&amp;lt;eos&amp;gt;&lt;/code&gt;）时，预测就结束了。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;predict_seq2seq&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;序列到序列模型的预测&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()  &lt;span class=&#34;comment&#34;&gt;# 在预测时将net设置为评估模式&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    src_tokens = src_vocab[src_sentence.lower().split(&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;)] + [src_vocab[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;eos&amp;gt;&amp;#x27;&lt;/span&gt;]]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    enc_valid_len = torch.tensor([&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(src_tokens)], device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;pad&amp;gt;&amp;#x27;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 添加批量维度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    enc_outputs = net.encoder(enc_X, enc_valid_len)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;bos&amp;gt;&amp;#x27;&lt;/span&gt;]], dtype=torch.long, device=device), dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 添加批量维度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output_seq, attention_weight_seq = [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; _ &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_steps):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y, dec_state = net.decoder(dec_X, dec_state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        dec_X = Y.argmax(dim=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        pred = dec_X.squeeze(dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;).&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(torch.int32).item()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 保存注意力权重（稍后讨论）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; save_attention_weights:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            attention_weight_seq.append(net.decoder.attention_weights)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 一旦序列结束词元被预测，输出序列的生成就完成了&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; pred == tgt_vocab[&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;eos&amp;gt;&amp;#x27;&lt;/span&gt;]:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;break&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output_seq.append(pred)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以通过与真实的标签序列进行比较来评估预测序列。虽然BLEU（bilingual evaluation understudy）最先是用于评估机器翻译的结果，但现在它已经被广泛用于测量许多应用的输出序列的质量。BLEU的详细介绍可见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-modern/seq2seq.html&#34;&gt;序列到序列学习（seq2seq）&lt;/a&gt;。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;bleu&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;pred_seq, label_seq, k&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;计算BLEU&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pred_tokens, label_tokens = pred_seq.split(&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;), label_seq.split(&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    len_pred, len_label = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(pred_tokens), &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(label_tokens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    score = math.exp(&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; - len_label / len_pred))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; n &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, k + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        num_matches, label_subs = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, collections.defaultdict(&lt;span class=&#34;built_in&#34;&gt;int&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(len_label - n + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            label_subs[&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;.join(label_tokens[i: i + n])] += &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(len_pred - n + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; label_subs[&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;.join(pred_tokens[i: i + n])] &amp;gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                num_matches += &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                label_subs[&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;.join(pred_tokens[i: i + n])] -= &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        score *= math.&lt;span class=&#34;built_in&#34;&gt;pow&lt;/span&gt;(num_matches / (len_pred - n + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), math.&lt;span class=&#34;built_in&#34;&gt;pow&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, n))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; score&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;engs = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;go .&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;i lost .&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;he\&amp;#x27;s calm .&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;i\&amp;#x27;m home .&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;fras = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;va !&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;j\&amp;#x27;ai perdu .&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;il est calme .&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;je suis chez moi .&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; eng, fra &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(engs, fras):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    translation, attention_weight_seq = predict_seq2seq(net, eng, src_vocab, tgt_vocab, num_steps, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;eng&amp;#125;&lt;/span&gt; =&amp;gt; &lt;span class=&#34;subst&#34;&gt;&amp;#123;translation&amp;#125;&lt;/span&gt;, bleu &lt;span class=&#34;subst&#34;&gt;&amp;#123;bleu(translation, fra, k=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;):&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# go . =&amp;gt; va !, bleu 1.000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# i lost . =&amp;gt; j&amp;#x27;ai perdu ., bleu 1.000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# he&amp;#x27;s calm . =&amp;gt; il est bon malade pas gagné pas en gagné pas, bleu 0.258&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# i&amp;#x27;m home . =&amp;gt; je suis fainéante fainéante tomber ai ai homme paresseux ?, bleu 0.258&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;8-束搜索&#34;&gt;8. 束搜索&lt;/h2&gt;
&lt;p&gt;束搜索为预测输出序列的一个算法，详细介绍可见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-modern/beam-search.html&#34;&gt;束搜索&lt;/a&gt;。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/11559.html</guid>
            <title>动手学深度学习笔记(李沐)-循环神经网络</title>
            <link>https://asanosaki.github.io/posts/11559.html</link>
            <category>AI</category>
            <pubDate>Wed, 05 Apr 2023 14:04:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;李沐动手学深度学习（PyTorch）课程学习笔记第八章：循环神经网络。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-序列模型&#34;&gt;1. 序列模型&lt;/h2&gt;
&lt;p&gt;由于涉及较多数学公式，序列模型的讲解可以转至：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/sequence.html&#34;&gt;序列模型&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;首先，我们生成一些数据：使用正弦函数和一些可加性噪声来生成序列数据，时间步为 &lt;code&gt;1, 2, ..., 1000&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tqdm &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tqdm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;T = &lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;  &lt;span class=&#34;comment&#34;&gt;# 总共产生1000个点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;time = torch.arange(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, T + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, dtype=torch.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.sin(&lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt; * time) + torch.normal(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, (T,))  &lt;span class=&#34;comment&#34;&gt;# 0~10大概为一个半周期(3*PI)，并加入噪声&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.plot(time, [x], &lt;span class=&#34;string&#34;&gt;&amp;#x27;time&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;x&amp;#x27;&lt;/span&gt;, xlim=[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;], figsize=(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来，我们将这个序列转换为模型的特征-标签（feature-label）对。基于嵌入维度 &lt;code&gt;𝜏&lt;/code&gt;，我们将数据映射为数据对 &lt;code&gt;𝑦_𝑡 = 𝑥_𝑡&lt;/code&gt; 和 &lt;code&gt;𝐱_𝑡 = [𝑥_&amp;#123;𝑡 - 𝜏&amp;#125;, ...,𝑥_&amp;#123;𝑡 - 1&amp;#125;]&lt;/code&gt;，这比我们提供的数据样本少了 &lt;code&gt;𝜏&lt;/code&gt; 个，因为我们没有足够的历史记录来描述前 &lt;code&gt;𝜏&lt;/code&gt; 个数据样本。一个简单的解决办法是：如果拥有足够长的序列就丢弃这几项；另一个方法是用零填充序列。在这里，我们仅使用前600个特征-标签对进行训练：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tau = &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;features = torch.zeros((T - tau, tau))  &lt;span class=&#34;comment&#34;&gt;# 一共996个样本，每个样本的特征长度为4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(tau):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    features[:, i] = x[i:T - tau + i]  &lt;span class=&#34;comment&#34;&gt;# 按列填充&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;labels = x[tau:].reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# labels的元素在x中的下标为[4, 5, 6, ...]，即0~3预测4，1~4预测5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# features的元素在x中的下标:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [0, 1, 2, 3]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [1, 2, 3, 4]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [T - tau, T - tau + 1, T - tau + 2, T - tau + 3]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, n_train = &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;600&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 只有前n_train个样本用于训练&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter = d2l.load_array((features[:n_train], labels[:n_train]), batch_size, is_train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在这里，我们使用一个相当简单的架构训练模型：一个拥有两个全连接层的多层感知机，ReLU 激活函数和平方损失：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_weights&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;m&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.Linear:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.init.xavier_uniform_(m.weight)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Linear(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;), nn.ReLU(), nn.Linear(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net.apply(init_weights)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = nn.MSELoss(reduction=&lt;span class=&#34;string&#34;&gt;&amp;#x27;none&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 注意：MSELoss计算平方误差时不带系数1/2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在准备训练模型，实现下面的训练代码的方式与前面几章中的循环训练基本相同。因此，我们不会深入探讨太多细节：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, loss_function, num_epochs, lr, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;training on&amp;#x27;&lt;/span&gt;, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer = torch.optim.Adam(net.parameters(), lr=lr)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        net.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(train_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            X, y = X.to(device), y.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss = loss_function(net(X), y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss.mean().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_loss.append(loss.mean())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;quot;[ Train | &lt;span class=&#34;subst&#34;&gt;&amp;#123;epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:03d&amp;#125;&lt;/span&gt;/&lt;span class=&#34;subst&#34;&gt;&amp;#123;num_epochs:03d&amp;#125;&lt;/span&gt; ] loss = &lt;span class=&#34;subst&#34;&gt;&amp;#123;train_loss:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr, num_epochs = &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, loss_function, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;, device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;由于训练损失很小，因此我们期望模型能有很好的工作效果。让我们看看这在实践中意味着什么。首先是检查模型预测下一个时间步的能力，也就是单步预测（one-step-ahead prediction）：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;onestep_preds = net(features.to(device))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.plot([time, time[tau:]], [x.detach().numpy(), onestep_preds.cpu().detach().numpy()],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         &lt;span class=&#34;string&#34;&gt;&amp;#x27;time&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;x&amp;#x27;&lt;/span&gt;, legend=[&lt;span class=&#34;string&#34;&gt;&amp;#x27;data&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;1-step preds&amp;#x27;&lt;/span&gt;], xlim=[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;], figsize=(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;正如我们所料，单步预测效果不错。即使这些预测的时间步超过了604（&lt;code&gt;n_train + tau&lt;/code&gt;），其结果看起来仍然是可信的。然而有一个小问题：如果数据观察序列的时间步只到604，我们需要一步一步地向前迈进，换句话说，我们必须使用我们自己的预测（而不是原始数据）来进行多步预测。让我们看看效果如何：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;multistep_preds = torch.zeros(T)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;multistep_preds[:n_train + tau] = x[:n_train + tau]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(n_train + tau, T):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    multistep_preds[i] = net(multistep_preds[i - tau:i].reshape((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)).to(device))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.plot([time, time[tau:], time[n_train + tau:]],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [x.detach().numpy(), onestep_preds.cpu().detach().numpy(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;          multistep_preds[n_train + tau:].cpu().detach().numpy()], &lt;span class=&#34;string&#34;&gt;&amp;#x27;time&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;x&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         legend=[&lt;span class=&#34;string&#34;&gt;&amp;#x27;data&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;1-step preds&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;multi-step preds&amp;#x27;&lt;/span&gt;], xlim=[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;], figsize=(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如上面的例子所示，绿线的预测显然并不理想。经过几个预测步骤之后，预测的结果很快就会衰减到一个常数。为什么这个算法效果这么差呢？事实是由于误差的累积：假设在步骤1之后，我们积累了一些误差，于是步骤2的输入被扰动了，后面的预测误差依此类推。因此误差可能会相当快地偏离真实的观测结果。例如，未来24小时的天气预报往往相当准确，但超过这一点，精度就会迅速下降。我们将在本章及后续章节中讨论如何改进这一点。&lt;/p&gt;
&lt;p&gt;基于 &lt;code&gt;k = 1, 4, 16, 64&lt;/code&gt;，通过对整个序列预测的计算，让我们更仔细地看一下 &lt;code&gt;k&lt;/code&gt; 步预测的困难：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;max_steps = &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;features = torch.zeros((T - tau - max_steps + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, tau + max_steps))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 列i(i&amp;lt;tau)是来自x的观测，其时间步从(i)到(i+T-tau-max_steps+1)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(tau):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    features[:, i] = x[i:i + T - tau - max_steps + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 列i(i&amp;gt;=tau)是来自(i-tau+1)步的预测，其时间步从(i)到(i+T-tau-max_steps+1)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(tau, tau + max_steps):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    features[:, i] = net(features[:, i - tau:i].to(device)).reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;steps = (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.plot([time[tau + i - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:T - max_steps + i] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; steps],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         [features[:, tau + i - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].cpu().detach().numpy() &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; steps], &lt;span class=&#34;string&#34;&gt;&amp;#x27;time&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;x&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         legend=[&lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;i&amp;#125;&lt;/span&gt;-step preds&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; steps], xlim=[&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;], figsize=(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-文本预处理&#34;&gt;2. 文本预处理&lt;/h2&gt;
&lt;p&gt;对于序列数据处理问题，我们在上一节中评估了所需的统计工具和预测时面临的挑战。这样的数据存在许多种形式，文本是最常见例子之一。例如，一篇文章可以被简单地看作一串单词序列，甚至是一串字符序列。本节中，我们将解析文本的常见预处理步骤。这些步骤通常包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将文本作为字符串加载到内存中。&lt;/li&gt;
&lt;li&gt;将字符串拆分为词元（如单词和字符）。&lt;/li&gt;
&lt;li&gt;建立一个词表，将拆分的词元映射到数字索引。&lt;/li&gt;
&lt;li&gt;将文本转换为数字索引序列，方便模型操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;首先，我们从 H.G.Well 的&lt;a href=&#34;https://www.gutenberg.org/ebooks/35&#34;&gt;时光机器&lt;/a&gt;中加载文本。这是一个相当小的语料库，只有30000多个单词，但足够我们小试牛刀，而现实中的文档集合可能会包含数十亿个单词。下面的函数将数据集读取到由多条文本行组成的列表中，其中每条文本行都是一个字符串。为简单起见，我们在这里忽略了标点符号和字母大写：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; collections&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; re&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.DATA_HUB[&lt;span class=&#34;string&#34;&gt;&amp;#x27;time_machine&amp;#x27;&lt;/span&gt;] = (d2l.DATA_URL + &lt;span class=&#34;string&#34;&gt;&amp;#x27;timemachine.txt&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;090b5e7e70c295757f55df93cb0a180b9691891a&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.download(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time_machine&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 默认路径在../data&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;read_time_machine&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;将时间机器数据集加载到文本行的列表中，同时将非大小写字母外的所有字符替换为空格&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../data/timemachine.txt&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        lines = f.readlines()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; [re.sub(&lt;span class=&#34;string&#34;&gt;&amp;#x27;[^A-Za-z]+&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;, line).strip().lower() &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; line &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; lines]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lines = read_time_machine()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;文本总行数: &lt;span class=&#34;subst&#34;&gt;&amp;#123;&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(lines)&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 文本总行数: 3221&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(lines[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# the time machine by h g wells&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(lines[&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# twinkled and his usually pale face was flushed and animated the&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下面的 &lt;code&gt;tokenize&lt;/code&gt; 函数将文本行列表（lines）作为输入，列表中的每个元素是一个文本序列（如一条文本行）。每个文本序列又被拆分成一个词元列表，词元（token）是文本的基本单位。最后，返回一个由词元列表组成的列表，其中的每个词元都是一个字符串（string）：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;tokenize&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;lines, token=&lt;span class=&#34;string&#34;&gt;&amp;#x27;word&amp;#x27;&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;将文本行拆分为单词或字符词元&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; token == &lt;span class=&#34;string&#34;&gt;&amp;#x27;word&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; [line.split() &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; line &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; lines]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; token == &lt;span class=&#34;string&#34;&gt;&amp;#x27;char&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; [&lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(line) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; line &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; lines]  &lt;span class=&#34;comment&#34;&gt;# list(str)能将字符串中的每个字符分隔开形成list&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;错误！未知词元类型:&amp;#x27;&lt;/span&gt; + token)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokens = tokenize(lines)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tokens = tokenize(lines, token=&amp;#x27;char&amp;#x27;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(tokens[i])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [&amp;#x27;the&amp;#x27;, &amp;#x27;time&amp;#x27;, &amp;#x27;machine&amp;#x27;, &amp;#x27;by&amp;#x27;, &amp;#x27;h&amp;#x27;, &amp;#x27;g&amp;#x27;, &amp;#x27;wells&amp;#x27;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# []&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# []&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# []&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# []&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [&amp;#x27;i&amp;#x27;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# []&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# []&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [&amp;#x27;the&amp;#x27;, &amp;#x27;time&amp;#x27;, &amp;#x27;traveller&amp;#x27;, &amp;#x27;for&amp;#x27;, &amp;#x27;so&amp;#x27;, &amp;#x27;it&amp;#x27;, &amp;#x27;will&amp;#x27;, &amp;#x27;be&amp;#x27;, &amp;#x27;convenient&amp;#x27;, &amp;#x27;to&amp;#x27;, &amp;#x27;speak&amp;#x27;, &amp;#x27;of&amp;#x27;, &amp;#x27;him&amp;#x27;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [&amp;#x27;was&amp;#x27;, &amp;#x27;expounding&amp;#x27;, &amp;#x27;a&amp;#x27;, &amp;#x27;recondite&amp;#x27;, &amp;#x27;matter&amp;#x27;, &amp;#x27;to&amp;#x27;, &amp;#x27;us&amp;#x27;, &amp;#x27;his&amp;#x27;, &amp;#x27;grey&amp;#x27;, &amp;#x27;eyes&amp;#x27;, &amp;#x27;shone&amp;#x27;, &amp;#x27;and&amp;#x27;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;词元的类型是字符串，而模型需要的输入是数字，因此这种类型不方便模型使用。现在，让我们构建一个字典，通常也叫做词表（vocabulary），用来将字符串类型的词元映射到从0开始的数字索引中。我们先将训练集中的所有文档合并在一起，对它们的唯一词元进行统计，得到的统计结果称之为语料（corpus）。然后根据每个唯一词元的出现频率，为其分配一个数字索引。很少出现的词元通常被移除，这可以降低复杂性。另外，语料库中不存在或已删除的任何词元都将映射到一个特定的未知词元 &lt;code&gt;&amp;lt;unk&amp;gt;&lt;/code&gt;。我们可以选择增加一个列表，用于保存那些被保留的词元，例如：填充词元（&lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;）、序列开始词元（&lt;code&gt;&amp;lt;bos&amp;gt;&lt;/code&gt;）、序列结束词元（&lt;code&gt;&amp;lt;eos&amp;gt;&lt;/code&gt;）：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Vocab&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;文本词表&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, tokens=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, min_freq=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, reserved_tokens=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; tokens &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            tokens = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; reserved_tokens &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            reserved_tokens = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 按出现频率从大到小排序&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        counter = count_corpus(tokens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self._token_freqs = &lt;span class=&#34;built_in&#34;&gt;sorted&lt;/span&gt;(counter.items(), key=&lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; x: x[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], reverse=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 构建索引到词元与词元到索引的映射，未知词元的索引为0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.idx_to_token = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;lt;unk&amp;gt;&amp;#x27;&lt;/span&gt;] + reserved_tokens&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.token_to_idx = &amp;#123;token: idx &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; idx, token &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(self.idx_to_token)&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; token, freq &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self._token_freqs:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; freq &amp;lt; min_freq:  &lt;span class=&#34;comment&#34;&gt;# 如果token出现的次数少于min_freq次则直接丢弃&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;break&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; token &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self.token_to_idx:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                self.idx_to_token.append(token)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                self.token_to_idx[token] = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(self.idx_to_token) - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__len__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(self.idx_to_token)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__getitem__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, tokens&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(tokens, (&lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;, &lt;span class=&#34;built_in&#34;&gt;tuple&lt;/span&gt;)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.token_to_idx.get(tokens, self.unk)  &lt;span class=&#34;comment&#34;&gt;# tokens不存在则返回0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; [self.__getitem__(token) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; token &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tokens]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;to_tokens&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, indices&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(indices, (&lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;, &lt;span class=&#34;built_in&#34;&gt;tuple&lt;/span&gt;)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.idx_to_token[indices]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; [self.idx_to_token[index] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; index &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; indices]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;meta&#34;&gt;    @property&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;unk&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# 未知词元的索引为0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;meta&#34;&gt;    @property&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;token_freqs&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self._token_freqs&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;count_corpus&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;tokens&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;统计词元的频率&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 这里的tokens是1D列表或2D列表&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(tokens) == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(tokens[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], &lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        tokens = [token &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; line &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tokens &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; token &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; line]  &lt;span class=&#34;comment&#34;&gt;# 将词元列表展平成一个列表&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; collections.Counter(tokens)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们首先使用时光机器数据集作为语料库来构建词表，然后打印前几个高频词元及其索引：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;vocab = Vocab(tokens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(vocab.token_to_idx.items())[:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# 注意不加item()的话只会将key转成list&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [(&amp;#x27;&amp;lt;unk&amp;gt;&amp;#x27;, 0), (&amp;#x27;the&amp;#x27;, 1), (&amp;#x27;i&amp;#x27;, 2), (&amp;#x27;and&amp;#x27;, 3), (&amp;#x27;of&amp;#x27;, 4), (&amp;#x27;a&amp;#x27;, 5), (&amp;#x27;to&amp;#x27;, 6), (&amp;#x27;was&amp;#x27;, 7), (&amp;#x27;in&amp;#x27;, 8), (&amp;#x27;that&amp;#x27;, 9)]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在，我们可以将每一条文本行转换成一个数字索引列表：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;文本:&amp;#x27;&lt;/span&gt;, tokens[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# 文本: [&amp;#x27;the&amp;#x27;, &amp;#x27;time&amp;#x27;, &amp;#x27;machine&amp;#x27;, &amp;#x27;by&amp;#x27;, &amp;#x27;h&amp;#x27;, &amp;#x27;g&amp;#x27;, &amp;#x27;wells&amp;#x27;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;索引:&amp;#x27;&lt;/span&gt;, vocab[tokens[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]])  &lt;span class=&#34;comment&#34;&gt;# 索引: [1, 19, 50, 40, 2183, 2184, 400]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在使用上述函数时，我们将所有功能打包到 &lt;code&gt;load_corpus_time_machine&lt;/code&gt; 函数中，该函数返回 &lt;code&gt;corpus&lt;/code&gt;（词元索引列表）和 &lt;code&gt;vocab&lt;/code&gt;（时光机器语料库的词表）。我们在这里所做的改变是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为了简化后面章节中的训练，我们使用字符（而不是单词）实现文本词元化；&lt;/li&gt;
&lt;li&gt;时光机器数据集中的每个文本行不一定是一个句子或一个段落，还可能是一个单词，因此返回的 &lt;code&gt;corpus&lt;/code&gt; 仅处理为单个列表，而不是使用多词元列表构成的一个列表。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;load_corpus_time_machine&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;max_tokens=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;返回时光机器数据集的词元索引列表和词表&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    lines = read_time_machine()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    tokens = tokenize(lines, &lt;span class=&#34;string&#34;&gt;&amp;#x27;char&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    vocab = Vocab(tokens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，所以将所有文本行展平到一个列表中&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    corpus = [vocab[token] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; line &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tokens &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; token &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; line]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; max_tokens &amp;gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        corpus = corpus[:max_tokens]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; corpus, vocab&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;corpus, vocab = load_corpus_time_machine()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(corpus), &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab))  &lt;span class=&#34;comment&#34;&gt;# 170580 28&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;索引:&amp;#x27;&lt;/span&gt;, corpus[:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# 索引: [3, 9, 2, 1, 3, 5, 13, 2, 1, 13]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;文本:&amp;#x27;&lt;/span&gt;, vocab.to_tokens(corpus[:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;]))  &lt;span class=&#34;comment&#34;&gt;# 文本: [&amp;#x27;t&amp;#x27;, &amp;#x27;h&amp;#x27;, &amp;#x27;e&amp;#x27;, &amp;#x27; &amp;#x27;, &amp;#x27;t&amp;#x27;, &amp;#x27;i&amp;#x27;, &amp;#x27;m&amp;#x27;, &amp;#x27;e&amp;#x27;, &amp;#x27; &amp;#x27;, &amp;#x27;m&amp;#x27;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-语言模型和数据集&#34;&gt;3. 语言模型和数据集&lt;/h2&gt;
&lt;p&gt;由于涉及较多数学公式，语言模型的讲解可以转至：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/language-models-and-dataset.html&#34;&gt;语言模型和数据集&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;根据上一节中介绍的时光机器数据集构建词表，并打印前10个最常用的（频率最高的）单词：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; random&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokens = d2l.tokenize(d2l.read_time_machine())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 因为每个文本行不一定是一个句子或一个段落，因此我们把所有文本行拼接到一起&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;corpus = [token &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; line &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tokens &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; token &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; line]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(corpus[:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# [&amp;#x27;the&amp;#x27;, &amp;#x27;time&amp;#x27;, &amp;#x27;machine&amp;#x27;, &amp;#x27;by&amp;#x27;, &amp;#x27;h&amp;#x27;, &amp;#x27;g&amp;#x27;, &amp;#x27;wells&amp;#x27;, &amp;#x27;i&amp;#x27;, &amp;#x27;the&amp;#x27;, &amp;#x27;time&amp;#x27;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;vocab = d2l.Vocab(corpus)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(vocab.token_freqs[:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# [(&amp;#x27;the&amp;#x27;, 2261), (&amp;#x27;i&amp;#x27;, 1267), (&amp;#x27;and&amp;#x27;, 1245), (&amp;#x27;of&amp;#x27;, 1155), ...]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;正如我们所看到的，最流行的词看起来很无聊，这些词通常被称为停用词（stop words），因此可以被过滤掉。尽管如此，它们本身仍然是有意义的，我们仍然会在模型中使用它们。此外，还有个明显的问题是词频衰减的速度相当地快。例如，最常用单词的词频对比，第10个还不到第1个的1/5。为了更好地理解，我们可以画出的词频图：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;freqs = [freq &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; token, freq &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; vocab.token_freqs]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.plot(freqs, xlabel=&lt;span class=&#34;string&#34;&gt;&amp;#x27;token: x&amp;#x27;&lt;/span&gt;, ylabel=&lt;span class=&#34;string&#34;&gt;&amp;#x27;frequency: n(x)&amp;#x27;&lt;/span&gt;, xscale=&lt;span class=&#34;string&#34;&gt;&amp;#x27;log&amp;#x27;&lt;/span&gt;, yscale=&lt;span class=&#34;string&#34;&gt;&amp;#x27;log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过词频图我们可以发现：词频以一种明确的方式迅速衰减。将前几个单词作为例外消除后，剩余的所有单词大致遵循双对数坐标图上的一条直线。这意味着单词的频率满足齐普夫定律（Zipf’s law）。这告诉我们想要通过计数统计和平滑来建模单词是不可行的，因为这样建模的结果会大大高估尾部单词的频率，也就是所谓的不常用单词。那么其他的词元组合，比如二元语法、三元语法等等，又会如何呢？我们来看看二元语法的频率是否与一元语法的频率表现出相同的行为方式：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;bigram_tokens = [pair &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; pair &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(corpus[:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], corpus[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:])]  &lt;span class=&#34;comment&#34;&gt;# 遍历所有连续的两个词元&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;bigram_vocab = d2l.Vocab(bigram_tokens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(bigram_vocab.token_freqs[:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# [((&amp;#x27;of&amp;#x27;, &amp;#x27;the&amp;#x27;), 309), ((&amp;#x27;in&amp;#x27;, &amp;#x27;the&amp;#x27;), 169), ...]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这里值得注意：在十个最频繁的词对中，有九个是由两个停用词组成的，只有一个与 &lt;code&gt;the time&lt;/code&gt; 有关。我们再进一步看看三元语法的频率是否表现出相同的行为方式：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;trigram_tokens = [triple &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; triple &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(corpus[:-&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], corpus[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], corpus[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:])]  &lt;span class=&#34;comment&#34;&gt;# 遍历所有连续的三个词元&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trigram_vocab = d2l.Vocab(trigram_tokens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(trigram_vocab.token_freqs[:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# [((&amp;#x27;the&amp;#x27;, &amp;#x27;time&amp;#x27;, &amp;#x27;traveller&amp;#x27;), 59), ((&amp;#x27;the&amp;#x27;, &amp;#x27;time&amp;#x27;, &amp;#x27;machine&amp;#x27;), 30), ...]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后，我们直观地对比三种模型中的词元频率：一元语法、二元语法和三元语法：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;bigram_freqs = [freq &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; token, freq &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; bigram_vocab.token_freqs]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trigram_freqs = [freq &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; token, freq &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; trigram_vocab.token_freqs]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.plot([freqs, bigram_freqs, trigram_freqs], xlabel=&lt;span class=&#34;string&#34;&gt;&amp;#x27;token: x&amp;#x27;&lt;/span&gt;, ylabel=&lt;span class=&#34;string&#34;&gt;&amp;#x27;frequency: n(x)&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;         xscale=&lt;span class=&#34;string&#34;&gt;&amp;#x27;log&amp;#x27;&lt;/span&gt;, yscale=&lt;span class=&#34;string&#34;&gt;&amp;#x27;log&amp;#x27;&lt;/span&gt;, legend=[&lt;span class=&#34;string&#34;&gt;&amp;#x27;unigram&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;bigram&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;trigram&amp;#x27;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;由于序列数据本质上是&lt;strong&gt;连续的&lt;/strong&gt;，因此我们在处理数据时需要解决这个问题。在第一节中我们以一种相当特别的方式做到了这一点：当序列变得太长而不能被模型一次性全部处理时，我们可能希望拆分这样的序列方便模型读取。&lt;/p&gt;
&lt;p&gt;在介绍该模型之前，我们看一下总体策略。假设我们将使用神经网络来训练语言模型，模型中的网络一次处理具有预定义长度（例如 𝑛 个时间步）的一个小批量序列。现在的问题是如何随机生成一个小批量数据的特征和标签以供读取。&lt;/p&gt;
&lt;p&gt;首先，由于文本序列可以是任意长的，例如整本《时光机器》（The Time Machine），于是任意长的序列可以被我们划分为具有相同时间步数的子序列。当训练我们的神经网络时，这样的小批量子序列将被输入到模型中。假设网络一次只处理具有 𝑛 个时间步的子序列，那么可以从指定的起始位置开始截取连续的长度为 𝑛 的子序列，因为我们可以选择任意偏移量来指示初始位置，所以我们有相当大的自由度。&lt;/p&gt;
&lt;p&gt;如果我们只选择一个偏移量，那么用于训练网络的、所有可能的子序列的覆盖范围将是有限的。因此，我们可以从&lt;strong&gt;随机偏移量&lt;/strong&gt;开始划分序列，以同时获得覆盖性（coverage）和随机性（randomness）。下面，我们将描述如何实现&lt;strong&gt;随机采样&lt;/strong&gt;（random sampling）和&lt;strong&gt;顺序分区&lt;/strong&gt;（sequential partitioning）策略。&lt;/p&gt;
&lt;p&gt;在随机采样中，每个样本都是在原始的长序列上&lt;strong&gt;任意捕获&lt;/strong&gt;的子序列。在迭代过程中，来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻。对于语言建模，目标是基于到目前为止我们看到的词元来预测下一个词元，因此标签是移位了一个词元的原始序列。&lt;/p&gt;
&lt;p&gt;下面的代码每次可以从数据中随机生成一个小批量。在这里，参数 &lt;code&gt;batch_size&lt;/code&gt; 指定了每个小批量中子序列样本的数目，参数 &lt;code&gt;num_steps&lt;/code&gt; 是每个子序列中预定义的时间步数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;seq_data_iter_random&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;corpus, batch_size, num_steps&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;使用随机抽样生成一个小批量子序列&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    corpus = corpus[random.randint(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, num_steps - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;):]  &lt;span class=&#34;comment&#34;&gt;# 截取随机起始位置之后的部分&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 减去1，是因为我们需要考虑标签，要留至少一个数据作为最后一组预测的标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_subseqs = (&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(corpus) - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) // num_steps  &lt;span class=&#34;comment&#34;&gt;# 分区数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 长度为num_steps的子序列的起始索引&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    initial_indices = &lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, num_subseqs * num_steps, num_steps))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 在随机抽样的迭代过程中，来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    random.shuffle(initial_indices)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;data&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;pos&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 返回从pos位置开始的长度为num_steps的序列&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; corpus[pos:pos + num_steps]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_batches = num_subseqs // batch_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, batch_size * num_batches, batch_size):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 在这里，initial_indices包含子序列的随机起始索引&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        initial_indices_per_batch = initial_indices[i:i + batch_size]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = [data(j) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; j &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; initial_indices_per_batch]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y = [data(j + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; j &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; initial_indices_per_batch]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;yield&lt;/span&gt; torch.tensor(X), torch.tensor(Y)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下面我们生成一个从0到34的序列。假设批量大小为2，时间步数为5，这意味着可以生成6个特征-标签子序列对。如果设置小批量大小为2，我们只能得到3个小批量：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;my_seq = &lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;35&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, Y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; seq_data_iter_random(my_seq, batch_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, num_steps=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;X:&amp;#x27;&lt;/span&gt;, X, &lt;span class=&#34;string&#34;&gt;&amp;#x27;\nY:&amp;#x27;&lt;/span&gt;, Y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# X: tensor([[ 7,  8,  9, 10, 11], [17, 18, 19, 20, 21]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Y: tensor([[ 8,  9, 10, 11, 12], [18, 19, 20, 21, 22]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# X: tensor([[22, 23, 24, 25, 26], [27, 28, 29, 30, 31]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Y: tensor([[23, 24, 25, 26, 27], [28, 29, 30, 31, 32]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# X: tensor([[ 2,  3,  4,  5,  6], [12, 13, 14, 15, 16]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Y: tensor([[ 3,  4,  5,  6,  7], [13, 14, 15, 16, 17]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在迭代过程中，除了对原始序列可以随机抽样外，我们还可以保证两个相邻的小批量中的子序列在原始序列上也是相邻的。这种策略在基于小批量的迭代过程中保留了拆分的子序列的顺序，因此称为顺序分区：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;seq_data_iter_sequential&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;corpus, batch_size, num_steps&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;使用顺序分区生成一个小批量子序列&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 从随机偏移量开始划分序列&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    offset = random.randint(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, num_steps)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_tokens = ((&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(corpus) - offset - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) // batch_size) * batch_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Xs = torch.tensor(corpus[offset:offset + num_tokens])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Ys = torch.tensor(corpus[offset + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:offset + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; + num_tokens])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Xs, Ys = Xs.reshape(batch_size, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), Ys.reshape(batch_size, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_batches = Xs.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] // num_steps  &lt;span class=&#34;comment&#34;&gt;# batch的数量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, num_steps * num_batches, num_steps):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = Xs[:, i:i + num_steps]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y = Ys[:, i:i + num_steps]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;yield&lt;/span&gt; X, Y&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;基于相同的设置，通过顺序分区读取每个小批量的子序列的特征 &lt;code&gt;X&lt;/code&gt; 和标签 &lt;code&gt;Y&lt;/code&gt;。通过将它们打印出来可以发现：迭代期间来自两个相邻的小批量中的子序列在原始序列中确实是相邻的：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, Y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; seq_data_iter_sequential(my_seq, batch_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, num_steps=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;X:&amp;#x27;&lt;/span&gt;, X, &lt;span class=&#34;string&#34;&gt;&amp;#x27;\nY:&amp;#x27;&lt;/span&gt;, Y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# X: tensor([[ 2,  3,  4,  5,  6], [18, 19, 20, 21, 22]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Y: tensor([[ 3,  4,  5,  6,  7], [19, 20, 21, 22, 23]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# X: tensor([[ 7,  8,  9, 10, 11], [23, 24, 25, 26, 27]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Y: tensor([[ 8,  9, 10, 11, 12], [24, 25, 26, 27, 28]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# X: tensor([[12, 13, 14, 15, 16], [28, 29, 30, 31, 32]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Y: tensor([[13, 14, 15, 16, 17], [29, 30, 31, 32, 33]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在，我们将上面的两个采样函数包装到一个类中，以便稍后可以将其用作数据迭代器：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;SeqDataLoader&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;加载序列数据的迭代器&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, batch_size, num_steps, use_random_iter, max_tokens&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; use_random_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.data_iter_fn = d2l.seq_data_iter_random&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.data_iter_fn = d2l.seq_data_iter_sequential&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.batch_size, self.num_steps = batch_size, num_steps&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__iter__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后，我们定义了一个函数 &lt;code&gt;load_data_time_machine&lt;/code&gt;，它同时返回数据迭代器和词表，因此可以与其他带有 &lt;code&gt;load_data&lt;/code&gt; 前缀的函数（如 &lt;code&gt;d2l.load_data_fashion_mnist&lt;/code&gt;）类似地使用：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;load_data_time_machine&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size, num_steps, use_random_iter=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, max_tokens=&lt;span class=&#34;number&#34;&gt;10000&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;返回时光机器数据集的迭代器和词表&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    data_iter = SeqDataLoader(batch_size, num_steps, use_random_iter, max_tokens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; data_iter, data_iter.vocab&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;4-循环神经网络&#34;&gt;4. 循环神经网络&lt;/h2&gt;
&lt;p&gt;由于涉及较多数学公式，循环神经网络的理论部分可以转至：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/rnn.html&#34;&gt;循环神经网络&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;4-1-循环神经网络的从零开始实现&#34;&gt;4.1 循环神经网络的从零开始实现&lt;/h3&gt;
&lt;p&gt;本节将从头开始基于循环神经网络实现字符级语言模型。这样的模型将在 H.G.Wells 的时光机器数据集上训练。和前面上一节中介绍过的一样，我们先读取数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; math&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tqdm &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tqdm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, num_steps = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;35&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps, max_tokens=&lt;span class=&#34;number&#34;&gt;10000&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_iter.corpus))  &lt;span class=&#34;comment&#34;&gt;# 10000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; train_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(X.shape, y.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([32, 35]) torch.Size([32, 35])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;break&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;回想一下，在 &lt;code&gt;train_iter&lt;/code&gt; 中，每个词元都表示为一个数字索引，将这些索引直接输入神经网络可能会使学习变得困难。我们通常将每个词元表示为更具表现力的特征向量。最简单的表示称为独热编码（one-hot encoding）。&lt;/p&gt;
&lt;p&gt;简言之，将每个索引映射为相互不同的单位向量：假设词表中不同词元的数目为N（即 &lt;code&gt;len(vocab)&lt;/code&gt;），词元索引的范围为0~N-1。如果词元的索引是整数 &lt;code&gt;i&lt;/code&gt;，那么我们将创建一个长度为N的全0向量，并将第 &lt;code&gt;i&lt;/code&gt; 处的元素设置为1。此向量是原始词元的一个独热向量。索引为0和2的独热向量如下所示：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(F.one_hot(torch.tensor([&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]), &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们每次采样的小批量数据形状是二维张量：&lt;code&gt;(批量大小, 时间步数)&lt;/code&gt;。&lt;code&gt;one_hot&lt;/code&gt; 函数将这样一个小批量数据转换成三维张量，张量的最后一个维度等于词表大小（&lt;code&gt;len(vocab)&lt;/code&gt;）。我们经常转换输入的维度，以便获得形状为 &lt;code&gt;(时间步数, 批量大小, 词表大小)&lt;/code&gt; 的输出。这将使我们能够更方便地通过最外层的维度，一步一步地更新小批量数据的隐状态：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = torch.arange(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;).reshape((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(F.one_hot(X.T, &lt;span class=&#34;number&#34;&gt;28&lt;/span&gt;).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([5, 2, 28])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来，我们初始化循环神经网络模型的模型参数。隐藏单元数 &lt;code&gt;num_hiddens&lt;/code&gt; 是一个可调的超参数。当训练语言模型时，输入和输出来自相同的词表（输出可以看成多分类问题，即输出表示对每个词元的预测概率）。因此，它们具有相同的维度，即词表的大小：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;get_params&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;vocab_size, num_hiddens, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_inputs = num_outputs = vocab_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;normal&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;shape&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.randn(size=shape, device=device) * &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隐藏层参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_xh = normal((num_inputs, num_hiddens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_hh = normal((num_hiddens, num_hiddens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    b_h = torch.zeros(num_hiddens, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 输出层参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_hq = normal((num_hiddens, num_outputs))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    b_q = torch.zeros(num_outputs, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 附加梯度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    params = [W_xh, W_hh, b_h, W_hq, b_q]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; params:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        param.requires_grad_(&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; params&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;为了定义循环神经网络模型，我们首先需要一个 &lt;code&gt;init_rnn_state&lt;/code&gt; 函数在初始化时返回隐状态。这个函数的返回是一个张量，张量全用0填充，形状为 &lt;code&gt;(批量大小, 隐藏单元数)&lt;/code&gt;。在后面的章节中我们将会遇到隐状态包含多个变量的情况，而使用元组可以更容易地处理些：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_rnn_state&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size, num_hiddens, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (torch.zeros((batch_size, num_hiddens), device=device),)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下面的 &lt;code&gt;rnn&lt;/code&gt; 函数定义了如何在一个时间步内计算隐状态和输出。循环神经网络模型通过 &lt;code&gt;inputs&lt;/code&gt; 最外层的维度实现循环，以便逐时间步更新小批量数据的隐状态H。此外，这里使用 &lt;code&gt;tanh&lt;/code&gt; 函数作为激活函数，当元素在实数上满足均匀分布时，&lt;code&gt;tanh&lt;/code&gt; 函数的平均值为0：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;rnn&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;inputs, state, params&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# inputs.shape: (时间步数量, 批量大小, 词表大小)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    W_xh, W_hh, b_h, W_hq, b_q = params&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    H, = state&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    outputs = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# X.shape: (批量大小, 词表大小)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; inputs:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y = torch.mm(H, W_hq) + b_q&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs.append(Y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.cat(outputs, dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;), (H,)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义了所有需要的函数之后，接下来我们创建一个类来包装这些函数，并存储从零开始实现的循环神经网络模型的参数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;RNNModelScratch&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;从零开始实现的循环神经网络模型&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, vocab_size, num_hiddens, device, get_params, init_state, forward_fn&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.params = get_params(vocab_size, num_hiddens, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.init_state, self.forward_fn = init_state, forward_fn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__call__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X, state&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = F.one_hot(X.T, self.vocab_size).&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(torch.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.forward_fn(X, state, self.params)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;begin_state&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, batch_size, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.init_state(batch_size, self.num_hiddens, device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;让我们检查输出是否具有正确的形状。例如，隐状态的维数是否保持不变：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_hiddens = &lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = RNNModelScratch(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab), num_hiddens, device, get_params, init_rnn_state, rnn)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;state = net.begin_state(X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y, new_state = net(X.to(device), state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(Y.shape, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(new_state), new_state[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([10, 28]) 1 torch.Size([2, 512])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以看到输出形状是 &lt;code&gt;(时间步数 * 批量大小, 词表大小)&lt;/code&gt;，而隐状态形状保持不变，即 &lt;code&gt;(批量大小, 隐藏单元数)&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;让我们首先定义预测函数来生成 &lt;code&gt;prefix&lt;/code&gt; 之后的新字符，其中的 &lt;code&gt;prefix&lt;/code&gt; 是一个用户提供的包含多个字符的字符串。在循环遍历 &lt;code&gt;prefix&lt;/code&gt; 中的开始字符时，我们不断地将隐状态传递到下一个时间步，但是不生成任何输出。这被称为预热（warm-up）期，因为在此期间模型会自我更新（例如，更新隐状态），但不会进行预测。预热期结束后，隐状态的值通常比刚开始的初始值更适合预测，从而预测字符并输出它们：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;predict&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;prefix, num_preds, net, vocab, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;在prefix后面生成新字符&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    state = net.begin_state(batch_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    outputs = [vocab[prefix[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]]]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    get_input = &lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt;: torch.tensor([outputs[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]], device=device).reshape((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; prefix[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:]:  &lt;span class=&#34;comment&#34;&gt;# 预热期&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        _, state = net(get_input(), state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs.append(vocab[y])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; _ &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_preds):  &lt;span class=&#34;comment&#34;&gt;# 预测num_preds步&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y, state = net(get_input(), state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        outputs.append(&lt;span class=&#34;built_in&#34;&gt;int&lt;/span&gt;(y.argmax(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;).reshape(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;&amp;#x27;&lt;/span&gt;.join([vocab.idx_to_token[i] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; outputs])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在我们可以测试 &lt;code&gt;predict&lt;/code&gt; 函数。我们将前缀指定为 &lt;code&gt;time traveller&lt;/code&gt;，并基于这个前缀生成10个后续字符。鉴于我们还没有训练网络，它会生成荒谬的预测结果：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(predict(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time traveller &amp;#x27;&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, net, vocab, device))  &lt;span class=&#34;comment&#34;&gt;# time traveller gxgtlsryyy&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;梯度裁剪的理论可转至：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/rnn-scratch.html&#34;&gt;循环神经网络的从零开始实现&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下面我们定义一个函数来裁剪模型的梯度，模型是从零开始实现的模型或由高级 API 构建的模型。我们在此计算了所有模型参数的梯度的范数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;grad_clipping&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, theta&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;裁剪梯度&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(net, nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        params = [p &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; p &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; net.parameters() &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; p.requires_grad]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        params = net.params&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    norm = torch.sqrt(&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(torch.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;((p.grad ** &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; p &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; params))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; norm &amp;gt; theta:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; params:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            param.grad[:] *= theta / norm&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在训练模型之前，让我们定义一个函数在一个迭代周期内训练模型。它与我们训练 Softmax 模型的方式有三个不同之处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;序列数据的不同采样方法（随机采样和顺序分区）将导致隐状态初始化的差异。&lt;/li&gt;
&lt;li&gt;我们在更新模型参数之前裁剪梯度。这样的操作的目的是，即使训练过程中某个点上发生了梯度爆炸，也能保证模型不会发散。&lt;/li&gt;
&lt;li&gt;我们用困惑度来评价模型。这样的度量确保了不同长度的序列具有可比性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体来说，当使用顺序分区时，我们只在每个迭代周期的开始位置初始化隐状态。由于下一个小批量数据中的第 &lt;code&gt;i&lt;/code&gt; 个子序列样本与当前第 &lt;code&gt;i&lt;/code&gt; 个子序列样本相邻，因此当前小批量数据最后一个样本的隐状态，将用于初始化下一个小批量数据第一个样本的隐状态。这样，存储在隐状态中的序列的历史信息可以在一个迭代周期内流经相邻的子序列。然而，在任何一点隐状态的计算，都依赖于同一迭代周期中前面所有的小批量数据，这使得梯度计算变得复杂。为了降低计算量，在处理任何一个小批量数据之前，我们先&lt;strong&gt;分离梯度&lt;/strong&gt;，使得隐状态的梯度计算总是限制在一个小批量数据的时间步内。&lt;/p&gt;
&lt;p&gt;当使用随机抽样时，因为每个样本都是在一个随机位置抽样的，因此需要&lt;strong&gt;为每个迭代周期重新初始化隐状态&lt;/strong&gt;。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train_epoch&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, loss_function, optimizer, device, use_random_iter&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;训练网络一个迭代周期（定义见第8章）&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    state = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_loss = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, Y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(train_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; state &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; use_random_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 在第一次迭代或使用随机抽样时初始化state&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            state = net.begin_state(batch_size=X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(net, nn.Module) &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(state, &lt;span class=&#34;built_in&#34;&gt;tuple&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;comment&#34;&gt;# state对于nn.GRU是个张量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                state.detach_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;comment&#34;&gt;# state对于nn.LSTM或对于我们从零开始实现的模型是个元组&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; s &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; state:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    s.detach_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y = Y.T.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X, y = X.to(device), y.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y_hat, state = net(X, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(y_hat, y.long()).mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(optimizer, torch.optim.Optimizer):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            grad_clipping(net, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            grad_clipping(net, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer(batch_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss.append(loss)  &lt;span class=&#34;comment&#34;&gt;# 因为已经调用了mean函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; math.exp(&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loss))  &lt;span class=&#34;comment&#34;&gt;# 返回困惑度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;循环神经网络模型的训练函数既支持从零开始实现，也可以使用高级 API 来实现。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, vocab, lr, num_epochs, device, use_random_iter=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;训练模型（定义见第8章）&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 初始化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(net, nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer = torch.optim.SGD(net.parameters(), lr)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer = &lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; batch_size: d2l.sgd(net.params, lr, batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pred = &lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; prefix: predict(prefix, &lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, net, vocab, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 训练和预测&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/RNN_scratch_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ppl = train_epoch(net, train_iter, loss_function, optimizer, device, use_random_iter)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; (epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt; == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;Perplexity: &lt;span class=&#34;subst&#34;&gt;&amp;#123;ppl:&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_loss&amp;#x27;&lt;/span&gt;, ppl, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在，我们训练循环神经网络模型。因为我们在数据集中只使用了10000个词元，所以模型需要更多的迭代周期来更好地收敛：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;num_epochs, lr = &lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, vocab, lr, num_epochs, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Perplexity: 1.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# time travelleryou can show black is white by argument said filby&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# travelleryou can show black is white by argument said filby&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;4-2-循环神经网络的简洁实现&#34;&gt;4.2 循环神经网络的简洁实现&lt;/h3&gt;
&lt;p&gt;虽然从零开始实现循环神经网络对了解网络的实现方式具有指导意义，但并不方便。本节将展示如何使用深度学习框架的高级 API 提供的函数更有效地实现相同的语言模型。我们仍然从读取时光机器数据集开始：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; math&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tqdm &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tqdm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size, num_steps = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;35&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;高级 API 提供了循环神经网络的实现。我们构造一个具有256个隐藏单元的单隐藏层的循环神经网络层 &lt;code&gt;rnn_layer&lt;/code&gt;。事实上，我们还没有讨论多层循环神经网络的意义（这将在深度循环神经网络中介绍）。现在仅需要将多层理解为一层循环神经网络的输出被用作下一层循环神经网络的输入就足够了：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;num_hiddens = &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;rnn_layer = nn.RNN(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab), num_hiddens)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们使用张量来初始化隐状态，它的形状是 &lt;code&gt;(隐藏层数, 批量大小, 隐藏单元数)&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;state = torch.zeros((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, batch_size, num_hiddens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(state.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 32, 256])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过一个隐状态和一个输入，我们就可以用更新后的隐状态计算输出。需要强调的是，&lt;code&gt;rnn_layer&lt;/code&gt; 的输出（&lt;code&gt;Y&lt;/code&gt;）不涉及输出层的计算：它是指&lt;strong&gt;每个时间步的隐状态&lt;/strong&gt;，这些隐状态可以用作后续输出层的输入：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = torch.rand(size=(num_steps, batch_size, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y, state_new = rnn_layer(X, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(Y.shape, state_new.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([35, 32, 256]) torch.Size([1, 32, 256])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们为一个完整的循环神经网络模型定义了一个 &lt;code&gt;RNNModel&lt;/code&gt; 类。注意，&lt;code&gt;rnn_layer&lt;/code&gt; 只包含隐藏的循环层，我们还需要创建一个单独的输出层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;RNNModel&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;循环神经网络模型&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, rnn_layer, vocab_size, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(RNNModel, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.rnn = rnn_layer&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.vocab_size = vocab_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.num_hiddens = self.rnn.hidden_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; self.rnn.bidirectional:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.num_directions = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.num_directions = &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.linear = nn.Linear(self.num_hiddens * &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, self.vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, inputs, state&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = F.one_hot(inputs.T.long(), self.vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = X.to(torch.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y, state = self.rnn(X, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 全连接层首先将Y的形状改为：(时间步数 * 批量大小, 隐藏单元数)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 它的输出形状是：(时间步数 * 批量大小, 词表大小)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.linear(Y.reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, Y.shape[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])))  &lt;span class=&#34;comment&#34;&gt;# (35 * 32, 256) -&amp;gt; (35 * 32, 28)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output, state&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;begin_state&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, device, batch_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(self.rnn, nn.LSTM):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# nn.GRU以张量作为隐状态&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# nn.LSTM以元组作为隐状态&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在训练模型之前，让我们基于一个具有随机权重的模型进行预测，&lt;code&gt;d2l.predict_ch8&lt;/code&gt; 函数与上一节中的 &lt;code&gt;predict&lt;/code&gt; 函数相同：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = RNNModel(rnn_layer, vocab_size=&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(vocab))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(d2l.predict_ch8(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time traveller&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, net, vocab, device))  &lt;span class=&#34;comment&#34;&gt;# time travellerxhhhhhhhhh&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;很明显，这种模型根本不能输出好的结果。接下来，我们使用上一节中定义的超参数训练模型：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train_epoch&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, loss_function, optimizer, device, use_random_iter&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    state = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_loss = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, Y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(train_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; state &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; use_random_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            state = net.begin_state(batch_size=X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(net, nn.Module) &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(state, &lt;span class=&#34;built_in&#34;&gt;tuple&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                state.detach_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; s &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; state:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    s.detach_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y = Y.T.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X, y = X.to(device), y.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss_function.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y_hat, state = net(X, state)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(y_hat, y.long()).mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        d2l.grad_clipping(net, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 与上一节中的grad_clipping函数相同&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss.append(loss)  &lt;span class=&#34;comment&#34;&gt;# 因为已经调用了mean函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; math.exp(&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loss))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, vocab, lr, num_epochs, device, use_random_iter=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer = torch.optim.SGD(net.parameters(), lr)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pred = &lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; prefix: d2l.predict_ch8(prefix, &lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, net, vocab, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/RNN_scratch_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ppl = train_epoch(net, train_iter, loss_function, optimizer, device, use_random_iter)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; (epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt; == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;Perplexity: &lt;span class=&#34;subst&#34;&gt;&amp;#123;ppl:&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_loss&amp;#x27;&lt;/span&gt;, ppl, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;time traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pred(&lt;span class=&#34;string&#34;&gt;&amp;#x27;traveller&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.close()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_epochs, lr = &lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, vocab, lr, num_epochs, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Perplexity: 1.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# time traveller for so ig will aboca thoursugli gpseknop how stac&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# travelleryou can space of the simestiok satt or al and wisc&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/24840.html</guid>
            <title>动手学深度学习笔记(李沐)-计算机视觉</title>
            <link>https://asanosaki.github.io/posts/24840.html</link>
            <category>AI</category>
            <pubDate>Fri, 10 Mar 2023 10:24:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;李沐动手学深度学习（PyTorch）课程学习笔记第七章：计算机视觉。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-图像增广&#34;&gt;1. 图像增广&lt;/h2&gt;
&lt;p&gt;图像增广在对训练图像进行一系列的随机变化之后，生成相似但不同的训练样本，从而扩大了训练集的规模。此外，应用图像增广的原因是，随机改变训练样本可以减少模型对某些属性的依赖，从而提高模型的泛化能力。例如，我们可以以不同的方式裁剪图像，使感兴趣的对象出现在不同的位置，减少模型对于对象出现位置的依赖。我们还可以调整亮度、颜色等因素来降低模型对颜色的敏感度。&lt;/p&gt;
&lt;p&gt;下面的代码有50%的几率使图像向左或向右翻转：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;trans = torchvision.transforms.RandomHorizontalFlip()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;有50%的几率向上或向下翻转，注意，上下翻转图像不如左右图像翻转那样常用，需要根据数据集的特征考虑是否可以将图像上下翻转：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;trans = torchvision.transforms.RandomVerticalFlip()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;随机裁剪一个面积为原始面积10%到100%的区域，该区域的宽高比从0.5~2之间随机取值。然后，区域的宽度和高度都被缩放到200像素：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;trans = torchvision.transforms.RandomResizedCrop((&lt;span class=&#34;number&#34;&gt;200&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;200&lt;/span&gt;), scale=(&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), ratio=(&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以改变图像颜色的四个方面：亮度、对比度、饱和度和色调。在下面的示例中，我们随机更改图像的亮度，随机值为原始图像的50%(1 - 0.5)到150%(1 + 0.5)之间：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;trans = torchvision.transforms.ColorJitter(brightness=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, contrast=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, saturation=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, hue=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在实践中，我们将结合多种图像增广方法。我们可以通过使用一个 &lt;code&gt;Compose&lt;/code&gt; 实例来综合上面定义的不同的图像增广方法，并将它们应用到每个图像：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;trans = transforms.Compose([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.RandomHorizontalFlip(p=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# 50%的概率使图片水平翻转&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.ColorJitter(brightness=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, contrast=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, saturation=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, hue=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.ToTensor()])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;图像增广可以直接作用在图像数据上，也可以在使用 &lt;code&gt;torchvision.datasets&lt;/code&gt; 导入数据集的时候通过 &lt;code&gt;transform&lt;/code&gt; 参数指定：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = trans(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cifar_train = torchvision.datasets.CIFAR10(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-微调&#34;&gt;2. 微调&lt;/h2&gt;
&lt;p&gt;微调（fine-tuning）是迁移学习（transfer learning）中的常见技巧，微调包括以下四个步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在源数据集（例如 ImageNet 数据集）上预训练神经网络模型，即源模型。&lt;/li&gt;
&lt;li&gt;创建一个新的神经网络模型，即目标模型。这将复制源模型上的所有模型设计及其参数（输出层除外）。我们假定这些模型参数包含从源数据集中学到的知识，这些知识也将适用于目标数据集。我们还假设源模型的输出层与源数据集的标签密切相关；因此不在目标模型中使用该层。&lt;/li&gt;
&lt;li&gt;向目标模型添加输出层，其输出数是目标数据集中的类别数。然后随机初始化该层的模型参数。&lt;/li&gt;
&lt;li&gt;在目标数据集（如椅子数据集）上训练目标模型。输出层将从头开始进行训练，而所有其他层的参数将根据源模型的参数进行微调。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当目标数据集比源数据集小得多时，微调有助于提高模型的泛化能力。&lt;/p&gt;
&lt;p&gt;我们将在一个 CIFAR10 数据集上微调 ResNet-18 模型。该模型已在 ImageNet 数据集上进行了预训练：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;114&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; models&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tqdm &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tqdm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ---------- Data ----------&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_trans = transforms.Compose([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.RandomResizedCrop(&lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.RandomHorizontalFlip(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.ToTensor(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 使用ImageNet的RGB通道的均值和标准差，以标准化每个通道&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.Normalize([&lt;span class=&#34;number&#34;&gt;0.485&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.456&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.406&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                         [&lt;span class=&#34;number&#34;&gt;0.229&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.224&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.225&lt;/span&gt;])])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_trans = transforms.Compose([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.Resize([&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.CenterCrop(&lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.ToTensor(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.Normalize([&lt;span class=&#34;number&#34;&gt;0.485&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.456&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.406&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                         [&lt;span class=&#34;number&#34;&gt;0.229&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.224&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.225&lt;/span&gt;])])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size = &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cifar_train = torchvision.datasets.CIFAR10(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=train_trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cifar_test = torchvision.datasets.CIFAR10(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=test_trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter = data.DataLoader(cifar_train, batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_iter = data.DataLoader(cifar_test, batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ---------- ResNet-18 ----------&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;resnet_model&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;num_classes, use_pretrained=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net = models.resnet18(pretrained=use_pretrained)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.fc = nn.Linear(net.fc.in_features, num_classes)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.init.xavier_uniform_(net.fc.weight)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; net&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = resnet_model(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ---------- Train ----------&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 如果param_group=True，输出层中的模型参数将使用十倍的学习率&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, test_iter, num_epochs, lr, device, wd, param_group=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;training on&amp;#x27;&lt;/span&gt;, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; param_group:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        params_1x = [param &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; name, param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; net.named_parameters() &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; name &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; [&lt;span class=&#34;string&#34;&gt;&amp;quot;fc.weight&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;fc.bias&amp;quot;&lt;/span&gt;]]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer = torch.optim.SGD([&amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;params&amp;#x27;&lt;/span&gt;: params_1x&amp;#125;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                     &amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;params&amp;#x27;&lt;/span&gt;: net.fc.parameters(), &lt;span class=&#34;string&#34;&gt;&amp;#x27;lr&amp;#x27;&lt;/span&gt;: lr * &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&amp;#125;], lr=lr, weight_decay=wd)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/FineTune_CIFAR10_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    best_acc = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        net.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_acc = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; img, label &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(train_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            img, label = img.to(device), label.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            label_hat = net(img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss = loss_function(label_hat, label)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            label_hat = label_hat.argmax(axis=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            acc = (label_hat.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(label.dtype) == label).&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;().mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_loss.append(loss.item())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_acc.append(acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_acc = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_acc) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;quot;[ Train | &lt;span class=&#34;subst&#34;&gt;&amp;#123;epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:03d&amp;#125;&lt;/span&gt;/&lt;span class=&#34;subst&#34;&gt;&amp;#123;num_epochs:03d&amp;#125;&lt;/span&gt; ] loss = &lt;span class=&#34;subst&#34;&gt;&amp;#123;train_loss:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;, acc = &lt;span class=&#34;subst&#34;&gt;&amp;#123;train_acc:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        net.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_loss = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_acc = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; img, label &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(test_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                img, label = img.to(device), label.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                label_hat = net(img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                loss = loss_function(label_hat, label)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                label_hat = label_hat.argmax(axis=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                acc = (label_hat.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(label.dtype) == label).&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;().mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                valid_loss.append(loss.item())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                valid_acc.append(acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_loss = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(valid_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(valid_loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_acc = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(valid_acc) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(valid_acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;quot;[ Valid | &lt;span class=&#34;subst&#34;&gt;&amp;#123;epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:03d&amp;#125;&lt;/span&gt;/&lt;span class=&#34;subst&#34;&gt;&amp;#123;num_epochs:03d&amp;#125;&lt;/span&gt; ] loss = &lt;span class=&#34;subst&#34;&gt;&amp;#123;valid_loss:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;, acc = &lt;span class=&#34;subst&#34;&gt;&amp;#123;valid_acc:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_loss&amp;#x27;&lt;/span&gt;, train_loss, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_acc&amp;#x27;&lt;/span&gt;, train_acc, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;valid_loss&amp;#x27;&lt;/span&gt;, valid_loss, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;valid_acc&amp;#x27;&lt;/span&gt;, valid_acc, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; valid_acc &amp;gt; best_acc:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            best_acc = valid_acc&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            torch.save(net.state_dict(), &lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/FineTune_CIFAR10_train.params&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;saving model with acc &amp;#123;:.3f&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(best_acc))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.close()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr, wd, num_epochs = &lt;span class=&#34;number&#34;&gt;0.0005&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.001&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, test_iter, num_epochs, lr, device, wd, param_group=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-目标检测和边界框&#34;&gt;3. 目标检测和边界框&lt;/h2&gt;
&lt;p&gt;在图像分类任务中，我们假设图像中只有一个主要物体对象，我们只关注如何识别其类别。然而，很多时候图像里有多个我们感兴趣的目标，我们不仅想知道它们的类别，还想得到它们在图像中的&lt;strong&gt;具体位置&lt;/strong&gt;。在计算机视觉里，我们将这类任务称为&lt;strong&gt;目标检测&lt;/strong&gt;（object detection）或&lt;strong&gt;目标识别&lt;/strong&gt;（object recognition）。&lt;/p&gt;
&lt;p&gt;下面加载本节将使用的示例图像。图像左边是一只狗，右边是一只猫。它们是这张图像里的两个主要目标：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.rcParams[&lt;span class=&#34;string&#34;&gt;&amp;#x27;font.sans-serif&amp;#x27;&lt;/span&gt;] = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;SimHei&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.rcParams[&lt;span class=&#34;string&#34;&gt;&amp;#x27;axes.unicode_minus&amp;#x27;&lt;/span&gt;] = &lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.figure(dpi=&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;, figsize=(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img = plt.imread(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../images/catdog.jpg&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.imshow(img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在目标检测中，我们通常使用边界框（bounding box）来描述对象的空间位置。边界框是矩形的，由矩形左上角的以及右下角的 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 坐标决定。另一种常用的边界框表示方法是边界框中心的 &lt;code&gt;(x, y)&lt;/code&gt; 轴坐标以及框的宽度和高度。&lt;/p&gt;
&lt;p&gt;在这里，我们定义在这两种表示法之间进行转换的函数：&lt;code&gt;box_corner_to_center&lt;/code&gt; 从两角表示法转换为中心宽度表示法，而 &lt;code&gt;box_center_to_corner&lt;/code&gt; 反之亦然。输入参数 &lt;code&gt;boxes&lt;/code&gt; 可以是长度为4的张量，也可以是形状为 &lt;code&gt;(N, 4)&lt;/code&gt; 的二维张量，其中 N 是边界框的数量。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;box_corner_to_center&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;boxes&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;从（左上，右下）转换到（中间，宽度，高度）&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x1, y1, x2, y2 = boxes[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], boxes[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], boxes[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], boxes[:, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    cx = (x1 + x2) / &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    cy = (y1 + y2) / &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    w = x2 - x1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    h = y2 - y1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    boxes = torch.stack((cx, cy, w, h), dim=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; boxes&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;box_center_to_corner&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;boxes&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;从（中间，宽度，高度）转换到（左上，右下）&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    cx, cy, w, h = boxes[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], boxes[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], boxes[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], boxes[:, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x1 = cx - &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt; * w&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y1 = cy - &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt; * h&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x2 = cx + &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt; * w&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y2 = cy + &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt; * h&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    boxes = torch.stack((x1, y1, x2, y2), dim=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; boxes&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们将根据坐标信息定义图像中狗和猫的边界框。图像中坐标的原点是图像的左上角，向右的方向为 &lt;code&gt;x&lt;/code&gt; 轴的正方向，向下的方向为 &lt;code&gt;y&lt;/code&gt; 轴的正方向：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# bbox是边界框的英文缩写&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dog_bbox, cat_bbox = [&lt;span class=&#34;number&#34;&gt;60.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;45.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;378.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;516.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;400.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;112.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;655.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;493.0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;boxes = torch.tensor((dog_bbox, cat_bbox))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(box_center_to_corner(box_corner_to_center(boxes)) == boxes)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[True, True, True, True],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [True, True, True, True]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以将边界框在图中画出，以检查其是否准确。画之前，我们定义一个辅助函数 &lt;code&gt;bbox_to_rect&lt;/code&gt;。它将边界框表示成 &lt;code&gt;matplotlib&lt;/code&gt; 的边界框格式，在图像上添加边界框之后，我们可以看到两个物体的主要轮廓基本上在两个框内：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;bbox_to_rect&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;bbox, color&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 将边界框(左上x, 左上y, 右下x, 右下y)格式转换成matplotlib格式：(xy=(左上x, 左上y), width=宽, height=高)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; plt.Rectangle(xy=(bbox[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], bbox[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]), width=bbox[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]-bbox[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], height=bbox[&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;]-bbox[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                         fill=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, edgecolor=color, linewidth=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;fig = plt.imshow(img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;fig.axes.add_patch(bbox_to_rect(dog_bbox, &lt;span class=&#34;string&#34;&gt;&amp;#x27;blue&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;fig.axes.add_patch(bbox_to_rect(cat_bbox, &lt;span class=&#34;string&#34;&gt;&amp;#x27;red&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;4-目标检测数据集&#34;&gt;4. 目标检测数据集&lt;/h2&gt;
&lt;p&gt;目标检测领域没有像 MNIST 和 Fashion-MNIST 那样的小数据集。为了快速测试目标检测模型，我们收集并标记了一个小型数据集。首先，我们拍摄了一组香蕉的照片，并生成了1000张不同角度和大小的香蕉图像。然后，我们在一些背景图片的随机位置上放一张香蕉的图像。最后，我们在图片上为这些香蕉标记了边界框。&lt;/p&gt;
&lt;p&gt;包含所有图像和 CSV 标签文件的香蕉检测数据集可以直接从互联网下载，通过 &lt;code&gt;read_data_bananas&lt;/code&gt; 函数，我们读取香蕉检测数据集的图像和标签。该数据集的 CSV 文件内含目标类别标签和位于左上角和右下角的真实边界框坐标：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; pandas &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.rcParams[&lt;span class=&#34;string&#34;&gt;&amp;#x27;font.sans-serif&amp;#x27;&lt;/span&gt;] = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;SimHei&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.rcParams[&lt;span class=&#34;string&#34;&gt;&amp;#x27;axes.unicode_minus&amp;#x27;&lt;/span&gt;] = &lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Dataset, DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.DATA_HUB[&lt;span class=&#34;string&#34;&gt;&amp;#x27;banana-detection&amp;#x27;&lt;/span&gt;] = (d2l.DATA_URL + &lt;span class=&#34;string&#34;&gt;&amp;#x27;banana-detection.zip&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;5de26c8fce5ccdea9f91267273464dc968d20d72&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;read_data_bananas&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;is_train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;读取香蕉检测数据集中的图像和标签&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    data_dir = d2l.download_extract(&lt;span class=&#34;string&#34;&gt;&amp;#x27;banana-detection&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 路径为../data&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    csv_fname = os.path.join(data_dir, &lt;span class=&#34;string&#34;&gt;&amp;#x27;bananas_train&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; is_train &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;bananas_val&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;label.csv&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    csv_data = pd.read_csv(csv_fname)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    csv_data = csv_data.set_index(&lt;span class=&#34;string&#34;&gt;&amp;#x27;img_name&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    images, targets = [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; img_name, target &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; csv_data.iterrows():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        images.append(torchvision.io.read_image(os.path.join(data_dir, &lt;span class=&#34;string&#34;&gt;&amp;#x27;bananas_train&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; is_train &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;bananas_val&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;images&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;img_name&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 这里的target为：(类别, 左上角x, 左上角y, 右下角x, 右下角y)，其中所有图像都具有相同的香蕉类（索引为0）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        targets.append(&lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(target))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; images, torch.tensor(targets).unsqueeze(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) / &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;以下 &lt;code&gt;BananasDataset&lt;/code&gt; 类别将允许我们创建一个自定义 &lt;code&gt;Dataset&lt;/code&gt; 实例来加载香蕉检测数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;BananasDataset&lt;/span&gt;(&lt;span class=&#34;title class_ inherited__&#34;&gt;Dataset&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;一个用于加载香蕉检测数据集的自定义数据集&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, is_train&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.features, self.labels = read_data_bananas(is_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;read &amp;#x27;&lt;/span&gt; + &lt;span class=&#34;built_in&#34;&gt;str&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(self.features)) + (&lt;span class=&#34;string&#34;&gt;f&amp;#x27; training examples&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; is_train &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;f&amp;#x27; validation examples&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__getitem__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, idx&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (self.features[idx].&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(), self.labels[idx])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__len__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(self.features)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后，我们定义 &lt;code&gt;load_data_bananas&lt;/code&gt; 函数，来为训练集和测试集返回两个数据加载器实例。对于测试集，无须按随机顺序读取它：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;load_data_bananas&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;加载香蕉检测数据集&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_iter = DataLoader(BananasDataset(is_train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;), batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    val_iter = DataLoader(BananasDataset(is_train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;), batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; train_iter, val_iter&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;让我们读取一个小批量，并打印其中的图像和标签的形状。图像的小批量的形状为：&lt;code&gt;(批量大小, 通道数, 高度, 宽度)&lt;/code&gt;，它与我们之前图像分类任务中的相同。标签的小批量的形状为：&lt;code&gt;(批量大小, M, 5)&lt;/code&gt;，其中 M 是数据集的任何图像中边界框可能出现的最大数量。&lt;/p&gt;
&lt;p&gt;小批量计算虽然高效，但它要求每张图像含有相同数量的边界框，以便放在同一个批量中。通常来说，图像可能拥有不同数量个边界框；因此，在达到 M 之前，边界框少于 M 的图像将被非法边界框填充。这样，每个边界框的标签将被长度为5的数组表示。数组中的第一个元素是边界框中对象的类别，其中-1表示用于填充的非法边界框。数组的其余四个元素是边界框左上角和右下角的 &lt;code&gt;(x, y)&lt;/code&gt; 坐标值（值域在0~1之间）。对于香蕉数据集而言，由于每张图像上只有一个边界框，因此 &lt;code&gt;M = 1&lt;/code&gt;。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;batch_size, edge_size = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, val_iter = load_data_bananas(batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;features, labels = &lt;span class=&#34;built_in&#34;&gt;next&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;iter&lt;/span&gt;(train_iter))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(features.shape, labels.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([32, 3, 256, 256]) torch.Size([32, 1, 5])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来让我们展示10幅带有真实边界框的图像。我们可以看到在所有这些图像中香蕉的旋转角度、大小和位置都有所不同。当然，这只是一个简单的人工数据集，实践中真实世界的数据集通常要复杂得多：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# d2l.show_images()函数的实现&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;show_images&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;imgs, num_rows, num_cols, titles=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, scale=&lt;span class=&#34;number&#34;&gt;1.5&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    figsize = (num_cols * scale, num_rows * scale)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    axes = axes.flatten()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, (ax, img) &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(axes, imgs)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;try&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            img = img.numpy()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;except&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;pass&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ax.imshow(img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ax.axes.get_xaxis().set_visible(&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ax.axes.get_yaxis().set_visible(&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; titles:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            ax.set_title(titles[i])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; axes&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;bbox_to_rect&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;bbox, color&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; plt.Rectangle(xy=(bbox[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], bbox[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]), width=bbox[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]-bbox[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], height=bbox[&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;]-bbox[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                         fill=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, edgecolor=color, linewidth=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;imgs = (features[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;].permute(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)) / &lt;span class=&#34;number&#34;&gt;255&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;axes = show_images(imgs, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, scale=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; ax, label &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(axes, labels[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;]):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ax.add_patch(bbox_to_rect(label[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;] * edge_size, color=&lt;span class=&#34;string&#34;&gt;&amp;#x27;white&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# d2l.show_bboxes(ax, [label[0][1:5] * edge_size], colors=[&amp;#x27;w&amp;#x27;])  # 功能与上一行相同&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;5-锚框&#34;&gt;5. 锚框&lt;/h2&gt;
&lt;p&gt;由于本节难度较大，因此详细分析见：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_computer-vision/anchor.html&#34;&gt;D2L-计算机视觉-锚框&lt;/a&gt;。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;114&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;115&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;116&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;117&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;118&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;119&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;120&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;121&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;122&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;123&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;124&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;125&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;126&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;127&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;128&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;129&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;130&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;131&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;132&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;133&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;134&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;135&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;136&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;137&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;138&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;139&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;140&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;141&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;142&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;143&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;144&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;145&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;146&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;147&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;148&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;149&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;150&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;151&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;152&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;153&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;154&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;155&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;156&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;157&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;158&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;159&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;160&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;161&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;162&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;163&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;164&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;165&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;166&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;167&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;168&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;169&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;170&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;171&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;172&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;173&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;174&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;175&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;176&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;177&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;178&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;179&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;180&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;181&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;182&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;183&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;184&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;185&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;186&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;187&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;188&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;189&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;190&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;191&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;192&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;193&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;194&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;195&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;196&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;197&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;198&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;199&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;200&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;201&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;202&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;203&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;204&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;205&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;206&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;207&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;208&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;209&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;210&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;211&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;212&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;213&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;214&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;215&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;216&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;217&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;218&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;219&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;220&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;221&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;222&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;223&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;224&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;225&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;226&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;227&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;228&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;229&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;230&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;231&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;232&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;233&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;234&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;235&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;236&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;237&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;238&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;239&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;240&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;241&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;242&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;243&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;244&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;245&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;246&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;247&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;248&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;249&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;250&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;251&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;252&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;253&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;254&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;255&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;256&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;257&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;258&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;259&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;260&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;261&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.set_printoptions(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 精简输出精度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;multibox_prior&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;data, sizes, ratios&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;生成以每个像素为中心具有不同形状的锚框&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    in_height, in_width = data.shape[-&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    device, num_sizes, num_ratios = data.device, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(sizes), &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(ratios)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    boxes_per_pixel = (num_sizes + num_ratios - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    size_tensor = torch.tensor(sizes, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ratio_tensor = torch.tensor(ratios, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 为了将锚点移动到像素的中心，需要设置偏移量。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 因为一个像素的高为1且宽为1，我们选择偏移我们的中心0.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    offset_h, offset_w = &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    steps_h = &lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt; / in_height  &lt;span class=&#34;comment&#34;&gt;# 在y轴上缩放步长&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    steps_w = &lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt; / in_width  &lt;span class=&#34;comment&#34;&gt;# 在x轴上缩放步长&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 生成锚框的所有中心点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing=&lt;span class=&#34;string&#34;&gt;&amp;#x27;ij&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    shift_y, shift_x = shift_y.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), shift_x.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(center_h.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([561])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(shift_y.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([408408])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 生成“boxes_per_pixel”个高和宽，之后用于创建锚框的四角坐标(xmin, xmax, ymin, ymax)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   sizes[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] * torch.sqrt(ratio_tensor[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:]))) * in_height / in_width  &lt;span class=&#34;comment&#34;&gt;# 处理矩形输入&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   sizes[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] / torch.sqrt(ratio_tensor[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:])))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(w.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([5])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 除以2来获得半高和半宽作为中心点到左上和右下的偏移量，repeat(a, b)表示在行上复制a倍，在列上复制b倍&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(in_height * in_width, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) / &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(anchor_manipulations.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2042040, 4])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 每个中心点都将有“boxes_per_pixel”个锚框，所以生成含所有锚框中心的网格，重复了“boxes_per_pixel”次&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y], dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;).repeat_interleave(boxes_per_pixel, dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(out_grid.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2042040, 4])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = out_grid + anchor_manipulations&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output.unsqueeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 增加batch维度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img = plt.imread(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../images/catdog.jpg&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;h, w = img.shape[:&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(h, w)  &lt;span class=&#34;comment&#34;&gt;# 561 728&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.rand(size=(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, h, w))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = multibox_prior(X, sizes=[&lt;span class=&#34;number&#34;&gt;0.75&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.25&lt;/span&gt;], ratios=[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(Y.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 2042040, 4])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;boxes = Y.reshape(h, w, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(boxes[&lt;span class=&#34;number&#34;&gt;250&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;250&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, :])  &lt;span class=&#34;comment&#34;&gt;# tensor([0.06, 0.07, 0.63, 0.82])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;show_bboxes&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;axes, bboxes, labels=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, colors=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;显示所有边界框&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;_make_list&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;obj, default_values=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; obj &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            obj = default_values&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(obj, (&lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;, &lt;span class=&#34;built_in&#34;&gt;tuple&lt;/span&gt;)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            obj = [obj]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; obj&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    labels = _make_list(labels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    colors = _make_list(colors, [&lt;span class=&#34;string&#34;&gt;&amp;#x27;b&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;g&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;m&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;c&amp;#x27;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, bbox &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(bboxes):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        color = colors[i % &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(colors)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        rect = d2l.bbox_to_rect(bbox.detach().numpy(), color)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        axes.add_patch(rect)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; labels &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(labels) &amp;gt; i:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            text_color = &lt;span class=&#34;string&#34;&gt;&amp;#x27;k&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; color == &lt;span class=&#34;string&#34;&gt;&amp;#x27;w&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;w&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            axes.text(rect.xy[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], rect.xy[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], labels[i], va=&lt;span class=&#34;string&#34;&gt;&amp;#x27;center&amp;#x27;&lt;/span&gt;, ha=&lt;span class=&#34;string&#34;&gt;&amp;#x27;center&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                      fontsize=&lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;, color=text_color, bbox=&lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(facecolor=color, lw=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.figure(dpi=&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;bbox_scale = torch.tensor((w, h, w, h))  &lt;span class=&#34;comment&#34;&gt;# 用于将坐标值从0~1复原为0~w(h)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# fig = plt.imshow(img)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# show_bboxes(fig.axes, boxes[250, 250, :, :] * bbox_scale,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#             [&amp;#x27;s=0.75, r=1&amp;#x27;, &amp;#x27;s=0.5, r=1&amp;#x27;, &amp;#x27;s=0.25, r=1&amp;#x27;, &amp;#x27;s=0.75, r=2&amp;#x27;, &amp;#x27;s=0.75, r=0.5&amp;#x27;])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# plt.show()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;box_iou&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;boxes1, boxes2&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;计算两个锚框或边界框列表中成对的交并比&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    box_area = &lt;span class=&#34;keyword&#34;&gt;lambda&lt;/span&gt; boxes: ((boxes[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;] - boxes[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]) * (boxes[:, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;] - boxes[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# boxes1.shape: (boxes1的数量, 4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# boxes2.shape: (boxes2的数量, 4)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# areas1.shape: (boxes1的数量,)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# areas2.shape: (boxes2的数量,)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    areas1 = box_area(boxes1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    areas2 = box_area(boxes2)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# inter_upperlefts.shape, inter_lowerrights.shape, inters.shape: (boxes1的数量, boxes2的数量, 2)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    inter_upperlefts = torch.&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;(boxes1[:, &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, :&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], boxes2[:, :&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    inter_lowerrights = torch.&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;(boxes1[:, &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:], boxes2[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    inters = (inter_lowerrights - inter_upperlefts).clamp(&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# inter_areas.shape, union_areas.shape: (boxes1的数量, boxes2的数量)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    inter_areas = inters[:, :, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] * inters[:, :, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    union_areas = areas1[:, &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;] + areas2 - inter_areas&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; inter_areas / union_areas&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;assign_anchor_to_bbox&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;ground_truth, anchors, device, iou_threshold=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;将最接近的真实边界框分配给锚框&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_anchors, num_gt_boxes = anchors.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], ground_truth.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 位于第i行和第j列的元素x_ij是锚框i和真实边界框j的IoU&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    jaccard = box_iou(anchors, ground_truth)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 对于每个锚框，分配的真实边界框的张量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    anchors_bbox_map = torch.full((num_anchors,), -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, dtype=torch.long, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 根据阈值，决定是否分配真实边界框&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    max_ious, indices = torch.&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;(jaccard, dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    anc_i = torch.nonzero(max_ious &amp;gt;= iou_threshold).reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    box_j = indices[max_ious &amp;gt;= iou_threshold]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    anchors_bbox_map[anc_i] = box_j&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    col_discard = torch.full((num_anchors,), -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    row_discard = torch.full((num_gt_boxes,), -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; _ &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_gt_boxes):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        max_idx = torch.argmax(jaccard)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        box_idx = (max_idx % num_gt_boxes).long()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        anc_idx = (max_idx / num_gt_boxes).long()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        anchors_bbox_map[anc_idx] = box_idx&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        jaccard[:, box_idx] = col_discard&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        jaccard[anc_idx, :] = row_discard&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; anchors_bbox_map&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;offset_boxes&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;anchors, assigned_bb, eps=&lt;span class=&#34;number&#34;&gt;1e-6&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;对锚框偏移量的转换&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    c_anc = d2l.box_corner_to_center(anchors)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    c_assigned_bb = d2l.box_corner_to_center(assigned_bb)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    offset_xy = &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt; * (c_assigned_bb[:, :&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;] - c_anc[:, :&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]) / c_anc[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    offset_wh = &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt; * torch.log(eps + c_assigned_bb[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:] / c_anc[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    offset = torch.cat([offset_xy, offset_wh], dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; offset&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;multibox_target&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;anchors, labels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;使用真实边界框标记锚框&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    batch_size, anchors = labels.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], anchors.squeeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    batch_offset, batch_mask, batch_class_labels = [], [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    device, num_anchors = anchors.device, anchors.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(batch_size):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        label = labels[i, :, :]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        anchors_bbox_map = assign_anchor_to_bbox(label[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:], anchors, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        bbox_mask = ((anchors_bbox_map &amp;gt;= &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;).&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;().unsqueeze(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)).repeat(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 将类标签和分配的边界框坐标初始化为零&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        class_labels = torch.zeros(num_anchors, dtype=torch.long, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        assigned_bb = torch.zeros((num_anchors, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;), dtype=torch.float32, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 使用真实边界框来标记锚框的类别&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 如果一个锚框没有被分配，标记其为背景（值为零）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        indices_true = torch.nonzero(anchors_bbox_map &amp;gt;= &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        bb_idx = anchors_bbox_map[indices_true]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        class_labels[indices_true] = label[bb_idx, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].long() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        assigned_bb[indices_true] = label[bb_idx, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 偏移量转换&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        offset = offset_boxes(anchors, assigned_bb) * bbox_mask&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        batch_offset.append(offset.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        batch_mask.append(bbox_mask.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        batch_class_labels.append(class_labels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    bbox_offset = torch.stack(batch_offset)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    bbox_mask = torch.stack(batch_mask)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    class_labels = torch.stack(batch_class_labels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (bbox_offset, bbox_mask, class_labels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ground_truth = torch.tensor([[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.08&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.52&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.92&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                             [&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.55&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.88&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;anchors = torch.tensor([[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0.15&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.4&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                        [&lt;span class=&#34;number&#34;&gt;0.63&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.05&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.88&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.98&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0.66&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.45&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.8&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                        [&lt;span class=&#34;number&#34;&gt;0.57&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.92&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# fig = plt.imshow(img)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# show_bboxes(fig.axes, ground_truth[:, 1:] * bbox_scale, [&amp;#x27;dog&amp;#x27;, &amp;#x27;cat&amp;#x27;], &amp;#x27;k&amp;#x27;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# show_bboxes(fig.axes, anchors * bbox_scale, [&amp;#x27;0&amp;#x27;, &amp;#x27;1&amp;#x27;, &amp;#x27;2&amp;#x27;, &amp;#x27;3&amp;#x27;, &amp;#x27;4&amp;#x27;])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# plt.show()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 返回的结果中有三个元素，都是张量格式。第一个元素包含了为每个锚框标记的四个偏移值。注意负类锚框的偏移量被标记为零&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 第二个元素是掩码（mask）变量，形状为（批量大小，锚框数的四倍）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 第三个元素包含标记的输入锚框的类别&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;labels = multibox_target(anchors.unsqueeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;), ground_truth.unsqueeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(labels[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# tensor([[0, 1, 2, 0, 2]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;offset_inverse&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;anchors, offset_preds&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;根据带有预测偏移量的锚框来预测边界框&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    anc = d2l.box_corner_to_center(anchors)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pred_bbox_xy = (offset_preds[:, :&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;] * anc[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:] / &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;) + anc[:, :&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pred_bbox_wh = torch.exp(offset_preds[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:] / &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;) * anc[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pred_bbox = torch.cat((pred_bbox_xy, pred_bbox_wh), dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    predicted_bbox = d2l.box_center_to_corner(pred_bbox)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; predicted_bbox&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;nms&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;boxes, scores, iou_threshold&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;对预测边界框的置信度进行排序&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    B = torch.argsort(scores, dim=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, descending=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    keep = []  &lt;span class=&#34;comment&#34;&gt;# 保留预测边界框的指标&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;while&lt;/span&gt; B.numel() &amp;gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        i = B[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        keep.append(i)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; B.numel() == &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;: &lt;span class=&#34;keyword&#34;&gt;break&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        iou = box_iou(boxes[i, :].reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;), boxes[B[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:], :].reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)).reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        inds = torch.nonzero(torch.as_tensor(iou &amp;lt;= iou_threshold, dtype=torch.float32)).reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        B = B[inds + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.tensor(keep, device=boxes.device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;multibox_detection&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;cls_probs, offset_preds, anchors, nms_threshold=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, pos_threshold=&lt;span class=&#34;number&#34;&gt;0.009999999&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;使用非极大值抑制来预测边界框&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    device, batch_size = cls_probs.device, cls_probs.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    anchors = anchors.squeeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_classes, num_anchors = cls_probs.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], cls_probs.shape[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    out = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(batch_size):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        conf, class_id = torch.&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;(cls_prob[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:], &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        predicted_bb = offset_inverse(anchors, offset_pred)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        keep = nms(predicted_bb, conf, nms_threshold)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 找到所有的non_keep索引，并将类设置为背景&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        all_idx = torch.arange(num_anchors, dtype=torch.long, device=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        combined = torch.cat((keep, all_idx))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        uniques, counts = combined.unique(return_counts=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        non_keep = uniques[counts == &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        all_id_sorted = torch.cat((keep, non_keep))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        class_id[non_keep] = -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        class_id = class_id[all_id_sorted]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# pos_threshold是一个用于非背景预测的阈值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        below_min_idx = (conf &amp;lt; pos_threshold)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        class_id[below_min_idx] = -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        conf[below_min_idx] = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; - conf[below_min_idx]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        pred_info = torch.cat((class_id.unsqueeze(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), conf.unsqueeze(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), predicted_bb), dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out.append(pred_info)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.stack(out)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;anchors = torch.tensor([[&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.08&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.52&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.92&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0.08&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.56&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.95&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                        [&lt;span class=&#34;number&#34;&gt;0.15&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.62&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.91&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0.55&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.88&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;offset_preds = torch.tensor([&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] * anchors.numel())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cls_probs = torch.tensor([[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] * &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;,  &lt;span class=&#34;comment&#34;&gt;# 背景的预测概率&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                          [&lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.7&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;],  &lt;span class=&#34;comment&#34;&gt;# 狗的预测概率&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                          [&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;]])  &lt;span class=&#34;comment&#34;&gt;# 猫的预测概率&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# fig = plt.imshow(img)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# show_bboxes(fig.axes, anchors * bbox_scale, [&amp;#x27;dog=0.9&amp;#x27;, &amp;#x27;dog=0.8&amp;#x27;, &amp;#x27;dog=0.7&amp;#x27;, &amp;#x27;cat=0.9&amp;#x27;])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# plt.show()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 返回结果的形状是（批量大小，锚框的数量，6）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 第一个元素是预测的类索引，从0开始（0代表狗，1代表猫），值-1表示背景或在非极大值抑制中被移除了&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 第二个元素是预测的边界框的置信度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 其余四个元素分别是预测边界框左上角和右下角的坐标（范围介于0~1之间）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output = multibox_detection(cls_probs.unsqueeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                            offset_preds.unsqueeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                            anchors.unsqueeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                            nms_threshold=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[ 0.00,  0.90,  0.10,  0.08,  0.52,  0.92],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [ 1.00,  0.90,  0.55,  0.20,  0.90,  0.88],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [-1.00,  0.80,  0.08,  0.20,  0.56,  0.95],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [-1.00,  0.70,  0.15,  0.30,  0.62,  0.91]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 删除-1类别（背景）的预测边界框后，我们可以输出由非极大值抑制保存的最终预测边界框&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;fig = plt.imshow(img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; output[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].detach().numpy():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; i[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] == -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;continue&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    label = (&lt;span class=&#34;string&#34;&gt;&amp;#x27;dog=&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;cat=&amp;#x27;&lt;/span&gt;)[&lt;span class=&#34;built_in&#34;&gt;int&lt;/span&gt;(i[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])] + &lt;span class=&#34;built_in&#34;&gt;str&lt;/span&gt;(i[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    show_bboxes(fig.axes, [torch.tensor(i[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:]) * bbox_scale], label)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;6-多尺度目标检测&#34;&gt;6. 多尺度目标检测&lt;/h2&gt;
&lt;p&gt;在上一节中，我们以输入图像的每个像素为中心，生成了多个锚框。基本而言，这些锚框代表了图像不同区域的样本。然而，如果为每个像素都生成的锚框，我们最终可能会得到太多需要计算的锚框。想象一个561*728的输入图像，如果以每个像素为中心生成五个形状不同的锚框，就需要在图像上标记和预测超过200万个锚框（561*728*5）。&lt;/p&gt;
&lt;h3 id=&#34;6-1-多尺度锚框&#34;&gt;6.1 多尺度锚框&lt;/h3&gt;
&lt;p&gt;减少图像上的锚框数量并不困难。比如，我们可以在输入图像中均匀采样一小部分像素，并以它们为中心生成锚框。此外，在不同尺度下，我们可以生成不同数量和不同大小的锚框。直观地说，比起较大的目标，较小的目标在图像上出现的可能性更多样。例如，1*1、1*2和2*2的目标可以分别以4、2和1种可能的方式出现在2*2的图像上。因此，当使用较小的锚框检测较小的物体时，我们可以采样更多的区域，而对于较大的物体，我们可以采样较少的区域。&lt;/p&gt;
&lt;p&gt;为了演示如何在多个尺度下生成锚框，让我们先读取一张图像。它的高度和宽度分别为561和728像素：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img = plt.imread(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../images/catdog.jpg&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;h, w = img.shape[:&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(h, w)  &lt;span class=&#34;comment&#34;&gt;# 561 728&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;display_anchors&lt;/code&gt; 函数定义如下。我们在&lt;strong&gt;特征图&lt;/strong&gt;（fmap）上生成锚框（anchors），每个单位（像素）作为锚框的中心。由于锚框中的 &lt;code&gt;(x, y)&lt;/code&gt; 轴坐标值（anchors）已经被除以特征图（fmap）的宽度和高度，因此这些值介于0和1之间，表示特征图中锚框的相对位置。&lt;/p&gt;
&lt;p&gt;由于锚框（anchors）的中心分布于特征图（fmap）上的所有单位，因此这些中心必须根据其相对空间位置在任何输入图像上均匀分布。更具体地说，给定特征图的宽度和高度 &lt;code&gt;fmap_w&lt;/code&gt; 和 &lt;code&gt;fmap_h&lt;/code&gt;，以下函数将均匀地对任何输入图像中 &lt;code&gt;fmap_h&lt;/code&gt; 行和 &lt;code&gt;fmap_w&lt;/code&gt; 列中的像素进行采样。以这些均匀采样的像素为中心，将会生成大小为 &lt;code&gt;s&lt;/code&gt;（假设列表 &lt;code&gt;s&lt;/code&gt; 的长度为1）且宽高比（ratios）不同的锚框：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;display_anchors&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;fmap_w, fmap_h, s&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.figure(dpi=&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 前两个维度上的值不影响输出&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fmap = torch.zeros((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, fmap_h, fmap_w))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    anchors = d2l.multibox_prior(fmap, sizes=s, ratios=[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    bbox_scale = torch.tensor((w, h, w, h))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    d2l.show_bboxes(plt.imshow(img).axes, anchors[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] * bbox_scale)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;首先，让我们考虑探测小目标。为了在显示时更容易分辨，在这里具有不同中心的锚框不会重叠：锚框的尺度设置为0.15，特征图的高度和宽度设置为4。我们可以看到，图像上4行和4列的锚框的中心是均匀分布的：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;display_anchors(fmap_w=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, fmap_h=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, s=[&lt;span class=&#34;number&#34;&gt;0.15&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后，我们将特征图的高度和宽度减小一半，然后使用较大的锚框来检测较大的目标。当尺度设置为0.4时，一些锚框将彼此重叠：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;display_anchors(fmap_w=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, fmap_h=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, s=[&lt;span class=&#34;number&#34;&gt;0.4&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后，我们进一步将特征图的高度和宽度减小一半，然后将锚框的尺度增加到0.8。此时，锚框的中心即是图像的中心：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;display_anchors(fmap_w=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, fmap_h=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, s=[&lt;span class=&#34;number&#34;&gt;0.8&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;6-2-多尺度检测&#34;&gt;6.2 多尺度检测&lt;/h3&gt;
&lt;p&gt;既然我们已经生成了多尺度的锚框，我们就将使用它们来检测不同尺度下各种大小的目标。下面，我们介绍一种基于 CNN 的多尺度目标检测方法，将在第8节（SSD）中实现。&lt;/p&gt;
&lt;p&gt;在某种规模上，假设我们有 &lt;code&gt;c&lt;/code&gt; 张形状为 &lt;code&gt;h * w&lt;/code&gt; 的特征图。使用上一小节中的方法，我们生成了 &lt;code&gt;hw&lt;/code&gt; 组锚框，其中每组都有 &lt;code&gt;a&lt;/code&gt; 个中心相同的锚框。例如，在上一小节实验的第一个尺度上，给定10个（通道数量）&lt;code&gt;4 * 4&lt;/code&gt; 的特征图，我们生成了16组锚框，每组包含3个中心相同的锚框。接下来，每个锚框都根据真实值边界框来标记了类和偏移量。在当前尺度下，目标检测模型需要预测输入图像上 &lt;code&gt;hw&lt;/code&gt; 组锚框类别和偏移量，其中不同组锚框具有不同的中心。&lt;/p&gt;
&lt;p&gt;假设此处的 &lt;code&gt;c&lt;/code&gt; 张特征图是 CNN 基于输入图像的正向传播算法获得的中间输出。既然每张特征图上都有 &lt;code&gt;hw&lt;/code&gt; 个不同的空间位置，那么相同空间位置可以看作含有 &lt;code&gt;c&lt;/code&gt; 个单元。根据感受野的定义，特征图在相同空间位置的 &lt;code&gt;c&lt;/code&gt; 个单元在输入图像上的感受野相同：它们表征了同一感受野内的输入图像信息。因此，我们可以将特征图在同一空间位置的 &lt;code&gt;c&lt;/code&gt; 个单元变换为使用此空间位置生成的 &lt;code&gt;a&lt;/code&gt; 个锚框类别和偏移量。本质上，我们用输入图像在某个感受野区域内的信息，来预测输入图像上与该区域位置相近的锚框类别和偏移量。&lt;/p&gt;
&lt;p&gt;当不同层的特征图在输入图像上分别拥有不同大小的感受野时，它们可以用于检测不同大小的目标。例如，我们可以设计一个神经网络，其中靠近输出层的特征图单元具有更宽的感受野，这样它们就可以从输入图像中检测到较大的目标。&lt;/p&gt;
&lt;p&gt;简言之，我们可以利用深层神经网络在多个层次上对图像进行分层表示，从而实现多尺度目标检测。在第8节我们将通过一个具体的例子来说明它是如何工作的。&lt;/p&gt;
&lt;h2 id=&#34;7-区域卷积神经网络（R-CNN）系列&#34;&gt;7. 区域卷积神经网络（R-CNN）系列&lt;/h2&gt;
&lt;h3 id=&#34;7-1-R-CNN&#34;&gt;7.1 R-CNN&lt;/h3&gt;
&lt;p&gt;R-CNN 首先从输入图像中选取若干（例如2000个）提议区域（如锚框也是一种选取方法），并标注它们的类别和边界框（如偏移量）。然后，用卷积神经网络对每个提议区域进行前向传播以抽取其特征。接下来，我们用每个提议区域的特征来预测类别和边界框。具体来说，R-CNN 包括以下四个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对输入图像使用选择性搜索来选取多个高质量的提议区域。这些提议区域通常是在多个尺度下选取的，并具有不同的形状和大小。每个提议区域都将被标注类别和真实边界框；&lt;/li&gt;
&lt;li&gt;选择一个预训练的卷积神经网络，并将其在输出层之前截断。将每个提议区域变形为网络需要的输入尺寸，并通过前向传播输出抽取的提议区域特征；&lt;/li&gt;
&lt;li&gt;将每个提议区域的特征连同其标注的类别作为一个样本。训练多个支持向量机对目标分类，其中每个支持向量机用来判断样本是否属于某一个类别；&lt;/li&gt;
&lt;li&gt;将每个提议区域的特征连同其标注的边界框作为一个样本，训练线性回归模型来预测真实边界框。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;尽管 R-CNN 模型通过预训练的卷积神经网络有效地抽取了图像特征，但它的速度很慢。想象一下，我们可能从一张图像中选出上千个提议区域，这需要上千次的卷积神经网络的前向传播来执行目标检测。这种庞大的计算量使得 R-CNN 在现实世界中难以被广泛应用。&lt;/p&gt;
&lt;h3 id=&#34;7-2-Fast-R-CNN&#34;&gt;7.2 Fast R-CNN&lt;/h3&gt;
&lt;p&gt;R-CNN 的主要性能瓶颈在于，对每个提议区域，卷积神经网络的前向传播是独立的，而没有共享计算。由于这些区域通常有重叠，独立的特征抽取会导致重复的计算。Fast R-CNN 对 R-CNN 的主要改进之一，是仅在&lt;strong&gt;整张图像&lt;/strong&gt;上执行卷积神经网络的前向传播。Fast R-CNN 的主要计算如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;与 R-CNN 相比，Fast R-CNN 用来提取特征的入卷积神经网络的输入是整个图像，而不是各个提议区域。此外，这个网络通常会参与训练。设输入为一张图像，将卷积神经网络的输出的形状记为 &lt;code&gt;1 * c * h1 * w1&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;假设选择性搜索生成了 &lt;code&gt;n&lt;/code&gt; 个提议区域。这些形状各异的提议区域在卷积神经网络的输出上分别标出了形状各异的兴趣区域。然后，这些感兴趣的区域需要进一步抽取出&lt;strong&gt;形状相同&lt;/strong&gt;的特征（比如指定高度 &lt;code&gt;h2&lt;/code&gt; 和宽度 &lt;code&gt;w2&lt;/code&gt;），以便于连结后输出。为了实现这一目标，Fast R-CNN 引入了&lt;strong&gt;兴趣区域汇聚层&lt;/strong&gt;（RoI pooling）：将卷积神经网络的输出和提议区域作为输入，输出连结后的各个提议区域抽取的特征，形状为 &lt;code&gt;n * c * h2 * w2&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;通过全连接层将输出形状变换为 &lt;code&gt;n * d&lt;/code&gt;，其中超参数 &lt;code&gt;d&lt;/code&gt; 取决于模型设计；&lt;/li&gt;
&lt;li&gt;预测 &lt;code&gt;n&lt;/code&gt; 个提议区域中每个区域的类别和边界框。更具体地说，在预测类别和边界框时，将全连接层的输出分别转换为形状为 &lt;code&gt;n * q&lt;/code&gt;（&lt;code&gt;q&lt;/code&gt; 是类别的数量）的输出和形状为 &lt;code&gt;n * 4&lt;/code&gt; 的输出。其中预测类别时使用 Softmax 回归。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面，我们演示了兴趣区域汇聚层的计算方法。假设卷积神经网络抽取的特征 &lt;code&gt;X&lt;/code&gt; 的高度和宽度都是4，且只有单通道：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.arange(&lt;span class=&#34;number&#34;&gt;16.&lt;/span&gt;).reshape(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[[ 0.,  1.,  2.,  3.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [ 4.,  5.,  6.,  7.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [ 8.,  9., 10., 11.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [12., 13., 14., 15.]]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;让我们进一步假设输入图像的高度和宽度都是40像素，且选择性搜索在此图像上生成了两个提议区域。每个区域由5个元素表示：区域目标类别、左上角和右下角的 &lt;code&gt;(x, y)&lt;/code&gt; 坐标：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;rois = torch.Tensor([[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;30&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;30&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;由于 &lt;code&gt;X&lt;/code&gt; 的高和宽是输入图像高和宽的1/10，因此，两个提议区域的坐标先按 &lt;code&gt;spatial_scale&lt;/code&gt; 乘以0.1。然后，在 &lt;code&gt;X&lt;/code&gt; 上分别标出这两个兴趣区域 &lt;code&gt;X[:, :, 0:3, 0:3]&lt;/code&gt; 和 &lt;code&gt;X[:, :, 1:4, 0:4]&lt;/code&gt;。最后，在 &lt;code&gt;2 * 2&lt;/code&gt; 的兴趣区域汇聚层中，每个兴趣区域被划分为子窗口网格，并进一步抽取相同形状 &lt;code&gt;2 * 2&lt;/code&gt; 的特征：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torchvision.ops.roi_pool(X, rois, output_size=(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), spatial_scale=&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[[ 5.,  6.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [ 9., 10.]]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[[ 9., 11.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [13., 15.]]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;7-3-Faster-R-CNN&#34;&gt;7.3 Faster R-CNN&lt;/h3&gt;
&lt;p&gt;为了较精确地检测目标结果，Fast R-CNN 模型通常需要在选择性搜索中生成大量的提议区域。Faster R-CNN 提出将选择性搜索替换为&lt;strong&gt;区域提议网络&lt;/strong&gt;（region proposal network），从而减少提议区域的生成数量，并保证目标检测的精度。具体来说，区域提议网络的计算步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用填充为1的 &lt;code&gt;3 * 3&lt;/code&gt; 的卷积层变换卷积神经网络的输出，并将输出通道数记为 &lt;code&gt;c&lt;/code&gt;。这样，卷积神经网络为图像抽取的特征图中的每个单元均得到一个长度为 &lt;code&gt;c&lt;/code&gt; 的新特征；&lt;/li&gt;
&lt;li&gt;以特征图的每个像素为中心，生成多个不同大小和宽高比的锚框并标注它们；&lt;/li&gt;
&lt;li&gt;使用锚框中心单元长度为 &lt;code&gt;c&lt;/code&gt; 的特征，分别预测该锚框的二元类别（含目标还是背景）和边界框；&lt;/li&gt;
&lt;li&gt;使用非极大值抑制，从预测类别为目标的预测边界框中移除相似的结果。最终输出的预测边界框即是兴趣区域汇聚层所需的提议区域。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;值得一提的是，区域提议网络作为 Faster R-CNN 模型的一部分，是和整个模型一起训练得到的。换句话说，Faster R-CNN 的目标函数不仅包括目标检测中的类别和边界框预测，还包括区域提议网络中锚框的二元类别和边界框预测。作为端到端训练的结果，区域提议网络能够学习到如何生成高质量的提议区域，从而在减少了从数据中学习的提议区域的数量的情况下，仍保持目标检测的精度。&lt;/p&gt;
&lt;h3 id=&#34;7-4-Mask-R-CNN&#34;&gt;7.4 Mask R-CNN&lt;/h3&gt;
&lt;p&gt;如果在训练集中还标注了每个目标在图像上的&lt;strong&gt;像素级位置&lt;/strong&gt;，那么 Mask R-CNN 能够有效地利用这些详尽的标注信息进一步提升目标检测的精度。&lt;/p&gt;
&lt;p&gt;Mask R-CNN 是基于 Faster R-CNN 修改而来的。具体来说，Mask R-CNN 将兴趣区域汇聚层替换为了兴趣区域对齐层（RoI Align），使用双线性插值（bilinear interpolation）来保留特征图上的空间信息，从而更适于像素级预测。兴趣区域对齐层的输出包含了所有与兴趣区域的形状相同的特征图。它们不仅被用于预测每个兴趣区域的类别和边界框，还通过额外的全卷积网络预测目标的像素级位置。本章的后续章节将更详细地介绍如何使用全卷积网络预测图像中像素级的语义。&lt;/p&gt;
&lt;h2 id=&#34;8-单发多框检测（SSD）&#34;&gt;8. 单发多框检测（SSD）&lt;/h2&gt;
&lt;p&gt;SSD 模型主要由基础网络组成，其后是几个多尺度特征块。基本网络用于从输入图像中提取特征，因此它可以使用深度卷积神经网络。单发多框检测论文中选用了在分类层之前截断的 VGG，现在也常用 ResNet 替代。我们可以设计基础网络，使它输出的高和宽较大。这样一来，基于该特征图生成的锚框数量较多，可以用来检测尺寸较小的目标。接下来的每个多尺度特征块将上一层提供的特征图的高和宽缩小（如减半），并使特征图中每个单元在输入图像上的感受野变得更广阔。&lt;/p&gt;
&lt;p&gt;回想一下在第6节中，通过深度神经网络分层表示图像的多尺度目标检测的设计。由于接近顶部的多尺度特征图较小，但具有较大的感受野，它们适合检测较少但较大的物体。简而言之，通过多尺度特征块，单发多框检测生成不同大小的锚框，并通过预测边界框的类别和偏移量来检测大小不同的目标，因此这是一个多尺度目标检测模型。&lt;/p&gt;
&lt;h3 id=&#34;8-1-类别预测层与边界框预测层&#34;&gt;8.1 类别预测层与边界框预测层&lt;/h3&gt;
&lt;p&gt;设目标类别的数量为 &lt;code&gt;q&lt;/code&gt;。这样一来，锚框有 &lt;code&gt;q + 1&lt;/code&gt; 个类别，其中第0类是背景。在某个尺度下，设特征图的高和宽分别为 &lt;code&gt;h&lt;/code&gt; 和 &lt;code&gt;w&lt;/code&gt;。如果以其中每个单元为中心生成 &lt;code&gt;a&lt;/code&gt; 个锚框，那么我们需要对 &lt;code&gt;hwa&lt;/code&gt; 个锚框进行分类。如果使用全连接层作为输出，很容易导致模型参数过多。回忆 NiN 一节介绍的使用卷积层的通道来输出类别预测的方法，单发多框检测采用同样的方法来降低模型复杂度。&lt;/p&gt;
&lt;p&gt;具体来说，类别预测层使用一个保持输入高和宽的卷积层。这样一来，输出和输入在特征图宽和高上的空间坐标一一对应。考虑输出和输入同一空间坐标 &lt;code&gt;(x, y)&lt;/code&gt;：输出特征图上 &lt;code&gt;(x, y)&lt;/code&gt; 坐标的通道里包含了以输入特征图 &lt;code&gt;(x, y)&lt;/code&gt; 坐标为中心生成的所有锚框的类别预测。因此输出通道数为 &lt;code&gt;a * (q + 1)&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;类别预测层的定义如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tqdm &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tqdm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# num_inputs为输入通道数，(num_classes + 1)表示还有一个背景类，因为需要预测每个锚框是哪个类因此输出通道要乘以num_anchors&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 即对于输入的每一个像素，它的输出通道数就是以该像素为中心的num_anchors个锚框的预测值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;cls_predictor&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;num_inputs, num_anchors, num_classes&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Conv2d(num_inputs, num_anchors * (num_classes + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;边界框预测层的设计与类别预测层的设计类似。唯一不同的是，这里需要为每个锚框预测4个偏移量，而不是 &lt;code&gt;q + 1&lt;/code&gt; 个类别：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 预测锚框和真实边界框的offset，对每一个锚框有4个预测值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;bbox_predictor&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;num_inputs, num_anchors&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Conv2d(num_inputs, num_anchors * &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;8-2-连结多尺度的预测&#34;&gt;8.2 连结多尺度的预测&lt;/h3&gt;
&lt;p&gt;单发多框检测使用多尺度特征图来生成锚框并预测其类别和偏移量。在不同的尺度下，特征图的形状或以同一单元为中心的锚框的数量可能会有所不同。因此，不同尺度下预测输出的形状可能会有所不同。&lt;/p&gt;
&lt;p&gt;在以下示例中，我们为同一个小批量构建两个不同比例（&lt;code&gt;Y1&lt;/code&gt; 和 &lt;code&gt;Y2&lt;/code&gt;）的特征图，其中 &lt;code&gt;Y2&lt;/code&gt; 的高度和宽度是 &lt;code&gt;Y1&lt;/code&gt; 的一半。以类别预测为例，假设 &lt;code&gt;Y1&lt;/code&gt; 和 &lt;code&gt;Y2&lt;/code&gt; 的每个单元分别生成了5个和3个锚框。进一步假设目标类别的数量为10，对于特征图 &lt;code&gt;Y1&lt;/code&gt; 和 &lt;code&gt;Y2&lt;/code&gt;，类别预测输出中的通道数分别为 &lt;code&gt;5 * (10 + 1) = 55&lt;/code&gt; 和 &lt;code&gt;3 * (10 + 1) = 33&lt;/code&gt;，其中任一输出的形状是 &lt;code&gt;(批量大小, 通道数, 高度, 宽度)&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x, block&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; block(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Y1为对输入的400(20*20)个像素都会做55(5*(10+1))个预测&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 因此在不同尺度下的预测除了batch维之外另外三个维度都会发生变化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y1 = forward(torch.zeros((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;)), cls_predictor(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y2 = forward(torch.zeros((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)), cls_predictor(&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(Y1.shape, Y2.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 55, 20, 20]) torch.Size([2, 33, 10, 10])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;除了批量大小这一维度外，其他三个维度都具有不同的尺寸。为了将这两个预测输出链接起来以提高计算效率，我们将把这些张量转换为更一致的格式。&lt;/p&gt;
&lt;p&gt;通道维包含中心相同的锚框的预测结果。我们首先将通道维移到最后一维。因为不同尺度下批量大小仍保持不变，我们可以将预测结果转成二维的 &lt;code&gt;(批量大小, 高 * 宽 * 通道数)&lt;/code&gt; 的格式，以方便之后在维度1上的连结。这样一来，尽管 &lt;code&gt;Y1&lt;/code&gt; 和 &lt;code&gt;Y2&lt;/code&gt; 在通道数、高度和宽度方面具有不同的大小，我们仍然可以在同一个小批量的两个不同尺度上连接这两个预测输出：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# start_dim=1表示将后面三个维度展平成一维&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 把通道放最后表示对于每个像素的预测是连续值，否则展平后每个像素的预测就不是连续的&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;flatten_pred&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;pred&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.flatten(pred.permute(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), start_dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;concat_preds&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;preds&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.cat([flatten_pred(p) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; p &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; preds], dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(concat_preds([Y1, Y2]).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 25300])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;8-3-高和宽减半块&#34;&gt;8.3 高和宽减半块&lt;/h3&gt;
&lt;p&gt;高和宽减半块将输入特征图的高度和宽度减半，会扩大每个单元在其输出特征图中的感受野，该模块此前已在 VGG 中使用过：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 高宽减半块，该模块将输入特征图的高度和宽度减半&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;down_sample_blk&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;in_channels, out_channels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    blk = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; _ &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        blk.append(nn.BatchNorm2d(out_channels))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        blk.append(nn.ReLU())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        in_channels = out_channels&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    blk.append(nn.MaxPool2d(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Sequential(*blk)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(forward(torch.zeros((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;)), down_sample_blk(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 10, 10, 10])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;8-4-基本网络块&#34;&gt;8.4 基本网络块&lt;/h3&gt;
&lt;p&gt;基本网络块用于从输入图像中抽取特征。为了计算简洁，我们构造了一个小的基础网络，该网络串联3个高和宽减半块，并逐步将通道数翻倍：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;base_net&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    blk = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_filters = [&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(num_filters) - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        blk.append(down_sample_blk(num_filters[i], num_filters[i + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Sequential(*blk)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(forward(torch.zeros((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;)), base_net()).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 64, 32, 32])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;8-5-完整的模型&#34;&gt;8.5 完整的模型&lt;/h3&gt;
&lt;p&gt;完整的单发多框检测模型由&lt;strong&gt;五个模块&lt;/strong&gt;组成，每个块生成的特征图既用于生成锚框，又用于预测这些锚框的类别和偏移量。在这五个模块中，第一个是&lt;strong&gt;基本网络块&lt;/strong&gt;，第二个到第四个是&lt;strong&gt;高和宽减半块&lt;/strong&gt;，最后一个模块使用&lt;strong&gt;全局最大池化层&lt;/strong&gt;将高度和宽度都降到1。从技术上讲，第二到第五个区块都是 SSD 中的&lt;strong&gt;多尺度特征块&lt;/strong&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;get_blk&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;i&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; i == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        blk = base_net()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; i == &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        blk = down_sample_blk(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; i == &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        blk = nn.AdaptiveMaxPool2d((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        blk = down_sample_blk(&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; blk&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在我们为每个块定义前向传播。与图像分类任务不同，此处的输出包括：CNN 特征图 &lt;code&gt;Y&lt;/code&gt;、在当前尺度下根据 &lt;code&gt;Y&lt;/code&gt; 生成的锚框、预测的这些锚框的类别和偏移量（基于 &lt;code&gt;Y&lt;/code&gt;）：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 为每个块定义前向传播，此处的cls_predictor和bbox_predictor为已经构造好的卷积层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;blk_forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, blk, size, ratio, cls_predictor, bbox_predictor&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Y = blk(X)  &lt;span class=&#34;comment&#34;&gt;# feature map&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    anchors = d2l.multibox_prior(Y, sizes=size, ratios=ratio)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    cls_preds = cls_predictor(Y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    bbox_preds = bbox_predictor(Y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (Y, anchors, cls_preds, bbox_preds)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;超参数的设置过程可以看：&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_computer-vision/ssd.html&#34;&gt;单发多框检测（SSD）&lt;/a&gt;。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;sizes = [[&lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.272&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0.37&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.447&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0.54&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.619&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0.71&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.79&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0.88&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.961&lt;/span&gt;]]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ratios = [[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;]] * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_anchors = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(sizes[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]) + &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(ratios[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]) - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在，我们就可以按如下方式定义完整的模型 &lt;code&gt;TinySSD&lt;/code&gt; 了：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;TinySSD&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, num_classes, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(TinySSD, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.num_classes = num_classes&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        idx_to_in_channels = [&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 即赋值语句self.blk_i=get_blk(i)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;setattr&lt;/span&gt;(self, &lt;span class=&#34;string&#34;&gt;f&amp;#x27;blk_&lt;span class=&#34;subst&#34;&gt;&amp;#123;i&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;, get_blk(i))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;setattr&lt;/span&gt;(self, &lt;span class=&#34;string&#34;&gt;f&amp;#x27;cls_&lt;span class=&#34;subst&#34;&gt;&amp;#123;i&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;, cls_predictor(idx_to_in_channels[i], num_anchors, num_classes))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;setattr&lt;/span&gt;(self, &lt;span class=&#34;string&#34;&gt;f&amp;#x27;bbox_&lt;span class=&#34;subst&#34;&gt;&amp;#123;i&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;, bbox_predictor(idx_to_in_channels[i], num_anchors))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        anchors, cls_preds, bbox_preds = [&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;] * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, [&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;] * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, [&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;] * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# getattr(self, &amp;#x27;blk_%d&amp;#x27;%i)即访问self.blk_i&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                X, &lt;span class=&#34;built_in&#34;&gt;getattr&lt;/span&gt;(self, &lt;span class=&#34;string&#34;&gt;f&amp;#x27;blk_&lt;span class=&#34;subst&#34;&gt;&amp;#123;i&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;), sizes[i], ratios[i],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;built_in&#34;&gt;getattr&lt;/span&gt;(self, &lt;span class=&#34;string&#34;&gt;f&amp;#x27;cls_&lt;span class=&#34;subst&#34;&gt;&amp;#123;i&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;), &lt;span class=&#34;built_in&#34;&gt;getattr&lt;/span&gt;(self, &lt;span class=&#34;string&#34;&gt;f&amp;#x27;bbox_&lt;span class=&#34;subst&#34;&gt;&amp;#123;i&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# print(f&amp;#x27;anchors[&amp;#123;i&amp;#125;], cls_preds[&amp;#123;i&amp;#125;], bbox_preds[&amp;#123;i&amp;#125;]:&amp;#x27;, anchors[i].shape, cls_preds[i].shape, bbox_preds[i].shape)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        anchors = torch.cat(anchors, dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        cls_preds = concat_preds(cls_preds)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        cls_preds = cls_preds.reshape(cls_preds.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, self.num_classes + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        bbox_preds = concat_preds(bbox_preds)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; anchors, cls_preds, bbox_preds&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# f_map: (32, 3, 256, 256)-&amp;gt;(32, 64, 32, 32)-&amp;gt;(32, 128, 16, 16)-&amp;gt;(32, 128, 8, 8)-&amp;gt;(32, 128, 4, 4)-&amp;gt;(32, 128, 1, 1)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# anchors[0], cls_preds[0], bbox_preds[0]: torch.Size([1, 4096, 4]) torch.Size([32, 8, 32, 32]) torch.Size([32, 16, 32, 32])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# anchors[1], cls_preds[1], bbox_preds[1]: torch.Size([1, 1024, 4]) torch.Size([32, 8, 16, 16]) torch.Size([32, 16, 16, 16])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# anchors[2], cls_preds[2], bbox_preds[2]: torch.Size([1, 256, 4]) torch.Size([32, 8, 8, 8]) torch.Size([32, 16, 8, 8])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# anchors[3], cls_preds[3], bbox_preds[3]: torch.Size([1, 64, 4]) torch.Size([32, 8, 4, 4]) torch.Size([32, 16, 4, 4])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# anchors[4], cls_preds[4], bbox_preds[4]: torch.Size([1, 4, 4]) torch.Size([32, 8, 1, 1]) torch.Size([32, 16, 1, 1])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = TinySSD(num_classes=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.zeros((&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;anchors, cls_preds, bbox_preds = net(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;output anchors:&amp;#x27;&lt;/span&gt;, anchors.shape)  &lt;span class=&#34;comment&#34;&gt;# output anchors: torch.Size([1, 5444, 4])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;output class preds:&amp;#x27;&lt;/span&gt;, cls_preds.shape)  &lt;span class=&#34;comment&#34;&gt;# output class preds: torch.Size([32, 5444, 2])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;output bbox preds:&amp;#x27;&lt;/span&gt;, bbox_preds.shape)  &lt;span class=&#34;comment&#34;&gt;# output bbox preds: torch.Size([32, 21776])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;8-6-训练模型&#34;&gt;8.6 训练模型&lt;/h3&gt;
&lt;p&gt;首先读取数据集和设置超参数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr, num_epochs, batch_size = &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, valid_iter = d2l.load_data_bananas(batch_size)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后定义损失函数和评价函数，目标检测有两种类型的损失。第一种有关&lt;strong&gt;锚框类别&lt;/strong&gt;的损失：我们可以简单地复用之前图像分类问题里一直使用的交叉熵损失函数来计算；第二种有关&lt;strong&gt;正类锚框偏移量&lt;/strong&gt;的损失：预测偏移量是一个回归问题。但是，对于这个回归问题，我们在这里不使用平方损失，而是使用 L1 范数损失，即预测值和真实值之差的绝对值。掩码变量 &lt;code&gt;bbox_masks&lt;/code&gt; 令负类锚框和填充锚框不参与损失的计算。最后，我们将锚框类别和偏移量的损失相加，以获得模型的最终损失函数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;cls_loss = nn.CrossEntropyLoss(reduction=&lt;span class=&#34;string&#34;&gt;&amp;#x27;none&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;bbox_loss = nn.L1Loss(reduction=&lt;span class=&#34;string&#34;&gt;&amp;#x27;none&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;calc_loss&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    batch_size, num_classes = cls_preds.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], cls_preds.shape[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    cls = cls_loss(cls_preds.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, num_classes), cls_labels.reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)).reshape(batch_size, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;).mean(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    bbox = bbox_loss(bbox_preds * bbox_masks, bbox_labels * bbox_masks).mean(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; cls + bbox&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以沿用准确率评价分类结果。由于偏移量使用了 L1 范数损失，我们使用平均绝对误差来（MAE）评价边界框的预测结果。这些预测结果是从生成的锚框及其预测偏移量中获得的：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;cls_eval&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;cls_preds, cls_labels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 由于类别预测结果放在最后一维，argmax需要指定最后一维&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;((cls_preds.argmax(dim=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;).&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(cls_labels.dtype) == cls_labels).&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;bbox_eval&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;bbox_preds, bbox_labels, bbox_masks&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;((torch.&lt;span class=&#34;built_in&#34;&gt;abs&lt;/span&gt;((bbox_labels - bbox_preds) * bbox_masks)).&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后是训练模型，在训练模型时，我们需要在模型的前向传播过程中生成多尺度锚框 &lt;code&gt;anchors&lt;/code&gt;，并预测其类别 &lt;code&gt;cls_preds&lt;/code&gt; 和偏移量 &lt;code&gt;bbox_preds&lt;/code&gt;。然后，我们根据标签信息 &lt;code&gt;label&lt;/code&gt; 为生成的锚框标记类别 &lt;code&gt;cls_labels&lt;/code&gt; 和偏移量 &lt;code&gt;bbox_labels&lt;/code&gt;。最后，我们根据类别和偏移量的预测和标注值计算损失函数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, valid_iter, num_epochs, lr, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_weights&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;m&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.Linear &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.Conv2d:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.init.xavier_uniform_(m.weight)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.apply(init_weights)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;training on&amp;#x27;&lt;/span&gt;, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=&lt;span class=&#34;number&#34;&gt;5e-4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/SSD_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    best_acc = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        net.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss, train_acc, train_bbox_err = [], [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; feature, label &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(train_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            feature, label = feature.to(device), label.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 生成多尺度的锚框，为每个锚框预测类别和偏移量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            anchors, cls_preds, bbox_preds = net(feature)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 为每个锚框标注类别和偏移量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            bbox_labels, bbox_masks, cls_labels = d2l.multibox_target(anchors, label)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 根据类别和偏移量的预测和标注值计算损失函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss.mean().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            acc = cls_eval(cls_preds, cls_labels) / cls_labels.numel()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            bbox_mae = bbox_eval(bbox_preds, bbox_labels, bbox_masks) / bbox_labels.numel()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_loss.append(loss.mean())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_acc.append(acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_bbox_err.append(bbox_mae)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_acc = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_acc) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_bbox_err = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_bbox_err) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_bbox_err)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;quot;[ Train | &lt;span class=&#34;subst&#34;&gt;&amp;#123;epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:03d&amp;#125;&lt;/span&gt;/&lt;span class=&#34;subst&#34;&gt;&amp;#123;num_epochs:03d&amp;#125;&lt;/span&gt; ] loss = &lt;span class=&#34;subst&#34;&gt;&amp;#123;train_loss:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;, acc = &lt;span class=&#34;subst&#34;&gt;&amp;#123;train_acc:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;, bbox_err = &lt;span class=&#34;subst&#34;&gt;&amp;#123;train_bbox_err:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        net.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_loss, valid_acc, valid_bbox_err = [], [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; feature, label &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(valid_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                feature, label = feature.to(device), label.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                anchors, cls_preds, bbox_preds = net(feature)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                bbox_labels, bbox_masks, cls_labels = d2l.multibox_target(anchors, label)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                loss = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                acc = cls_eval(cls_preds, cls_labels) / cls_labels.numel()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                bbox_mae = bbox_eval(bbox_preds, bbox_labels, bbox_masks) / bbox_labels.numel()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                valid_loss.append(loss.mean())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                valid_acc.append(acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                valid_bbox_err.append(bbox_mae)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_loss = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(valid_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(valid_loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_acc = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(valid_acc) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(valid_acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_bbox_err = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(valid_bbox_err) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(valid_bbox_err)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;quot;[ Valid | &lt;span class=&#34;subst&#34;&gt;&amp;#123;epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:03d&amp;#125;&lt;/span&gt;/&lt;span class=&#34;subst&#34;&gt;&amp;#123;num_epochs:03d&amp;#125;&lt;/span&gt; ] loss = &lt;span class=&#34;subst&#34;&gt;&amp;#123;valid_loss:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;, acc = &lt;span class=&#34;subst&#34;&gt;&amp;#123;valid_acc:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;, bbox_err = &lt;span class=&#34;subst&#34;&gt;&amp;#123;valid_bbox_err:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalars(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train&amp;#x27;&lt;/span&gt;, &amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;loss&amp;#x27;&lt;/span&gt;: train_loss,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                     &lt;span class=&#34;string&#34;&gt;&amp;#x27;acc&amp;#x27;&lt;/span&gt;: train_acc,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                     &lt;span class=&#34;string&#34;&gt;&amp;#x27;bbox_err&amp;#x27;&lt;/span&gt;: train_bbox_err&amp;#125;, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalars(&lt;span class=&#34;string&#34;&gt;&amp;#x27;valid&amp;#x27;&lt;/span&gt;, &amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;loss&amp;#x27;&lt;/span&gt;: valid_loss,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                     &lt;span class=&#34;string&#34;&gt;&amp;#x27;acc&amp;#x27;&lt;/span&gt;: valid_acc,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                     &lt;span class=&#34;string&#34;&gt;&amp;#x27;bbox_err&amp;#x27;&lt;/span&gt;: valid_bbox_err&amp;#125;, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; valid_acc &amp;gt; best_acc:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            best_acc = valid_acc&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            torch.save(net.state_dict(), &lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/SSD_train.params&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;saving model with acc &amp;#123;:.3f&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(best_acc))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.close()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train(net, train_iter, valid_iter, num_epochs, lr, device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;8-7-预测目标&#34;&gt;8.7 预测目标&lt;/h3&gt;
&lt;p&gt;在预测阶段，我们希望能把图像里面所有我们感兴趣的目标检测出来。在下面，我们读取并调整测试图像的大小，然后将其转成卷积层需要的四维格式。使用 &lt;code&gt;multibox_detection&lt;/code&gt; 函数，我们可以根据锚框及其预测偏移量得到预测边界框，然后通过非极大值抑制来移除相似的预测边界框。最后，我们筛选所有置信度不低于0.9的边界框，做为最终输出：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = torchvision.io.read_image(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../images/banana.jpg&amp;#x27;&lt;/span&gt;).unsqueeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;).&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;()  &lt;span class=&#34;comment&#34;&gt;# 将其转成卷积层需要的四维格式&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img = X.squeeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;).permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;).long()  &lt;span class=&#34;comment&#34;&gt;# (h, w, c)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net.load_state_dict(torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/SSD_train.params&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;predict&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x, net, device&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    anchors, cls_preds, bbox_preds = net(X.to(device))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    cls_probs = F.softmax(cls_preds, dim=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;).permute(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = d2l.multibox_detection(cls_probs, bbox_preds, anchors)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    idx = [i &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, row &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(output[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]) &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; row[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] != -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, idx]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;display&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;img, output, threshold&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.figure(dpi=&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    fig = plt.imshow(img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; row &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; output:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        score = &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(row[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; score &amp;lt; threshold:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;continue&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        h, w = img.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        bbox = [row[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;] * torch.tensor((w, h, w, h), device=row.device)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        d2l.show_bboxes(fig.axes, bbox, &lt;span class=&#34;string&#34;&gt;&amp;#x27;%.2f&amp;#x27;&lt;/span&gt; % score, &lt;span class=&#34;string&#34;&gt;&amp;#x27;w&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output = predict(X, net, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;display(img, output.cpu(), threshold=&lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;9-语义分割和数据集&#34;&gt;9. 语义分割和数据集&lt;/h2&gt;
&lt;p&gt;在前几节中讨论的目标检测问题中，我们一直使用方形边界框来标注和预测图像中的目标。本节将探讨&lt;strong&gt;语义分割&lt;/strong&gt;（semantic segmentation）问题，它重点关注于如何将图像分割成属于不同语义类别的区域。与目标检测不同，语义分割可以识别并理解图像中&lt;strong&gt;每一个像素&lt;/strong&gt;的内容：其语义区域的标注和预测是像素级的。与目标检测相比，语义分割标注的像素级的边框显然更加精细。&lt;/p&gt;
&lt;h3 id=&#34;9-1-图像分割和实例分割&#34;&gt;9.1 图像分割和实例分割&lt;/h3&gt;
&lt;p&gt;计算机视觉领域还有2个与语义分割相似的重要问题，即&lt;strong&gt;图像分割&lt;/strong&gt;（image segmentation）和&lt;strong&gt;实例分割&lt;/strong&gt;（instance segmentation）。我们在这里将它们同语义分割简单区分一下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像分割将图像划分为若干组成区域，这类问题的方法通常利用图像中像素之间的相关性。它在训练时不需要有关图像像素的标签信息，在预测时也无法保证分割出的区域具有我们希望得到的语义。以图像 &lt;code&gt;catdog.jpg&lt;/code&gt; 作为输入，图像分割可能会将狗分为两个区域：一个覆盖以黑色为主的嘴和眼睛，另一个覆盖以黄色为主的其余部分身体。&lt;/li&gt;
&lt;li&gt;实例分割也叫同时检测并分割（simultaneous detection and segmentation），它研究如何识别图像中各个目标实例的像素级区域。与语义分割不同，实例分割不仅需要区分语义，还要&lt;strong&gt;区分不同的目标实例&lt;/strong&gt;。例如，如果图像中有两条狗，则实例分割需要区分像素属于的两条狗中的哪一条。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-2-Pascal-VOC2012-语义分割数据集&#34;&gt;9.2 Pascal VOC2012 语义分割数据集&lt;/h3&gt;
&lt;p&gt;最重要的语义分割数据集之一是 Pascal VOC2012，下面我们深入了解一下这个数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Dataset, DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.DATA_HUB[&lt;span class=&#34;string&#34;&gt;&amp;#x27;voc2012&amp;#x27;&lt;/span&gt;] = (d2l.DATA_URL + &lt;span class=&#34;string&#34;&gt;&amp;#x27;VOCtrainval_11-May-2012.tar&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;4e443f8a2eca6b1dac8a6c57641b67dd40621a49&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;voc_dir = d2l.download_extract(&lt;span class=&#34;string&#34;&gt;&amp;#x27;voc2012&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;VOCdevkit/VOC2012&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 提取出的数据集位于../data/VOCdevkit/VOC2012&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;进入路径 &lt;code&gt;../data/VOCdevkit/VOC2012&lt;/code&gt; 之后，我们可以看到数据集的不同组件。&lt;code&gt;ImageSets/Segmentation&lt;/code&gt; 路径包含用于训练和测试样本的文本文件，而 &lt;code&gt;JPEGImages&lt;/code&gt; 和 &lt;code&gt;SegmentationClass&lt;/code&gt; 路径分别存储着每个示例的输入图像和标签。此处的标签也采用图像格式，其尺寸和它所标注的输入图像的尺寸相同。此外，标签中颜色相同的像素属于同一个语义类别。下面将 &lt;code&gt;read_voc_images&lt;/code&gt; 函数定义为将所有输入的图像和标签读入内存：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;read_voc_images&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;voc_dir, is_train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;读取所有VOC图像并标注&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    txt_fname = os.path.join(voc_dir, &lt;span class=&#34;string&#34;&gt;&amp;#x27;ImageSets&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;Segmentation&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;train.txt&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; is_train &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;val.txt&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mode = torchvision.io.image.ImageReadMode.RGB&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(txt_fname, &lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        images = f.read().split()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    features, labels = [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, fname &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(images):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        features.append(torchvision.io.read_image(os.path.join(voc_dir, &lt;span class=&#34;string&#34;&gt;&amp;#x27;JPEGImages&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;fname&amp;#125;&lt;/span&gt;.jpg&amp;#x27;&lt;/span&gt;)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        labels.append(torchvision.io.read_image(os.path.join(voc_dir, &lt;span class=&#34;string&#34;&gt;&amp;#x27;SegmentationClass&amp;#x27;&lt;/span&gt; , &lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;fname&amp;#125;&lt;/span&gt;.png&amp;#x27;&lt;/span&gt;), mode))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; features, labels&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_features, train_labels = read_voc_images(voc_dir, &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_features))  &lt;span class=&#34;comment&#34;&gt;# 1464&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(train_features[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].shape, train_labels[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([3, 281, 500]) torch.Size([3, 281, 500])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下面我们绘制前5个输入图像及其标签。在标签图像中，白色和黑色分别表示边框和背景，而其他颜色则对应不同的类别：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;imgs = train_features[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;] + train_labels[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;imgs = [img.permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; img &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; imgs]  &lt;span class=&#34;comment&#34;&gt;# 将通道放到最后一维&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(imgs), imgs[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].shape)  &lt;span class=&#34;comment&#34;&gt;# 10 torch.Size([281, 500, 3])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.show_images(imgs, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来，我们列举 RGB 颜色值和类名：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;VOC_COLORMAP = [[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                [&lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;]]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;VOC_CLASSES = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;background&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;aeroplane&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;bicycle&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;bird&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;boat&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;bottle&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;bus&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;               &lt;span class=&#34;string&#34;&gt;&amp;#x27;car&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;cat&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;chair&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;cow&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;diningtable&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;dog&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;horse&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;motorbike&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;               &lt;span class=&#34;string&#34;&gt;&amp;#x27;person&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;potted plant&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;sheep&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;sofa&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;train&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;tv/monitor&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过上面定义的两个常量，我们可以方便地查找标签中每个像素的类索引。我们定义了 &lt;code&gt;voc_colormap2label&lt;/code&gt; 函数来构建从上述 RGB 颜色值到类别索引的映射，而 &lt;code&gt;voc_label_indices&lt;/code&gt; 函数将 RGB 值映射到在 Pascal VOC2012 数据集中的类别索引：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;voc_colormap2label&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;构建从RGB到VOC类别索引的映射&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    colormap2label = torch.zeros(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt; ** &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, dtype=torch.long)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, colormap &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(VOC_COLORMAP):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        colormap2label[(colormap[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] * &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt; + colormap[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]) * &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt; + colormap[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]] = i  &lt;span class=&#34;comment&#34;&gt;# 哈希映射&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; colormap2label&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;voc_label_indices&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;colormap, colormap2label&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;将VOC标签中的RGB值映射到它们的类别索引&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    colormap = colormap.permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;).numpy().astype(&lt;span class=&#34;string&#34;&gt;&amp;#x27;int32&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    idx = ((colormap[:, :, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] * &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt; + colormap[:, :, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]) * &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt; + colormap[:, :, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; colormap2label[idx]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;例如，在第一张样本图像中，飞机头部区域的类别索引为1，而背景索引为0：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;colormap2label = voc_colormap2label()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = voc_label_indices(train_labels[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], colormap2label)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(y[&lt;span class=&#34;number&#34;&gt;105&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;115&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;130&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;140&lt;/span&gt;], VOC_CLASSES[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]) aeroplane&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;之前的实验我们通过再缩放图像使其符合模型的输入形状。然而在语义分割中，这样做需要将预测的像素类别重新映射回原始尺寸的输入图像。这样的映射可能不够精确，尤其在不同语义的分割区域。为了避免这个问题，我们将图像&lt;strong&gt;裁剪为固定尺寸&lt;/strong&gt;，而不是再缩放。具体来说，我们使用图像增广中的随机裁剪，裁剪输入图像和标签的相同区域：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;voc_rand_crop&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;feature, label, height, width&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;随机裁剪特征和标签图像&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    rect = torchvision.transforms.RandomCrop.get_params(feature, (height, width))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    feature = torchvision.transforms.functional.crop(feature, *rect)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    label = torchvision.transforms.functional.crop(label, *rect)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; feature, label&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;imgs = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; _ &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs += voc_rand_crop(train_features[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], train_labels[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], &lt;span class=&#34;number&#34;&gt;200&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;300&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;imgs = [img.permute(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; img &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; imgs]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d2l.show_images(imgs[::&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;] + imgs[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;::&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们通过继承高级 API 提供的 &lt;code&gt;Dataset&lt;/code&gt; 类，自定义了一个语义分割数据集类 &lt;code&gt;VOCSegDataset&lt;/code&gt;。通过实现 &lt;code&gt;__getitem__&lt;/code&gt; 函数，我们可以任意访问数据集中索引为 &lt;code&gt;idx&lt;/code&gt; 的输入图像及其每个像素的类别索引。由于数据集中有些图像的尺寸可能小于随机裁剪所指定的输出尺寸，这些样本可以通过自定义的 &lt;code&gt;filter&lt;/code&gt; 函数移除掉。此外，我们还定义了 &lt;code&gt;normalize_image&lt;/code&gt; 函数，从而对输入图像的 RGB 三个通道的值分别做标准化：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;VOCSegDataset&lt;/span&gt;(&lt;span class=&#34;title class_ inherited__&#34;&gt;Dataset&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;一个用于加载VOC数据集的自定义数据集&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, is_train, crop_size, voc_dir&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.transform = torchvision.transforms.Normalize(mean=[&lt;span class=&#34;number&#34;&gt;0.485&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.456&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.406&lt;/span&gt;], std=[&lt;span class=&#34;number&#34;&gt;0.229&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.224&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.225&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.crop_size = crop_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        features, labels = read_voc_images(voc_dir, is_train=is_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.features = [self.normalize_image(feature) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; feature &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self.&lt;span class=&#34;built_in&#34;&gt;filter&lt;/span&gt;(features)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.labels = self.&lt;span class=&#34;built_in&#34;&gt;filter&lt;/span&gt;(labels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.colormap2label = voc_colormap2label()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;read &amp;#x27;&lt;/span&gt; + &lt;span class=&#34;built_in&#34;&gt;str&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(self.features)) + &lt;span class=&#34;string&#34;&gt;&amp;#x27; examples&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;normalize_image&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, img&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.transform(img.&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;() / &lt;span class=&#34;number&#34;&gt;255&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 过滤掉比裁切大小还小的图像&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;filter&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, imgs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; [img &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; img &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; imgs &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; (img.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] &amp;gt;= self.crop_size[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                        img.shape[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;] &amp;gt;= self.crop_size[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__getitem__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, idx&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        feature, label = voc_rand_crop(self.features[idx], self.labels[idx], *self.crop_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (feature, voc_label_indices(label, self.colormap2label))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__len__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(self.features)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;crop_size = (&lt;span class=&#34;number&#34;&gt;320&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;480&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;voc_train, voc_valid = VOCSegDataset(&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, crop_size, voc_dir), VOCSegDataset(&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, crop_size, voc_dir)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后，我们定义以下 &lt;code&gt;load_data_voc&lt;/code&gt; 函数来下载并读取 Pascal VOC2012 语义分割数据集。它返回训练集和测试集的数据迭代器：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;load_data_voc&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;加载VOC语义分割数据集&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_iter = DataLoader(voc_train, batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, drop_last=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    valid_iter = DataLoader(voc_valid, batch_size, drop_last=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; train_iter, valid_iter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size = &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, valid_iter = load_data_voc(batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; features, labels &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; train_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(features.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([64, 3, 320, 480])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(labels.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([64, 320, 480])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;break&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;10-转置卷积&#34;&gt;10. 转置卷积&lt;/h2&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/21165.html</guid>
            <title>动手学深度学习笔记(李沐)-现代卷积神经网络</title>
            <link>https://asanosaki.github.io/posts/21165.html</link>
            <category>AI</category>
            <pubDate>Fri, 03 Mar 2023 09:57:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;李沐动手学深度学习（PyTorch）课程学习笔记第六章：现代卷积神经网络。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-深度卷积神经网络（AlexNet）&#34;&gt;1. 深度卷积神经网络（AlexNet）&lt;/h2&gt;
&lt;p&gt;AlexNet 和 LeNet 的设计理念非常相似，但也存在显著差异：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AlexNet 比相对较小的 LeNet5 要深得多。AlexNet 由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。&lt;/li&gt;
&lt;li&gt;AlexNet 使用 ReLU 而不是 Sigmoid 作为其激活函数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，AlexNet 将 Sigmoid 激活函数改为更简单的 ReLU 激活函数。一方面，ReLU 激活函数的计算更简单，它不需要如 Sigmoid 激活函数那般复杂的求幂运算。另一方面，当使用不同的参数初始化方法时，ReLU 激活函数使训练模型更加容易。当 Sigmoid 激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。相反，ReLU 激活函数在正区间的梯度总是1。因此，如果模型参数没有正确初始化，Sigmoid 函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。&lt;/p&gt;
&lt;p&gt;尽管原文中 AlexNet 是在 ImageNet 上进行训练的，但本文在这里使用的是 Fashion-MNIST 数据集。因为即使在现代 GPU 上，训练 ImageNet 模型，同时使其收敛可能需要数小时或数天的时间。将 AlexNet 直接应用于 Fashion-MNIST 的一个问题是 Fashion-MNIST 图像的分辨率（28×28像素）低于 ImageNet 图像。为了解决这个问题，我们将它们增加到224×224像素（通常来讲这不是一个明智的做法，但在这里这样做是为了有效使用 AlexNet 架构）。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; util.functions &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_classifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 这里使用11*11的更大窗口来捕捉对象，同时步幅为4，以减少输出的高度和宽度，此外输出通道的数目远大于LeNet&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;96&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;11&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), nn.ReLU(),  &lt;span class=&#34;comment&#34;&gt;# (96, 54, 54)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# (96, 26, 26)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(&lt;span class=&#34;number&#34;&gt;96&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), nn.ReLU(),  &lt;span class=&#34;comment&#34;&gt;# (256, 26, 26)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# (256, 12, 12)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 使用三个连续的卷积层和较小的卷积窗口，除了最后的卷积层，输出通道的数量进一步增加&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;384&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), nn.ReLU(),  &lt;span class=&#34;comment&#34;&gt;# (384, 12, 12)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(&lt;span class=&#34;number&#34;&gt;384&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;384&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), nn.ReLU(),  &lt;span class=&#34;comment&#34;&gt;# (384, 12, 12)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(&lt;span class=&#34;number&#34;&gt;384&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), nn.ReLU(),  &lt;span class=&#34;comment&#34;&gt;# (256, 12, 12)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# (256, 5, 5)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Flatten(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 这里全连接层的输出数量是LeNet中的好几倍，因此使用Dropout层来减轻过拟合&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Linear(&lt;span class=&#34;number&#34;&gt;6400&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4096&lt;/span&gt;), nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Dropout(p=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Linear(&lt;span class=&#34;number&#34;&gt;4096&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4096&lt;/span&gt;), nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Dropout(p=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 最后是输出层，由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Linear(&lt;span class=&#34;number&#34;&gt;4096&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size = &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trans = transforms.Compose([transforms.Resize((&lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;)), transforms.ToTensor()])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mnist_train = torchvision.datasets.FashionMNIST(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mnist_test = torchvision.datasets.FashionMNIST(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter = data.DataLoader(mnist_train, batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_iter = data.DataLoader(mnist_test, batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr, num_epochs = &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_classifier(net, train_iter, test_iter, num_epochs, lr, device, &lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/AlexNet_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-使用块的网络（VGG）&#34;&gt;2. 使用块的网络（VGG）&lt;/h2&gt;
&lt;p&gt;虽然 AlexNet 证明深层神经网络卓有成效，但它没有提供一个通用的模板来指导后续的研究人员设计新的网络。&lt;/p&gt;
&lt;p&gt;经典卷积神经网络的基本组成部分是下面的这个序列：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;带填充以保持分辨率的卷积层。&lt;/li&gt;
&lt;li&gt;非线性激活函数，如 ReLU。&lt;/li&gt;
&lt;li&gt;汇聚层，如最大汇聚层。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而一个 VGG 块与之类似，由一系列卷积层组成，后面再加上用于空间下采样的最大汇聚层。&lt;/p&gt;
&lt;p&gt;VGG 使用&lt;strong&gt;可重复使用&lt;/strong&gt;的卷积块来构建深度卷积神经网络，不同的卷积块个数和超参数可以得到不同复杂度的变种。&lt;/p&gt;
&lt;p&gt;下面的代码中，我们定义了一个名为 &lt;code&gt;vgg_block&lt;/code&gt; 的函数来实现一个 VGG 块，该函数有三个参数，分别对应于卷积层的数量 &lt;code&gt;num_convs&lt;/code&gt;、输入通道的数量 &lt;code&gt;in_channels&lt;/code&gt; 和输出通道的数量 &lt;code&gt;out_channels&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;vgg_block&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;num_convs, in_channels, out_channels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    layers = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; _ &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_convs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        layers.append(nn.ReLU())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        in_channels = out_channels&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    layers.append(nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Sequential(*layers)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;原始 VGG 网络有5个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层。第一个模块有64个输出通道，每个后续模块将输出通道数量翻倍，直到达到512。由于该网络使用8个卷积层和3个全连接层，因此它通常被称为 VGG-11。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;vgg&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;conv_arch&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv_blks = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    in_channels = &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 卷积层部分&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; (num_convs, out_channels) &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; conv_arch:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        in_channels = out_channels&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        *conv_blks, nn.Flatten(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 全连接层部分&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.Linear(out_channels * &lt;span class=&#34;number&#34;&gt;7&lt;/span&gt; * &lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4096&lt;/span&gt;), nn.ReLU(), nn.Dropout(&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.Linear(&lt;span class=&#34;number&#34;&gt;4096&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4096&lt;/span&gt;), nn.ReLU(), nn.Dropout(&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.Linear(&lt;span class=&#34;number&#34;&gt;4096&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;conv_arch = ((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = vgg(conv_arch)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;由于 VGG-11 比 AlexNet 计算量更大，因此我们构建了一个通道数较少的网络，足够用于训练 Fashion-MNIST 数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conv_arch = ((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = vgg(conv_arch)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后我们读取数据集并进行训练，超参数设置：&lt;code&gt;lr, num_epochs = 0.02, 15&lt;/code&gt;，训练过程与第一节内容一样，因此不再放出代码。&lt;/p&gt;
&lt;p&gt;PS：如果显存不够可以减小 &lt;code&gt;batch_size&lt;/code&gt;，从128改为64或32。&lt;/p&gt;
&lt;h2 id=&#34;3-网络中的网络（NiN）&#34;&gt;3. 网络中的网络（NiN）&lt;/h2&gt;
&lt;p&gt;回想一下，卷积层的输入和输出由四维张量组成，张量的每个轴分别对应样本、通道、高度和宽度。另外，全连接层的输入和输出通常是分别对应于样本和特征的二维张量。NiN 的想法是&lt;strong&gt;在每个像素位置（针对每个高度和宽度）应用一个全连接层&lt;/strong&gt;。如果我们将权重连接到每个空间位置，我们可以将其视为1×1卷积层（如第五章第四节 PS 中所述），或作为在每个像素位置上独立作用的全连接层。从另一个角度看，即将空间维度中的每个像素视为单个样本，将通道维度视为不同特征（feature）。&lt;/p&gt;
&lt;p&gt;NiN 块以一个普通卷积层开始，后面是两个1×1的卷积层。这两个1×1卷积层充当带有 ReLU 激活函数的逐像素全连接层，对每个像素增加了非线性特性：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;nin_block&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;in_channels, out_channels, kernel_size, strides, padding&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.Conv2d(out_channels, out_channels, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.Conv2d(out_channels, out_channels, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), nn.ReLU())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;NiN 和 AlexNet 之间的一个显著区别是 NiN 完全取消了全连接层。相反，NiN 使用一个 NiN 块，其输出通道数等于标签类别的数量。最后放一个全局平均汇聚层（global average pooling layer），生成一个对数几率（logits）。NiN 设计的一个优点是，它显著减少了模型所需参数的数量。然而，在实践中，这种设计有时会增加训练模型的时间。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nin_block(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;96&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;11&lt;/span&gt;, strides=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.MaxPool2d(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nin_block(&lt;span class=&#34;number&#34;&gt;96&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, strides=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.MaxPool2d(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nin_block(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;384&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, strides=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.MaxPool2d(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Dropout(&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nin_block(&lt;span class=&#34;number&#34;&gt;384&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, strides=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# 标签类别数是10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.AdaptiveAvgPool2d((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)),  &lt;span class=&#34;comment&#34;&gt;# 将四维的输出转成二维的输出，其形状为(批量大小,10)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Flatten())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后我们读取数据集并进行训练，超参数设置：&lt;code&gt;lr, num_epochs = 0.1, 15&lt;/code&gt;，训练过程与第一节内容一样，因此不再放出代码。&lt;/p&gt;
&lt;h2 id=&#34;4-含并行连结的网络（GoogLeNet）&#34;&gt;4. 含并行连结的网络（GoogLeNet）&lt;/h2&gt;
&lt;p&gt;在 GoogLeNet 中，基本的卷积块被称为 Inception 块（Inception block）。Inception 块由四条并行路径组成。前三条路径使用窗口大小为1×1、3×3和5×5的卷积层，从不同空间大小中提取信息。中间的两条路径在输入上执行1×1卷积，以减少通道数，从而降低模型的复杂性。第四条路径使用3×3最大汇聚层，然后使用1×1卷积层来改变通道数。这四条路径都使用合适的填充来使&lt;strong&gt;输入与输出的高和宽一致&lt;/strong&gt;，最后我们将每条线路的输出在&lt;strong&gt;通道维度&lt;/strong&gt;上连结，并构成 Inception 块的输出。在 Inception 块中，通常调整的超参数是每层输出通道数。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Inception&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# c1-c4是每条路径的输出通道数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_channels, c1, c2, c3, c4, **kwargs&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Inception, self).__init__(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 线路1，单1x1卷积层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 线路2，1x1卷积层后接3x3卷积层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.p2_1 = nn.Conv2d(in_channels, c2[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.p2_2 = nn.Conv2d(c2[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], c2[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 线路3，1x1卷积层后接5x5卷积层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.p3_1 = nn.Conv2d(in_channels, c3[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.p3_2 = nn.Conv2d(c3[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], c3[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 线路4，3x3最大汇聚层后接1x1卷积层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.p4_1 = nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p1 = F.relu(self.p1_1(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        p4 = F.relu(self.p4_2(self.p4_1(x)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 在通道维度（第一维）上连结输出&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.cat((p1, p2, p3, p4), dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;GoogLeNet 一共使用9个 Inception 块和全局平均汇聚层的堆叠来生成其估计值。Inception 块之间的最大汇聚层可降低维度。第一个模块类似于 AlexNet 和 LeNet，Inception 块的组合从 VGG 继承，全局平均汇聚层避免了在最后使用全连接层。&lt;/p&gt;
&lt;p&gt;现在，我们逐一实现 GoogLeNet 的每个模块。第一个模块使用64个通道、7×7卷积层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;b1 = nn.Sequential(nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;第二个模块使用两个卷积层：第一个卷积层是64个通道、1×1卷积层；第二个卷积层使用将通道数量增加三倍的3×3卷积层。这对应于 Inception 块中的第二条路径：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;b2 = nn.Sequential(nn.Conv2d(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.Conv2d(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;第三个模块串联两个完整的 Inception 块。第一个 Inception 块的输出通道数为 &lt;code&gt;64 + 128 + 32 + 32 = 256&lt;/code&gt;，四个路径之间的输出通道数量比为 &lt;code&gt;2 : 4 : 1 : 1&lt;/code&gt;，第二个和第三个路径首先将输入通道的数量分别减少到96和16，然后连接第二个卷积层。第二个 Inception 块的输出通道数增加到 &lt;code&gt;128 + 192 + 96 + 64 = 480&lt;/code&gt;，四个路径之间的输出通道数量比为 &lt;code&gt;4 : 6 : 3 : 2&lt;/code&gt;，第二条和第三条路径首先将输入通道的数量分别减少到128和32：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;b3 = nn.Sequential(Inception(&lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;96&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   Inception(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;96&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;第四模块更加复杂，它串联了5个 Inception 块，其输出通道数分别是 &lt;code&gt;192 + 208 + 48 + 64 = 512&lt;/code&gt;、&lt;code&gt;160 + 224 + 64 + 64 = 512&lt;/code&gt;、&lt;code&gt;128 + 256 + 64 + 64 = 512&lt;/code&gt;、&lt;code&gt;112 + 288 + 64 + 64 = 528&lt;/code&gt; 和 &lt;code&gt;256 + 320 + 128 + 128 = 832&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;b4 = nn.Sequential(Inception(&lt;span class=&#34;number&#34;&gt;480&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;96&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;208&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;48&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   Inception(&lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;160&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;112&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;224&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;24&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   Inception(&lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;24&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   Inception(&lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;112&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;144&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;288&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   Inception(&lt;span class=&#34;number&#34;&gt;528&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;160&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;320&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;第五模块包含输出通道数为 &lt;code&gt;256 + 320 + 128 + 128 = 832&lt;/code&gt; 和 &lt;code&gt;384 + 384 + 128 + 128 = 1024&lt;/code&gt; 的两个 Inception 块。需要注意的是，第五模块的后面紧跟输出层，该模块同 NiN 一样使用全局平均汇聚层，将每个通道的高和宽变成1。最后我们将输出变成二维数组，再接上一个输出个数为标签类别数的全连接层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;b5 = nn.Sequential(Inception(&lt;span class=&#34;number&#34;&gt;832&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;160&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;320&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   Inception(&lt;span class=&#34;number&#34;&gt;832&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;384&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;192&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;384&lt;/span&gt;), (&lt;span class=&#34;number&#34;&gt;48&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.AdaptiveAvgPool2d((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.Flatten())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(&lt;span class=&#34;number&#34;&gt;1024&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后我们读取数据集并进行训练，超参数设置：&lt;code&gt;lr, num_epochs = 0.1, 15&lt;/code&gt;，训练过程与第一节内容一样，因此不再放出代码。&lt;/p&gt;
&lt;h2 id=&#34;5-批量规范化（BN）&#34;&gt;5. 批量规范化（BN）&lt;/h2&gt;
&lt;p&gt;批量规范化（Batch Normalization）是一种流行且有效的技术，可持续加速深层网络的收敛速度。&lt;/p&gt;
&lt;p&gt;使用真实数据时，我们的第一步是标准化输入特征，使其平均值为0，方差为1。直观地说，这种标准化可以很好地与我们的优化器配合使用，因为它可以将参数的量级进行统一。&lt;/p&gt;
&lt;p&gt;第二，对于典型的多层感知机或卷积神经网络。当我们训练时，中间层中的变量（例如，多层感知机中的仿射变换输出）可能具有更广的变化范围：不论是沿着从输入到输出的层，跨同一层中的单元，或是随着时间的推移，模型参数随着训练更新的变幻莫测。批量规范化的发明者非正式地假设，这些变量分布中的这种偏移可能会阻碍网络的收敛。直观地说，我们可能会猜想，如果一个层的可变值是另一层的100倍，这可能需要对学习率进行补偿调整。&lt;/p&gt;
&lt;p&gt;第三，更深层的网络很复杂，容易过拟合。这意味着正则化变得更加重要。&lt;/p&gt;
&lt;p&gt;批量规范化应用于单个可选层（也可以应用到所有层），其原理如下：在每次训练迭代中，我们首先规范化输入，即通过&lt;strong&gt;减去其均值并除以其标准差&lt;/strong&gt;，其中两者均基于当前小批量处理。接下来，我们应用&lt;strong&gt;比例系数和比例偏移&lt;/strong&gt;。正是由于这个基于批量统计的标准化，才有了批量规范化的名称。&lt;/p&gt;
&lt;p&gt;请注意，如果我们尝试使用大小为1的小批量应用批量规范化，我们将无法学到任何东西。这是因为在减去均值之后，每个隐藏单元将为0。所以，只有使用足够大的小批量，批量规范化这种方法才是有效且稳定的。请注意，在应用批量规范化时，批量大小的选择可能比没有批量规范化时更重要。&lt;/p&gt;
&lt;p&gt;通常，我们将批量规范化层置于全连接层中的仿射变换和激活函数之间。同样，对于卷积层，我们可以在卷积层之后和非线性激活函数之前应用批量规范化。&lt;/p&gt;
&lt;p&gt;下面，我们从头开始实现一个具有张量的批量规范化层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;batch_norm&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, gamma, beta, moving_mean, moving_var, eps, momentum&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 通过is_grad_enabled来判断当前模式是训练模式还是预测模式&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; torch.is_grad_enabled():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 假设只考虑全连接和二维卷积&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(X.shape) &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(X.shape) == &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 使用全连接层的情况，计算特征维上的均值和方差&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            mean = X.mean(dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            var = ((X - mean) ** &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;).mean(dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 这里我们需要保持X的形状以便后面可以做广播运算&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            mean = X.mean(dim=(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), keepdim=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            var = ((X - mean) ** &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;).mean(dim=(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), keepdim=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 训练模式下，用当前的均值和方差做标准化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X_hat = (X - mean) / torch.sqrt(var + eps)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 更新移动平均的均值和方差&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        moving_mean = momentum * moving_mean + (&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt; - momentum) * mean&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        moving_var = momentum * moving_var + (&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt; - momentum) * var&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Y = gamma * X_hat + beta  &lt;span class=&#34;comment&#34;&gt;# 缩放和移位&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; Y, moving_mean.data, moving_var.data&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们现在可以创建一个正确的 BatchNorm 层。这个层将保持适当的参数：拉伸 &lt;code&gt;gamma&lt;/code&gt; 和偏移 &lt;code&gt;beta&lt;/code&gt;，这两个参数将在训练过程中更新。此外，我们的层将保存均值和方差的移动平均值，以便在模型预测期间随后使用。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;BatchNorm&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# num_features：全连接层的输出数量或卷积层的输出通道数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# num_dims：2表示全连接层，4表示卷积层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, num_features, num_dims&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; num_dims == &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            shape = (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, num_features)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            shape = (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, num_features, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.gamma = nn.Parameter(torch.ones(shape))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.beta = nn.Parameter(torch.zeros(shape))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 非模型参数的变量初始化为0和1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.moving_mean = torch.zeros(shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.moving_var = torch.ones(shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 如果X不在内存上，将moving_mean和moving_var，复制到X所在显存上&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; self.moving_mean.device != X.device:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.moving_mean = self.moving_mean.to(X.device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.moving_var = self.moving_var.to(X.device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 保存更新过的moving_mean和moving_var&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y, self.moving_mean, self.moving_var = batch_norm(X, self.gamma,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.beta, self.moving_mean, self.moving_var, eps=&lt;span class=&#34;number&#34;&gt;1e-5&lt;/span&gt;, momentum=&lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; Y&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;为了更好理解如何应用 BatchNorm，下面我们将其应用于 LeNet 模型：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), BatchNorm(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, num_dims=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;), nn.Sigmoid(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.AvgPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;), BatchNorm(&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, num_dims=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;), nn.Sigmoid(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.AvgPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), nn.Flatten(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Linear(&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt; * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt; * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;), BatchNorm(&lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;, num_dims=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), nn.Sigmoid(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Linear(&lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;), BatchNorm(&lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;, num_dims=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), nn.Sigmoid(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Linear(&lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后我们读取数据集并进行训练，超参数设置：&lt;code&gt;lr, num_epochs = 1, 15&lt;/code&gt;，由于网络模型类似 LeNet，因此无需对输入图像进行 Resize 操作，训练过程与第一节内容一样，因此不再放出代码。&lt;/p&gt;
&lt;h2 id=&#34;6-残差网络（ResNet）&#34;&gt;6. 残差网络（ResNet）&lt;/h2&gt;
&lt;p&gt;只有当较复杂的函数类包含较小的函数类时，我们才能确保提高它们的性能。对于深度神经网络，如果我们能将新添加的层训练成恒等映射（identity function）：&lt;code&gt;f(x) = x&lt;/code&gt;，新模型和原模型将同样有效。同时，由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差。&lt;/p&gt;
&lt;p&gt;残差网络的核心思想是：每个附加层都应该更容易地&lt;strong&gt;包含原始函数&lt;/strong&gt;作为其元素之一。&lt;/p&gt;
&lt;p&gt;ResNet 沿用了 VGG 完整的卷积层设计。残差块里首先有2个有相同输出通道数的卷积层。每个卷积层后接一个批量规范化层和 ReLU 激活函数。然后我们通过跨层数据通路，跳过这2个卷积运算，将输入直接加在最后的 ReLU 激活函数前。这样的设计要求2个卷积层的输出与输入形状一样，从而使它们可以相加。如果想改变通道数，就需要引入一个额外的1×1卷积层来将输入变换成需要的形状后再做相加运算。残差块的实现如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Residual&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, input_channels, num_channels, use_1x1conv=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, strides=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=strides)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; use_1x1conv:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=strides)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self.conv3 = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bn1 = nn.BatchNorm2d(num_channels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bn2 = nn.BatchNorm2d(num_channels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y = F.relu(self.bn1(self.conv1(X)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y = self.bn2(self.conv2(Y))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; self.conv3:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            X = self.conv3(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y += X&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; F.relu(Y)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;此代码生成两种类型的网络：一种是当 &lt;code&gt;use_1x1conv = False&lt;/code&gt; 时，应用 ReLU 非线性函数之前，将输入添加到输出。另一种是当 &lt;code&gt;use_1x1conv = True&lt;/code&gt; 时，添加通过1×1卷积调整通道和分辨率。&lt;/p&gt;
&lt;p&gt;ResNet 的前两层跟之前介绍的 GoogLeNet 中的一样：在输出通道数为64、步幅为2的7×7卷积层后，接步幅为2的3×3最大汇聚层。不同之处在于 ResNet 每个卷积层后增加了批量规范化层。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;b1 = nn.Sequential(nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;), nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;GoogLeNet 在后面接了4个由 Inception 块组成的模块。ResNet 则使用4个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块。第一个模块的通道数同输入通道数一致。由于之前已经使用了步幅为2的最大汇聚层，所以无须减小高和宽。之后的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半。&lt;/p&gt;
&lt;p&gt;下面我们来实现这个模块。注意，我们对第一个模块做了特别处理：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;resnet_block&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;input_channels, num_channels, num_residuals, first_block=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    blk = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_residuals):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; i == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; first_block:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            blk.append(Residual(input_channels, num_channels, use_1x1conv=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, strides=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            blk.append(Residual(num_channels, num_channels))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; blk&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接着在 ResNet 加入所有残差块，这里每个模块使用2个残差块：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;b2 = nn.Sequential(*resnet_block(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, first_block=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b3 = nn.Sequential(*resnet_block(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b4 = nn.Sequential(*resnet_block(&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b5 = nn.Sequential(*resnet_block(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后，与 GoogLeNet 一样，在 ResNet 中加入全局平均汇聚层，以及全连接层输出：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(b1, b2, b3, b4, b5,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.AdaptiveAvgPool2d((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.Flatten(), nn.Linear(&lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;每个模块有4个卷积层（不包括恒等映射的卷积层）。加上第一个7×7卷积层和最后一个全连接层，共有18层。因此，这种模型通常被称为 ResNet-18。通过配置不同的通道数和模块里的残差块数可以得到不同的 ResNet 模型，例如更深的含152层的 ResNet-152。&lt;/p&gt;
&lt;p&gt;最后我们读取数据集并进行训练，超参数设置：&lt;code&gt;lr, num_epochs = 0.02, 15&lt;/code&gt;，由于 ResNet 性能很强，对于 FashionMNIST 数据集很容易就过拟合了，因此可以将输入图像 Resize 为 &lt;code&gt;(96, 96)&lt;/code&gt;，训练过程与第一节内容一样，因此不再放出代码。&lt;/p&gt;
&lt;p&gt;ResNet 其它版本的模型结构可以参考：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/54289848&#34;&gt;ResNet 及其变种的结构梳理、有效性分析与代码解读&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/085f4c8256f1&#34;&gt;ResNet18、50网络结构以及 PyTorch 实现代码&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/New_WR/article/details/121777644&#34;&gt;ResNet50网络结构搭建（PyTorch）&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;7-稠密连接网络（DenseNet）&#34;&gt;7. 稠密连接网络（DenseNet）&lt;/h2&gt;
&lt;p&gt;ResNet 和 DenseNet 的关键区别在于，DenseNet 输出是连接（用 &lt;code&gt;[.]&lt;/code&gt; 表示）而不是如 ResNet 的简单相加。&lt;/p&gt;
&lt;p&gt;稠密网络主要由2部分构成：稠密块（dense block）和过渡层（transition layer）。前者定义如何连接输入和输出，而后者则控制通道数量，使其不会太复杂。&lt;/p&gt;
&lt;p&gt;DenseNet 使用了 ResNet 改良版的“批量规范化、激活和卷积”架构。我们首先实现一下这个架构：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;conv_block&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;input_channels, num_channels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.BatchNorm2d(input_channels), nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.Conv2d(input_channels, num_channels, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;一个稠密块由多个卷积块组成，每个卷积块使用相同数量的输出通道。然而，在前向传播中，我们将每个卷积块的输入和输出在通道维上连结：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;DenseBlock&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, num_convs, input_channels, num_channels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(DenseBlock, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        layer = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_convs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            layer.append(conv_block(num_channels * i + input_channels, num_channels))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.net = nn.Sequential(*layer)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; blk &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self.net:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            Y = blk(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 连接通道维度上每个块的输入和输出&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            X = torch.cat((X, Y), dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;例如我们构建一个 &lt;code&gt;DenseBlock(2, 3, 10)&lt;/code&gt;，那么两层卷积层分别为 &lt;code&gt;conv_block(3, 10)&lt;/code&gt;、&lt;code&gt;conv_block(13, 10)&lt;/code&gt;。第一层卷积输出的通道维是10，与输入 &lt;code&gt;X&lt;/code&gt; 在通道维上连结后通道维是13，因此第二层卷积输入的通道维是13，第二层卷积输出的通道维是10，与输入 &lt;code&gt;X&lt;/code&gt; 在通道维上连结后通道维是23：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;blk = DenseBlock(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.randn(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = blk(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(Y.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([4, 23, 8, 8])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;由于每个稠密块都会带来通道数的增加，使用过多则会过于复杂化模型。而过渡层可以用来控制模型复杂度。它通过1×1卷积层来&lt;strong&gt;减小通道数&lt;/strong&gt;，并使用步幅为2的平均汇聚层减半高和宽，从而进一步降低模型复杂度：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;transition_block&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;input_channels, num_channels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.BatchNorm2d(input_channels), nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.Conv2d(input_channels, num_channels, kernel_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.AvgPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;对上一个例子中稠密块的输出使用通道数为10的过渡层。此时输出的通道数减为10，高和宽均减半：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;blk = transition_block(&lt;span class=&#34;number&#34;&gt;23&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(blk(Y).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([4, 10, 4, 4])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们来构造 DenseNet 模型。DenseNet 首先使用同 ResNet 一样的单卷积层和最大汇聚层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;b1 = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;), nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来，类似于 ResNet 使用的4个残差块，DenseNet 使用的是4个稠密块。与 ResNet 类似，我们可以设置每个稠密块使用多少个卷积层。这里我们设成4，从而与之前的 ResNet-18 保持一致。稠密块里的卷积层通道数（即增长率）设为32，所以每个稠密块将增加128个通道。&lt;/p&gt;
&lt;p&gt;在每个模块之间，ResNet 通过步幅为2的残差块减小高和宽，DenseNet 则使用过渡层来减半高和宽，并减半通道数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# num_channels为当前的通道数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_channels, growth_rate = &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_convs_in_dense_blocks = [&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;blks = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, num_convs &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(num_convs_in_dense_blocks):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    blks.append(DenseBlock(num_convs, num_channels, growth_rate))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 上一个稠密块的输出通道数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_channels += num_convs * growth_rate&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 在稠密块之间添加一个转换层，使通道数量减半&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; i != &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(num_convs_in_dense_blocks) - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        blks.append(transition_block(num_channels, num_channels // &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        num_channels = num_channels // &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;与 ResNet 类似，最后接上全局汇聚层和全连接层来输出结果：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    b1, *blks,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.BatchNorm2d(num_channels), nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.AdaptiveAvgPool2d((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Flatten(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Linear(num_channels, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后我们读取数据集并进行训练，超参数设置：&lt;code&gt;lr, num_epochs = 0.1, 15&lt;/code&gt;，将输入图像 Resize 为 &lt;code&gt;(96, 96)&lt;/code&gt;，训练过程与第一节内容一样，因此不再放出代码。&lt;/p&gt;
&lt;p&gt;下一章：&lt;a href=&#34;/posts/24840.html&#34;&gt;计算机视觉&lt;/a&gt;。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/25122.html</guid>
            <title>动手学深度学习笔记(李沐)-卷积神经网络</title>
            <link>https://asanosaki.github.io/posts/25122.html</link>
            <category>AI</category>
            <pubDate>Wed, 01 Mar 2023 09:20:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;李沐动手学深度学习（PyTorch）课程学习笔记第五章：卷积神经网络。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-从全连接层到卷积&#34;&gt;1. 从全连接层到卷积&lt;/h2&gt;
&lt;p&gt;假设我们有一个足够充分的照片数据集，数据集中是拥有标注的照片，每张照片具有百万级像素，这意味着网络的每次输入都有一百万个维度。即使将隐藏层维度降低到1000，这个全连接层也将有十亿个参数。&lt;/p&gt;
&lt;p&gt;假设我们想从一张图片中找到某个物体。合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关。卷积神经网络正是将&lt;strong&gt;空间不变性&lt;/strong&gt;（spatial invariance）的这一概念系统化，从而基于这个模型使用较少的参数来学习有用的表示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平移不变性（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。&lt;/li&gt;
&lt;li&gt;局部性（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-图像卷积&#34;&gt;2. 图像卷积&lt;/h2&gt;
&lt;p&gt;严格来说，卷积层是个错误的叫法，因为它所表达的运算其实是&lt;strong&gt;互相关运算&lt;/strong&gt;（cross-correlation），而不是卷积运算。在卷积层中，输入张量和核张量通过互相关运算产生输出张量。&lt;/p&gt;
&lt;p&gt;在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。当卷积窗口滑动到新一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的标量值，由此我们得出了这一位置的输出张量值。&lt;/p&gt;
&lt;p&gt;我们可以自己实现如上过程：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;corr2d&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, K&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;计算二维互相关运算&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    h, w = K.shape&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Y = torch.zeros((X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] - h + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, X.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] - w + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(Y.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; j &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(Y.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            Y[i, j] = (X[i:i + h, j:j + w] * K).&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; Y&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.tensor([[&lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;6.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;7.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8.0&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;K = torch.tensor([[&lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(corr2d(X, K))  &lt;span class=&#34;comment&#34;&gt;# tensor([[19., 25.], [37., 43.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。所以，卷积层中的两个被训练的参数是卷积核权重和标量偏置。&lt;/p&gt;
&lt;p&gt;我们可以基于上面定义的 &lt;code&gt;corr2d&lt;/code&gt; 函数实现二维卷积层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Conv2D&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, kernel_size&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.weight = nn.Parameter(torch.rand(kernel_size))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bias = nn.Parameter(torch.zeros(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; corr2d(x, self.weight) + self.bias&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在来看一下卷积层的一个简单应用：通过找到像素变化的位置，来检测图像中不同颜色的边缘。我们假设0为黑色像素，1为白色像素：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = torch.ones((&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;] = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;X&lt;/code&gt; 的内容如下：&lt;/p&gt;
&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[1., 1., 0., 0., 0., 0., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1., 1., 0., 0., 0., 0., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1., 1., 0., 0., 0., 0., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1., 1., 0., 0., 0., 0., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1., 1., 0., 0., 0., 0., 1., 1.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [1., 1., 0., 0., 0., 0., 1., 1.]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来，我们构造一个高度为1、宽度为2的卷积核K。当进行互相关运算时，如果水平相邻的两元素相同，则输出为零，否则输出为非零：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;K = torch.tensor([[&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = corr2d(X, K)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;Y&lt;/code&gt; 的内容如下：&lt;/p&gt;
&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在我们使用 PyTorch 的卷积层尝试通过正确结果 &lt;code&gt;Y&lt;/code&gt; 是否能学习出我们之前自己构造出的卷积核参数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 构造一个二维卷积层，它具有1个输入通道和1个输出通道，卷积核形状为(1, 2)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;conv2d = nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, kernel_size=(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), bias=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 这个二维卷积层使用四维输入和输出格式(批量大小, 通道, 高度, 宽度)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 在本例中批量大小和通道数都为1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = X.reshape((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = Y.reshape((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr = &lt;span class=&#34;number&#34;&gt;3e-2&lt;/span&gt;  &lt;span class=&#34;comment&#34;&gt;# 学习率&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Y_hat = conv2d(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss = (Y_hat - Y) ** &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;  &lt;span class=&#34;comment&#34;&gt;# 均方误差&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv2d.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 迭代卷积核，手动实现梯度下降&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv2d.weight.data[:] -= lr * conv2d.weight.grad&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; (i + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) % &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;epoch &lt;span class=&#34;subst&#34;&gt;&amp;#123;i + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&amp;#125;&lt;/span&gt;, loss &lt;span class=&#34;subst&#34;&gt;&amp;#123;loss.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;():&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(conv2d.weight.data.reshape((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)))  &lt;span class=&#34;comment&#34;&gt;# tensor([[ 0.9756, -1.0059]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-填充和步幅&#34;&gt;3. 填充和步幅&lt;/h2&gt;
&lt;p&gt;在应用多层卷积时，我们常常丢失边缘像素。由于我们通常使用小卷积核，因此对于任何单个卷积，我们可能只会丢失几个像素。但随着我们应用许多连续卷积层，累积丢失的像素数就多了。解决这个问题的简单方法即为&lt;strong&gt;填充&lt;/strong&gt;（padding）：在输入图像的边界填充元素（通常填充元素是0）。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;conv2d = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.rand(size=(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(conv2d(X).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 1, 8, 8])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在计算互相关时，卷积窗口从输入张量的左上角开始，向下、向右滑动。在前面的例子中，我们默认每次滑动一个元素。但是，有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。我们将每次滑动元素的数量称为&lt;strong&gt;步幅&lt;/strong&gt;（stride）。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conv2d = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(conv2d(X).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 1, 4, 4])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;conv2d = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, kernel_size=(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;), padding=(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), stride=(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(conv2d(X).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([1, 1, 2, 2])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;4-多输入多输出通道&#34;&gt;4. 多输入多输出通道&lt;/h2&gt;
&lt;p&gt;当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相关运算。&lt;/p&gt;
&lt;p&gt;为了加深理解，我们实现一下多输入通道互相关运算。简而言之，我们所做的就是对每个通道执行互相关操作，然后将结果相加：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;corr2d_multi_in&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, K&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(d2l.corr2d(x, k) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; x, k &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(X, K))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.tensor([[[&lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;6.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;7.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8.0&lt;/span&gt;]],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                  [[&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;4.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;6.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;7.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;9.0&lt;/span&gt;]]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;K = torch.tensor([[[&lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;]], [[&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4.0&lt;/span&gt;]]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(corr2d_multi_in(X, K))  &lt;span class=&#34;comment&#34;&gt;# tensor([[ 56.,  72.], [104., 120.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;到目前为止，不论有多少输入通道，我们还只有一个输出通道。在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。直观地说，我们可以&lt;strong&gt;将每个通道看作对不同特征的响应&lt;/strong&gt;。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。因此，多输出通道并不仅是学习多个单通道的检测器。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;corr2d_multi_in_out&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, K&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算，最后将所有结果都叠加在一起&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.stack([corr2d_multi_in(X, k) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; k &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; K], &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 通过将核张量K与K+1（K中每个元素加1）和K+2连接起来，构造了一个具有3个输出通道的卷积核&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;K = torch.stack((K, K + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, K + &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(K.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([3, 2, 2, 2])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(corr2d_multi_in_out(X, K))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[ 56.,  72.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [104., 120.]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[ 76., 100.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [148., 172.]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[ 96., 128.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [192., 224.]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;PS：1*1卷积层通常用于调整网络层的通道数量和控制模型复杂性，其失去了卷积层的特有能力：在高度和宽度维度上，识别相邻元素间相互作用的能力。&lt;/p&gt;
&lt;h2 id=&#34;5-汇聚层（池化层）&#34;&gt;5. 汇聚层（池化层）&lt;/h2&gt;
&lt;p&gt;汇聚层（pooling layer）具有双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性。&lt;/p&gt;
&lt;p&gt;与卷积层类似，汇聚层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动（从左至右、从上至下），为固定形状窗口（有时称为汇聚窗口）遍历的每个位置计算一个输出。然而，不同于卷积层中的输入与卷积核之间的互相关计算，汇聚层&lt;strong&gt;不包含参数&lt;/strong&gt;。相反，池运算是确定性的，我们通常计算汇聚窗口中所有元素的&lt;strong&gt;最大值或平均值&lt;/strong&gt;。这些操作分别称为最大汇聚层（maximum pooling）和平均汇聚层（average pooling）。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;pool2d&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, pool_size, mode=&lt;span class=&#34;string&#34;&gt;&amp;#x27;max&amp;#x27;&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    p_h, p_w = pool_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Y = torch.zeros((X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] - p_h + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, X.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] - p_w + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(Y.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; j &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(Y.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; mode == &lt;span class=&#34;string&#34;&gt;&amp;#x27;max&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                Y[i, j] = X[i:i + p_h, j:j + p_w].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; mode == &lt;span class=&#34;string&#34;&gt;&amp;#x27;avg&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                Y[i, j] = X[i:i + p_h, j:j + p_w].mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; Y&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.tensor([[&lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5.0&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;6.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;7.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8.0&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pool2d(X, (&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)))  &lt;span class=&#34;comment&#34;&gt;# tensor([[4., 5.], [7., 8.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;与卷积层一样，汇聚层也可以改变输出形状。和以前一样，我们可以通过填充和步幅以获得所需的输出形状。下面，我们用深度学习框架中内置的二维最大汇聚层，来演示汇聚层中填充和步幅的使用。&lt;/p&gt;
&lt;p&gt;默认情况下，深度学习框架中的&lt;strong&gt;步幅与汇聚窗口的大小相同&lt;/strong&gt;。因此，如果我们使用形状为 &lt;code&gt;(3, 3)&lt;/code&gt; 的汇聚窗口，那么默认情况下，我们得到的步幅形状为 &lt;code&gt;(3, 3)&lt;/code&gt;。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = torch.arange(&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, dtype=torch.float32).reshape((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pool2d = nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pool2d(X))  &lt;span class=&#34;comment&#34;&gt;# tensor([[[[10.]]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pool2d = nn.MaxPool2d(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pool2d(X))  &lt;span class=&#34;comment&#34;&gt;# tensor([[[[ 5.,  7.], [13., 15.]]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在处理多通道输入数据时，汇聚层&lt;strong&gt;在每个输入通道上单独运算&lt;/strong&gt;，而不是像卷积层一样在通道上对输入进行汇总。这意味着汇聚层的输出通道数与输入通道数相同。下面，我们将在通道维度上连结张量 &lt;code&gt;X&lt;/code&gt; 和 &lt;code&gt;X + 1&lt;/code&gt;，以构建具有2个通道的输入：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = torch.cat((X, X + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(pool2d(X))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[[ 5.,  7.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [13., 15.]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [[ 6.,  8.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [14., 16.]]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;6-LeNet&#34;&gt;6. LeNet&lt;/h2&gt;
&lt;p&gt;本节将介绍 LeNet，它是最早发布的卷积神经网络之一。总体来看，LeNet（LeNet-5）由两个部分组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;卷积编码器：由两个卷积层组成。&lt;/li&gt;
&lt;li&gt;全连接层密集块：由三个全连接层组成。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每个卷积块中的基本单元是一个卷积层、一个 Sigmoid 激活函数和平均汇聚层。请注意，虽然 ReLU 和最大汇聚层更有效，但它们在20世纪90年代还没有出现。每个卷积层使用5×5卷积核和一个 Sigmoid 激活函数。这些层将输入映射到多个二维特征输出，通常同时增加通道的数量。第一卷积层有6个输出通道，而第二个卷积层有16个输出通道。每个2×2池化操作（步幅2）通过空间下采样将维数减少4倍。卷积的输出形状由批量大小、通道数、高度、宽度决定。&lt;/p&gt;
&lt;p&gt;虽然卷积神经网络的参数较少，但与深度的多层感知机相比，它们的计算成本仍然很高，因为每个参数都参与更多的乘法。通过使用 GPU，可以用它加快训练。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; util.functions &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_classifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;), nn.Sigmoid(),  &lt;span class=&#34;comment&#34;&gt;# (6, 28, 28)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.AvgPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# (6, 14, 14)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;), nn.Sigmoid(),  &lt;span class=&#34;comment&#34;&gt;# (16, 10, 10)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.AvgPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# (16, 5, 5)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Flatten(),  &lt;span class=&#34;comment&#34;&gt;# (16 * 5 * 5,)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Linear(&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt; * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt; * &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;), nn.Sigmoid(),  &lt;span class=&#34;comment&#34;&gt;# (120,)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Linear(&lt;span class=&#34;number&#34;&gt;120&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;), nn.Sigmoid(),  &lt;span class=&#34;comment&#34;&gt;# (84,)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Linear(&lt;span class=&#34;number&#34;&gt;84&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# (10,)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size = &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trans = transforms.ToTensor()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mnist_train = torchvision.datasets.MNIST(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mnist_test = torchvision.datasets.MNIST(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter = data.DataLoader(mnist_train, batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_iter = data.DataLoader(mnist_test, batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr, num_epochs = &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;30&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_classifier(net, train_iter, test_iter, num_epochs, lr, device, &lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/LeNet_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下一章：&lt;a href=&#34;/posts/21165.html&#34;&gt;现代卷积神经网络&lt;/a&gt;。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/23526.html</guid>
            <title>动手学深度学习笔记(李沐)-PyTorch神经网络基础</title>
            <link>https://asanosaki.github.io/posts/23526.html</link>
            <category>AI</category>
            <pubDate>Tue, 28 Feb 2023 10:34:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;李沐动手学深度学习（PyTorch）课程学习笔记第四章：PyTorch 神经网络基础。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-层和块&#34;&gt;1. 层和块&lt;/h2&gt;
&lt;p&gt;在构造自定义块之前，我们先回顾一下多层感知机（第三章第二节）的代码，下面的代码生成一个网络，其中包含一个具有256个单元和 ReLU 激活函数的全连接隐藏层，然后是一个具有10个隐藏单元且不带激活函数的全连接输出层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Linear(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;), nn.ReLU(), nn.Linear(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.rand(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net(X).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 10])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在这个例子中，我们通过实例化 &lt;code&gt;nn.Sequential&lt;/code&gt; 来构建我们的模型，层的执行顺序是作为参数传递的。简而言之，&lt;code&gt;nn.Sequential&lt;/code&gt; 定义了一种特殊的 &lt;code&gt;Module&lt;/code&gt;，即在 PyTorch 中表示一个块的类，它维护了一个由 &lt;code&gt;Module&lt;/code&gt; 组成的&lt;strong&gt;有序列表&lt;/strong&gt;。注意，两个全连接层都是 &lt;code&gt;Linear&lt;/code&gt; 类的实例，&lt;code&gt;Linear&lt;/code&gt; 类本身就是 &lt;code&gt;Module&lt;/code&gt; 的子类。另外，到目前为止，我们一直在通过 &lt;code&gt;net(X)&lt;/code&gt; 调用我们的模型来获得模型的输出。这实际上是 &lt;code&gt;net.__call__(X)&lt;/code&gt; 的简写。这个前向传播函数非常简单：它将列表中的每个块连接在一起，将每个块的输出作为下一个块的输入。&lt;/p&gt;
&lt;p&gt;在下面的代码片段中，我们从零开始编写一个块。它包含一个多层感知机，其具有256个隐藏单元的隐藏层和一个10维输出层。注意，下面的 &lt;code&gt;MLP&lt;/code&gt; 类继承了表示块的类。我们的实现只需要提供我们自己的构造函数（Python 中的 &lt;code&gt;__init__&lt;/code&gt; 函数）和前向传播函数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;MLP&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 模型参数声明层。这里，我们声明两个全连接的层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 调用MLP的父类Module的构造函数来执行必要的初始化。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.hidden = nn.Linear(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 隐藏层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.out = nn.Linear(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 输出层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 定义模型的前向传播，即如何根据输入X返回所需的模型输出&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.out(F.relu(self.hidden(X)))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接着我们实例化多层感知机的层，然后在每次调用前向传播函数时调用这些层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;net = MLP()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net(X).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 10])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在我们可以更仔细地看看 &lt;code&gt;Sequential&lt;/code&gt; 类是如何工作的，回想一下 &lt;code&gt;Sequential&lt;/code&gt; 的设计是为了把其他模块串起来。为了构建我们自己的简化的 &lt;code&gt;MySequential&lt;/code&gt;，我们只需要定义两个关键函数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一种将块逐个追加到列表中的函数；&lt;/li&gt;
&lt;li&gt;一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面的 &lt;code&gt;MySequential&lt;/code&gt; 类提供了与默认 &lt;code&gt;Sequential&lt;/code&gt; 类相同的功能：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;MySequential&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, *args&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; idx, module &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(args):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 这里，module是Module子类的一个实例，我们把它保存在&amp;#x27;Module&amp;#x27;类的成员&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 变量_modules中，_module的类型是OrderedDict&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            self._modules[&lt;span class=&#34;built_in&#34;&gt;str&lt;/span&gt;(idx)] = module&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# OrderedDict保证了按照成员添加的顺序遍历它们&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; block &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; self._modules.values():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            X = block(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = MySequential(nn.Linear(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;), nn.ReLU(), nn.Linear(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net(X).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 10])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;Sequential&lt;/code&gt; 类使模型构造变得简单，允许我们组合新的架构，而不必定义自己的类。然而，并不是所有的架构都是简单的顺序架构。当需要更强的灵活性时，我们需要定义自己的块。例如，我们可能希望在前向传播函数中执行 Python 的控制流。此外，我们可能希望执行任意的数学运算，而不是简单地依赖预定义的神经网络层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;FixedHiddenMLP&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 不计算梯度的随机权重参数，因此其在训练期间保持不变&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.rand_weight = torch.rand((&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;), requires_grad=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.linear = nn.Linear(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = self.linear(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 使用创建的常量参数以及relu和mm函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = F.relu(torch.mm(X, self.rand_weight) + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 复用全连接层，这相当于两个全连接层共享参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        X = self.linear(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 控制流&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;while&lt;/span&gt; X.&lt;span class=&#34;built_in&#34;&gt;abs&lt;/span&gt;().&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;() &amp;gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            X /= &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以混合搭配各种组合块的方法。在下面的例子中，我们以一些想到的方法嵌套块：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;NestMLP&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.net = nn.Sequential(nn.Linear(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;), nn.ReLU(), nn.Linear(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;), nn.ReLU())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.linear = nn.Linear(&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.linear(self.net(X))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;chimera = nn.Sequential(NestMLP(), nn.Linear(&lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;), FixedHiddenMLP())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(chimera(X))  &lt;span class=&#34;comment&#34;&gt;# tensor(-0.2911, grad_fn=&amp;lt;SumBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-参数管理&#34;&gt;2. 参数管理&lt;/h2&gt;
&lt;p&gt;我们首先看一下具有单隐藏层的多层感知机：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Linear(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;), nn.ReLU(), nn.Linear(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.rand(size=(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net(X).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 1])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们从已有模型中访问参数。当通过 &lt;code&gt;Sequential&lt;/code&gt; 类定义模型时，我们可以通过索引来访问模型的任意层。这就像模型是一个列表一样，每层的参数都在其属性中。如下所示，我们可以检查第二个全连接层的参数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;].state_dict())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# OrderedDict([(&amp;#x27;weight&amp;#x27;, tensor([[-0.1326,  0.1692, -0.0925, -0.1721,  0.0828, -0.0890, -0.0742, -0.2730]])), (&amp;#x27;bias&amp;#x27;, tensor([0.2011]))])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这个全连接层包含两个参数，分别是该层的权重和偏置，每个参数都表示为参数类的一个实例。要对参数执行任何操作，首先我们需要访问底层的数值：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;].bias))  &lt;span class=&#34;comment&#34;&gt;# &amp;lt;class &amp;#x27;torch.nn.parameter.Parameter&amp;#x27;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;].bias)  &lt;span class=&#34;comment&#34;&gt;# Parameter containing: tensor([-0.2786], requires_grad=True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;].bias.data)  &lt;span class=&#34;comment&#34;&gt;# tensor([-0.1571])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;参数是复合的对象，包含值、梯度和额外信息。这就是我们需要显式参数值的原因。除了值之外，我们还可以访问每个参数的梯度。在上面这个网络中，由于我们还没有调用反向传播，所以参数的梯度处于初始状态：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;].weight.grad == &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# True&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;当我们需要对所有参数执行操作时，逐个访问它们可能会很麻烦。下面，我们将通过演示来比较访问第一个全连接层的参数和访问所有层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(*[(name, param.shape) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; name, param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].named_parameters()])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# (&amp;#x27;weight&amp;#x27;, torch.Size([8, 4])) (&amp;#x27;bias&amp;#x27;, torch.Size([8]))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(*[(name, param.shape) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; name, param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; net.named_parameters()])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# (&amp;#x27;0.weight&amp;#x27;, torch.Size([8, 4])) (&amp;#x27;0.bias&amp;#x27;, torch.Size([8])) (&amp;#x27;2.weight&amp;#x27;, torch.Size([1, 8])) (&amp;#x27;2.bias&amp;#x27;, torch.Size([1]))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这为我们提供了另一种访问网络参数的方式，如下所示：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net.state_dict()[&lt;span class=&#34;string&#34;&gt;&amp;#x27;2.bias&amp;#x27;&lt;/span&gt;].data)  &lt;span class=&#34;comment&#34;&gt;# tensor([0.0992])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在让我们看看如果我们将多个块相互嵌套，参数命名约定是如何工作的：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;block1&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; nn.Sequential(nn.Linear(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;), nn.ReLU(), nn.Linear(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;), nn.ReLU())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;block2&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net = nn.Sequential()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 在这里嵌套&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        net.add_module(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;block &lt;span class=&#34;subst&#34;&gt;&amp;#123;i&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;, block1())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; net&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;rgnet = nn.Sequential(block2(), nn.Linear(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(rgnet)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Sequential(&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (0): Sequential(&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (block 0): Sequential(&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#       (0): Linear(in_features=4, out_features=8, bias=True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#       (1): ReLU()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#       ...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;因为层是分层嵌套的，所以我们也可以像通过嵌套列表索引一样访问它们：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(rgnet[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].bias.data)  &lt;span class=&#34;comment&#34;&gt;# tensor([ 0.4102,  0.1565,  0.1458,  0.0826,  0.2460, -0.0115, -0.4241,  0.1192])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;知道了如何访问参数后，现在我们看看如何正确地初始化参数。深度学习框架提供默认随机初始化，也允许我们创建自定义初始化方法。&lt;/p&gt;
&lt;p&gt;让我们首先调用内置的初始化器。下面的代码将所有权重参数初始化为标准差为0.01的高斯随机变量，且将偏置参数设置为0：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_normal&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;m&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.Linear:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.init.normal_(m.weight, mean=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, std=&lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.init.zeros_(m.bias)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net.apply(init_normal)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].weight.data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].bias.data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# tensor([0.0037, 0.0052, 0.0020, 0.0028]) tensor(0.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们还可以将所有参数初始化为给定的常数，比如初始化为1：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;nn.init.constant_(m.weight, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们还可以对某些块应用不同的初始化方法。例如，下面我们使用 Xavier 初始化方法初始化第一个神经网络层，然后将第三个神经网络层初始化为常量值42：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_xavier&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;m&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.Linear:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.init.xavier_uniform_(m.weight)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_42&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;m&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.Linear:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.init.constant_(m.weight, &lt;span class=&#34;number&#34;&gt;42&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].apply(init_xavier)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;].apply(init_42)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].weight.data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# tensor([-0.7014,  0.1061,  0.2061,  0.2125])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;].weight.data)  &lt;span class=&#34;comment&#34;&gt;# tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;有时，深度学习框架没有提供我们需要的初始化方法。在下面的例子中，我们先初始化为-10~10的均匀分布，然后将绝对值小于5的参数置零：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;my_init&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;m&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.Linear:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;Init&amp;quot;&lt;/span&gt;, *[(name, param.shape) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; name, param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; m.named_parameters()][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        nn.init.uniform_(m.weight, -&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        m.weight.data *= m.weight.data.&lt;span class=&#34;built_in&#34;&gt;abs&lt;/span&gt;() &amp;gt;= &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net.apply(my_init)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].weight[:&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[-0.0000,  8.9053,  0.0000,  8.9382],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [-9.5017, -0.0000,  5.4470, -0.0000]], grad_fn=&amp;lt;SliceBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;有时我们希望在多个层间共享参数：我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;shared = nn.Linear(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 我们需要给共享层一个名称，以便可以引用它的参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Linear(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;), nn.ReLU(), shared, nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    shared, nn.ReLU(), nn.Linear(&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 检查参数是否相同&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;].weight.data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] == net[&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;].weight.data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# tensor([True, True, True, True, True, True, True, True])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;].weight.data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] = &lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 确保它们实际上是同一个对象，而不只是有相同的值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;].weight.data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] == net[&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;].weight.data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# tensor([True, True, True, True, True, True, True, True])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这个例子表明第三个和第五个神经网络层的参数是绑定的。它们不仅值相等，而且由相同的张量表示。因此，如果我们改变其中一个参数，另一个参数也会改变。这里有一个问题：当参数绑定时，梯度会发生什么情况？答案是由于模型参数包含梯度，因此在反向传播期间第二个隐藏层（即第三个神经网络层）和第三个隐藏层（即第五个神经网络层）的梯度会加在一起。&lt;/p&gt;
&lt;h2 id=&#34;3-自定义层&#34;&gt;3. 自定义层&lt;/h2&gt;
&lt;p&gt;我们构造一个没有任何参数的自定义层，下面的 &lt;code&gt;CenteredLayer&lt;/code&gt; 类要从其输入中减去均值。要构建它，我们只需继承基础层类并实现前向传播功能：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn.functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;CenteredLayer&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X - X.mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;layer = CenteredLayer()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(layer(torch.FloatTensor([&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;])))  &lt;span class=&#34;comment&#34;&gt;# tensor([-2., -1.,  0.,  1.,  2.])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下面我们继续定义具有参数的层，这些参数可以通过训练进行调整。让我们实现自定义版本的全连接层。回想一下，该层需要两个参数，一个用于表示权重，另一个用于表示偏置项。在此实现中，我们使用 ReLU 作为激活函数。该层需要输入参数：&lt;code&gt;in_units&lt;/code&gt; 和 &lt;code&gt;units&lt;/code&gt;，分别表示输入数和输出数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;MyLinear&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, in_units, units&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.weight = nn.Parameter(torch.randn(in_units, units))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.bias = nn.Parameter(torch.randn(units,))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        linear = torch.matmul(X, self.weight.data) + self.bias.data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; F.relu(linear)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;linear = MyLinear(&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(linear.weight.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([5, 3])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;4-读写文件&#34;&gt;4. 读写文件&lt;/h2&gt;
&lt;p&gt;加载和保存张量：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.arange(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.save(x, &lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/x-file&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;将存储在文件中的数据读回内存：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x2 = torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/x-file&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x2)  &lt;span class=&#34;comment&#34;&gt;# tensor([0, 1, 2, 3])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;存储一个张量列表，然后把它们读回内存：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;y = torch.zeros(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.save([x, y],&lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/x-files&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x2, y2 = torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/x-files&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;((x2, y2))  &lt;span class=&#34;comment&#34;&gt;# (tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以写入或读取从字符串映射到张量的字典。当我们要读取或写入模型中的所有权重时，这很方便：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;mydict = &amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;x&amp;#x27;&lt;/span&gt;: x, &lt;span class=&#34;string&#34;&gt;&amp;#x27;y&amp;#x27;&lt;/span&gt;: y&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.save(mydict, &lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/mydict&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mydict2 = torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/mydict&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(mydict2)  &lt;span class=&#34;comment&#34;&gt;# &amp;#123;&amp;#x27;x&amp;#x27;: tensor([0, 1, 2, 3]), &amp;#x27;y&amp;#x27;: tensor([0., 0., 0., 0.])&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;深度学习框架提供了内置函数来保存和加载整个网络。需要注意的一个重要细节是，这将&lt;strong&gt;保存模型的参数&lt;/strong&gt;而不是保存整个模型：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;MLP&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.hidden = nn.Linear(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.output = nn.Linear(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.output(F.relu(self.hidden(x)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = MLP()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;X = torch.randn(size=(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = net(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.save(net.state_dict(), &lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/mlp.params&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 为了恢复模型，我们实例化了原始多层感知机模型的一个备份。这里我们不需要随机初始化模型参数，而是直接读取文件中存储的参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;clone = MLP()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;clone.load_state_dict(torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../save/mlp.params&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;clone.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y_clone = clone(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(Y_clone == Y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[True, True, True, True, True, True, True, True, True, True],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [True, True, True, True, True, True, True, True, True, True]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;5-GPU&#34;&gt;5. GPU&lt;/h2&gt;
&lt;p&gt;CUDA 的安装配置教程：&lt;a href=&#34;/posts/15428.html&#34;&gt;Anaconda与PyTorch安装教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在 PyTorch 中，CPU 和 GPU 可以用 &lt;code&gt;torch.device(&#39;cpu&#39;)&lt;/code&gt; 和 &lt;code&gt;torch.device(&#39;cuda&#39;)&lt;/code&gt; 表示：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;), torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt;), torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda:0&amp;#x27;&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# cpu cuda cuda:0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以查询可用 GPU 的数量：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.cuda.device_count())  &lt;span class=&#34;comment&#34;&gt;# 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以查询张量所在的设备。默认情况下，张量是在 CPU 上创建的：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor([&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.device)  &lt;span class=&#34;comment&#34;&gt;# cpu&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;需要注意的是，无论何时我们要对多个项进行操作，它们都必须在同一个设备上。例如，如果我们对两个张量求和，我们需要确保两个张量都位于同一个设备上，否则框架将不知道在哪里存储结果，甚至不知道在哪里执行计算。&lt;/p&gt;
&lt;p&gt;有几种方法可以在 GPU 上存储张量。例如，我们可以在创建张量时指定存储设备：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;X = torch.ones(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, device=&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(X.device)  &lt;span class=&#34;comment&#34;&gt;# cuda:0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;数据在同一个 GPU 上我们才可以将它们相加：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;Y = X.cuda(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(Y.device)  &lt;span class=&#34;comment&#34;&gt;# cuda:0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;((X + Y).device)  &lt;span class=&#34;comment&#34;&gt;# cuda:0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;类似地，神经网络模型可以指定设备。下面的代码将模型参数放在 GPU 上：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Linear(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = net.to(device=&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net(X))  &lt;span class=&#34;comment&#34;&gt;# tensor([[-0.0370], [-0.0370]], device=&amp;#x27;cuda:0&amp;#x27;, grad_fn=&amp;lt;AddmmBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].weight.data.device)  &lt;span class=&#34;comment&#34;&gt;# cuda:0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;总之，只要所有的数据和参数都在同一个设备上，我们就可以有效地学习模型。&lt;/p&gt;
&lt;p&gt;下一章：&lt;a href=&#34;/posts/25122.html&#34;&gt;卷积神经网络&lt;/a&gt;。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/46068.html</guid>
            <title>动手学深度学习笔记(李沐)-多层感知机</title>
            <link>https://asanosaki.github.io/posts/46068.html</link>
            <category>AI</category>
            <pubDate>Sat, 18 Feb 2023 16:36:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;李沐动手学深度学习（PyTorch）课程学习笔记第三章：多层感知机。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-多层感知机的从零实现&#34;&gt;1. 多层感知机的从零实现&lt;/h2&gt;
&lt;p&gt;FashionMNIST 数据集的读取与第二章第四节一样，此处不再放上代码。&lt;/p&gt;
&lt;p&gt;初始化模型参数，我们将实现一个具有单隐藏层的多层感知机，它包含256个隐藏单元。注意，我们可以将这两个变量都视为超参数。通常，我们选择2的若干次幂作为层的宽度。因为内存在硬件中的分配和寻址方式，这么做往往可以在计算上更高效。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;num_inputs, num_outputs, num_hiddens = &lt;span class=&#34;number&#34;&gt;784&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;) * &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;) * &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;params = [W1, b1, W2, b2]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;为了确保我们对模型的细节了如指掌，我们将实现 ReLU 激活函数，而不是直接调用内置的 &lt;code&gt;relu&lt;/code&gt; 函数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;relu&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    a = torch.zeros_like(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;(X, a)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来定义模型：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;net&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    H = relu(torch.matmul(X.reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, num_inputs)), W1) + b1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.matmul(H, W2) + b2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;训练函数的代码也与2.4节基本一样，只需将 &lt;code&gt;net.to(device)&lt;/code&gt; 与 &lt;code&gt;net.train()&lt;/code&gt; 等与 &lt;code&gt;nn.Module&lt;/code&gt; 相关的代码去掉即可，因此不放出完整代码：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train_classifier&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, test_iter, num_epochs, lr&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;---------- Training on cpu ----------&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function = nn.CrossEntropyLoss()  &lt;span class=&#34;comment&#34;&gt;# reduction默认为&amp;#x27;mean&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer = torch.optim.SGD(params, lr=lr)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# train&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# valid&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr, num_epochs = &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_classifier(net, train_iter, train_iter, num_epochs, lr)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-多层感知机的简洁实现&#34;&gt;2. 多层感知机的简洁实现&lt;/h2&gt;
&lt;p&gt;与 Softmax 回归的简洁实现（第二章第四节）相比，唯一的区别是我们添加了2个全连接层（之前我们只添加了1个全连接层）。第一层是隐藏层，它包含256个隐藏单元，并使用了 ReLU 激活函数。第二层是输出层，因此我们只需要重点看一下模型即可：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; util.functions &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_classifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 读取数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_inputs, num_outputs, num_hiddens = &lt;span class=&#34;number&#34;&gt;784&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Flatten(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.Linear(num_inputs, num_hiddens),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.Linear(num_hiddens, num_outputs))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr, num_epochs = &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_classifier(net, train_iter, test_iter, num_epochs, lr, device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [ Train | epoch: 010/010 ] loss = 0.35276, acc = 0.87549&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [ Valid | epoch: 010/010 ] loss = 0.38964, acc = 0.85898&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-模型选择、欠拟合和过拟合&#34;&gt;3. 模型选择、欠拟合和过拟合&lt;/h2&gt;
&lt;p&gt;首先我们需要了解&lt;strong&gt;训练误差&lt;/strong&gt;和&lt;strong&gt;泛化误差&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;训练误差（training error）：模型在训练数据集上计算得到的误差。&lt;/li&gt;
&lt;li&gt;泛化误差（generalization error）：模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;问题是，我们永远不能准确地计算出泛化误差。这是因为无限多的数据样本是一个虚构的对象。在实际中，我们只能通过将模型应用于一个&lt;strong&gt;独立&lt;/strong&gt;的测试集来估计泛化误差，该测试集由随机选取的、未曾在训练集中出现的数据样本构成。&lt;/p&gt;
&lt;p&gt;在机器学习中，我们通常在评估几个候选模型后选择最终的模型。这个过程叫做模型选择。有时，需要进行比较的模型在本质上是完全不同的（比如，决策树与线性模型）。又有时，我们需要比较&lt;strong&gt;不同的超参数设置&lt;/strong&gt;下的同一类模型。&lt;/p&gt;
&lt;p&gt;例如，训练多层感知机模型时，我们可能希望比较具有不同数量的隐藏层、不同数量的隐藏单元以及不同的激活函数组合的模型。为了确定候选模型中的最佳模型，我们通常会使用&lt;strong&gt;验证集&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;验证数据集：一个用来评估模型好坏的数据集，训练数据集用来训练模型参数，验证数据集用来选择模型超参数。
&lt;ul&gt;
&lt;li&gt;例如在数据集中拿出50%的训练数据作为验证数据集。&lt;/li&gt;
&lt;li&gt;不要跟训练数据混在一起（常犯错误）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;测试数据集：只用一次的数据集。
&lt;ul&gt;
&lt;li&gt;例如未来的考试。&lt;/li&gt;
&lt;li&gt;例如我出价的房子的实际成交价。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来我们需要了解一下&lt;strong&gt;模型容量&lt;/strong&gt;的概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型容量表示模型拟合各种函数的能力。&lt;/li&gt;
&lt;li&gt;低容量的模型难以拟合复杂的训练数据。&lt;/li&gt;
&lt;li&gt;高容量的模型可以记住所有的训练数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是否过拟合或欠拟合主要取决于&lt;strong&gt;模型复杂性&lt;/strong&gt;和&lt;strong&gt;可用训练数据集的大小&lt;/strong&gt;。当我们比较训练和验证误差时，我们要注意两种常见的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;训练误差和验证误差都很差，但它们之间仅有一点差距。如果模型不能降低训练误差，这可能意味着模型过于简单（即表达能力不足），无法捕获试图学习的模式。此外，由于我们的训练和验证误差之间的泛化误差很小，我们有理由相信可以用一个更复杂的模型降低训练误差。这种现象被称为欠拟合（underfitting）。&lt;/li&gt;
&lt;li&gt;当我们的训练误差&lt;strong&gt;明显低于&lt;/strong&gt;验证误差时要小心，这表明严重的过拟合（overfitting）。注意，过拟合并不总是一件坏事。特别是在深度学习领域，众所周知，最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。最终，我们通常更关心验证误差，而不是训练误差和验证误差之间的差距。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4-权重衰减&#34;&gt;4. 权重衰减&lt;/h2&gt;
&lt;p&gt;在训练参数化机器学习模型时，权重衰减（weight decay）是最广泛使用的正则化的技术之一，它通常也被称为L2正则化。&lt;/p&gt;
&lt;p&gt;通过限制参数值的选择范围来控制模型容量，通常不限制偏移 &lt;code&gt;b&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;首先生成一些数据：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;n_train, n_test, num_inputs, batch_size = &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;200&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;  &lt;span class=&#34;comment&#34;&gt;# 训练数据少，特征维度大，因此容易过拟合&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;true_w, true_b = torch.ones((num_inputs, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)) * &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.05&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_data = d2l.synthetic_data(true_w, true_b, n_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter = d2l.load_array(train_data, batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = d2l.synthetic_data(true_w, true_b, n_test)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_iter = d2l.load_array(test_data, batch_size, is_train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义网络模型与损失函数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Linear(num_inputs, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = nn.MSELoss(reduction=&lt;span class=&#34;string&#34;&gt;&amp;#x27;none&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义优化算法，我们在实例化优化器时直接通过 &lt;code&gt;weight_decay&lt;/code&gt; 指定 &lt;code&gt;weight decay&lt;/code&gt; 超参数。默认情况下，PyTorch 同时衰减权重和偏移。这里我们只为权重设置了 &lt;code&gt;weight_decay&lt;/code&gt;，所以偏置参数不会衰减：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;num_epochs, lr, wd = &lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.003&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;  &lt;span class=&#34;comment&#34;&gt;# wd为0表示不使用权重衰减&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 偏置参数没有衰减，net[0]即为nn.Linear(num_inputs, 1)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = torch.optim.SGD([&amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;params&amp;#x27;&lt;/span&gt;:net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].weight, &lt;span class=&#34;string&#34;&gt;&amp;#x27;weight_decay&amp;#x27;&lt;/span&gt;:wd&amp;#125;, &amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;params&amp;#x27;&lt;/span&gt;:net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].bias&amp;#125;], lr=lr)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后进行训练：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/WeightDecay_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; net.parameters():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    param.data.normal_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_loss = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_loss = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; train_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y_hat = net(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(y_hat, y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.mean().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss += loss.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_loss /= n_train&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; test_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            y_hat = net(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss = loss_function(y_hat, y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            test_loss += loss.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_loss /= n_test&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_loss&amp;#x27;&lt;/span&gt;, train_loss, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;test_loss&amp;#x27;&lt;/span&gt;, test_loss, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;w的L2范数：&amp;#x27;&lt;/span&gt;, net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].weight.norm().item())&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过结果可以看到模型很快就过拟合了，可以通过修改超参数 &lt;code&gt;wd&lt;/code&gt; 的值应用权重衰减的方式来缓解过拟合的现象。&lt;/p&gt;
&lt;h2 id=&#34;5-暂退法（Dropout）&#34;&gt;5. 暂退法（Dropout）&lt;/h2&gt;
&lt;p&gt;一个好的模型需要对输入数据的扰动鲁棒。在训练过程中，建议在计算后续层之前&lt;strong&gt;向网络的每一层注入噪声&lt;/strong&gt;，因为当训练一个有多层的深层网络时，注入噪声只会在输入-输出映射上增强平滑性。&lt;/p&gt;
&lt;p&gt;这个想法被称为暂退法（dropout）。暂退法在前向传播过程中，计算每一内部层的同时注入噪声，这已经成为训练神经网络的常用技术。这种方法之所以被称为暂退法，因为我们从表面上看是&lt;strong&gt;在训练过程中丢弃（drop out）一些神经元&lt;/strong&gt;。在整个训练过程的每一次迭代中，标准暂退法包括&lt;strong&gt;在计算下一层之前将当前层中的一些节点置零&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在标准暂退法正则化中，通过按保留（未丢弃）的节点的分数进行规范化来消除每一层的偏差。换言之，每个中间活性值 &lt;code&gt;h&lt;/code&gt; 以暂退概率 &lt;code&gt;p&lt;/code&gt; 由随机变量替换。&lt;/p&gt;
&lt;p&gt;Dropout 说的简单一点就是：我们在前向传播的时候，让某个神经元的激活值以一定的概率 &lt;code&gt;p&lt;/code&gt; 停止工作（将一些输出项随机置0），这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。&lt;/p&gt;
&lt;p&gt;我们可以将暂退法应用于每个隐藏层的输出（在激活函数之后），并且可以为每一层分别设置暂退概率：常见的技巧是在靠近输入层的地方设置较低的暂退概率。下面的模型将第一个和第二个隐藏层的暂退概率分别设置为0.2和0.5，并且暂退法&lt;strong&gt;只在训练期间有效&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Dropout 的从零实现核心代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;dropout_layer&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, p&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &amp;lt;= p &amp;lt;= &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 在本情况中，所有元素都被丢弃&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; p == &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.zeros_like(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 在本情况中，所有元素都被保留&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; p == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mask = (torch.rand(X.shape) &amp;gt; p).&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; mask * X / (&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt; - p)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_inputs, num_outputs, num_hiddens1, num_hiddens2 = &lt;span class=&#34;number&#34;&gt;784&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;p1, p2 = &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Net&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, num_inputs, num_outputs, num_hiddens1, num_hiddens2, is_training = &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Net, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.num_inputs = num_inputs&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.training = is_training&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.lin1 = nn.Linear(num_inputs, num_hiddens1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.lin3 = nn.Linear(num_hiddens2, num_outputs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.relu = nn.ReLU()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        H1 = self.relu(self.lin1(X.reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, self.num_inputs))))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 只有在训练模型时才使用dropout&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; self.training == &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 在第一个全连接层之后添加一个dropout层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            H1 = dropout_layer(H1, p1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        H2 = self.relu(self.lin2(H1))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; self.training == &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 在第二个全连接层之后添加一个dropout层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            H2 = dropout_layer(H2, p2)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        out = self.lin3(H2)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; out&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Dropout 的简洁实现及完整训练代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; util.functions &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_classifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mnist_train = torchvision.datasets.FashionMNIST(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=transforms.ToTensor(), download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mnist_test = torchvision.datasets.FashionMNIST(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor(), download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter = data.DataLoader(mnist_train, batch_size=&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_iter = data.DataLoader(mnist_test, batch_size=&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, shuffle=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Flatten(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.Linear(&lt;span class=&#34;number&#34;&gt;784&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.Dropout(&lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.Linear(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.Dropout(&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    nn.Linear(&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr, num_epochs = &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer_path = &lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/Dropout_train_log&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_classifier(net, train_iter, test_iter, num_epochs, lr, device, writer_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [ Train | epoch: 010/010 ] loss = 0.37249, acc = 0.86702&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [ Valid | epoch: 010/010 ] loss = 0.37481, acc = 0.86348&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;6-数值稳定性和模型初始化&#34;&gt;6. 数值稳定性和模型初始化&lt;/h2&gt;
&lt;p&gt;我们可能面临一些问题，要么是&lt;strong&gt;梯度爆炸&lt;/strong&gt;（gradient exploding）问题：参数更新过大，破坏了模型的稳定收敛；要么是&lt;strong&gt;梯度消失&lt;/strong&gt;（gradient vanishing）问题：参数更新过小，在每次更新时几乎不会移动，导致模型无法学习。&lt;/p&gt;
&lt;p&gt;例如当 Sigmoid 函数的输入很大或是很小时，它的梯度都会消失。此外，当反向传播通过许多层时，除非我们在刚刚好的地方，这些地方 Sigmoid 函数的输入接近于零，否则整个乘积的梯度可能会消失。&lt;/p&gt;
&lt;p&gt;Xavier 初始化：从均值为零，方差为 &lt;code&gt;2 / (n_in + n_out)&lt;/code&gt; 的高斯分布中采样权重（&lt;code&gt;n_in&lt;/code&gt; 为输入的数量，&lt;code&gt;n_out&lt;/code&gt; 为输出的数量）。&lt;/p&gt;
&lt;p&gt;下一章：&lt;a href=&#34;/posts/23526.html&#34;&gt;PyTorch 神经网络基础&lt;/a&gt;。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/19931.html</guid>
            <title>动手学深度学习笔记(李沐)-线性神经网络</title>
            <link>https://asanosaki.github.io/posts/19931.html</link>
            <category>AI</category>
            <pubDate>Thu, 02 Feb 2023 19:25:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;李沐动手学深度学习（PyTorch）课程学习笔记第二章：线性神经网络。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-线性回归的从零实现&#34;&gt;1. 线性回归的从零实现&lt;/h2&gt;
&lt;p&gt;为了简单起见，我们将根据带有噪声的线性模型构造一个人造数据集。我们的任务是使用这个有限样本的数据集来恢复这个模型的参数。&lt;/p&gt;
&lt;p&gt;首先我们生成数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; random&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;synthetic_data&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;w, b, num_examples&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;生成y = Xw + b + 噪声&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    X = torch.normal(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, (num_examples, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(w)))  &lt;span class=&#34;comment&#34;&gt;# 均值为0，方差为1的随机数，大小为(num_examples, len(w))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y = torch.matmul(X, w) + b  &lt;span class=&#34;comment&#34;&gt;# y = Xw + b&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y += torch.normal(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;, y.shape)  &lt;span class=&#34;comment&#34;&gt;# 加入一个随机噪音&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X, y.reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# y为列向量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;true_w = torch.tensor([&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;3.4&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;true_b = &lt;span class=&#34;number&#34;&gt;4.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;features, labels = synthetic_data(true_w, true_b, &lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;features:&amp;#x27;&lt;/span&gt;, features[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],&lt;span class=&#34;string&#34;&gt;&amp;#x27;\nlabel:&amp;#x27;&lt;/span&gt;, labels[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# features: tensor([ 0.7764, -1.2998])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# label: tensor([10.1756])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 通过生成第二个特征features[:, 1]和labels的散点图，可以直观观察到两者之间的线性关系&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(features[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].detach().numpy(), labels.detach().numpy(), &lt;span class=&#34;string&#34;&gt;&amp;#x27;ro&amp;#x27;&lt;/span&gt;, ms=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;训练模型时要对数据集进行遍历，每次抽取一小批量样本，并使用它们来更新我们的模型。由于这个过程是训练机器学习算法的基础，所以有必要定义一个函数，该函数能打乱数据集中的样本并以小批量方式获取数据。&lt;/p&gt;
&lt;p&gt;在下面的代码中，我们定义一个 &lt;code&gt;data_iter&lt;/code&gt; 函数，该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为 &lt;code&gt;batch_size&lt;/code&gt; 的小批量。每个小批量包含一组特征和标签：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;data_iter&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size, features, labels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_examples = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(features)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    indices = &lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_examples))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 这些样本是随机读取的，没有特定的顺序，因此要打乱下标&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    random.shuffle(indices)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, num_examples, batch_size):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        batch_indices = torch.tensor(indices[i:&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;(i + batch_size, num_examples)])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;yield&lt;/span&gt; features[batch_indices], labels[batch_indices]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size = &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; data_iter(batch_size, features, labels):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(X, &lt;span class=&#34;string&#34;&gt;&amp;#x27;\n&amp;#x27;&lt;/span&gt;, y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;break&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在我们开始用小批量随机梯度下降优化我们的模型参数之前，我们需要先有一些参数。在下面的代码中，我们通过从均值为0、标准差为0.01的正态分布中采样随机数来&lt;strong&gt;初始化权重&lt;/strong&gt;，并将偏置初始化为0：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;w = torch.normal(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;, size=(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b = torch.zeros(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义线性回归模型：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;linreg&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X, w, b&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;线性回归模型&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.matmul(X, w) + b&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义损失函数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;squared_loss&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;y_hat, y&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;均方损失&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (y_hat - y.reshape(y_hat.shape)) ** &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; / &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义优化算法：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;sgd&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;params, lr, batch_size&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;小批量随机梯度下降&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():  &lt;span class=&#34;comment&#34;&gt;# 更新参数的时候不需要计算梯度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; params:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            param -= lr * param.grad / batch_size&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            param.grad.zero_()  &lt;span class=&#34;comment&#34;&gt;# 将梯度清零&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在我们已经准备好了模型训练所有需要的要素，可以实现主要的训练过程部分了。理解这段代码至关重要，因为从事深度学习后，相同的训练过程几乎一遍又一遍地出现。在每次迭代中，我们读取一小批量训练样本，并通过我们的模型来获得一组预测。计算完损失后，我们开始反向传播，存储每个参数的梯度。最后，我们调用优化算法（随机梯度下降法SGD）来更新模型参数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 超参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr, num_epochs = &lt;span class=&#34;number&#34;&gt;0.03&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = linreg&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = squared_loss&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; data_iter(batch_size, features, labels):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(net(X, w, b), y)  &lt;span class=&#34;comment&#34;&gt;# X和y的小批量损失&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# loss的形状是(batch_size, 1)，而不是标量，将loss中的所有元素加到一起，并以此计算关于[w, b]的梯度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        sgd([w, b], lr, batch_size)  &lt;span class=&#34;comment&#34;&gt;# 使用参数的梯度更新参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss = loss_function(net(features, w, b), labels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;epoch &lt;span class=&#34;subst&#34;&gt;&amp;#123;epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&amp;#125;&lt;/span&gt;, loss &lt;span class=&#34;subst&#34;&gt;&amp;#123;&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(train_loss.mean()):f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-线性回归的简洁实现&#34;&gt;2. 线性回归的简洁实现&lt;/h2&gt;
&lt;p&gt;首先生成数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;true_w = torch.tensor([&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;3.4&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;true_b = &lt;span class=&#34;number&#34;&gt;4.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;features, labels = d2l.synthetic_data(true_w, true_b, &lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;读取数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;load_array&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;data_arrays, batch_size, is_train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;构造一个PyTorch数据迭代器&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    dataset = data.TensorDataset(*data_arrays)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; data.DataLoader(dataset, batch_size, shuffle=is_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size = &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_iter = load_array((features, labels), batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 这里我们使用iter构造Python迭代器，并使用next从迭代器中获取第一项&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;feature, label = &lt;span class=&#34;built_in&#34;&gt;next&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;iter&lt;/span&gt;(data_iter))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(feature)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(label)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来我们定义模型，在 PyTorch 中，全连接层在 &lt;code&gt;Linear&lt;/code&gt; 类中定义。值得注意的是，我们将两个参数传递到 &lt;code&gt;nn.Linear&lt;/code&gt; 中。第一个指定输入特征形状，即2，第二个指定输出特征形状，输出特征形状为单个标量，因此为1：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Linear(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 初始化模型参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].weight.data.normal_(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].bias.data.fill_(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义损失函数，计算均方误差使用的是 &lt;code&gt;MSELoss&lt;/code&gt; 类，也称平方 L2 范数，默认情况下，它返回所有样本损失的平均值：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;loss_function = nn.MSELoss()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义优化算法：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;optimizer = torch.optim.SGD(net.parameters(), lr=&lt;span class=&#34;number&#34;&gt;0.03&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;训练过程代码与我们从零开始实现时所做的非常相似：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;num_epochs = &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; data_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(net(X), y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss = loss_function(net(features), labels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;epoch &lt;span class=&#34;subst&#34;&gt;&amp;#123;epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&amp;#125;&lt;/span&gt;, loss &lt;span class=&#34;subst&#34;&gt;&amp;#123;train_loss:f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-Softmax回归的从零实现&#34;&gt;3. Softmax回归的从零实现&lt;/h2&gt;
&lt;p&gt;首先读入 Fashion-MNIST 数据集，原始数据集中的每个样本都是28*28的图像。本节将展平每个图像，把它们看作长度为784的向量。在后面的章节中，我们将讨论能够利用&lt;strong&gt;图像空间结构&lt;/strong&gt;的特征，但现在我们暂时只把每个像素位置看作一个特征。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; d2l &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; d2l&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;load_data_fashion_mnist&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size, resize=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;下载Fashion-MNIST数据集，然后将其加载到内存中&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    trans = [transforms.ToTensor()]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; resize:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        trans.insert(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, transforms.Resize(resize))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    trans = transforms.Compose(trans)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mnist_train = torchvision.datasets.FashionMNIST(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    mnist_test = torchvision.datasets.FashionMNIST(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=trans, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; (data.DataLoader(mnist_train, batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            data.DataLoader(mnist_test, batch_size, shuffle=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size = &lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter, test_iter = load_data_fashion_mnist(batch_size)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;初始化模型参数，在 Softmax 回归中，我们的输出与类别一样多。因为我们的数据集有10个类别，所以网络输出维度为10。因此，权重将构成一个784*10的矩阵，偏置将构成一个1*10的行向量：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;num_inputs = &lt;span class=&#34;number&#34;&gt;784&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_outputs = &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;W = torch.normal(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;, size=(num_inputs, num_outputs), requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b = torch.zeros(num_outputs, requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义 Softmax 操作，注意，虽然这在数学上看起来是正确的，但我们在代码实现中有点草率。矩阵中的非常大或非常小的元素可能造成数值上溢或下溢，但我们没有采取措施来防止这点：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;softmax&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    X_exp = torch.exp(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    partition = X_exp.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, keepdim=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; X_exp / partition  &lt;span class=&#34;comment&#34;&gt;# 这里应用了广播机制&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义 Softmax 操作后，我们可以实现 Softmax 回归模型。下面的代码定义了输入如何通过网络映射到输出。注意，将数据传递到模型之前，我们使用 &lt;code&gt;reshape&lt;/code&gt; 函数将每张原始图像展平为向量：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;net&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;X&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; softmax(torch.matmul(X.reshape((-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, W.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])), W) + b)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来我们定义损失函数，交叉熵采用真实标签的预测概率的&lt;strong&gt;负对数似然&lt;/strong&gt;。这里我们不使用 Python 的 &lt;code&gt;for&lt;/code&gt; 循环迭代预测（这往往是低效的），而是通过一个运算符选择所有元素。下面我们创建一个数据样本 &lt;code&gt;y_hat&lt;/code&gt;，其中包含2个样本在3个类别的预测概率，以及它们对应的标签 &lt;code&gt;y&lt;/code&gt;。有了 &lt;code&gt;y&lt;/code&gt;，我们知道在第一个样本中，第一类是正确的预测；而在第二个样本中，第三类是正确的预测。然后使用 &lt;code&gt;y&lt;/code&gt; 作为 &lt;code&gt;y_hat&lt;/code&gt; 中概率的索引，我们选择第一个样本中第一个类的概率和第二个样本中第三个类的概率：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;y = torch.tensor([&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_hat = torch.tensor([[&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.6&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(y_hat[[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], y])  &lt;span class=&#34;comment&#34;&gt;# tensor([0.1000, 0.5000])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;cross_entropy&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;y_hat, y&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; -torch.log(y_hat[&lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(y_hat)), y])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(cross_entropy(y_hat, y))  &lt;span class=&#34;comment&#34;&gt;# tensor([2.3026, 0.6931])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;为了计算精度，我们执行以下操作。首先，如果 &lt;code&gt;y_hat&lt;/code&gt; 是矩阵，那么假定第二个维度存储每个类的预测分数。我们使用 &lt;code&gt;argmax&lt;/code&gt; 获得每行中&lt;strong&gt;最大&lt;/strong&gt;元素的索引来获得预测类别。然后我们将预测类别与真实 &lt;code&gt;y&lt;/code&gt; 元素进行比较。由于等式运算符 &lt;code&gt;==&lt;/code&gt; 对数据类型很敏感，因此我们将 &lt;code&gt;y_hat&lt;/code&gt; 的数据类型转换为与 &lt;code&gt;y&lt;/code&gt; 的数据类型一致。结果是一个包含0（错）和1（对）的张量。最后，我们求和会得到正确预测的数量：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;accuracy&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;y_hat, y&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;计算预测正确的数量&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(y_hat.shape) &amp;gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; y_hat.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] &amp;gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y_hat = y_hat.argmax(axis=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    cmp = y_hat.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(y.dtype) == y  &lt;span class=&#34;comment&#34;&gt;# tensor([False,  True])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(cmp.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(y.dtype).&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(accuracy(y_hat, y) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(y))  &lt;span class=&#34;comment&#34;&gt;# 0.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;同样，对于任意数据迭代器 &lt;code&gt;data_iter&lt;/code&gt; 可访问的数据集，我们可以评估在任意模型 &lt;code&gt;net&lt;/code&gt; 的精度，这里定义一个实用程序类 &lt;code&gt;Accumulator&lt;/code&gt;，用于对多个变量进行累加。在 &lt;code&gt;evaluate_accuracy&lt;/code&gt; 函数中，我们在 &lt;code&gt;Accumulator&lt;/code&gt; 实例中创建了2个变量，分别用于存储正确预测的数量和预测的总数量。当我们遍历数据集时，两者都将随着时间的推移而累加：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;evaluate_accuracy&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, data_iter&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;计算在指定数据集上模型的精度&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(net, torch.nn.Module):  &lt;span class=&#34;comment&#34;&gt;# 如果是用torch.nn实现的模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        net.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()  &lt;span class=&#34;comment&#34;&gt;# 将模型先设置为评估模式&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    metric = Accumulator(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 正确预测数、预测总数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; data_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            metric.add(accuracy(net(X), y), y.numel())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; metric[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] / metric[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Accumulator&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;在n个变量上累加&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, n&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.data = [&lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;] * n&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, *args&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.data = [a + &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(b) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; a, b &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(self.data, args)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;reset&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.data = [&lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;] * &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(self.data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__getitem__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, idx&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; self.data[idx]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来可以开始进行训练：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train_epoch_ch3&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, loss_function, updater&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;训练模型一个迭代周期（定义见第3章）&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 如果net是用torch.nn实现的话先将模型设置为训练模式&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(net, torch.nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        net.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 训练损失总和、训练准确度总和、样本数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    metric = Accumulator(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; train_iter:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 计算梯度并更新参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y_hat = net(X)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(y_hat, y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;isinstance&lt;/span&gt;(updater, torch.optim.Optimizer):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 使用PyTorch内置的优化器和损失函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            updater.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss.mean().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            updater.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# 使用定制的优化器和损失函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            updater(X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        metric.add(&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(loss.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()), accuracy(y_hat, y), y.numel())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 返回训练损失和训练精度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; metric[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] / metric[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], metric[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] / metric[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train_ch3&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, test_iter, loss_function, num_epochs, updater&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot;训练模型&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/FashionMNIST_train_log&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_metrics = train_epoch_ch3(net, train_iter, loss_function, updater)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        test_acc = evaluate_accuracy(net, test_iter)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_loss&amp;#x27;&lt;/span&gt;, train_metrics[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_acc&amp;#x27;&lt;/span&gt;, train_metrics[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;test_acc&amp;#x27;&lt;/span&gt;, test_acc, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_loss, train_acc = train_metrics&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.close()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; train_loss &amp;lt; &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, train_loss&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; train_acc &amp;lt;= &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; train_acc &amp;gt; &lt;span class=&#34;number&#34;&gt;0.7&lt;/span&gt;, train_acc&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;assert&lt;/span&gt; test_acc &amp;lt;= &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; test_acc &amp;gt; &lt;span class=&#34;number&#34;&gt;0.7&lt;/span&gt;, test_acc&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr = &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;updater&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; d2l.sgd([W, b], lr, batch_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;num_epochs = &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;可以在项目路径下打开 Anaconda 的 PyTorch 环境，然后使用 TensorBoard 查看训练曲线：&lt;/p&gt;
&lt;figure class=&#34;highlight shell&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensorboard --logdir logs\FashionMNIST_train_log&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;4-Softmax回归的简洁实现&#34;&gt;4. Softmax回归的简洁实现&lt;/h2&gt;
&lt;p&gt;首先读取数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tqdm &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tqdm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mnist_train = torchvision.datasets.FashionMNIST(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=transforms.ToTensor(), download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mnist_test = torchvision.datasets.FashionMNIST(root=&lt;span class=&#34;string&#34;&gt;&amp;quot;../data&amp;quot;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor(), download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_iter = data.DataLoader(mnist_train, batch_size=&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_iter = data.DataLoader(mnist_test, batch_size=&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, shuffle=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义模型，我们只需在 &lt;code&gt;Sequential&lt;/code&gt; 中添加一个带有10个输出的全连接层，这10个输出分别表示对10个类别的预测概率：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# PyTorch不会隐式地调整输入的形状。因此，我们在线性层前定义了展平层（Flatten），来调整网络输入的形状&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;net = nn.Sequential(nn.Flatten(), nn.Linear(&lt;span class=&#34;number&#34;&gt;784&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;定义训练函数，由于之后很多模型的训练过程也是相似的，因此该函数可以复用：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 以后较为通用的函数将定义到util.functions.py中&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train_classifier&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;net, train_iter, test_iter, num_epochs, lr, device, writer_path=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, save_path=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;init_weights&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;m&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.Linear &lt;span class=&#34;keyword&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(m) == nn.Conv2d:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# nn.init.normal_(m.weight, mean=0, std=0.01)  # 以均值0和标准差0.01随机初始化权重&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.init.xavier_uniform_(m.weight)  &lt;span class=&#34;comment&#34;&gt;# Xavier初始化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.apply(init_weights)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;---------- Training on &lt;span class=&#34;subst&#34;&gt;&amp;#123;device&amp;#125;&lt;/span&gt; ----------&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    net.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function = nn.CrossEntropyLoss()  &lt;span class=&#34;comment&#34;&gt;# reduction默认为&amp;#x27;mean&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss_function.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer = torch.optim.SGD(net.parameters(), lr=lr)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; writer_path &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer = SummaryWriter(writer_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    best_acc = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        net.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss, train_acc = [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; x, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(train_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            x, y = x.to(device), y.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            y_hat = net(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss = loss_function(y_hat, y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            y_hat = y_hat.argmax(axis=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            acc = (y_hat.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(y.dtype) == y).&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;().mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_loss.append(loss.item())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_acc.append(acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_acc = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(train_acc) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;[ Train | epoch: &lt;span class=&#34;subst&#34;&gt;&amp;#123;epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:03d&amp;#125;&lt;/span&gt;/&lt;span class=&#34;subst&#34;&gt;&amp;#123;num_epochs:03d&amp;#125;&lt;/span&gt; ] loss = &lt;span class=&#34;subst&#34;&gt;&amp;#123;train_loss:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;, acc = &lt;span class=&#34;subst&#34;&gt;&amp;#123;train_acc:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        net.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_loss, valid_acc = [], []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; x, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; tqdm(test_iter):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                x, y = x.to(device), y.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                y_hat = net(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                loss = loss_function(y_hat, y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                y_hat = y_hat.argmax(axis=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                acc = (y_hat.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(y.dtype) == y).&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;().mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                valid_loss.append(loss.item())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                valid_acc.append(acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_loss = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(valid_loss) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(valid_loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        valid_acc = &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(valid_acc) / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(valid_acc)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;quot;[ Valid | epoch: &lt;span class=&#34;subst&#34;&gt;&amp;#123;epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:03d&amp;#125;&lt;/span&gt;/&lt;span class=&#34;subst&#34;&gt;&amp;#123;num_epochs:03d&amp;#125;&lt;/span&gt; ] loss = &lt;span class=&#34;subst&#34;&gt;&amp;#123;valid_loss:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;, acc = &lt;span class=&#34;subst&#34;&gt;&amp;#123;valid_acc:&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; writer_path &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            writer.add_scalars(&lt;span class=&#34;string&#34;&gt;&amp;#x27;loss&amp;#x27;&lt;/span&gt;, &amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;train&amp;#x27;&lt;/span&gt;: train_loss,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                        &lt;span class=&#34;string&#34;&gt;&amp;#x27;valid&amp;#x27;&lt;/span&gt;: valid_loss&amp;#125;, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            writer.add_scalars(&lt;span class=&#34;string&#34;&gt;&amp;#x27;acc&amp;#x27;&lt;/span&gt;, &amp;#123;&lt;span class=&#34;string&#34;&gt;&amp;#x27;train&amp;#x27;&lt;/span&gt;: train_acc,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                       &lt;span class=&#34;string&#34;&gt;&amp;#x27;valid&amp;#x27;&lt;/span&gt;: valid_acc&amp;#125;, epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; save_path &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;and&lt;/span&gt; valid_acc &amp;gt; best_acc:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            best_acc = valid_acc&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            torch.save(net.state_dict(), save_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Saving model with acc &amp;#123;:.3f&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(best_acc))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; writer_path &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后设定超参数训练模型：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;writer_path = &lt;span class=&#34;string&#34;&gt;&amp;#x27;../logs/FashionMNIST_train_log&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr, num_epochs = &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_classifier(net, train_iter, test_iter, num_epochs, lr, device, writer_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [ Train | epoch: 010/010 ] loss = 0.60980, acc = 0.80254&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [ Valid | epoch: 010/010 ] loss = 0.62191, acc = 0.79395&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下一章：&lt;a href=&#34;/posts/46068.html&#34;&gt;多层感知机&lt;/a&gt;。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/15604.html</guid>
            <title>动手学深度学习笔记(李沐)-预备知识</title>
            <link>https://asanosaki.github.io/posts/15604.html</link>
            <category>AI</category>
            <pubDate>Wed, 18 Jan 2023 16:37:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;李沐动手学深度学习（PyTorch）课程学习笔记第一章：预备知识。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-环境安装&#34;&gt;1. 环境安装&lt;/h2&gt;
&lt;p&gt;首先安装好 PyTorch 环境：&lt;a href=&#34;/posts/15428.html&#34;&gt;Anaconda与PyTorch安装教程&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;安装需要的包：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;pip install d2l&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-数据操作与数据预处理&#34;&gt;2. 数据操作与数据预处理&lt;/h2&gt;
&lt;p&gt;张量表示一个数值组成的数组，这个数组可能有多个维度：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.arange(&lt;span class=&#34;number&#34;&gt;12&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x)  &lt;span class=&#34;comment&#34;&gt;# tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以通过张量的 &lt;code&gt;shape&lt;/code&gt; 属性来访问张量的形状和张量中元素的总数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([12])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.numel())  &lt;span class=&#34;comment&#34;&gt;# 12&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;要改变一个张量的形状而不改变元素数量和元素值，我们可以调用 &lt;code&gt;reshape&lt;/code&gt; 函数：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = x.reshape(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[ 0,  1,  2,  3],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [ 4,  5,  6,  7],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [ 8,  9, 10, 11]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;使用全0、全1、其他常量或者从特定分布中随机采样的数字：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.zeros((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[0., 0., 0., 0.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [0., 0., 0., 0.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [0., 0., 0., 0.]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[0., 0., 0., 0.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [0., 0., 0., 0.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [0., 0., 0., 0.]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.ones((&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[1., 1., 1., 1.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [1., 1., 1., 1.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [1., 1., 1., 1.]],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [[1., 1., 1., 1.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [1., 1., 1., 1.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#          [1., 1., 1., 1.]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过提供包含数值的 Python 列表（或嵌套列表）来为所需张量中的每个元素赋予确定值：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor([&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x)  &lt;span class=&#34;comment&#34;&gt;# tensor([2, 3, 4, 5])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;常见的标准算术运算符（&lt;code&gt;+&lt;/code&gt;、&lt;code&gt;-&lt;/code&gt;、&lt;code&gt;*&lt;/code&gt;、&lt;code&gt;/&lt;/code&gt; 和 &lt;code&gt;**&lt;/code&gt;）都可以被升级为按元素运算：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor([&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = torch.tensor([&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;x + y:&amp;#x27;&lt;/span&gt;, x + y, &lt;span class=&#34;string&#34;&gt;&amp;#x27;x - y:&amp;#x27;&lt;/span&gt;, x - y)  &lt;span class=&#34;comment&#34;&gt;# x + y: tensor([3., 4., 5.]) x - y: tensor([-1., 0., 1.])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.exp(x))  &lt;span class=&#34;comment&#34;&gt;# tensor([ 2.7183,  7.3891, 20.0855])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们也可以把多个张量拼接在一起：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.arange(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, dtype=torch.float32).reshape(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = torch.tensor([[&lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# dim表示在哪个维度上拼接&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.cat((x, y), dim=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([4, 3])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.cat((x, y), dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;).shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([2, 6])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过逻辑运算符构建二元张量：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor([&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = torch.tensor([&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x == y)  &lt;span class=&#34;comment&#34;&gt;# tensor([True, False, True])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;对张量中的所有元素进行求和会产生一个只有一个元素的张量，或者指定在某一维度上求和：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor([[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;())  &lt;span class=&#34;comment&#34;&gt;# tensor(9)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# tensor([2, 3, 4])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;即使形状不同，我们仍然可以通过调用广播机制（broadcasting mechanism）来执行按元素操作：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.arange(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;).reshape((&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = torch.arange(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;).reshape((&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 必须维度一样才能广播，先将x复制成3行2列，再将y复制成3行2列，然后运算&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x + y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[0, 1],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [1, 2],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [2, 3]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;与 NumPy 张量相互转化：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;a = x.numpy()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b = torch.tensor(a)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(a), &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(b))  &lt;span class=&#34;comment&#34;&gt;# &amp;lt;class &amp;#x27;numpy.ndarray&amp;#x27;&amp;gt; &amp;lt;class &amp;#x27;torch.Tensor&amp;#x27;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;将大小为1的张量转换为 Python 标量：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor([&lt;span class=&#34;number&#34;&gt;3.5&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x, x.item(), &lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(x))  &lt;span class=&#34;comment&#34;&gt;# tensor([3.5000]) 3.5 3.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;创建一个人工数据集，并存储在 CSV（逗号分隔值）文件中：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;os.makedirs(os.path.join(&lt;span class=&#34;string&#34;&gt;&amp;#x27;..&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;data&amp;#x27;&lt;/span&gt;), exist_ok=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_file = os.path.join(&lt;span class=&#34;string&#34;&gt;&amp;#x27;..&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;data&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;house_tiny.csv&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(data_file, &lt;span class=&#34;string&#34;&gt;&amp;#x27;w&amp;#x27;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.write(&lt;span class=&#34;string&#34;&gt;&amp;#x27;NumRooms,Alley,Price\n&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 列名&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.write(&lt;span class=&#34;string&#34;&gt;&amp;#x27;NA,Pave,127500\n&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 每行表示一个数据样本&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.write(&lt;span class=&#34;string&#34;&gt;&amp;#x27;2,NA,106000\n&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.write(&lt;span class=&#34;string&#34;&gt;&amp;#x27;4,NA,178100\n&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    f.write(&lt;span class=&#34;string&#34;&gt;&amp;#x27;NA,NA,140000\n&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;从创建的 CSV 文件中加载原始数据集：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; pandas &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = pd.read_csv(data_file)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#    NumRooms Alley   Price&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 0       NaN  Pave  127500&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 1       2.0   NaN  106000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 2       4.0   NaN  178100&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 3       NaN   NaN  140000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;为了处理缺失的数据，典型的方法包括&lt;strong&gt;插值&lt;/strong&gt;和&lt;strong&gt;删除&lt;/strong&gt;，这里，我们将考虑插值：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;inputs, outputs = data.iloc[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], data.iloc[:, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]  &lt;span class=&#34;comment&#34;&gt;# 将data的第0、1列作为input，第2列作为output&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;inputs = inputs.fillna(inputs.mean(numeric_only=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# 将input中为NaN的数据用平均值填充&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(inputs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#    NumRooms Alley&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 0       3.0  Pave&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 1       2.0   NaN&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 2       4.0   NaN&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 3       3.0   NaN&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;对于 &lt;code&gt;inputs&lt;/code&gt; 中的类别值或离散值，我们可以将 &lt;code&gt;NaN&lt;/code&gt; 视为一个类别：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;inputs = pd.get_dummies(inputs, dummy_na=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(inputs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#    NumRooms  Alley_Pave  Alley_nan&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 0       3.0           1          0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 1       2.0           0          1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 2       4.0           0          1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 3       3.0           0          1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在 &lt;code&gt;inputs&lt;/code&gt; 和 &lt;code&gt;outputs&lt;/code&gt; 中的所有条目都是数值类型，它们可以转换为张量格式：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x, y = torch.tensor(inputs.values), torch.tensor(outputs.values)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x, y)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[3., 1., 0.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [2., 0., 1.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [4., 0., 1.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [3., 0., 1.]], dtype=torch.float64) tensor([127500, 106000, 178100, 140000])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-线性代数&#34;&gt;3. 线性代数&lt;/h2&gt;
&lt;p&gt;标量由只有一个元素的张量表示，你可以将向量视为标量值组成的列表：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor(&lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = torch.tensor(&lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x + y, x * y)  &lt;span class=&#34;comment&#34;&gt;# tensor(5.) tensor(6.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.arange(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x)  &lt;span class=&#34;comment&#34;&gt;# tensor([0, 1, 2, 3])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;访问张量的长度和形状：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(x))  &lt;span class=&#34;comment&#34;&gt;# 4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([4])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;矩阵和矩阵的转置：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;A = torch.arange(&lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;).reshape(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(A.T)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[0, 3, 6],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [1, 4, 7],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [2, 5, 8]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;给定具有相同形状的任何两个张量，任何按元素二元运算的结果都将是相同形状的张量：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;A = torch.arange(&lt;span class=&#34;number&#34;&gt;12&lt;/span&gt;, dtype=torch.float32).reshape(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;B = A.clone()  &lt;span class=&#34;comment&#34;&gt;# 通过分配新内存，将A的一个副本分配给B&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(A + B)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[ 0.,  2.,  4.,  6.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [ 8., 10., 12., 14.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [16., 18., 20., 22.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;求和与求平均值：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(A.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;())  &lt;span class=&#34;comment&#34;&gt;# tensor(66.)，所有元素求和&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(A.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(axis=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# tensor([12., 15., 18., 21.])，在第0维上求和&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(A.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(axis=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# tensor([ 6., 22., 38.])，在第1维上求和&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(A.mean())  &lt;span class=&#34;comment&#34;&gt;# tensor(5.5000)，所有元素均值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(A.mean(axis=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# tensor([1.5000, 5.5000, 9.5000])，在第1维上求均值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(A.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(axis=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, keepdims=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# 计算总和或均值时保持维度不变&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[ 6.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [22.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [38.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;点积是相同位置的按元素乘积的和，&lt;code&gt;torch.dot&lt;/code&gt; 只能对一维向量做点积。注意 NumPy 中的 &lt;code&gt;np.dot&lt;/code&gt; 函数计算的是两个矩阵的矩阵乘法，而非对应元素相乘求和：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.arange(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, dtype=torch.float32)  &lt;span class=&#34;comment&#34;&gt;# tensor([0., 1., 2., 3.])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = torch.ones(&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, dtype=torch.float32)  &lt;span class=&#34;comment&#34;&gt;# tensor([1., 1., 1., 1.])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.dot(x, y))  &lt;span class=&#34;comment&#34;&gt;# tensor(6.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;矩阵向量积：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.arange(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, dtype=torch.float32).reshape(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[0., 1., 2.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [3., 4., 5.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = torch.tensor([&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], dtype=torch.float32)  &lt;span class=&#34;comment&#34;&gt;# tensor([1., 2., 3.])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.mv(x, y))  &lt;span class=&#34;comment&#34;&gt;# tensor([ 8., 26.])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;矩阵乘法，&lt;code&gt;torch.mm&lt;/code&gt; 与 &lt;code&gt;np.dot&lt;/code&gt; 类似：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.arange(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, dtype=torch.float32).reshape(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[0., 1., 2.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [3., 4., 5.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = torch.ones(&lt;span class=&#34;number&#34;&gt;6&lt;/span&gt;, dtype=torch.float32).reshape(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[1., 1.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [1., 1.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [1., 1.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.mm(x, y))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[ 3.,  3.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [12., 12.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(np.dot(x, y))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# [[ 3.  3.]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#  [12. 12.]]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;L2 范数是向量所有元素的平方和的平方根：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor([&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;], dtype=torch.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.norm(x))  &lt;span class=&#34;comment&#34;&gt;# tensor(5.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.norm(x, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# tensor(5.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;L1 范数为向量所有元素的绝对值之和：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.&lt;span class=&#34;built_in&#34;&gt;abs&lt;/span&gt;(x).&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;())  &lt;span class=&#34;comment&#34;&gt;# tensor(7.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.norm(x, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# tensor(7.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;F 范数（弗罗贝尼乌斯范数）是矩阵所有元素的平方和的平方根：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.norm(torch.ones((&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;))))  &lt;span class=&#34;comment&#34;&gt;# tensor(6.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;4-自动微分&#34;&gt;4. 自动微分&lt;/h2&gt;
&lt;p&gt;先举一个简单的例子：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.arange(&lt;span class=&#34;number&#34;&gt;4.0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x)  &lt;span class=&#34;comment&#34;&gt;# tensor([0., 1., 2., 3.])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x.requires_grad_(&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 等价于x = torch.arange(4.0, requires_grad=True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.grad)  &lt;span class=&#34;comment&#34;&gt;# 默认值是None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; * torch.dot(x, x)  &lt;span class=&#34;comment&#34;&gt;# 计算y，注意一个标量函数关于向量x的梯度是向量，并且与x具有相同的形状&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(y)  &lt;span class=&#34;comment&#34;&gt;# tensor(28., grad_fn=&amp;lt;MulBackward0&amp;gt;)，隐式构造了计算图，所以有一个求梯度的函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y.backward()  &lt;span class=&#34;comment&#34;&gt;# 通过调用反向传播函数来自动计算y关于x每个分量的梯度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.grad)  &lt;span class=&#34;comment&#34;&gt;# tensor([ 0.,  4.,  8., 12.])，y=2*x*x的导数为4x&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.grad == &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt; * x)  &lt;span class=&#34;comment&#34;&gt;# tensor([True, True, True, True])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 现在计算x的另一个函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x.grad.zero_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = x.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.grad)  &lt;span class=&#34;comment&#34;&gt;# tensor([1., 1., 1., 1.])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;当 &lt;code&gt;y&lt;/code&gt; 不是标量时，向量 &lt;code&gt;y&lt;/code&gt; 关于向量 &lt;code&gt;x&lt;/code&gt; 的导数的最自然解释是一个矩阵。对于高阶和高维的 &lt;code&gt;y&lt;/code&gt; 和 &lt;code&gt;x&lt;/code&gt;，求导的结果可以是一个高阶张量。&lt;/p&gt;
&lt;p&gt;然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括深度学习中），但当调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 对非标量调用backward()需要传入一个gradient参数，该参数指定微分函数关于self的梯度。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 本例只想求偏导数的和，所以传递一个1的梯度是合适的&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x.grad.zero_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = x * x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(y)  &lt;span class=&#34;comment&#34;&gt;# tensor([0., 1., 4., 9.], grad_fn=&amp;lt;MulBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 等价于y.backward(torch.ones(len(x)))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.grad)  &lt;span class=&#34;comment&#34;&gt;# tensor([0., 2., 4., 6.])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;有时，我们希望将某些计算移动到记录的计算图之外。例如，假设 &lt;code&gt;y&lt;/code&gt; 是作为 &lt;code&gt;x&lt;/code&gt; 的函数计算的，而 &lt;code&gt;z&lt;/code&gt; 则是作为 &lt;code&gt;y&lt;/code&gt; 和 &lt;code&gt;x&lt;/code&gt; 的函数计算的。想象一下，我们想计算 &lt;code&gt;z&lt;/code&gt; 关于 &lt;code&gt;x&lt;/code&gt; 的梯度，但由于某种原因，希望将 &lt;code&gt;y&lt;/code&gt; 视为一个常数，并且只考虑到 &lt;code&gt;x&lt;/code&gt; 在 &lt;code&gt;y&lt;/code&gt; 被计算后发挥的作用。&lt;/p&gt;
&lt;p&gt;这里可以分离 &lt;code&gt;y&lt;/code&gt; 来返回一个新变量 &lt;code&gt;u&lt;/code&gt;，该变量与 &lt;code&gt;y&lt;/code&gt; 具有相同的值，但丢弃计算图中如何计算 &lt;code&gt;y&lt;/code&gt; 的任何信息。换句话说，梯度不会向后流经 &lt;code&gt;u&lt;/code&gt; 到 &lt;code&gt;x&lt;/code&gt;。因此，下面的反向传播函数计算 &lt;code&gt;z = u * x&lt;/code&gt; 关于 &lt;code&gt;x&lt;/code&gt; 的偏导数，同时将 &lt;code&gt;u&lt;/code&gt; 作为常数处理，而不是计算 &lt;code&gt;z = x * x * x&lt;/code&gt; 关于 &lt;code&gt;x&lt;/code&gt; 的偏导数。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;x.grad.zero_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = x * x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;u = y.detach()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = u * x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.grad == u)  &lt;span class=&#34;comment&#34;&gt;# tensor([True, True, True, True])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x.grad.zero_()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;().backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x.grad == &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; * x)  &lt;span class=&#34;comment&#34;&gt;# tensor([True, True, True, True])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;使用自动微分的一个好处是：即使构建函数的计算图需要通过 Python 控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到变量的梯度。在下面的代码中，&lt;code&gt;while&lt;/code&gt; 循环的迭代次数和 &lt;code&gt;if&lt;/code&gt; 语句的结果都取决于输入 &lt;code&gt;a&lt;/code&gt; 的值。对于任何 &lt;code&gt;a&lt;/code&gt;，存在某个常量标量 &lt;code&gt;k&lt;/code&gt;，使得 &lt;code&gt;d = f(a) = k * a&lt;/code&gt;，其中 &lt;code&gt;k&lt;/code&gt; 的值取决于输入 &lt;code&gt;a&lt;/code&gt;，因此可以用 &lt;code&gt;d / a&lt;/code&gt; 验证梯度是否正确。&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;f&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;a&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    b = a * &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;while&lt;/span&gt; b.norm() &amp;lt; &lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        b = b * &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; b.&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;() &amp;gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        c = b&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        c = &lt;span class=&#34;number&#34;&gt;100&lt;/span&gt; * b&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; c&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;a = torch.randn(size=(), requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d = f(a)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(a.grad == d / a)  &lt;span class=&#34;comment&#34;&gt;# tensor(True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下一章：&lt;a href=&#34;/posts/19931.html&#34;&gt;线性神经网络&lt;/a&gt;。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/33687.html</guid>
            <title>实用机器学习课程笔记(Stanford)</title>
            <link>https://asanosaki.github.io/posts/33687.html</link>
            <category>AI</category>
            <pubDate>Thu, 22 Dec 2022 10:28:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;Stanford 2021 秋季实用机器学习课程学习笔记。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-概论&#34;&gt;1. 概论&lt;/h2&gt;
&lt;h3 id=&#34;1-1-课程介绍&#34;&gt;1.1 课程介绍&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Challenges&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Formulate problem：关注最具影响力的行业问题（如自助超市、自动驾驶汽车等）。&lt;/li&gt;
&lt;li&gt;Data：高质量数据的稀缺、隐私问题。&lt;/li&gt;
&lt;li&gt;Train models：模型越来越复杂，需要大量数据，成本也越来越高。&lt;/li&gt;
&lt;li&gt;Deploy models：计算量大，不适合实时推理。&lt;/li&gt;
&lt;li&gt;Monitor：数据分布的变化、公平性问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Roles（不同类型的人在 ML 中的作用）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Domain experts（领域专家）：具有商业洞察力，知道什么数据是重要的以及在哪可以找到它，确定一个 ML 模型真正的影响。&lt;/li&gt;
&lt;li&gt;Data scientists：在 Data mining、Model training and deployment 方面做全栈的工作。&lt;/li&gt;
&lt;li&gt;ML experts：定制最先进（state of the art，SOTA）的 ML models。&lt;/li&gt;
&lt;li&gt;SDE（软件开发工程师）：开发/维护数据管道、模型训练和服务管道。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Corse topics&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本课程的内容为数据科学家需要的技术，但是没有大学传统的 ML/统计/编程方面的教学。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;收集、处理数据。&lt;/li&gt;
&lt;li&gt;部署的时候场景发生变化导致数据不一样，如 covariate（协变量）、concepts、label 的改变。&lt;/li&gt;
&lt;li&gt;独立同分布之外的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Train
&lt;ul&gt;
&lt;li&gt;模型验证、融合、调优。&lt;/li&gt;
&lt;li&gt;迁移学习（Transfer learning）。&lt;/li&gt;
&lt;li&gt;多模态（Multi-modality）：如何把不同的数据源融合起来做一个比较大的模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deploy
&lt;ul&gt;
&lt;li&gt;模型怎样部署。&lt;/li&gt;
&lt;li&gt;蒸馏（Distillation）：将比较大的模型提取出精华做的小一点。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Monitor
&lt;ul&gt;
&lt;li&gt;公平性，之后会讲模型的公平是什么含义。&lt;/li&gt;
&lt;li&gt;可解释性，怎样理解模型在干什么。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-2-数据获取&#34;&gt;1.2 数据获取&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Flow Chart for data acquisition&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Discover what data is available&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;找已经有的数据集。&lt;/li&gt;
&lt;li&gt;找基准数据集来检验我们的想法：
&lt;ul&gt;
&lt;li&gt;例如要做一个新的调超参数的算法，可能需要找一些数据集，且数据集不能太大，要小一点的或者中等大小的，为了客观地检验算法还要考虑找不同方面的数据集。&lt;/li&gt;
&lt;li&gt;如果训练比较深的神经网络就需要非常大的数据集。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;收集新数据（做一个应用或产品很多时候没有现成的数据集）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Source of popular ML datasets&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MNIST：手写数字。&lt;/li&gt;
&lt;li&gt;ImageNet：百万级别的来自搜索引擎的图片，可训练较为深度的模型。&lt;/li&gt;
&lt;li&gt;AudioSet：YouTube 上的一些声音的切片，用于做声音的分类。&lt;/li&gt;
&lt;li&gt;Kinetics：YouTube 上的一些视频的切片，用于人的行为分类。&lt;/li&gt;
&lt;li&gt;KITTI：摄像头或激光雷达等各种 sensor 记录下的交通场景。&lt;/li&gt;
&lt;li&gt;Amazon Review：Amazon 产品的用户评论。&lt;/li&gt;
&lt;li&gt;SQuAD：维基中的一些 Q-A 对。&lt;/li&gt;
&lt;li&gt;Librispeech：1000小时的有声读物。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;数据集两大来源：各个网站上爬取，采集数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Where to find datasets&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Paperwithcodes Datasets：学术数据集与排行榜。&lt;/li&gt;
&lt;li&gt;Kaggle Datasets：数据科学家提交的 ML datasets。&lt;/li&gt;
&lt;li&gt;Google Dataset search：搜索网页上的数据集。&lt;/li&gt;
&lt;li&gt;Various toolkits datasets（开源工具包）：TensorFlow、HuggingFace。&lt;/li&gt;
&lt;li&gt;会议/公司的 ML 竞赛。&lt;/li&gt;
&lt;li&gt;自己组织的 Data lakes（数据湖）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Datasets comparison&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;数据集&lt;/th&gt;
            &lt;th&gt;好处&lt;/th&gt;
            &lt;th&gt;坏处&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;学术数据集&lt;/td&gt;
            &lt;td&gt;数据干净、难度适中&lt;/td&gt;
            &lt;td&gt;选择面较小、太精简、规模小&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;竞赛数据集&lt;/td&gt;
            &lt;td&gt;更接近真实的 ML 应用&lt;/td&gt;
            &lt;td&gt;仍较精简，且只专注在较热门的应用&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;原生数据&lt;/td&gt;
            &lt;td&gt;很灵活&lt;/td&gt;
            &lt;td&gt;需要很多精力去预处理&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Data integration&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;产品数据通常存放在不同的表中，因此要涉及到表的连接。&lt;/p&gt;
&lt;table&gt;
    &lt;caption&gt;Table 1&lt;/caption&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;ID&lt;/th&gt;
            &lt;th&gt;Val 1&lt;/th&gt;
            &lt;th&gt;Val 2&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1_val1&lt;/td&gt;
            &lt;td&gt;1_val2&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;2&lt;/td&gt;
            &lt;td&gt;2_val1&lt;/td&gt;
            &lt;td&gt;2_val2&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
    &lt;caption&gt;Table 2&lt;/caption&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;ID&lt;/th&gt;
            &lt;th&gt;Val 3&lt;/th&gt;
            &lt;th&gt;Val 4&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1_val3&lt;/td&gt;
            &lt;td&gt;1_val4&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;3&lt;/td&gt;
            &lt;td&gt;3_val3&lt;/td&gt;
            &lt;td&gt;3_val4&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
    &lt;caption&gt;Inner Join T1 &amp; T2&lt;/caption&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;ID&lt;/th&gt;
            &lt;th&gt;Val 1&lt;/th&gt;
            &lt;th&gt;Val 2&lt;/th&gt;
            &lt;th&gt;Val 3&lt;/th&gt;
            &lt;th&gt;Val 4&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1_val1&lt;/td&gt;
            &lt;td&gt;1_val2&lt;/td&gt;
            &lt;td&gt;1_val3&lt;/td&gt;
            &lt;td&gt;1_val4&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
    &lt;caption&gt;Left Join T1 &amp; T2&lt;/caption&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;ID&lt;/th&gt;
            &lt;th&gt;Val 1&lt;/th&gt;
            &lt;th&gt;Val 2&lt;/th&gt;
            &lt;th&gt;Val 3&lt;/th&gt;
            &lt;th&gt;Val 4&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1_val1&lt;/td&gt;
            &lt;td&gt;1_val2&lt;/td&gt;
            &lt;td&gt;1_val3&lt;/td&gt;
            &lt;td&gt;1_val4&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;2&lt;/td&gt;
            &lt;td&gt;2_val1&lt;/td&gt;
            &lt;td&gt;2_val2&lt;/td&gt;
            &lt;td&gt;/&lt;/td&gt;
            &lt;td&gt;/&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;1-3-网页数据抓取&#34;&gt;1.3 网页数据抓取&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一般不能用 &lt;code&gt;curl&lt;/code&gt;，因为网站所有者能使用各种方法阻止。&lt;/li&gt;
&lt;li&gt;使用无头浏览器（一个没有 GUI 的网络浏览器）：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; selenium &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; webdriver&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;chrome_options = webdriver.ChromeOptions()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;chrome_options.headless = &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;chrome = webdriver.Chrome(chrome_options = chrome_options)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;page = chrome.get(url)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;你需要大量的新 IP，可以通过云获得很多 IP。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-4-数据标注&#34;&gt;1.4 数据标注&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;半监督学习Semi-Supervised Learning（SSL）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;重点关注有少量标记数据和大量未标记数据的场景。&lt;/li&gt;
&lt;li&gt;对没有标注的数据和有标注的数据的数据分布做一些假设：
&lt;ul&gt;
&lt;li&gt;连续性假设（Continuity assumption）：如果一个样本的特征和另外一个样本相似，那么这两个样本很可能具有相同的标号。&lt;/li&gt;
&lt;li&gt;聚类假设（Cluster assumption）：数据具有内在的聚类结构，那么假设一个类里面具有相同的标号。&lt;/li&gt;
&lt;li&gt;流形假设（Manifold assumption）：很有可能数据在本质上是在低维的一个流形上分布的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;自学习Self-training&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主动学习Active Learning&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;关注的场景与 SSL 相同，但有人工干预，即选择最有趣的数据（最重要的没有标号的数据）给标注工标注。&lt;/li&gt;
&lt;li&gt;不确定性抽样（Uncertainty sampling）：选择一个最不确信的预测让人来判断。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Active Learning + Self-training&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;弱监督学习Weak Supervision&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;半自动地生成标号，通常比手动标注的准确率差，但是也是好到可以训练一个还不错的模型。&lt;/li&gt;
&lt;li&gt;数据编程（Data programming）：用启发式的方法赋予标号：
&lt;ul&gt;
&lt;li&gt;关键字搜索、模式匹配、第三方模型。&lt;/li&gt;
&lt;li&gt;假设判断一个 YouTube 的评论是垃圾（spam）还是有用的东西（ham）：&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;check_out&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; SPAM &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;check out&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; x.lower() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; ABSTAIN&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;sentiment&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; HAM &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; sentiment_polarity(x) &amp;gt; &lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; ABSTAIN&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-机器学习模型&#34;&gt;2. 机器学习模型&lt;/h2&gt;
&lt;h3 id=&#34;2-1-机器学习模型概览&#34;&gt;2.1 机器学习模型概览&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;ML 算法的种类&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;监督学习（Supervised）：训练有标签的数据来预测标签。
&lt;ul&gt;
&lt;li&gt;自监督学习（Self-supervised）：标签的生成来自于数据本身。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;半监督学习（Semi-supervised）：在有标签和无标签的数据上进行训练，使用模型来预测无标签数据的标签。&lt;/li&gt;
&lt;li&gt;无监督学习（Unsupervised）：在未标记的数据上进行训练。&lt;/li&gt;
&lt;li&gt;强化学习（Reinforcement）：利用观察与环境互动的结果来采取行动以最大化收益。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本课程最多讨论的内容为监督学习。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;监督学习的组成部分&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型（Model）：将输入映射到标签的参数化函数。&lt;/li&gt;
&lt;li&gt;损失（Loss）：衡量模型在预测结果方面有多好，即衡量模型预测出来的值和真实值之间的差距，需要指导模型尽量向真实值靠近。&lt;/li&gt;
&lt;li&gt;目标函数（Objective）：优化模型参数的目标，例如需要优化模型在训练集合上的所有预测结果的损失之和最小。&lt;/li&gt;
&lt;li&gt;优化（Optimization）：解决 Objective 的算法，即把模型中没有指定的参数（可学习的参数）优化为合适的值，使得能够解决目标函数，也就是最小化损失。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;监督学习的模型&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;决策树（Decision trees）：用树来做决定。&lt;/li&gt;
&lt;li&gt;线性模型（Linear methods）：决策是根据输入特征的线性组合做出的。&lt;/li&gt;
&lt;li&gt;核方法（Kernel machines）：使用核函数衡量两个样本的特征相似度，达到非线性的效果。&lt;/li&gt;
&lt;li&gt;神经网络（Neural Networks）：使用神经网络学习特征表示。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-2-决策树&#34;&gt;2.2 决策树&lt;/h3&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以用来解释，即训练后的模型可以看到叶子结点是什么内容，决策是怎么一步步做下来的。&lt;/li&gt;
&lt;li&gt;能够处理数值和类别的特征。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;非常不稳定，可能数据内产生了一点噪音后整棵树构建出来的样子就不一样了。&lt;/li&gt;
&lt;li&gt;如果数据特别复杂，会生成一个特别复杂的树，可以把整个数据里面的各种情况列出来，生成大量的节点，最后会导致过拟合。&lt;/li&gt;
&lt;li&gt;不容易并行计算。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;随机森林&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;训练多个决策树以提高稳定性。
&lt;ul&gt;
&lt;li&gt;树是并行地独立训练的。&lt;/li&gt;
&lt;li&gt;对于分类问题可以用多数投票法（例如超过一半的树觉得类别是1，那么它就是1），对于回归问题可以在多棵树上取平均。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;为什么叫随机呢？
&lt;ul&gt;
&lt;li&gt;Bagging：&lt;strong&gt;随机&lt;/strong&gt;抽取训练样本并进行替换。例如样本本来是 &lt;code&gt;[1, 2, 3, 4, 5]&lt;/code&gt;，做 Bagging 的时候在里面随机采样5个出来，但是采样可能是有重复的，采样到的结果为 &lt;code&gt;[1, 2, 2, 3, 4]&lt;/code&gt;，然后拿到这个 Bagging 出来的数据集后我们就在上面训练一棵树，然后一直重复训练 N 棵树为止。&lt;/li&gt;
&lt;li&gt;随机选择一个特征子集，即把 Bagging 出的数据拿出来之后，再从里面的特征中&lt;strong&gt;随机&lt;/strong&gt;采样一些特征列出来（假设树是一个表，那么就是先随机采样出一些行，再随机采样出一些列）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-3-线性模型&#34;&gt;2.3 线性模型&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;线性回归&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个简单的房价预测模型：
&lt;ul&gt;
&lt;li&gt;假设有3个特征：卧室数量 &lt;code&gt;x1&lt;/code&gt;、浴室数量 &lt;code&gt;x2&lt;/code&gt;、居住面积 &lt;code&gt;x3&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;预测价格为：&lt;code&gt;y_hat = w1 * x1 + w2 * x2 + w3 * x3 + b&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;权重 &lt;code&gt;w1, w2, w3&lt;/code&gt; 和偏置 &lt;code&gt;b&lt;/code&gt; 将从训练数据中学习。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一般来说，给定数据 &lt;code&gt;x = [x1, x2, ..., xp]&lt;/code&gt;，线性回归的预测为：&lt;code&gt;y_hat = w1 * x1 + w2 * x2 + ... + wp * xp + b = &amp;lt;w, x&amp;gt; + b&lt;/code&gt;（其中 &lt;code&gt;w&lt;/code&gt; 和 &lt;code&gt;x&lt;/code&gt; 为长度为 &lt;code&gt;p&lt;/code&gt; 的向量，&lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt; 表示内积运算，&lt;code&gt;w&lt;/code&gt; 和 &lt;code&gt;b&lt;/code&gt; 都是可学习参数）。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# weight w has shape (p, 1)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# bias b is a scalar&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# data x has shape (p, 1)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_hat = (x * w).&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;() + b&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;线性回归目标函数&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设我们收集了 &lt;code&gt;n&lt;/code&gt; 个训练样本 &lt;code&gt;X = [x1, x2, ..., xn]&lt;/code&gt;，其中每个 &lt;code&gt;xi&lt;/code&gt; 均为长为 &lt;code&gt;p&lt;/code&gt; 的向量，将其转置后即为一个 &lt;code&gt;n&lt;/code&gt; 行 &lt;code&gt;p&lt;/code&gt; 列的矩阵，其对应的标号为 &lt;code&gt;y = [y1, ..., yn]&lt;/code&gt;，是一个长为 &lt;code&gt;n&lt;/code&gt; 的向量。&lt;/p&gt;
&lt;p&gt;目标函数是最小化均方误差（MSE），即优化 &lt;code&gt;w, b&lt;/code&gt; 的值使得 &lt;code&gt;sum((yi - &amp;lt;xi, w&amp;gt; - b)**2) / n&lt;/code&gt; 最小。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;线性回归在分类问题中的应用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;回归的输出是一个连续的实数，而对于分类问题，我们要输出对某个样本的类别的预测。&lt;/p&gt;
&lt;p&gt;多类别分类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;假设标签为独热编码，即 &lt;code&gt;y = [y1, y2, ..., ym]&lt;/code&gt;，如果该样本为第 &lt;code&gt;i&lt;/code&gt; 类则 &lt;code&gt;yi = 1&lt;/code&gt;，否则 &lt;code&gt;yi = 0&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;预测结果 &lt;code&gt;y_hat = [o1, o2, ..., om]&lt;/code&gt;，其中 &lt;code&gt;oi&lt;/code&gt; 表示预测该样本为第 &lt;code&gt;i&lt;/code&gt; 类的概率。&lt;/li&gt;
&lt;li&gt;为每个类学习一个线性模型：&lt;code&gt;oi = &amp;lt;x, wi&amp;gt; + bi&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;最小化 MSE 损失函数：&lt;code&gt;(y_hat - y)**2 / m&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;预测结果所表示的类为 &lt;code&gt;m&lt;/code&gt; 个概率中最大的那个，即 &lt;code&gt;argmax(y_hat)&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Mini-batch 随机梯度下降&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# &amp;#x27;batch_size&amp;#x27; 为批大小，&amp;#x27;features&amp;#x27; 为所有样本的特征即 X，&amp;#x27;labels&amp;#x27; 为标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# &amp;#x27;features&amp;#x27; shape is (n, p), `labels` shape is (n, 1)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;data_iter&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;batch_size, features, labels&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_examples = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(features)  &lt;span class=&#34;comment&#34;&gt;# 样本数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    indices = &lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_examples))  &lt;span class=&#34;comment&#34;&gt;# 下标&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    random.shuffle(indices)  &lt;span class=&#34;comment&#34;&gt;# 随机打乱&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, num_examples, batch_size):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        batch_indices = torch.tensor(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            indices[i:&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;(i + batch_size, num_examples)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;yield&lt;/span&gt; features[batch_indices], labels[batch_indices]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# w 用均值为0，方差为0.01的高斯分布初始化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;w = torch.normal(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;, size=(p, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b = torch.zeros(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, requires_grad=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(num_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; x, y &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; data_iter(batch_size, features, labels):  &lt;span class=&#34;comment&#34;&gt;# 随机取出一个 batch&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        y_hat = np.dot(x, w) + b&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = ((y_hat - y)**&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt; / &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;).mean()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; param &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; [w, b]:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            param -= learning_rate * param.grad&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            param.grad.zero_()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;2-4-神经网络&#34;&gt;2.4 神经网络&lt;/h3&gt;
&lt;p&gt;神经网络就是将手工特征提取的部分换成了一个神经网络。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;神经网络通常需要更多的数据和更多的计算，一般都是大&lt;strong&gt;数个数量级&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;可以选择不同的神经网络架构来更有效地抽取我们的特征：
&lt;ul&gt;
&lt;li&gt;多层感知机。&lt;/li&gt;
&lt;li&gt;卷积神经网络。&lt;/li&gt;
&lt;li&gt;循环神经网络。&lt;/li&gt;
&lt;li&gt;Transformers。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;设计神经网络以结合数据的先验知识。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;线性模型到多层感知机（Multilayer Perceptron，MLP）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;引入一种全连接层（稠密层，dense），假设输入样本数量为 &lt;code&gt;n&lt;/code&gt;，每个样本的特征长度为 &lt;code&gt;m&lt;/code&gt;，那么全连接层具有两个可学习参数 &lt;code&gt;w, b&lt;/code&gt;，其中 &lt;code&gt;w&lt;/code&gt; 是一个 &lt;code&gt;n&lt;/code&gt; 行 &lt;code&gt;m&lt;/code&gt; 列的实数矩阵，&lt;code&gt;b&lt;/code&gt; 是一个长为 &lt;code&gt;n&lt;/code&gt; 的向量。则全连接层的计算结果为：&lt;code&gt;y = np.dot(w, x) + b&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;线性回归可以认为是一个只有一个输出的全连接层。&lt;/li&gt;
&lt;li&gt;Softmax 回归可以认为是一个有 C 个输出的全连接层，C 表示类别的数量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;多层感知机的目的是实现一个非线性的模型，但是如果只是简单使用多个全连接层是没用的，多个线性操作的叠加还是一个线性操作，因此还需要加入非线性函数（激活函数）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;激活函数是一个基于元素的非线性函数：
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sigmoid(x) = 1 / (1 + np.exp(-x))&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;relu(x) = max(x, 0)&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;非线性的激活函数能让我们得到非线性模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可以堆叠多个隐藏层（例如多个 dense 层和 activation 层堆叠），得到更深层次的模型。&lt;/li&gt;
&lt;li&gt;超参数：隐藏层数量 &lt;code&gt;hidden layers&lt;/code&gt;，每个隐藏层的输出大小 &lt;code&gt;outputs of each hidden layer&lt;/code&gt;（最后一层的输出无法改变）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码实现：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;relu&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;×&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; torch.&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;(x, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# &amp;#x27;num_hiddens&amp;#x27; 为超参数，randn() 产生均值为0，方差为1的正态分布&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;w1 = nn.Parameter(torch.randn(num_inputs, num_hiddens) * &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b1 = nn.Parameter(torch.zeros(num_hiddens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;w2 = nn.Parameter(torch.randn(num_hiddens, num_outputs) * &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b2 = nn.Parameter(torch.zeros(num_outputs))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;H = relu(np.dot(x, w1) + b1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = np.dot(H, w2) + b2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;2-5-卷积神经网络&#34;&gt;2.5 卷积神经网络&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;全连接层到卷积神经网络&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以一个图像识别任务为例，使用 MLP 模型学习 ImageNet（每张图像大小为300*300像素，有1000个类别），我们假设其中一个隐藏层具有10000个输出：
&lt;ul&gt;
&lt;li&gt;它会产生10亿个可学习参数，这太大了！&lt;/li&gt;
&lt;li&gt;因为全连接的输出是所有输入元素的加权和，而且每个输出的权重是不一样的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;识别图像中的物体：
&lt;ul&gt;
&lt;li&gt;平移不变性：无论对象在哪里，输出都是相似的。&lt;/li&gt;
&lt;li&gt;局部性：像素与其周围像素的相关性比较高，因为图像中的物体都是连续性的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;将先验知识构建到模型结构中：
&lt;ul&gt;
&lt;li&gt;用更少的参数（#params）实现相同的模型容量。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;卷积层（Convolution layer）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;局部性：从 &lt;code&gt;k * k&lt;/code&gt; 大小的输入窗口计算输出，即做局部的计算。&lt;/li&gt;
&lt;li&gt;平移不变性：输出使用相同的 &lt;code&gt;k * k&lt;/code&gt; 权重（核）。&lt;/li&gt;
&lt;li&gt;卷积层的模型参数不依赖于输入/输出的大小。&lt;/li&gt;
&lt;li&gt;一个卷积核可以被学习成去识别一个图像里面的模式，比如识别绿色通道中的某个块状物体，识别某个方向上的纹理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# both input `X` and weight `K` are matrices（矩阵）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;h, w = K.shape  &lt;span class=&#34;comment&#34;&gt;# 一般长和宽都是相等的，例如3、5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = torch.zeros((X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] - h + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, X.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] - w + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# 卷积输出的矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# stride = 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(Y.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; j &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(Y.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        Y[i, j] = (X[i:i + h, j:j + w] * K).&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;池化层（Pooling layer）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;卷积层对输入的位置很敏感，即输入中模式的转换/旋转会导致输出中模式类似地变化，因此我们需要一定的对未知移动的鲁棒性。&lt;/li&gt;
&lt;li&gt;池化层在大小为 &lt;code&gt;k * k&lt;/code&gt; 的窗口中计算平均值/最大值/最小值。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# h, w: pooling window height and width&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# mode: max or avg&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Y = torch.zeros((X.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] - h + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, X.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] - w + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(Y.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; j &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(Y.shape[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; mode == &lt;span class=&#34;string&#34;&gt;&amp;#x27;max&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            Y[i, j] = X[i:i + h, j:j + w].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;elif&lt;/span&gt; mode == &lt;span class=&#34;string&#34;&gt;&amp;#x27;avg&amp;#x27;&lt;/span&gt;: &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            Y[i, j] = X[i:i + h, j:j + w].mean() &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;卷积神经网络（Convolutional Neural Networks，CNN）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;卷积神经网络的原理为叠加卷积层来提取特征。
&lt;ul&gt;
&lt;li&gt;激活函数应用于每个卷积层之后。&lt;/li&gt;
&lt;li&gt;使用池化操作来降低位置敏感性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;现代 CNN 是具有各种超参数和层连接的深度神经网络（AlexNet, VGG, inception, ResNet, MobileNet）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-6-循环神经网络&#34;&gt;2.6 循环神经网络&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;全连接层到循环神经网络&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;语言模型：给出一个句子前面的一些词，预测下一个词是什么。例如：&lt;code&gt;hello -&amp;gt; world&lt;/code&gt;、&lt;code&gt;hello world -&amp;gt; !&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;单纯使用 MLP 不能很好地处理序列信息，例如长度的变化和时序的变化。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;循环神经网络的原理为将上一个全连接层输出的状态复制一份作为隐藏状态 H，与下一个输入状态进行拼接后再进行预测。即：&lt;code&gt;h_t = RNN(W_hh * h&#39; + W_hx * x_t + b_h)&lt;/code&gt;，其中 &lt;code&gt;h&#39;&lt;/code&gt; 为隐藏状态，&lt;code&gt;x_t&lt;/code&gt; 为当前输入。&lt;/p&gt;
&lt;p&gt;代码：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;W_xh = nn.Parameter(torch.randn(num_inputs, num_hiddens) * &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;W_hh = nn.Parameter(torch.rand(num_hiddens, num_hiddens) * &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b_h = nn.Parameter(torch.zeros(num_hiddens))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;H = torch.zeros(num_hiddens)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;outputs = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; X &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; inputs:  &lt;span class=&#34;comment&#34;&gt;# `inputs` shape : (num_steps, batch_size, num_inputs)，num_steps表示时间维度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    H = torch.tanh(np.dot(X, W_xh) + np.dot(H, W_hh) + b_h)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    outputs.append(H)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;3-模型评估&#34;&gt;3. 模型评估&lt;/h2&gt;
&lt;h3 id=&#34;3-1-评估指标&#34;&gt;3.1 评估指标&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;损失（Loss）衡量模型在预测监督学习结果的方面有多好。&lt;/li&gt;
&lt;li&gt;评估模型性能的其他指标：
&lt;ul&gt;
&lt;li&gt;模型相关的指标：例如分类的精度，物体检测的 mAP。&lt;/li&gt;
&lt;li&gt;商业相关的指标：例如收益，推理延迟（如模型能在100毫秒之内返回结果）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;我们一般通过考虑多种指标来选择模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;二分类的评估指标&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Accuracy：正确的预测数量/样本总数&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(y == y_hat) / y.size&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;Precision：预测结果为类 &lt;code&gt;i&lt;/code&gt; 且实际结果也为类 &lt;code&gt;i&lt;/code&gt; 的数量/预测结果为类 &lt;code&gt;i&lt;/code&gt; 的数量&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;((y_hat == i) &amp;amp; (y == i)) / &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(y_hat == i)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;Recall：预测结果为类 &lt;code&gt;i&lt;/code&gt; 且实际结果也为类 &lt;code&gt;i&lt;/code&gt; 的数量/实际结果为类 &lt;code&gt;i&lt;/code&gt; 的数量&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;((y_hat == i) &amp;amp; (y == i)) / &lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;(y == i)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;F1：平衡 Precision 和 Recall 的指标，为 Precision 和 Recall 的调和平均值：&lt;code&gt;2pr / (p + r)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;二分类中的 AUC 和 ROC&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AUC 为 ROC 曲线下的面积，大小范围为 &lt;code&gt;[0.5, 1]&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;衡量模型分离这两个类的能力。&lt;/li&gt;
&lt;li&gt;选择决策阈值 &lt;code&gt;x&lt;/code&gt;，如果输出 &lt;code&gt;y_hat &amp;gt;= x&lt;/code&gt; 则预测为正类，否则为负类。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;展示广告的商业指标&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最优化收入和客户体验。
&lt;ul&gt;
&lt;li&gt;Latency：广告应该与其他内容同时显示给用户。&lt;/li&gt;
&lt;li&gt;ASN：平均每页显示的广告数量。&lt;/li&gt;
&lt;li&gt;CTR：用户实际点击率。&lt;/li&gt;
&lt;li&gt;ACP：广告商每次点击支付的平均价格。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;收益 = 页面浏览量 * ASN * CTR * ACP。&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Image base64 code --&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://asanosaki.github.io/posts/48394.html</guid>
            <title>PyTorch深度学习入门(CIFAR10分类)</title>
            <link>https://asanosaki.github.io/posts/48394.html</link>
            <category>AI</category>
            <pubDate>Thu, 01 Dec 2022 18:22:00 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;通过 CIFAR10 数据集的分类问题初入门 Deep Learning，也是开坑 AI 系列的第一篇文章。&lt;br&gt;
相关环境的搭建可以转至：&lt;a href=&#34;/posts/15428.html&#34;&gt;Anaconda与PyTorch安装教程&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;1-常用函数&#34;&gt;1. 常用函数&lt;/h2&gt;
&lt;p&gt;（1）路径函数&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;os&lt;/code&gt; 模块中常用的路径相关函数有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;os.listdir(path)&lt;/code&gt;：将 &lt;code&gt;path&lt;/code&gt; 目录下的内容列成一个 &lt;code&gt;list&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;os.path.join(path1, path2)&lt;/code&gt;：拼接路径：&lt;code&gt;path1\path2&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dir_path = &lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/hymenoptera_data/train/ants_image&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_path_list = os.listdir(dir_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_full_path = os.path.join(dir_path, img_path_list[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(img_path_list)  &lt;span class=&#34;comment&#34;&gt;# [&amp;#x27;0013035.jpg&amp;#x27;, &amp;#x27;1030023514_aad5c608f9.jpg&amp;#x27;, ...]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(img_full_path)  &lt;span class=&#34;comment&#34;&gt;# dataset/hymenoptera_data/train/ants_image\0013035.jpg&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;（2）辅助函数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dir()&lt;/code&gt;：不带参数时，返回当前范围内的变量、方法和定义的类型列表；带参数时，返回参数的属性、方法列表。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;help(func)&lt;/code&gt;：查看函数 &lt;code&gt;func&lt;/code&gt; 的使用说明。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;dir&lt;/span&gt;(torch))  &lt;span class=&#34;comment&#34;&gt;# [&amp;#x27;AVG&amp;#x27;, &amp;#x27;AggregationType&amp;#x27;, ..., &amp;#x27;cuda&amp;#x27;, ...]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;help&lt;/span&gt;(torch.cuda.is_available)  &lt;span class=&#34;comment&#34;&gt;# Help on function is_available in module torch.cuda: is_available() -&amp;gt; bool...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;2-数据加载&#34;&gt;2. 数据加载&lt;/h2&gt;
&lt;h3 id=&#34;2-1-Dataset&#34;&gt;2.1 Dataset&lt;/h3&gt;
&lt;p&gt;数据读取和预处理是进行机器学习的首要操作，PyTorch 提供了很多方法来完成数据的读取和预处理。&lt;/p&gt;
&lt;p&gt;其中 Dataset 表示数据集，&lt;code&gt;torch.utils.data.Dataset&lt;/code&gt; 是代表这一数据的抽象类。你可以自己定义你的数据类，继承和重写这个抽象类，非常简单，只需要定义 &lt;code&gt;__len__&lt;/code&gt; 和 &lt;code&gt;__getitem__&lt;/code&gt; 这个两个函数即可，例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Dataset&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; PIL &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Image&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;MyData&lt;/span&gt;(&lt;span class=&#34;title class_ inherited__&#34;&gt;Dataset&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, root_dir, label_dir&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.root_dir = root_dir&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.label_dir = label_dir&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.path = os.path.join(self.root_dir, self.label_dir + &lt;span class=&#34;string&#34;&gt;&amp;#x27;_image&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.img_path_list = os.listdir(self.path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__getitem__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, idx&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        img_path = self.img_path_list[idx]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        img_full_path = os.path.join(self.root_dir, self.label_dir + &lt;span class=&#34;string&#34;&gt;&amp;#x27;_image&amp;#x27;&lt;/span&gt;, img_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        img = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(img_full_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        label = self.label_dir&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; img, label&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__len__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(self.img_path_list)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;root_dir = &lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/hymenoptera_data/train&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ants_label_dir = &lt;span class=&#34;string&#34;&gt;&amp;#x27;ants&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ants_data = MyData(root_dir, ants_label_dir)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img, label = ants_data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(img, label)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过上面的方式，可以定义我们需要的数据类，可以通过迭代的方式来获取每一个数据，但这样很难实现取 batch、shuffle 或者是多线程去读取数据。&lt;/p&gt;
&lt;h3 id=&#34;2-2-DataLoader&#34;&gt;2.2 DataLoader&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;torch.utils.data.DataLoader&lt;/code&gt; 构建可迭代的数据装载器，我们在训练的时候，每一个 &lt;code&gt;for&lt;/code&gt; 循环，每一次 iteration，就是从 &lt;code&gt;DataLoader&lt;/code&gt; 中获取一个 &lt;code&gt;batch_size&lt;/code&gt; 大小的数据的。打个比方如果 &lt;code&gt;Dataset&lt;/code&gt; 是一副完整的扑克牌，那么 &lt;code&gt;DataLoader&lt;/code&gt; 就是抽取几张组成的一部分扑克牌。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DataLoader&lt;/code&gt; 的参数很多，但我们常用的主要有以下几个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dataset&lt;/code&gt;：&lt;code&gt;Dataset&lt;/code&gt; 类，决定从哪个数据集读取数据。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batch_size&lt;/code&gt;：批大小。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_works&lt;/code&gt;：是否多进程读取机制。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;shuffle&lt;/code&gt;：每个 Epoch 是否乱序。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;drop_last&lt;/code&gt;：当样本数不能被 &lt;code&gt;batch_size&lt;/code&gt; 整除时，是否舍弃最后一批数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要理解这个 &lt;code&gt;drop_last&lt;/code&gt;，首先，得先理解 Epoch、Iteration 和 Batch_size 的概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Epoch：所有训练样本都已输入到模型中，称为一个 Epoch。&lt;/li&gt;
&lt;li&gt;Iteration：一批样本输入到模型中，称为一个 Iteration。&lt;/li&gt;
&lt;li&gt;Batch_size：一批样本的大小，决定一个 Epoch 有多少个 Iteration。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;DataLoader&lt;/code&gt; 的作用就是构建一个数据装载器，根据我们提供的 &lt;code&gt;batch_size&lt;/code&gt; 的大小，将数据样本分成一个个的 Batch 去训练模型，而这个分的过程中需要把数据取到，这个就是借助 &lt;code&gt;Dataset&lt;/code&gt; 的 &lt;code&gt;__getitem__&lt;/code&gt; 方法。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Dataset, DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; PIL &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Image&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;MyData&lt;/span&gt;(&lt;span class=&#34;title class_ inherited__&#34;&gt;Dataset&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, root_dir, label_dir, transform&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.root_dir = root_dir&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.label_dir = label_dir&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.path = os.path.join(self.root_dir, self.label_dir + &lt;span class=&#34;string&#34;&gt;&amp;#x27;_image&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.img_path_list = os.listdir(self.path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.transform = transform  &lt;span class=&#34;comment&#34;&gt;# transform 的方式&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__getitem__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, idx&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        img_path = self.img_path_list[idx]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        img_full_path = os.path.join(self.root_dir, self.label_dir + &lt;span class=&#34;string&#34;&gt;&amp;#x27;_image&amp;#x27;&lt;/span&gt;, img_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        img = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(img_full_path).convert(&lt;span class=&#34;string&#34;&gt;&amp;#x27;RGB&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 先将图片转换成三通道&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; self.transform &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            img = self.transform(img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        label = self.label_dir&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; img, label&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__len__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(self.img_path_list)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;root_dir = &lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/hymenoptera_data/train&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ants_label_dir = &lt;span class=&#34;string&#34;&gt;&amp;#x27;ants&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trans_dataset = transforms.Compose([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.Resize((&lt;span class=&#34;number&#34;&gt;83&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;)),  &lt;span class=&#34;comment&#34;&gt;# tensor 大小必须统一&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.ToTensor()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ants_data = MyData(root_dir, ants_label_dir, trans_dataset)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_loader = DataLoader(dataset=ants_data, batch_size=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, drop_last=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(train_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs, labels = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(imgs))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(imgs[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(labels)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(labels[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来使用 CIFAR10 数据集再展示一次 &lt;code&gt;DataLoader&lt;/code&gt; 的用法：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms, datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_set = datasets.CIFAR10(root=&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor(), download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_loader = DataLoader(dataset=test_set, batch_size=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, drop_last=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;logs&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# 循环两个 epoch&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(test_loader):  &lt;span class=&#34;comment&#34;&gt;# step 表示第几个 batch&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_images(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Epoch_&amp;#123;&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(epoch), imgs, step)  &lt;span class=&#34;comment&#34;&gt;# 注意是 add_images，图像默认格式为 NCHW&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;PS：部分看不懂的代码可以先去学后面的 &lt;code&gt;transform&lt;/code&gt; 以及 &lt;code&gt;tensorboard&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;3-TensorBoard&#34;&gt;3. TensorBoard&lt;/h2&gt;
&lt;h3 id=&#34;3-1-add-scalar&#34;&gt;3.1 add_scalar&lt;/h3&gt;
&lt;p&gt;TensorBoard 原本是 TensorFlow 的可视化工具，PyTorch 从1.2.0开始支持 TensorBoard。之前的版本也可以使用 TensorBoardX 代替。&lt;/p&gt;
&lt;p&gt;先进入 Anaconda 的 PyTorch 环境，安装 TensorBoard：&lt;/p&gt;
&lt;figure class=&#34;highlight shell&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;conda activate PyTorch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pip install tensorboard&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在项目根目录下新建一个文件夹 &lt;code&gt;logs&lt;/code&gt;，TensorBoard 的工作流程简单来说是将代码运行过程中的，某些你关心的数据保存在这个文件夹中（由代码中的 &lt;code&gt;writer&lt;/code&gt; 完成），再读取这个文件夹中的数据，用浏览器显示出来（在命令行运行 TensorBoard 完成）。&lt;/p&gt;
&lt;p&gt;我们先绘制一个 &lt;code&gt;y = x&lt;/code&gt; 的图像，运行以下代码：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;logs&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; x &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;y=x&amp;#x27;&lt;/span&gt;, x, x)  &lt;span class=&#34;comment&#34;&gt;# tag=&amp;#x27;y=x&amp;#x27;, scalar_value=x, global_step=x&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;add_scalar&lt;/code&gt; 函数主要有三个参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tag&lt;/code&gt;：数据标识符，可以理解为数据图像的标题。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;scalar_value&lt;/code&gt;：保存的值，即纵轴上的值。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;global_step&lt;/code&gt;：记录的步长，即横轴的值，一般会设置一个不断增加的 &lt;code&gt;step&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;运行后会看到 &lt;code&gt;logs&lt;/code&gt; 文件夹下生成了一个文件，然后我们在 PyCharm 终端的 PyTorch 环境中打开 TensorBoard（要在当前项目中进入 PyTorch 环境，否则 &lt;code&gt;--logdir&lt;/code&gt; 的路径就不能用相对路径了）：&lt;/p&gt;
&lt;figure class=&#34;highlight shell&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensorboard --logdir logs&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;打开 &lt;code&gt;http://localhost:6006/&lt;/code&gt; 即可看到绘制的图像。&lt;/p&gt;
&lt;p&gt;如果因为某些原因导致端口冲突可以指定端口：&lt;/p&gt;
&lt;figure class=&#34;highlight shell&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tensorboard --logdir logs --port 6007&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;3-2-add-image&#34;&gt;3.2 add_image&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;add_image&lt;/code&gt; 函数主要有三个参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tag&lt;/code&gt;：同 &lt;code&gt;add_scalar&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;img_tensor&lt;/code&gt;：图像数据，类型必须是 &lt;code&gt;torch.Tensor&lt;/code&gt;、&lt;code&gt;numpy.ndarry&lt;/code&gt; 或 &lt;code&gt;string/blobname&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;global_step&lt;/code&gt;：同 &lt;code&gt;add_scalar&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到传入的图片数据有类型限制，目前还没学到 &lt;code&gt;torch.Tensor&lt;/code&gt; 类型，以 &lt;code&gt;numpy.ndarry&lt;/code&gt; 为例，因此我们需要先安装一下 NumPy，还是在 PyTorch 环境中安装：&lt;/p&gt;
&lt;figure class=&#34;highlight shell&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;pip install numpy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;使用 &lt;code&gt;PIL&lt;/code&gt; 打开一个图像，将其转换成 NumPy 数组：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; PIL &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Image&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_path = &lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/hymenoptera_data/train/ants_image/0013035.jpg&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_PIL = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(img_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_array = np.array(img_PIL)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(img_array))  &lt;span class=&#34;comment&#34;&gt;# &amp;lt;class &amp;#x27;numpy.ndarray&amp;#x27;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(img_array.shape)  &lt;span class=&#34;comment&#34;&gt;# (512, 768, 3)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;可以看到图片的形状是三维的数据，前两个数据分别表示高度和宽度，第三个数据表示通道数，可以记为 &lt;code&gt;(H, W, C)&lt;/code&gt;，简写为 &lt;code&gt;HWC&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;add_image&lt;/code&gt; 函数传入图片时格式默认为 &lt;code&gt;CHW&lt;/code&gt;，如果格式不匹配需要设定函数中的 &lt;code&gt;dataformats&lt;/code&gt; 参数，例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; PIL &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Image&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;logs&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_path = &lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/hymenoptera_data/train/ants_image/0013035.jpg&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_PIL = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(img_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_array = np.array(img_PIL)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer.add_image(&lt;span class=&#34;string&#34;&gt;&amp;#x27;img_test&amp;#x27;&lt;/span&gt;, img_array, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, dataformats=&lt;span class=&#34;string&#34;&gt;&amp;#x27;HWC&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;运行后打开 TensorBoard 即可在 IMAGES 页面下看到图片。&lt;/p&gt;
&lt;h2 id=&#34;4-Transform&#34;&gt;4. Transform&lt;/h2&gt;
&lt;h3 id=&#34;4-1-Transform的概念与基本用法&#34;&gt;4.1 Transform的概念与基本用法&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;transforms&lt;/code&gt; 在计算机视觉工具包 &lt;code&gt;torchvision&lt;/code&gt; 下，包含了很多种对图像数据进行变换的类，这些都是在我们进行图像数据读入步骤中必不可少的，通过图像变换可以将图片变成不同的类型，或者可以通过旋转、裁切等手段对图像数据集的图像进行变换，起到扩充数据集与数据增强的作用。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;transforms&lt;/code&gt; 主要使用的类为：&lt;code&gt;transforms.ToTensor&lt;/code&gt;，该类能够将 &lt;code&gt;PIL.Image&lt;/code&gt; 或者 &lt;code&gt;ndarray&lt;/code&gt; 类型的数据转换为 &lt;code&gt;tensor&lt;/code&gt;，并且归一化至 &lt;code&gt;[0, 1]&lt;/code&gt;。注意归一化至 &lt;code&gt;[0, 1]&lt;/code&gt; 是直接除以255，若自己的 &lt;code&gt;ndarray&lt;/code&gt; 数据尺度有变化，则需要自行修改。&lt;/p&gt;
&lt;p&gt;为什么需要 &lt;code&gt;tensor&lt;/code&gt; 数据类型？因为它包装了反向传播神经网络所需要的一些基础的参数，因此在神经网络中需要将图片类型转换为 &lt;code&gt;tensor&lt;/code&gt; 类型进行训练。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; PIL &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Image&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; cv2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_path = &lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/hymenoptera_data/train/ants_image/0013035.jpg&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_PIL = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(img_path)  &lt;span class=&#34;comment&#34;&gt;# &amp;lt;class &amp;#x27;PIL.JpegImagePlugin.JpegImageFile&amp;#x27;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tensor_trans = transforms.ToTensor()  &lt;span class=&#34;comment&#34;&gt;# 创建 ToTensor 的实例对象&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_tensor1 = tensor_trans(img_PIL)  &lt;span class=&#34;comment&#34;&gt;# 将 PIL Image 转换成 tensor&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(img_tensor1))  &lt;span class=&#34;comment&#34;&gt;# &amp;lt;class &amp;#x27;torch.Tensor&amp;#x27;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_cv = cv2.imread(img_path)  &lt;span class=&#34;comment&#34;&gt;# &amp;lt;class &amp;#x27;numpy.ndarray&amp;#x27;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_tensor2 = tensor_trans(img_cv)  &lt;span class=&#34;comment&#34;&gt;# 将 OpenCV Image 转换成 tensor&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(img_tensor2))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;4-2-Transform的常用类&#34;&gt;4.2 Transform的常用类&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;transforms.Compose&lt;/code&gt;：&lt;code&gt;Compose&lt;/code&gt; 能够将多种变换组合在一起。例如下面的代码可以先将 &lt;code&gt;PIL.Image&lt;/code&gt; 中心裁切，然后再转换成 &lt;code&gt;tensor&lt;/code&gt;：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;img_path = &lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/hymenoptera_data/train/ants_image/0013035.jpg&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_PIL = Image.&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(img_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trans = transforms.Compose([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.CenterCrop(&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.ToTensor()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_trans = trans(img_PIL)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;transforms.CenterCrop&lt;/code&gt;：需要传入参数 &lt;code&gt;size&lt;/code&gt;，表示以 &lt;code&gt;(size, size)&lt;/code&gt; 的大小从中心裁剪，参数也可以为 &lt;code&gt;(height, width)&lt;/code&gt;。例如：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;img_PIL.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trans_centercrop = transforms.CenterCrop((&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;150&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_centercrop = trans_centercrop(img_PIL)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_centercrop.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;transforms.RandomCrop&lt;/code&gt;：需要传入参数 &lt;code&gt;size&lt;/code&gt;，表示以 &lt;code&gt;(size, size)&lt;/code&gt; 的大小随机裁剪，参数也可以为 &lt;code&gt;(height, width)&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;transforms.Normalize(mean, std)&lt;/code&gt;：对数据按通道进行标准化，即先减均值 &lt;code&gt;mean&lt;/code&gt;，再除以标准差 &lt;code&gt;std&lt;/code&gt;，注意是 &lt;code&gt;HWC&lt;/code&gt; 格式，处理公式为：&lt;code&gt;output[channel] = (input[channel] - mean[channel]) / std[channel]&lt;/code&gt;，例如：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;trans_tensor = transforms.ToTensor()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_tensor = trans_tensor(img_PIL)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 如果 input 的范围是[0, 1]，那么用该参数归一化后的范围就变为[-1, 1]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trans_norm = transforms.Normalize([&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;], [&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_norm = trans_norm(img_tensor)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(img_norm)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;transforms.Resize&lt;/code&gt;：需要传入参数 &lt;code&gt;(height, width)&lt;/code&gt; 和 &lt;code&gt; interpolation&lt;/code&gt;，表示重置图像的分辨率为 &lt;code&gt;(h, w)&lt;/code&gt;，也可以传入一个整数 &lt;code&gt;size&lt;/code&gt;，这样会将较短的那条边缩放至 &lt;code&gt;size&lt;/code&gt;，另一条边按原图大小等比例缩放。&lt;code&gt;interpolation&lt;/code&gt; 为插值方法选择，默认为 &lt;code&gt;PIL.Image.BILINEAR&lt;/code&gt;，例如：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;trans_tensor = transforms.ToTensor()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_tensor = trans_tensor(img_PIL)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(img_tensor.size())  &lt;span class=&#34;comment&#34;&gt;# torch.Size([3, 512, 768])，tensor 图像使用 size() 获取大小，PIL 图像使用 size&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trans_resize = transforms.Resize((&lt;span class=&#34;number&#34;&gt;256&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;300&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_resize = trans_resize(img_tensor)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(img_resize.size())  &lt;span class=&#34;comment&#34;&gt;# torch.Size([3, 256, 300])，修改比例&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trans_resize = transforms.Resize(&lt;span class=&#34;number&#34;&gt;30&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img_resize = trans_resize(img_tensor)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(img_resize.size())  &lt;span class=&#34;comment&#34;&gt;# torch.Size([3, 30, 45])，与原图等比例&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;transforms.ToPILImage&lt;/code&gt;：：将 &lt;code&gt;tensor&lt;/code&gt; 或者 &lt;code&gt;ndarray&lt;/code&gt; 的数据转换为 &lt;code&gt;PIL.Image&lt;/code&gt; 类型数据，参数 &lt;code&gt;mode&lt;/code&gt; 默认为 &lt;code&gt;None&lt;/code&gt;，表示1通道， &lt;code&gt;mode=3&lt;/code&gt; 表示3通道，默认转换为 &lt;code&gt;RGB&lt;/code&gt;，4通道默认转换为 &lt;code&gt;RGBA&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-Torchvision数据集使用方法&#34;&gt;5. Torchvision数据集使用方法&lt;/h2&gt;
&lt;p&gt;Torchvision 官方文档 &lt;a href=&#34;https://pytorch.org/vision/stable/datasets.html&#34;&gt;Torchvision&lt;/a&gt; 中的 &lt;code&gt;torchvision.datasets&lt;/code&gt; 就是 Torchvision 提供的标准数据集，其中有很多已经构建和训练好的网络模型，在不同的领域下各自有着很优秀的性能。&lt;/p&gt;
&lt;p&gt;我们以 CIFAR10 为例，该数据集包括了60000张32*32像素的图像，总共有10个类别，每个类别有6000张图像，其中有50000张图像为训练图像，10000张为测试图像。其使用说明如下图所示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;root&lt;/code&gt;：数据集存放的路径。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;train&lt;/code&gt;：如果为 &lt;code&gt;True&lt;/code&gt;，创建的数据集就为训练集，否则创建的数据集就为测试集。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;transform&lt;/code&gt;：使用 &lt;code&gt;transforms&lt;/code&gt; 中的变换操作对数据集进行变换。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;target_transform&lt;/code&gt;：对 &lt;code&gt;target&lt;/code&gt; 进行 &lt;code&gt;transform&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;download&lt;/code&gt;：如果为 &lt;code&gt;True&lt;/code&gt;，就会自动从网上下载这个数据集，否则就不会下载。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_data = torchvision.datasets.CIFAR10(root=&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = torchvision.datasets.CIFAR10(root=&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(train_data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# (&amp;lt;PIL.Image.Image image mode=RGB size=32x32 at 0x24011FC4F40&amp;gt;, 6)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;刚开始运行时可以看到正在从网上下载数据集，如果下载速度非常慢可以复制链接去迅雷之类的地方下载，下载好后自己创建设定的路径，将数据集放过来即可。&lt;/p&gt;
&lt;p&gt;然后设置断点，用 Debug 模式运行一下代码，我们可以查看一下数据集的内容，数据集 &lt;code&gt;train_data&lt;/code&gt; 中的 &lt;code&gt;classes&lt;/code&gt; 表示图像的种类，&lt;code&gt;classes_to_idx&lt;/code&gt; 表示将种类映射为整数，&lt;code&gt;targets&lt;/code&gt; 表示每张图像对应的种类编号，试着输出一下第一张图的信息：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;img, target = train_data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(img)  &lt;span class=&#34;comment&#34;&gt;# &amp;lt;PIL.Image.Image image mode=RGB size=32x32 at 0x1EEAEC32190&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(target)  &lt;span class=&#34;comment&#34;&gt;# 6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(train_data.classes[target])  &lt;span class=&#34;comment&#34;&gt;# frog&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img.show()  &lt;span class=&#34;comment&#34;&gt;# 图像显示为青蛙&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在展示如何使用 &lt;code&gt;transform&lt;/code&gt; 参数，假设我们需要将数据集的图像都转换成 &lt;code&gt;tensor&lt;/code&gt; 类型：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;trans_dataset = torchvision.transforms.Compose([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    torchvision.transforms.ToTensor()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_data = torchvision.datasets.CIFAR10(root=&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=trans_dataset, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = torchvision.datasets.CIFAR10(root=&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=trans_dataset, download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img, target = train_data[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;(img))  &lt;span class=&#34;comment&#34;&gt;# &amp;lt;class &amp;#x27;torch.Tensor&amp;#x27;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;6-神经网络Torch-NN基本骨架的使用&#34;&gt;6. 神经网络Torch.NN基本骨架的使用&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;torch.nn&lt;/code&gt; 能够帮助我们更优雅地训练神经网络，使神经网络代码更加简洁和灵活。官方文档：&lt;a href=&#34;https://pytorch.org/docs/stable/nn.html&#34;&gt;Torch.NN&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在文档中可以看到第一块内容叫做 &lt;code&gt;Container&lt;/code&gt;（容器），这就相当于神经网络的骨架，&lt;code&gt;Container&lt;/code&gt; 之后的东西就用于往骨架里面填充，如 Convolution Layers（卷积层）、Pooling Layers（池化层），有卷积神经网络基础的小伙伴对这些词应该都很熟悉了。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Container&lt;/code&gt; 中有六个模块：&lt;code&gt;Module&lt;/code&gt;、&lt;code&gt;Sequential&lt;/code&gt;、&lt;code&gt;ModuleList&lt;/code&gt;、&lt;code&gt;ModuleDict&lt;/code&gt;、&lt;code&gt;ParameterList&lt;/code&gt;、&lt;code&gt;ParameterDict&lt;/code&gt;，其中最常用的为 &lt;code&gt;Module&lt;/code&gt;，这是所有神经网络的最基本的类，其基本的构造方式如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn.functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Model&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# 初始化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv2 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# 前向传播&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.relu(self.conv1(x))  &lt;span class=&#34;comment&#34;&gt;# 将 x 进行第一层卷积后用 ReLU 激活函数输出&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; F.relu(self.conv2(x))  &lt;span class=&#34;comment&#34;&gt;# 将处理后的 x 再进行第二层卷积后用 ReLU 处理后返回最后结果&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在我们尝试自己创建一个简单的神经网络，并输出前向传播的结果：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# 初始化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = torch.tensor(&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# x 为 tensor 类型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output = network(x)  &lt;span class=&#34;comment&#34;&gt;# Module 中的 __call__ 函数会调用 forward 函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output)  &lt;span class=&#34;comment&#34;&gt;# tensor(2.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们以 &lt;code&gt;Conv2d&lt;/code&gt; 函数为例，该函数的官方文档：&lt;a href=&#34;https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html#torch.nn.functional.conv2d&#34;&gt;TORCH.NN.FUNCTIONAL.CONV2D&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;该函数有以下几个参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;input&lt;/code&gt;：输入的图像，&lt;code&gt;size&lt;/code&gt; 为 &lt;code&gt;(mini_batch, in_channels, height, width)&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;：卷积核的大小，&lt;code&gt;size&lt;/code&gt; 为 &lt;code&gt;(out_channels, in_channels/groups, height, width)&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bias&lt;/code&gt;：偏置，默认为 &lt;code&gt;None&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stride&lt;/code&gt;：步长，用来控制卷积核移动间隔，如果为 &lt;code&gt;x&lt;/code&gt; 则水平和竖直方向的步长都为 &lt;code&gt;x&lt;/code&gt;，如果为 &lt;code&gt;(x, y)&lt;/code&gt; 则竖直方向步长为 &lt;code&gt;x&lt;/code&gt;，水平方向步长为 &lt;code&gt;y&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;padding&lt;/code&gt;：在输入图像的边沿进行扩边操作，以保证图像输入输出前后的尺寸大小不变，在 PyTorch 的卷积层定义中，默认的 &lt;code&gt;padding&lt;/code&gt; 为零填充，即在边缘填充0。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;padding_mode&lt;/code&gt;：扩边的方式。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dilation&lt;/code&gt;：设定了取数之间的间隔。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn.functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.tensor([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;kernel = torch.tensor([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.reshape(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# batch_size = 1，channel = 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;kernel = torch.reshape(kernel, (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output = F.conv2d(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, kernel, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[[15, 16],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [ 6, 15]]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output = F.conv2d(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, kernel, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, bias=torch.tensor([&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;]))  &lt;span class=&#34;comment&#34;&gt;# 注意 bias 必须也是矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[[18, 19],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [ 9, 18]]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;7-Convolution-Layers与Pooling-Layers&#34;&gt;7. Convolution Layers与Pooling Layers&lt;/h2&gt;
&lt;p&gt;由于图像是二维的，因此基本上最常用到的就是二维的卷积层和池化层：&lt;code&gt;torch.nn.Conv2d&lt;/code&gt;、&lt;code&gt;torch.nn.MaxPool2d&lt;/code&gt;，官方文档：&lt;a href=&#34;https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d&#34;&gt;torch.nn.Conv2d&lt;/a&gt;、&lt;a href=&#34;https://pytorch.org/docs/stable/nn.html#pooling-layers&#34;&gt;Pooling Layers&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;7-1-Convolution-Layers&#34;&gt;7.1 Convolution Layers&lt;/h3&gt;
&lt;p&gt;卷积运算能够&lt;strong&gt;提取输入图像的不同特征&lt;/strong&gt;，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;torch.nn.Conv2d&lt;/code&gt; 的主要参数有以下几个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;in_channels&lt;/code&gt;：输入图像的通道数，彩色图像一般都是三通道。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;out_channels&lt;/code&gt;：通过卷积后产生的输出图像的通道数。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kernel_size&lt;/code&gt;：可以是一个数或一个元组，表示卷积核的大小，卷积核的参数是从数据的分布中采样得到的，这些数是多少无所谓，因为在神经网络训练的过程中就是对这些参数进行不断地调整。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stride&lt;/code&gt;：步长。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;padding&lt;/code&gt;：填充。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;padding_mode&lt;/code&gt;：填充模式，有 &lt;code&gt;zeros&lt;/code&gt;、&lt;code&gt;reflect&lt;/code&gt;、&lt;code&gt;replicate&lt;/code&gt;、&lt;code&gt;circular&lt;/code&gt;，默认为 &lt;code&gt;zeros&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dilation&lt;/code&gt;：可以是一个数或一个元组，表示卷积核各个元素间的距离，也称空洞卷积。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;group&lt;/code&gt;：一般设置为1，基本用不到。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bias&lt;/code&gt;：偏置，一般设置为 &lt;code&gt;True&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如以下代码构建了一个只有一层卷积层的神经网络，该卷积层的输入和输出通道数都为三通道，卷积核大小为3*3，步长为1，无填充，然后用 CIFAR10 测试数据集进行测试：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms, datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = datasets.CIFAR10(&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_loader = DataLoader(test_data, batch_size=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.conv1(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(network)  &lt;span class=&#34;comment&#34;&gt;# Network((conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1)))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;logs&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = network(imgs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_images(&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;, imgs, step)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_images(&lt;span class=&#34;string&#34;&gt;&amp;#x27;output&amp;#x27;&lt;/span&gt;, output, step)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;运行后可以打开 TensorBoard 查看一下效果。&lt;/p&gt;
&lt;h3 id=&#34;7-2-Pooling-Layers&#34;&gt;7.2 Pooling Layers&lt;/h3&gt;
&lt;p&gt;Pooling Layers 中的 &lt;code&gt;MaxPool&lt;/code&gt; 表示最大池化，也称上采样；&lt;code&gt;MaxUnpool&lt;/code&gt; 表示最小池化，也称下采样；&lt;code&gt;AvgPool&lt;/code&gt; 表示平均池化。其中最常用的为 &lt;code&gt;MaxPool2d&lt;/code&gt;，官方文档：&lt;a href=&#34;https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d&#34;&gt;torch.nn.MaxPool2d&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;最大池化的目的是&lt;strong&gt;保留输入数据的特征，同时减小特征的数据量&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;torch.nn.MaxPool2d&lt;/code&gt; 的主要参数有以下几个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kernel_size&lt;/code&gt;：用来取最大值的窗口（池化核）大小，和之前的卷积核类似。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stride&lt;/code&gt;：步长，注意默认值为 &lt;code&gt;kernel_size&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;padding&lt;/code&gt;：填充，和 &lt;code&gt;Conv2d&lt;/code&gt; 一样。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dilation&lt;/code&gt;：池化核中各个元素间的距离，和 &lt;code&gt;Conv2d&lt;/code&gt; 一样。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;return_indices&lt;/code&gt;：如果为 &lt;code&gt;True&lt;/code&gt;，表示返回值中包含最大值位置的索引。注意这个最大值指的是在所有窗口中产生的最大值，如果窗口产生的最大值总共有5个，就会有5个返回值。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ceil_mode&lt;/code&gt;：如果为 &lt;code&gt;True&lt;/code&gt;，表示在计算输出结果形状的时候，使用向上取整，否则默认向下取整。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;输出图像的形状的计算公式可以在官方文档中查看。&lt;/p&gt;
&lt;p&gt;接下来我们用代码实现这个池化层：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms, datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.maxpool1 = nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.maxpool1(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.tensor([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;], dtype=torch.float32)  &lt;span class=&#34;comment&#34;&gt;# 注意池化层读入的数据需要为浮点型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.reshape(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(network)  &lt;span class=&#34;comment&#34;&gt;# Network((maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output = network(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[[[2., 3.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           [4., 2.]]]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们用图像来试试效果：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms, datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = datasets.CIFAR10(&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_loader = DataLoader(test_data, batch_size=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.maxpool1 = nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.maxpool1(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;logs&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = network(imgs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_images(&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;, imgs, step)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_images(&lt;span class=&#34;string&#34;&gt;&amp;#x27;output&amp;#x27;&lt;/span&gt;, output, step)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;运行后可以打开 TensorBoard 查看一下效果。&lt;/p&gt;
&lt;h2 id=&#34;8-Non-linear-Activations与Linear-Layers&#34;&gt;8. Non-linear Activations与Linear Layers&lt;/h2&gt;
&lt;h3 id=&#34;8-1-Non-linear-Activations&#34;&gt;8.1 Non-linear Activations&lt;/h3&gt;
&lt;p&gt;非线性激活的目的是为了在网络中引入一些&lt;strong&gt;非线性特征&lt;/strong&gt;，因为非线性特征越多才能训练出符合各种曲线（特征）的模型。&lt;/p&gt;
&lt;p&gt;非线性激活函数官方文档：&lt;a href=&#34;https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity&#34;&gt;Non-linear Activations&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;有深度学习基础的同学应该知道最常用的非线性激活函数就是 ReLU 和 Sigmoid 函数，多分类问题会在输出层使用 Softmax 函数（如果损失函数使用的是交叉熵误差函数 &lt;code&gt;CrossEntropyLoss&lt;/code&gt; 则会自动计算 Softmax，无需创建 Softmax 层）。这三个函数在 PyTorch 中分别为 &lt;code&gt;nn.ReLU&lt;/code&gt;、&lt;code&gt;nn.Sigmoid&lt;/code&gt; 和 &lt;code&gt;nn.Softmax&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这两个函数的输入都是只需指明 &lt;code&gt;batch_size&lt;/code&gt; 即可，在 PyTorch1.0 之后的版本任何形状的数据都能被计算，无需指定 &lt;code&gt;batch_size&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nn.ReLU&lt;/code&gt; 只有一个需要设置的参数 &lt;code&gt;inplace&lt;/code&gt;，如果为 &lt;code&gt;True&lt;/code&gt; 表示计算结果直接替换到输入数据上，例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;nn.ReLU(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# input = 0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;构建 ReLU 层代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.relu1 = nn.ReLU()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.relu1(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.tensor([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output = network(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[1., 0.],&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#         [0., 3.]])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;由于 ReLU 对图像处理的直观效果不明显，我们使用 Sigmoid 对图像进行处理：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms, datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.sigmoid1 = nn.Sigmoid()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.sigmoid1(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = datasets.CIFAR10(&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_loader = DataLoader(test_data, batch_size=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;logs&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = network(imgs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_images(&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;, imgs, step)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_images(&lt;span class=&#34;string&#34;&gt;&amp;#x27;output&amp;#x27;&lt;/span&gt;, output, step)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;8-2-Linear-Layers&#34;&gt;8.2 Linear Layers&lt;/h3&gt;
&lt;p&gt;线性层官方文档：&lt;a href=&#34;https://pytorch.org/docs/stable/nn.html#linear-layers&#34;&gt;Linear Layers&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;PyTorch 的 &lt;code&gt;nn.Linear&lt;/code&gt; 是用于设置网络中的全连接层的，需要注意的是全连接层的输入与输出都是二维张量，一般形状为：&lt;code&gt;[batch_size, size]&lt;/code&gt;，不同于卷积层要求输入输出是四维张量，因此在将图像传入全连接层之前一般都会展开成一维的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nn.Linear&lt;/code&gt; 有三个参数分别如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;in_features&lt;/code&gt;：指的是输入的二维张量的大小，即输入的 &lt;code&gt;[batch_size, size]&lt;/code&gt; 中的 &lt;code&gt;size&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;out_features&lt;/code&gt;：指的是输出的二维张量的大小，即输出的二维张量的形状为 &lt;code&gt;[batch_size, output_size]&lt;/code&gt;，当然，它也代表了该全连接层的神经元个数。从输入输出的张量的 &lt;code&gt;shape&lt;/code&gt; 角度来理解，相当于一个输入为 &lt;code&gt;[batch_size, in_features]&lt;/code&gt; 的张量变换成了 &lt;code&gt;[batch_size, out_features]&lt;/code&gt; 的输出张量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bias&lt;/code&gt;：偏置，相当于 &lt;code&gt;y = ax + b&lt;/code&gt; 中的 &lt;code&gt;b&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码示例如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.linear1 = nn.Linear(&lt;span class=&#34;number&#34;&gt;24&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;30&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.linear1(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.tensor([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;], dtype=torch.float32)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([3, 8])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.flatten(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 将 input 拉平成一维&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([24])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output = network(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([30])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;9-神经网络模型搭建小实战&#34;&gt;9. 神经网络模型搭建小实战&lt;/h2&gt;
&lt;h3 id=&#34;9-1-Sequential&#34;&gt;9.1 Sequential&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;torch.nn.Sequential&lt;/code&gt; 是一个 Sequential 容器，能够在容器中嵌套各种实现神经网络中具体功能相关的类，来完成对神经网络模型的搭建。模块的加入一般有两种方式，一种是直接嵌套，另一种是以 &lt;code&gt;OrderedDict&lt;/code&gt; 有序字典的方式进行传入，这两种方式的唯一区别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;OrderedDict&lt;/code&gt; 搭建的模型的每个模块都有我们自定义的名字。&lt;/li&gt;
&lt;li&gt;直接嵌套默认使用从零开始的数字序列作为每个模块的名字。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（1）直接嵌套方法的代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.ReLU(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.Conv2d(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    nn.ReLU()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Sequential(&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (1): ReLU()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (3): ReLU()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# )&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;（2）使用 &lt;code&gt;OrderedDict&lt;/code&gt; 的代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; collections &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; OrderedDict&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = nn.Sequential(OrderedDict([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    (&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv1&amp;#x27;&lt;/span&gt;, nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    (&lt;span class=&#34;string&#34;&gt;&amp;#x27;ReLU1&amp;#x27;&lt;/span&gt;, nn.ReLU()),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    (&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv2&amp;#x27;&lt;/span&gt;, nn.Conv2d(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    (&lt;span class=&#34;string&#34;&gt;&amp;#x27;ReLU2&amp;#x27;&lt;/span&gt;, nn.ReLU())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;]))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Sequential(&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (Conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (ReLU1): ReLU()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (Conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (ReLU2): ReLU()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# )&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;9-2-小实战&#34;&gt;9.2 小实战&lt;/h3&gt;
&lt;p&gt;由于代码很简单，都是学过的内容进行组装，因此直接看代码：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;CIFAR10_Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(CIFAR10_Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.model = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 32, 32]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 16, 16]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 16, 16]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 8, 8]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [64, 8, 8]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [64, 4, 4]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Flatten(),  &lt;span class=&#34;comment&#34;&gt;# [1024]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Linear(in_features=&lt;span class=&#34;number&#34;&gt;1024&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [64]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Linear(in_features=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;) &lt;span class=&#34;comment&#34;&gt;# [10]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.model(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = CIFAR10_Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.randn(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 返回一个包含了从标准正态分布中抽取的一组随机数的张量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([64, 3, 32, 32])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output = network(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output.shape)  &lt;span class=&#34;comment&#34;&gt;# torch.Size([64, 10])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;logs&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer.add_graph(network, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# 生成计算图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;使用 &lt;code&gt;add_graph&lt;/code&gt; 函数可以在 TensorBoard 中生成神经网络的计算图，通过计算图可以很清晰地看到每一层计算时数据流入流出的结果，双击相应的标签可以进一步深入查看更详细的信息。&lt;/p&gt;
&lt;h2 id=&#34;10-损失函数与反向传播&#34;&gt;10. 损失函数与反向传播&lt;/h2&gt;
&lt;h3 id=&#34;10-1-Loss-Functions&#34;&gt;10.1 Loss Functions&lt;/h3&gt;
&lt;p&gt;具有深度学习理论基础的同学对损失函数和反向传播一定不陌生，在此不详细展开理论介绍。损失函数是指用于计算标签值和预测值之间差异的函数，在机器学习过程中，有多种损失函数可供选择，典型的有距离向量，绝对值向量等。使用损失函数的流程概括如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;计算实际输出和目标之间的差距。&lt;/li&gt;
&lt;li&gt;为我们更新输出提供一定的依据（反向传播）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;损失函数的官方文档：&lt;a href=&#34;https://pytorch.org/docs/stable/nn.html#loss-functions&#34;&gt;Loss Functions&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;（1）&lt;code&gt;nn.L1Loss&lt;/code&gt;：平均绝对误差（MAE，Mean Absolute Error），计算方法很简单，取预测值和真实值的绝对误差的平均数即可。&lt;/p&gt;
&lt;p&gt;PyTorch1.13中 &lt;code&gt;nn.L1Loss&lt;/code&gt; 数据形状规定如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Input&lt;/code&gt;：&lt;code&gt;(*)&lt;/code&gt;，means any number of dimensions.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Target&lt;/code&gt;：&lt;code&gt;(*)&lt;/code&gt;，same shape as the input.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Output&lt;/code&gt;：scalar. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;none&lt;/code&gt;, then &lt;code&gt;(*)&lt;/code&gt;, same shape as the input.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;早先的版本需要指定 &lt;code&gt;batch_size&lt;/code&gt; 大小，现在不需要了。可以设置参数 &lt;code&gt;reduction&lt;/code&gt;，默认为 &lt;code&gt;mean&lt;/code&gt;，即取平均值，也可以设置为 &lt;code&gt;sum&lt;/code&gt;，顾名思义就是取和。&lt;/p&gt;
&lt;p&gt;测试代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.tensor([&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;target = torch.tensor([&lt;span class=&#34;number&#34;&gt;4.0&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5.0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss = nn.L1Loss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = loss(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, target)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(result)  &lt;span class=&#34;comment&#34;&gt;# tensor(3.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss = nn.L1Loss(reduction=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sum&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = loss(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, target)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(result)  &lt;span class=&#34;comment&#34;&gt;# tensor(9.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;（2）&lt;code&gt;nn.MSELoss&lt;/code&gt;：均方误差（MSE，Mean Squared Error），即预测值和真实值之差的平方和的平均数。&lt;/p&gt;
&lt;p&gt;该损失函数的用法与 &lt;code&gt;nn.L1Loss&lt;/code&gt; 相似，代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.tensor([&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;target = torch.tensor([&lt;span class=&#34;number&#34;&gt;4.0&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;2.0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5.0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss = nn.MSELoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = loss(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, target)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(result)  &lt;span class=&#34;comment&#34;&gt;# tensor(9.6667)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss = nn.MSELoss(reduction=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sum&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = loss(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, target)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(result)  &lt;span class=&#34;comment&#34;&gt;# tensor(29.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;（3）&lt;code&gt;nn.CrossEntropyLoss&lt;/code&gt;：交叉熵误差，训练分类 C 个类别的模型的时候较常用这个损失函数，一般用在 Softmax 层后面，计算公式较为复杂，可以在官网中查看。&lt;/p&gt;
&lt;p&gt;测试代码如下：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.tensor([&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.7&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;target = torch.tensor(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = loss(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, target)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(result)  &lt;span class=&#34;comment&#34;&gt;# tensor(0.7679)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt; = torch.tensor([&lt;span class=&#34;number&#34;&gt;0.8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = loss(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;, target)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(result)  &lt;span class=&#34;comment&#34;&gt;# tensor(1.3897)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;10-2-Backward&#34;&gt;10.2 Backward&lt;/h3&gt;
&lt;p&gt;接下来以 CIFAR10 数据集为例，用上一节搭建的神经网络先设置 &lt;code&gt;batch_size&lt;/code&gt; 为1，看一下输出结果：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms, datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;CIFAR10_Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(CIFAR10_Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.model = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 32, 32]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 16, 16]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 16, 16]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 8, 8]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [64, 8, 8]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [64, 4, 4]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Flatten(),  &lt;span class=&#34;comment&#34;&gt;# [1024]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Linear(in_features=&lt;span class=&#34;number&#34;&gt;1024&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [64]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Linear(in_features=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;) &lt;span class=&#34;comment&#34;&gt;# [10]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.model(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = CIFAR10_Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = datasets.CIFAR10(&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_loader = DataLoader(test_data, batch_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = network(imgs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output_loss = loss(output, targets)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(targets)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(output_loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([[ 0.1252, -0.1069, -0.0747,  0.0232,  0.0852,  0.1019,  0.0688, -0.1068,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#           0.0854, -0.0740]], grad_fn=&amp;lt;AddmmBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor([3])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tensor(2.2960, grad_fn=&amp;lt;NllLossBackward0&amp;gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在我们来尝试解决第二个问题，即损失函数如何为我们更新输出提供一定的依据（反向传播）。&lt;/p&gt;
&lt;p&gt;例如对于卷积层来说，其中卷积核中的每个参数就是我们需要调整的，每个参数具有一个属性 &lt;code&gt;grad&lt;/code&gt; 表示梯度，反向传播时每一个要更新的参数都会求出对应的梯度，在优化的过程中就可以根据这个梯度对参数进行优化，最终达到降低损失函数值的目的。&lt;/p&gt;
&lt;p&gt;PyTorch 中对损失函数计算出的结果使用 &lt;code&gt;backward&lt;/code&gt; 函数即可计算出梯度：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms, datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;CIFAR10_Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(CIFAR10_Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.model = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# Layers&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.model(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = CIFAR10_Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = datasets.CIFAR10(&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_loader = DataLoader(test_data, batch_size=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = network(imgs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output_loss = loss(output, targets)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output_loss.backward()  &lt;span class=&#34;comment&#34;&gt;# 反向传播&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们在计算反向传播之前设置断点，然后可以在 PyCharm 下方的变量区域通过目录 &lt;code&gt;network/model/Protected Attributes/_modules/&#39;0&#39;/weight/grad&lt;/code&gt; 查看到某一层参数的梯度，在反向传播之前为 &lt;code&gt;None&lt;/code&gt;，执行反向传播的代码后可以看到 &lt;code&gt;grad&lt;/code&gt; 处有数值了。&lt;/p&gt;
&lt;p&gt;我们有了各个节点参数的梯度，接下来就可以选用一个合适的优化器，来对这些参数进行优化。&lt;/p&gt;
&lt;h3 id=&#34;10-3-Optimizer&#34;&gt;10.3 Optimizer&lt;/h3&gt;
&lt;p&gt;优化器 &lt;code&gt;torch.optim&lt;/code&gt; 的官方文档：&lt;a href=&#34;https://pytorch.org/docs/stable/optim.html&#34;&gt;TORCH.OPTIM&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;优化器主要是在模型训练阶段对模型的可学习参数进行更新，常用优化器有：SGD、RMSprop、Adam等。优化器初始化时传入传入模型的可学习参数，以及其他超参数如 &lt;code&gt;lr&lt;/code&gt;、&lt;code&gt;momentum&lt;/code&gt; 等，例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.optim &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; optim&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = optim.SGD(model.parameters(), lr=&lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;, momentum=&lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = optim.Adam([var1, var2], lr=&lt;span class=&#34;number&#34;&gt;0.0001&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在训练过程中先调用 &lt;code&gt;optimizer.zero_grad()&lt;/code&gt; 清空梯度，再调用 &lt;code&gt;loss.backward()&lt;/code&gt; 反向传播，最后调用 &lt;code&gt;optimizer.step()&lt;/code&gt; 更新模型参数，例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output = network(imgs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss = loss_function(output, targets)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;接下来我们来训练20轮神经网络，看看损失函数值的变化：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms, datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.optim &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; optim&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;CIFAR10_Network&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(CIFAR10_Network, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.model = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# Layers&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.model(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = CIFAR10_Network()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = datasets.CIFAR10(&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_loader = DataLoader(test_data, batch_size=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = optim.SGD(network.parameters(), lr=&lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;):  &lt;span class=&#34;comment&#34;&gt;# 学习20轮&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    total_loss = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = network(imgs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(output, targets)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        total_loss += loss&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(total_loss)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;可以看到每一轮所有 &lt;code&gt;batch&lt;/code&gt; 的损失函数值的总和确实在不断降低了。&lt;/p&gt;
&lt;h2 id=&#34;11-现有网络模型的使用及修改&#34;&gt;11. 现有网络模型的使用及修改&lt;/h2&gt;
&lt;h3 id=&#34;11-1-VGG16模型的使用&#34;&gt;11.1 VGG16模型的使用&lt;/h3&gt;
&lt;p&gt;我们以 VGG16 为例，该网络模型是用于大规模图像识别的超深度卷积神经网络，官方文档：&lt;a href=&#34;https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.vgg16&#34;&gt;VGG16&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;该网络模型主要有以下参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;weights&lt;/code&gt;：可以设置成 &lt;code&gt;torchvision.models.VGG16_Weights.DEFAULT&lt;/code&gt;，&lt;code&gt;DEFAULT&lt;/code&gt; 表示自动使用最新的数据。老版本为 &lt;code&gt;pretrained&lt;/code&gt;，如果为 &lt;code&gt;True&lt;/code&gt;，表示使用预先训练好的权重，在官网可以看到这个权重是在 &lt;code&gt;ImageNet-1K&lt;/code&gt; 数据集训练的，默认为不使用预先训练好的权重。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;progress&lt;/code&gt;：如果为 &lt;code&gt;True&lt;/code&gt;，则显示下载的进度条，默认为 &lt;code&gt;True&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意，下载网络时默认的下载路径是 &lt;code&gt;C:\Users\&amp;lt;username&amp;gt;\.cache&lt;/code&gt;，因此在下载模型前，我们需要修改路径：打开 &lt;code&gt;D:\Anaconda3_Environments\envs\PyTorch\Lib\site-packages\torch&lt;/code&gt; 中的 &lt;code&gt;hub.py&lt;/code&gt; 文件，搜索 &lt;code&gt;load_state_dict_from_url&lt;/code&gt;，然后修改 &lt;code&gt;model_dir&lt;/code&gt; 即可：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;model_dir: &lt;span class=&#34;type&#34;&gt;Optional&lt;/span&gt;[&lt;span class=&#34;built_in&#34;&gt;str&lt;/span&gt;] = &lt;span class=&#34;string&#34;&gt;&amp;#x27;D:\\Anaconda3_Environments\\envs\\PyTorch\\Torch-model&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后我们输出一下这个网络模型：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;vgg = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(vgg)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# VGG(&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (features): Sequential(&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (1): ReLU(inplace=True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (3): ReLU(inplace=True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     ......&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   )&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   (classifier): Sequential(&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (0): Linear(in_features=25088, out_features=4096, bias=True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (1): ReLU(inplace=True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (2): Dropout(p=0.5, inplace=False)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (3): Linear(in_features=4096, out_features=4096, bias=True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (4): ReLU(inplace=True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (5): Dropout(p=0.5, inplace=False)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#     (6): Linear(in_features=4096, out_features=1000, bias=True)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#   )&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# )&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;可以看到这个模型的分类结果为1000类，那么假如我们需要分类 CIFAR10 该如何应用这个网络模型呢？一种方法就是直接将最后一层 &lt;code&gt;Linear&lt;/code&gt; 的 &lt;code&gt;out_features&lt;/code&gt; 改为10，还有一种方法就是再添加一层 &lt;code&gt;in_features=1000, out_features=10&lt;/code&gt; 的 &lt;code&gt;Linear&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms, datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.optim &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; optim&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;vgg = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;vgg.classifier.add_module(&lt;span class=&#34;string&#34;&gt;&amp;#x27;add_linear&amp;#x27;&lt;/span&gt;, nn.Linear(in_features=&lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))  &lt;span class=&#34;comment&#34;&gt;# 在 classifier 中加一层 Linear&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# vgg.classifier[6] = nn.Linear(in_features=4096, out_features=10)  # 修改 classifier 的最后一层 Linear&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = datasets.CIFAR10(&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_loader = DataLoader(test_data, batch_size=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = optim.SGD(vgg.parameters(), lr=&lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    total_loss = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = vgg(imgs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(output, targets)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        total_loss += loss&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(total_loss)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;可以看到效果是比之前自己构建的网络模型好很多的。&lt;/p&gt;
&lt;h3 id=&#34;11-2-模型的保存与读取&#34;&gt;11.2 模型的保存与读取&lt;/h3&gt;
&lt;p&gt;我们在对某些模型进行修改后可能想将其保存下来，方便以后用到时无需再构建一遍网络，可以按以下的方式将整个模型保存到路径 &lt;code&gt;models/CIFAR10_VGG16.pth&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.classifier.add_module(&lt;span class=&#34;string&#34;&gt;&amp;#x27;add_linear&amp;#x27;&lt;/span&gt;, nn.Linear(in_features=&lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.save(model, &lt;span class=&#34;string&#34;&gt;&amp;#x27;models/CIFAR10_VGG16.pth&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;其对应的加载模型的方式为：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;model = torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;models/CIFAR10_VGG16.pth&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;还有一种保存方式是将模型中的参数保存成字典的形式，官方建议使用该方式：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;torch.save(model.state_dict(), &lt;span class=&#34;string&#34;&gt;&amp;#x27;models/CIFAR10_VGG16_STATE.pkl&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;其对应的加载模型的方式为：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;model = torchvision.models.vgg16()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.load_state_dict(torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;models/CIFAR10_VGG16_STATE.pkl&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;注意如果是保存自己构建的网络模型，需要在模型的类的源代码中将该类导入进来，例如在 &lt;code&gt;test_save.py&lt;/code&gt; 中用以下代码保存自己的网络：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;MyNetwork&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(MyNetwork, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.conv1 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.conv1(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = MyNetwork()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.save(model, &lt;span class=&#34;string&#34;&gt;&amp;#x27;models/My_Network.pth&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在 &lt;code&gt;test_load.py&lt;/code&gt; 中导入时需要这样写：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; test_save &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; MyNetwork&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;models/My_Network.pth&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(model)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&#34;12-完整训练模型的方法&#34;&gt;12. 完整训练模型的方法&lt;/h2&gt;
&lt;h3 id=&#34;12-1-训练模型时的注意事项&#34;&gt;12.1 训练模型时的注意事项&lt;/h3&gt;
&lt;p&gt;（1）通常我们会将超参数的设置放在一起，使代码更加直观且方便修改：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;BATCH_SIZE = &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;LEARNING_RATE = &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;EPOCH = &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;（2）我们在每一轮 epoch 中会先对训练集进行训练，然后使用测试集进行正确率的测试，因此一般我们会记录总共训练的次数 &lt;code&gt;total_train_step&lt;/code&gt; 以及总共测试的次数 &lt;code&gt;total_test_step&lt;/code&gt;，方便后续绘图使用。&lt;/p&gt;
&lt;p&gt;（3）在开始训练之前一般需要将模型设置成训练状态，在测试之前需要设置成评估状态，这两种状态会影响少部分的层例如 &lt;code&gt;Dropout&lt;/code&gt; 和 &lt;code&gt;BatchNorm&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;model.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# training&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# evaluation&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;（4）在分类问题中计算准确率一般用以下方法：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;a = torch.tensor([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.7&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;span class=&#34;number&#34;&gt;0.6&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.4&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;])  &lt;span class=&#34;comment&#34;&gt;# 假设两个物体二分类的结果&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b = torch.tensor([&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])  &lt;span class=&#34;comment&#34;&gt;# 正确的标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(a.argmax(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;comment&#34;&gt;# tensor([1, 0])，在第1维上取最大值，即对每一行求最大值，将最大值作为分类结果&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(a.argmax(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) == b)  &lt;span class=&#34;comment&#34;&gt;# tensor([False,  True])，与标签进行比较，第一个物体的结果与标签不符，第二个和标签相符&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;((a.argmax(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) == b).&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;())  &lt;span class=&#34;comment&#34;&gt;# tensor(1)，将所有物体与标签的比较结果求和就是 True 的数量，也就是预测正确的数量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;（5）测试时不能对模型进行任何干扰，即在测试的时候神经网络不能产生梯度，因此在每次测试前需要加上以下代码：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# evaluation&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;12-2-使用GPU进行训练&#34;&gt;12.2 使用GPU进行训练&lt;/h3&gt;
&lt;p&gt;前提：电脑有 NVIDIA 显卡，配置好了 CUDA，可以使用 &lt;code&gt;torch.cuda.is_available()&lt;/code&gt; 来检查 CUDA 是否可用。&lt;/p&gt;
&lt;p&gt;使用 GPU 训练的时候，需要将 Module 对象和 Tensor 类型的数据转移到 GPU 上进行计算，一般来说即为将网络模型、数据、损失函数放到 GPU 上计算。&lt;/p&gt;
&lt;p&gt;使用 GPU 训练的方式有两种，第一种是使用 &lt;code&gt;cuda()&lt;/code&gt; 函数，例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 网络模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = MyNetwork()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = model.cuda()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 损失函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = loss_function.cuda()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs = imgs.cuda()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    targets = targets.cuda()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;另一种是使用 &lt;code&gt;to(device)&lt;/code&gt;，&lt;code&gt;device&lt;/code&gt; 就是我们选择用来训练模型的设备，该方式与 &lt;code&gt;cuda()&lt;/code&gt; 有一点细微的差别如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于 Tensor 类型的数据（图像、标签等），使用 &lt;code&gt;to(device)&lt;/code&gt; 之后，需要接收返回值，返回值才是正确设置了 &lt;code&gt;device&lt;/code&gt; 的 Tensor。&lt;/li&gt;
&lt;li&gt;对于 Module 对象（网络模型、损失函数），只用调用 &lt;code&gt;to(device)&lt;/code&gt; 就可以将模型设置为指定的 &lt;code&gt;device&lt;/code&gt;，不必接收返回值，当然接收返回值也是可以的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# &amp;#x27;cuda:0&amp;#x27; 表示第 0 号 GPU&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 网络模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = MyNetwork()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 损失函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    imgs = imgs.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    targets = targets.to(device)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;注意如果加载在 GPU 上训练好的模型，然后想在 CPU 上使用，需要映射回 CPU：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;model = torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;models/AFTER_TRAININGS_MODEL.pth&amp;#x27;&lt;/span&gt;, map_location=torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&#34;12-3-CIFAR10-Net-Simple-v3&#34;&gt;12.3 CIFAR10_Net_Simple_v3&lt;/h3&gt;
&lt;p&gt;最后放上经过自己调参达到88%左右的正确率的模型和训练代码吧：&lt;/p&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;CIFAR10_Net_Simple_v3&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(CIFAR10_Net_Simple_v3, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        self.model = nn.Sequential(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 32, 32]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 32, 32]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [32, 16, 16]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [64, 16, 16]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [64, 16, 16]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [64, 8, 8]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [128, 16, 16]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Conv2d(in_channels=&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, out_channels=&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, stride=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, padding=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [128, 16, 16]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.BatchNorm2d(&lt;span class=&#34;number&#34;&gt;128&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.MaxPool2d(kernel_size=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [128, 4, 4]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Flatten(),  &lt;span class=&#34;comment&#34;&gt;# [2048]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Dropout(p=&lt;span class=&#34;number&#34;&gt;0.4&lt;/span&gt;, inplace=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Linear(in_features=&lt;span class=&#34;number&#34;&gt;2048&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;),  &lt;span class=&#34;comment&#34;&gt;# [64]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.ReLU(inplace=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Dropout(p=&lt;span class=&#34;number&#34;&gt;0.4&lt;/span&gt;, inplace=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            nn.Linear(in_features=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, out_features=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;) &lt;span class=&#34;comment&#34;&gt;# [10]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        )&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, &lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = self.model(&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# model = CIFAR10_Net_Simple_v3()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# torch.save(model, &amp;#x27;../models/CIFAR10_Net_Simple_v3.pth&amp;#x27;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&#34;highlight py&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;114&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;115&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;116&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;117&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;118&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;119&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;120&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;121&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;122&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;123&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;124&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torchvision &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; transforms, datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data.dataset &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; ConcatDataset&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.tensorboard &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; SummaryWriter&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; util.CIFAR10_Net_Simple_v3 &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; *&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.optim &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; optim&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 超参数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;BATCH_SIZE = &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;LEARNING_RATE = &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;EPOCH = &lt;span class=&#34;number&#34;&gt;150&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;SHOW_INFO_STEP = &lt;span class=&#34;number&#34;&gt;200&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练设备&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device = torch.device(&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; torch.cuda.is_available() &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# &amp;#x27;cuda:0&amp;#x27; 表示第 0 号 GPU&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 数据增强&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trans = transforms.Compose([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.RandomCrop(&lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;, padding=[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;]),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.RandomHorizontalFlip(p=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transforms.ToTensor()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_data = datasets.CIFAR10(&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, transform=trans)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data = datasets.CIFAR10(&lt;span class=&#34;string&#34;&gt;&amp;#x27;dataset/CIFAR10&amp;#x27;&lt;/span&gt;, train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, transform=transforms.ToTensor())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 扩充训练集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# trans_train_data = datasets.CIFAR10(&amp;#x27;dataset/CIFAR10&amp;#x27;, train=True, transform=trans)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# train_data = ConcatDataset([train_data, trans_train_data])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 加载数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_data_len = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_data_len = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(test_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;models/CIFAR10_Net_Simple_v3.pth&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function = nn.CrossEntropyLoss()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=&lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;16&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;24&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;32&lt;/span&gt;], gamma=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer = SummaryWriter(&lt;span class=&#34;string&#34;&gt;&amp;#x27;logs/CIFAR10_Net_Simple_v3_Aug_Mom_logs&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;loss_function.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;total_train_step = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;total_test_step = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(EPOCH):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;---------- The &amp;#123;&amp;#125; epoch of training begins ----------&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(epoch))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Learning rate: &amp;#123;&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(optimizer.state_dict()[&lt;span class=&#34;string&#34;&gt;&amp;#x27;param_groups&amp;#x27;&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;string&#34;&gt;&amp;#x27;lr&amp;#x27;&lt;/span&gt;]))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_loss = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_acc = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(train_dataloader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        imgs = imgs.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        targets = targets.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = model(imgs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        acc = (output.argmax(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)==targets).&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;().&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = loss_function(output, targets)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_loss += loss.item()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train_acc += acc&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        total_train_step += &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; total_train_step % SHOW_INFO_STEP == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;The number of training: &amp;#123;&amp;#125;, Loss: &amp;#123;&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(total_train_step, loss.item()))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_acc /= train_data_len&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_loss&amp;#x27;&lt;/span&gt;, train_loss, epoch)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;train_acc&amp;#x27;&lt;/span&gt;, train_acc, epoch)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;The number of epoch: &amp;#123;&amp;#125;, train_loss: &amp;#123;&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(epoch, train_loss))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;The number of epoch: &amp;#123;&amp;#125;, train_acc: &amp;#123;&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(epoch, train_acc))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_loss = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_acc = &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; step, data &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(test_dataloader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            imgs, targets = data&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            imgs = imgs.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            targets = targets.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            output = model(imgs)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            acc = (output.argmax(dim=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;) == targets).&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;().&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            loss = loss_function(output, targets)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            test_loss += loss.item()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            test_acc += acc&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            total_test_step += &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        test_acc /= test_data_len&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;test_loss&amp;#x27;&lt;/span&gt;, test_loss, epoch)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;test_acc&amp;#x27;&lt;/span&gt;, test_acc, epoch)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;The number of epoch: &amp;#123;&amp;#125;, test_loss: &amp;#123;&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(epoch, test_loss))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;The number of epoch: &amp;#123;&amp;#125;, test_acc: &amp;#123;&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(epoch, test_acc))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        writer.add_scalar(&lt;span class=&#34;string&#34;&gt;&amp;#x27;learning_rate&amp;#x27;&lt;/span&gt;, optimizer.state_dict()[&lt;span class=&#34;string&#34;&gt;&amp;#x27;param_groups&amp;#x27;&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;string&#34;&gt;&amp;#x27;lr&amp;#x27;&lt;/span&gt;], epoch)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        scheduler.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.save(model, &lt;span class=&#34;string&#34;&gt;&amp;#x27;models/CIFAR10_Net_Simple_v3_Aug_Mom_150TRAININGS.pth&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# torch.save(model.state_dict(), &amp;#x27;models/CIFAR10_Net_Simple_v3_Aug_Mom_STATE.pkl&amp;#x27;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;writer.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;至此已经成功入门 PyTorch 啦！可以正式进入 Deep Learning 的学习啦！&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>

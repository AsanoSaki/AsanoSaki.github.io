{
    "version": "https://jsonfeed.org/version/1",
    "title": "AsanoSaki â€¢ All posts by \"ai\" tag",
    "description": "",
    "home_page_url": "https://asanosaki.github.io",
    "items": [
        {
            "id": "https://asanosaki.github.io/posts/23991.html",
            "url": "https://asanosaki.github.io/posts/23991.html",
            "title": "KMeansèšç±»ä¸PCAä¸»æˆåˆ†åˆ†æ",
            "date_published": "2023-08-09T02:03:00.000Z",
            "content_html": "<blockquote>\n<p>ä»‹ç»äºŒç»´æ•°æ®ä¸é«˜ç»´æ•°æ®çš„ K-Means èšç±»ç®—æ³•ä»¥åŠé«˜ç»´æ•°æ®çš„ PCA ä¸»æˆåˆ†åˆ†ææ–¹æ³•ã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-äºŒç»´æ•°æ®K-Meansèšç±»\">1. äºŒç»´æ•°æ®K-Meansèšç±»</h2>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> KMeans, MiniBatchKMeans</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.decomposition <span class=\"keyword\">import</span> PCA</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ä»¥centerä¸ºä¸­å¿ƒäº§ç”Ÿéšæœºåˆ†å¸ƒçš„æ•°æ®</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_random_data</span>(<span class=\"params\">center, data_num, data_dim=<span class=\"number\">2</span>, fix_seed=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> fix_seed:</span><br><span class=\"line\">        np.random.seed(<span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"comment\"># äº§ç”Ÿ-2~2çš„éšæœºæ•°</span></span><br><span class=\"line\">    offset = np.random.rand(data_num, data_dim) * <span class=\"number\">4</span> - <span class=\"number\">2</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> center + offset</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">centers = [[<span class=\"number\">2</span>, <span class=\"number\">8</span>], [<span class=\"number\">5</span>, <span class=\"number\">2</span>], [<span class=\"number\">9</span>, <span class=\"number\">6</span>]]</span><br><span class=\"line\">center_num = <span class=\"built_in\">len</span>(centers)</span><br><span class=\"line\">data_num = <span class=\"number\">500</span>  <span class=\"comment\"># æ¯ä¸ªcenteräº§ç”Ÿçš„æ ·æœ¬æ•°é‡</span></span><br><span class=\"line\"></span><br><span class=\"line\">data = np.zeros([data_num * center_num, <span class=\"number\">2</span>])</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, center <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(centers):</span><br><span class=\"line\">    data[i * data_num:(i + <span class=\"number\">1</span>) * data_num] = get_random_data(center, data_num)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æ˜¾ç¤ºæ•°æ®</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(data.shape)  <span class=\"comment\"># (1500, 2)</span></span><br><span class=\"line\">plt.scatter(data[:, <span class=\"number\">0</span>], data[:, <span class=\"number\">1</span>], s=<span class=\"number\">5</span>, color=<span class=\"string\">&#x27;c&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ---------- KMeansèšç±» ----------</span></span><br><span class=\"line\">kms = KMeans(n_clusters=<span class=\"number\">3</span>, init=<span class=\"string\">&#x27;k-means++&#x27;</span>)  <span class=\"comment\"># èšå‡º3ç±»</span></span><br><span class=\"line\">kms.fit(data)  <span class=\"comment\"># æ¨¡å‹æ‹Ÿåˆ</span></span><br><span class=\"line\">centers = kms.cluster_centers_  <span class=\"comment\"># è®¡ç®—èšç±»ä¸­å¿ƒ</span></span><br><span class=\"line\">labels = kms.labels_  <span class=\"comment\"># èšç±»åæ¯ä¸ªæ ·æœ¬çš„ç±»åˆ«æ ‡ç­¾</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ---------- MiniBatchKMeansèšç±» ----------</span></span><br><span class=\"line\"><span class=\"comment\"># mbk = MiniBatchKMeans(init=&#x27;k-means++&#x27;, n_clusters=3, batch_size=32, random_state=0)</span></span><br><span class=\"line\"><span class=\"comment\"># mbk.fit(data)</span></span><br><span class=\"line\"><span class=\"comment\"># centers = mbk.cluster_centers_</span></span><br><span class=\"line\"><span class=\"comment\"># labels = mbk.labels_</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">plt.scatter(data[:, <span class=\"number\">0</span>], data[:, <span class=\"number\">1</span>], s=<span class=\"number\">5</span>, c=labels, cmap=<span class=\"string\">&#x27;Accent&#x27;</span>, alpha=<span class=\"number\">0.5</span>)  <span class=\"comment\"># ç”»å‡ºèšç±»åå¸¦æ ‡ç­¾çš„æ ·æœ¬</span></span><br><span class=\"line\">plt.scatter(centers[:, <span class=\"number\">0</span>], centers[:, <span class=\"number\">1</span>], marker=<span class=\"string\">&#x27;*&#x27;</span>, s=<span class=\"number\">120</span>, c=[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>], cmap=<span class=\"string\">&#x27;Accent&#x27;</span>)  <span class=\"comment\"># ç”»å‡ºèšç±»ä¸­å¿ƒ</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-é«˜ç»´æ•°æ®PCAåèšç±»\">2. é«˜ç»´æ•°æ®PCAåèšç±»</h2>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># äº§ç”Ÿé«˜ç»´æ•°æ®</span></span><br><span class=\"line\">hd_centers = [</span><br><span class=\"line\">    [<span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">6</span>, <span class=\"number\">1</span>, <span class=\"number\">5</span>, <span class=\"number\">3</span>],</span><br><span class=\"line\">    [<span class=\"number\">5</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">9</span>, <span class=\"number\">3</span>, <span class=\"number\">6</span>, <span class=\"number\">6</span>, <span class=\"number\">5</span>],</span><br><span class=\"line\">    [<span class=\"number\">3</span>, <span class=\"number\">8</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">7</span>, <span class=\"number\">1</span>, <span class=\"number\">8</span>, <span class=\"number\">8</span>, <span class=\"number\">5</span>, <span class=\"number\">4</span>]</span><br><span class=\"line\">]</span><br><span class=\"line\">hd_center_num = <span class=\"built_in\">len</span>(hd_centers)</span><br><span class=\"line\">hd_data_num = <span class=\"number\">500</span></span><br><span class=\"line\"></span><br><span class=\"line\">hd_data = np.zeros([hd_data_num * hd_center_num, <span class=\"number\">10</span>])</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, center <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(hd_centers):</span><br><span class=\"line\">    hd_data[i * hd_data_num:(i + <span class=\"number\">1</span>) * hd_data_num] = get_random_data(center, hd_data_num, data_dim=<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(hd_data.shape)  <span class=\"comment\"># (1500, 10)</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ---------- PCAä¸»æˆåˆ†åˆ†æé™ç»´ ----------</span></span><br><span class=\"line\">pca = PCA(n_components=<span class=\"number\">2</span>)  <span class=\"comment\"># é™æˆäºŒç»´</span></span><br><span class=\"line\">pca.fit(hd_data)</span><br><span class=\"line\">pca_data = pca.transform(hd_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(pca_data.shape)  <span class=\"comment\"># (1500, 2)</span></span><br><span class=\"line\">plt.scatter(pca_data[:, <span class=\"number\">0</span>], pca_data[:, <span class=\"number\">1</span>], s=<span class=\"number\">5</span>, color=<span class=\"string\">&#x27;c&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ---------- KMeansèšç±» ----------</span></span><br><span class=\"line\">kms = KMeans(n_clusters=<span class=\"number\">3</span>, init=<span class=\"string\">&#x27;k-means++&#x27;</span>)</span><br><span class=\"line\">kms.fit(pca_data)  <span class=\"comment\"># æ¨¡å‹æ‹Ÿåˆ</span></span><br><span class=\"line\">centers = kms.cluster_centers_  <span class=\"comment\"># è®¡ç®—èšç±»ä¸­å¿ƒ</span></span><br><span class=\"line\">labels = kms.labels_  <span class=\"comment\"># èšç±»åæ¯ä¸ªæ ·æœ¬çš„ç±»åˆ«æ ‡ç­¾</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">plt.scatter(pca_data[:, <span class=\"number\">0</span>], pca_data[:, <span class=\"number\">1</span>], s=<span class=\"number\">5</span>, c=labels, cmap=<span class=\"string\">&#x27;Accent&#x27;</span>, alpha=<span class=\"number\">0.5</span>)  <span class=\"comment\"># ç”»å‡ºèšç±»åå¸¦æ ‡ç­¾çš„æ ·æœ¬</span></span><br><span class=\"line\">plt.scatter(centers[:, <span class=\"number\">0</span>], centers[:, <span class=\"number\">1</span>], marker=<span class=\"string\">&#x27;*&#x27;</span>, s=<span class=\"number\">120</span>, c=[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>], cmap=<span class=\"string\">&#x27;Accent&#x27;</span>)  <span class=\"comment\"># ç”»å‡ºèšç±»ä¸­å¿ƒ</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-é«˜ç»´æ•°æ®èšç±»å¹¶è®¡ç®—ä¸ä¸­å¿ƒçš„ç›¸ä¼¼åº¦\">3. é«˜ç»´æ•°æ®èšç±»å¹¶è®¡ç®—ä¸ä¸­å¿ƒçš„ç›¸ä¼¼åº¦</h2>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># äº§ç”Ÿé«˜ç»´æ•°æ®</span></span><br><span class=\"line\">hd_centers = [</span><br><span class=\"line\">    [<span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">6</span>, <span class=\"number\">1</span>, <span class=\"number\">5</span>, <span class=\"number\">3</span>],</span><br><span class=\"line\">    [<span class=\"number\">5</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">9</span>, <span class=\"number\">3</span>, <span class=\"number\">6</span>, <span class=\"number\">6</span>, <span class=\"number\">5</span>],</span><br><span class=\"line\">    [<span class=\"number\">3</span>, <span class=\"number\">8</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">7</span>, <span class=\"number\">1</span>, <span class=\"number\">8</span>, <span class=\"number\">8</span>, <span class=\"number\">5</span>, <span class=\"number\">4</span>]</span><br><span class=\"line\">]</span><br><span class=\"line\">hd_center_num = <span class=\"built_in\">len</span>(hd_centers)</span><br><span class=\"line\">hd_data_num = <span class=\"number\">500</span></span><br><span class=\"line\"></span><br><span class=\"line\">hd_data = np.zeros([hd_data_num * hd_center_num, <span class=\"number\">10</span>])</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, center <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(hd_centers):</span><br><span class=\"line\">    hd_data[i * hd_data_num:(i + <span class=\"number\">1</span>) * hd_data_num] = get_random_data(center, hd_data_num, data_dim=<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(hd_data.shape)  <span class=\"comment\"># (1500, 10)</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># å¯¹åŸå§‹é«˜ç»´æ•°æ®èšç±»</span></span><br><span class=\"line\">kms = KMeans(n_clusters=<span class=\"number\">3</span>, init=<span class=\"string\">&#x27;k-means++&#x27;</span>)</span><br><span class=\"line\">kms.fit(hd_data)  <span class=\"comment\"># æ¨¡å‹æ‹Ÿåˆ</span></span><br><span class=\"line\">centers = kms.cluster_centers_  <span class=\"comment\"># è®¡ç®—èšç±»ä¸­å¿ƒ</span></span><br><span class=\"line\">labels = kms.labels_  <span class=\"comment\"># èšç±»åæ¯ä¸ªæ ·æœ¬çš„ç±»åˆ«æ ‡ç­¾</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(centers.shape)  <span class=\"comment\"># (3, 10)ï¼Œ3ä¸ªèšç±»ä¸­å¿ƒçš„é«˜ç»´å‘é‡</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(labels[:<span class=\"number\">10</span>])  <span class=\"comment\"># [1 1 1 1 1 1 1 1 1 1]ï¼Œç¬¬1ç±»çš„æ ‡ç­¾</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(labels[<span class=\"number\">500</span>:<span class=\"number\">510</span>])  <span class=\"comment\"># [2 2 2 2 2 2 2 2 2 2]ï¼Œç¬¬2ç±»çš„æ ‡ç­¾</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(labels[<span class=\"number\">1490</span>:])  <span class=\"comment\"># [0 0 0 0 0 0 0 0 0 0]ï¼Œç¬¬3ç±»çš„æ ‡ç­¾</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è®¡ç®—æ¯ä¸ªå‘é‡åˆ†åˆ«ä¸3ä¸ªèšç±»ä¸­å¿ƒçš„ä½™å¼¦ç›¸ä¼¼åº¦</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">CosineSimilarity</span>(<span class=\"params\">x, y</span>):</span><br><span class=\"line\">    normalized_x = x / np.linalg.norm(x, axis=-<span class=\"number\">1</span>, keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    normalized_y = y / np.linalg.norm(y, axis=-<span class=\"number\">1</span>, keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.<span class=\"built_in\">sum</span>(normalized_x * normalized_y, axis=-<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">data_cnt = hd_data_num * hd_center_num</span><br><span class=\"line\">true_cnt = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(hd_data):</span><br><span class=\"line\">    score_0 = CosineSimilarity(data, centers[<span class=\"number\">0</span>])</span><br><span class=\"line\">    score_1 = CosineSimilarity(data, centers[<span class=\"number\">1</span>])</span><br><span class=\"line\">    score_2 = CosineSimilarity(data, centers[<span class=\"number\">2</span>])</span><br><span class=\"line\">    max_idx = np.argmax([score_0, score_1, score_2])</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;ID: <span class=\"subst\">&#123;i&#125;</span>, Score0: <span class=\"subst\">&#123;score_0:<span class=\"number\">.2</span>f&#125;</span>, Score1: <span class=\"subst\">&#123;score_1:<span class=\"number\">.2</span>f&#125;</span>, Score2: <span class=\"subst\">&#123;score_2:<span class=\"number\">.2</span>f&#125;</span>, Pred_label: <span class=\"subst\">&#123;max_idx&#125;</span>&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> i &lt; <span class=\"number\">500</span>:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> max_idx == <span class=\"number\">1</span>:</span><br><span class=\"line\">            true_cnt = true_cnt + <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> i &lt; <span class=\"number\">1000</span>:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> max_idx == <span class=\"number\">2</span>:</span><br><span class=\"line\">            true_cnt = true_cnt + <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> max_idx == <span class=\"number\">0</span>:</span><br><span class=\"line\">            true_cnt = true_cnt + <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"comment\"># ID: 0, Score0: 0.85, Score1: 0.98, Score2: 0.85, Pred_label: 1</span></span><br><span class=\"line\"><span class=\"comment\"># ID: 1, Score0: 0.84, Score1: 0.92, Score2: 0.79, Pred_label: 1</span></span><br><span class=\"line\"><span class=\"comment\"># ID: 2, Score0: 0.87, Score1: 0.93, Score2: 0.90, Pred_label: 1</span></span><br><span class=\"line\"><span class=\"comment\"># ...</span></span><br><span class=\"line\"><span class=\"comment\"># ID: 500, Score0: 0.85, Score1: 0.78, Score2: 0.99, Pred_label: 2</span></span><br><span class=\"line\"><span class=\"comment\"># ID: 501, Score0: 0.85, Score1: 0.75, Score2: 0.98, Pred_label: 2</span></span><br><span class=\"line\"><span class=\"comment\"># ID: 502, Score0: 0.83, Score1: 0.71, Score2: 0.98, Pred_label: 2</span></span><br><span class=\"line\"><span class=\"comment\"># ...</span></span><br><span class=\"line\"><span class=\"comment\"># ID: 1000, Score0: 0.99, Score1: 0.81, Score2: 0.87, Pred_label: 0</span></span><br><span class=\"line\"><span class=\"comment\"># ID: 1001, Score0: 0.98, Score1: 0.77, Score2: 0.83, Pred_label: 0</span></span><br><span class=\"line\"><span class=\"comment\"># ID: 1002, Score0: 0.99, Score1: 0.76, Score2: 0.87, Pred_label: 0</span></span><br><span class=\"line\"><span class=\"comment\"># ...</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;All: <span class=\"subst\">&#123;data_cnt&#125;</span>, True: <span class=\"subst\">&#123;true_cnt&#125;</span>, Acc: <span class=\"subst\">&#123;true_cnt / data_cnt:<span class=\"number\">.2</span>f&#125;</span>&#x27;</span>)  <span class=\"comment\"># All: 1500, True: 1499, Acc: 1.00</span></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/21944.html",
            "url": "https://asanosaki.github.io/posts/21944.html",
            "title": "åˆ†å‰²å›¾åƒçš„ç€è‰²ä¸ç›¸ä¼¼åº¦åŒ¹é…",
            "date_published": "2023-08-08T06:14:00.000Z",
            "content_html": "<blockquote>\n<p>ä»‹ç»å›¾åƒåˆ†å‰²åäº§ç”Ÿçš„ã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-åˆ†å‰²å›¾åƒç€è‰²\">1. åˆ†å‰²å›¾åƒç€è‰²</h2>\n<p>ä»¥ SAM åˆ†å‰²ä¸ºä¾‹ï¼Œæˆ‘ä»¬åˆ†å‰²å‡ºæ¥äº§ç”Ÿçš„ <code>masks</code> ä¸ºä¸€ä¸ª Listï¼Œé•¿åº¦ä¸ºåˆ†å‰²å‡ºæ¥çš„ç±»åˆ«æ•°ï¼ŒList ä¸­çš„æ¯ä¸ªå…ƒç´ ä¸ºä¸€ä¸ª Dictï¼Œè®°å½•äº†åˆ†å‰²ç›®æ ‡çš„é¢ç§¯ã€è¾¹ç•Œæ¡†ç­‰ä¿¡æ¯ï¼Œå…¶ä¸­çš„ <code>segmentation</code> å­—æ®µä¸ºåˆ†å‰²å‡ºæ¥çš„äºŒå€¼å›¾ï¼Œå®½é«˜ä¸åŸå›¾ä¸€è‡´ï¼Œç›®æ ‡åƒç´ ç‚¹ä¸º Trueï¼Œå¦åˆ™ä¸º Falseã€‚</p>\n<p>æˆ‘ä»¬å®ç°ä¸¤ç§æ–¹å¼åˆ†åˆ«å¯¹åˆ†å‰²å‡ºæ¥çš„ <code>masks</code> ä»¥åŠä¿å­˜ä¸‹æ¥çš„è‹¥å¹²å¼ åˆ†å‰²å›¾åƒè¿›è¡Œåˆå¹¶ä¸ä¸Šè‰²ã€‚ç°åº¦å›¾åƒå’Œä¼ªå½©è‰²å›¾åƒéƒ½å¯¹åº”ä¸€ä¸ªç´¢å¼•è¡¨ï¼Œè¿™ä¸ªç´¢å¼•è¡¨åˆå«è°ƒè‰²æ¿ã€‚å›¾åƒçš„åƒç´ å€¼å°±æ˜¯ç´¢å¼•ï¼Œç°åº¦å›¾çš„ç´¢å¼•è¡¨ä¸ºï¼š</p>\n<table>\n    <thead>\n        <tr>\n            <th>åƒç´ å€¼</th>\n            <th>R</th>\n            <th>G</th>\n            <th>B</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>0</td>\n            <td>0</td>\n            <td>0</td>\n            <td>0</td>\n        </tr>\n        <tr>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>2</td>\n            <td>2</td>\n            <td>2</td>\n            <td>2</td>\n        </tr>\n        <tr>\n            <td>3</td>\n            <td>3</td>\n            <td>3</td>\n            <td>3</td>\n        </tr>\n        <tr>\n            <td>...</td>\n            <td>...</td>\n            <td>...</td>\n            <td>...</td>\n        </tr>\n        <tr>\n            <td>255</td>\n            <td>255</td>\n            <td>255</td>\n            <td>255</td>\n        </tr>\n    </tbody>\n</table>\n<p>ç´¢å¼•è¡¨ä¸åŒçš„åƒç´ å€¼å¯¹åº”çš„ RGB å€¼å°±æ˜¯è¯¥åƒç´ çš„é¢œè‰²ï¼Œç°åº¦å›¾åƒçš„ç´¢å¼•è¡¨ä¸­çš„ RGB å€¼éƒ½ä¸åƒç´ å€¼ç›¸åŒã€‚åŒç†ï¼Œåªè¦ä¿®æ”¹è¿™äº› RGB æ•°å€¼ï¼Œå°±å¯ä»¥æ˜¾ç¤ºä¼ªå½©è‰²å›¾åƒäº†ã€‚æ³¨æ„è°ƒè‰²æ¿çš„ç´¢å¼•ä»0-255ï¼Œå› æ­¤ï¼Œè°ƒè‰²æ¿çš„æ¯ä¸ªç´¢å¼•å¯¹åº”çš„ RGB å€¼éƒ½è¦è¿›è¡Œè®¾ç½®ã€‚</p>\n<p>ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è°ƒè‰²æ¿</span></span><br><span class=\"line\">_palette = []</span><br><span class=\"line\">color_num = <span class=\"number\">100</span>  <span class=\"comment\"># ä¸åŒçš„é¢œè‰²æ•°é‡</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(color_num // <span class=\"number\">4</span>):</span><br><span class=\"line\">    _palette.append([(<span class=\"number\">255</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>, (<span class=\"number\">50</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>, (<span class=\"number\">100</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>])</span><br><span class=\"line\">    _palette.append([(<span class=\"number\">100</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>, (<span class=\"number\">50</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>, (<span class=\"number\">255</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>])</span><br><span class=\"line\">    _palette.append([(<span class=\"number\">33</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>, (<span class=\"number\">133</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>, (<span class=\"number\">233</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>])</span><br><span class=\"line\">    _palette.append([(<span class=\"number\">68</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>, (<span class=\"number\">218</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>, (<span class=\"number\">138</span> + i * <span class=\"number\">8</span>) % <span class=\"number\">256</span>])</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(color_num, <span class=\"number\">256</span>):  <span class=\"comment\"># è¡¥ä¸Šåé¢çš„ç°åº¦å€¼ç´¢å¼•</span></span><br><span class=\"line\">    _palette.append([i, i, i])</span><br><span class=\"line\">color_palette = np.array(_palette, dtype=<span class=\"string\">&#x27;uint8&#x27;</span>).reshape(-<span class=\"number\">1</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"comment\"># print(color_palette.shape)  # (256, 3)</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ç»™maskä¸Šè‰²</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">colorize_mask</span>(<span class=\"params\">mask</span>):</span><br><span class=\"line\">    mask = Image.fromarray(mask.astype(np.uint8))</span><br><span class=\"line\">    mask = mask.convert(mode=<span class=\"string\">&#x27;P&#x27;</span>)</span><br><span class=\"line\">    mask.putpalette(color_palette)</span><br><span class=\"line\">    <span class=\"comment\"># mask = mask.convert(mode=&#x27;RGB&#x27;)</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> mask</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ç»™maskä¸Šè‰²å¹¶ä¿å­˜</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">save_colorize_mask</span>(<span class=\"params\">mask, output_dir, file_name</span>):</span><br><span class=\"line\">    save_mask = colorize_mask(mask)</span><br><span class=\"line\">    save_mask.save(os.path.join(output_dir, file_name))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æ˜¾ç¤ºSAMåˆ†å‰²å‡ºæ¥çš„masks</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">show_origin_masks</span>(<span class=\"params\">masks</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(masks) == <span class=\"number\">0</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\">    sorted_masks = <span class=\"built_in\">sorted</span>(masks, key=(<span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&#x27;area&#x27;</span>]), reverse=<span class=\"literal\">True</span>)  <span class=\"comment\"># æŒ‰é¢ç§¯ä»å¤§åˆ°å°æ’åº</span></span><br><span class=\"line\">    <span class=\"comment\"># ax = plt.gca()  # åœ¨åŸæœ¬çš„å›¾ç‰‡ä¸Šç»˜åˆ¶</span></span><br><span class=\"line\">    <span class=\"comment\"># ax.set_autoscale_on(False)  # åœ¨åŸæœ¬çš„å›¾ç‰‡ä¸Šç»˜åˆ¶</span></span><br><span class=\"line\"></span><br><span class=\"line\">    img = np.ones((sorted_masks[<span class=\"number\">0</span>][<span class=\"string\">&#x27;segmentation&#x27;</span>].shape[<span class=\"number\">0</span>], sorted_masks[<span class=\"number\">0</span>][<span class=\"string\">&#x27;segmentation&#x27;</span>].shape[<span class=\"number\">1</span>], <span class=\"number\">4</span>))  <span class=\"comment\"># img.shape: (1080, 1920, 4)</span></span><br><span class=\"line\">    img[:, :, <span class=\"number\">3</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> mask <span class=\"keyword\">in</span> sorted_masks:</span><br><span class=\"line\">        m = mask[<span class=\"string\">&#x27;segmentation&#x27;</span>]  <span class=\"comment\"># (1080, 1920)çš„True or FalseçŸ©é˜µ</span></span><br><span class=\"line\">        color_mask = np.concatenate([np.random.random(<span class=\"number\">3</span>), [<span class=\"number\">0.35</span>]])  <span class=\"comment\"># ç¬¬4ç»´è¡¨ç¤ºé€æ˜åº¦</span></span><br><span class=\"line\">        img[m] = color_mask</span><br><span class=\"line\">    <span class=\"comment\"># ax.imshow(img)  # åœ¨åŸæœ¬çš„å›¾ç‰‡ä¸Šç»˜åˆ¶</span></span><br><span class=\"line\">    plt.axis(<span class=\"string\">&#x27;off&#x27;</span>)</span><br><span class=\"line\">    plt.imshow(img)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æ˜¾ç¤ºç›®å½•img_masks_pathä¸­çš„masks</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">show_img_masks</span>(<span class=\"params\">masks_dir, height, width, threshold</span>):</span><br><span class=\"line\">    mask = np.zeros((height, width))</span><br><span class=\"line\">    img_mask_names = os.listdir(masks_dir)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, img_mask_name <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(img_mask_names):</span><br><span class=\"line\">        img_mask = Image.<span class=\"built_in\">open</span>(os.path.join(masks_dir, img_mask_name))</span><br><span class=\"line\">        img_mask = np.asarray(img_mask, dtype=np.bool_)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> np.<span class=\"built_in\">sum</span>(img_mask) &lt; threshold:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        mask[img_mask] = idx + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Image.fromarray(mask).show()  <span class=\"comment\"># ä¸Šè‰²å‰çš„mask</span></span><br><span class=\"line\">    mask = colorize_mask(mask)</span><br><span class=\"line\">    mask.show()  <span class=\"comment\"># ä¸Šè‰²åçš„mask</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è¯»å–åŸå§‹å›¾åƒ</span></span><br><span class=\"line\">image = Image.<span class=\"built_in\">open</span>(<span class=\"string\">&#x27;../images/people.jpg&#x27;</span>)</span><br><span class=\"line\">width, height = image.size</span><br><span class=\"line\">image.show()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è¯»å–SAMåˆ†å‰²çš„è‹¥å¹²maskså›¾åƒè¿›è¡Œåˆå¹¶ä¸Šè‰²æ˜¾ç¤º</span></span><br><span class=\"line\">masks_dir = <span class=\"string\">&#x27;../images/people_sam/&#x27;</span></span><br><span class=\"line\">threshold = <span class=\"number\">200</span></span><br><span class=\"line\">show_img_masks(masks_dir, height, width, threshold)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># å±•ç¤ºä¸Šè‰²å‰åçš„mask</span></span><br><span class=\"line\">test_mask_path = <span class=\"string\">&#x27;../images/test_mask.png&#x27;</span></span><br><span class=\"line\">test_mask = Image.<span class=\"built_in\">open</span>(test_mask_path)</span><br><span class=\"line\">test_mask.show()</span><br><span class=\"line\">test_mask = np.array(test_mask, dtype=np.uint8)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(test_mask.shape)  <span class=\"comment\"># (1080, 1920)</span></span><br><span class=\"line\"></span><br><span class=\"line\">mask_gray = Image.fromarray(test_mask, <span class=\"string\">&#x27;P&#x27;</span>)</span><br><span class=\"line\">mask_gray.show()</span><br><span class=\"line\">mask_color = colorize_mask(test_mask)</span><br><span class=\"line\">mask_color.show()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">list</span>(np.unique(mask_color)))  <span class=\"comment\"># [0, 1, 2, 3, 4, 5, 6, ..., 44]ï¼Œå¯ä»¥çœ‹æˆç±»åˆ«</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"2-åˆ†å‰²å›¾ç›¸ä¼¼åº¦åŒ¹é…\">2. åˆ†å‰²å›¾ç›¸ä¼¼åº¦åŒ¹é…</h2>\n<p><strong>åŒºåŸŸç›¸ä¼¼åº¦</strong>ï¼ˆRegion Similarityï¼‰ï¼šä¸ºäº†æµ‹é‡åŸºäºåŒºåŸŸçš„åˆ†å‰²ç›¸ä¼¼åº¦ï¼Œå³é”™è¯¯åƒç´ çš„æ•°é‡ï¼Œæˆ‘ä»¬ä½¿ç”¨ Jaccard ç´¢å¼• ğ’¥ è¡¨ç¤ºï¼Œ ğ’¥ å®šä¹‰ä¸ºé¢„æµ‹çš„åˆ†å‰²è¾“å‡º Mask å’ŒçœŸå€¼ Mask ä¹‹é—´çš„äº¤å¹¶æ¯” IoUï¼ˆIntersection over Unionï¼‰ï¼ŒJaccard ç´¢å¼•æä¾›äº†å…³äºé”™è¯¯åˆ†ç±»åƒç´ çš„ç›´è§‚çš„ä¿¡æ¯ã€‚</p>\n<p><strong>è¾¹æ²¿ç²¾åº¦</strong>ï¼ˆContour Accuracyï¼‰ï¼šè¾¹æ²¿ç²¾åº¦å³è®¡ç®— F-scoreï¼ŒF-score è¯„ä¼°çš„æ˜¯é¢„æµ‹ Mask çš„è¾¹ç•Œæ˜¯å¦ä¸çœŸå€¼ Mask çš„è¾¹ç•Œå¯¹åº”ã€‚é¦–å…ˆåº”æå–é¢„æµ‹ Mask å’ŒçœŸå€¼ Mask çš„è¾¹ç•Œå…ƒç´ åæ ‡ï¼Œå°†è¾¹ç•Œä¸Šçš„å…ƒç´ ç½®ä¸º Trueï¼Œéè¾¹ç•Œçš„å…ƒç´ ç½®ä¸º Falseã€‚F-score è¢«å®šä¹‰ä¸º<strong>ç²¾åº¦</strong>å’Œ<strong>å¬å›ç‡</strong>çš„è°ƒå’Œå¹³å‡æ•°ã€‚</p>\n<p><strong>ç²¾åº¦</strong>ï¼ˆPrecisionï¼ŒPï¼Œä¹Ÿç§°æŸ¥å‡†ç‡ï¼‰ï¼šåˆ†æ¯åº”æ˜¯<strong>é¢„æµ‹</strong> Mask çš„è¾¹ç•Œå…ƒç´ æ€»æ•°ï¼Œåˆ†å­åˆ™æ˜¯åœ¨é¢„æµ‹ Mask ä¸ºè¾¹ç•Œçš„é‚£äº›å…ƒç´ ä¸­çœŸæ­£å±äºçœŸå€¼çš„ã€‚æ¢å¥è¯è¯´ï¼Œé¢„æµ‹ Mask å‡è®¾æœ‰100ä¸ªå…ƒç´ ä¸ºè¾¹ç•Œå…ƒç´ ï¼Œä½†å®é™…ä¸Šå¯èƒ½åªæœ‰70ä¸ªå­˜åœ¨äºçœŸå€¼å›¾çš„å¯¹åº”ä½ç½®ä¸Šï¼Œå³70ä¸ªçœŸå€¼çš„æ­£æ ·æœ¬è¢«æ­£ç¡®ï¼ˆTrueï¼‰é¢„æµ‹ä¸º Positiveï¼Œå±äº True Positiveï¼ˆTPï¼‰ï¼Œæ‰€ä»¥æ­¤æ—¶çš„æŸ¥å‡†ç‡ä¸º70%ï¼Œå‰©ä¸‹çš„30ä¸ªå…ƒç´ æ˜¯é”™è¯¯ï¼ˆFalseï¼‰é¢„æµ‹ä¸º Positiveï¼Œå±äº False Positiveï¼ˆFPï¼‰ã€‚</p>\n<p><strong>å¬å›ç‡</strong>ï¼ˆRecallï¼ŒRï¼Œä¹Ÿç§°æŸ¥å…¨ç‡ï¼‰ï¼šåˆ†æ¯æ˜¯<strong>çœŸå€¼</strong> Mask çš„è¾¹ç•Œå…ƒç´ æ€»æ•°ï¼Œåˆ†å­è¡¨ç¤ºå¤šå°‘ä¸ªæœ¬è´¨çš„æ­£æ ·æœ¬è¢«é¢„æµ‹å‡ºæ¥ã€‚ä¾‹å¦‚çœŸå€¼ Mask çš„è¾¹ç•Œæœ‰140ä¸ªå…ƒç´ ï¼Œä½†å®é™…çš„é¢„æµ‹ Mask ä¸­åªæœ‰70ä¸ªçœŸå€¼çš„æ­£æ ·æœ¬è¢«æ­£ç¡®ï¼ˆTrueï¼‰é¢„æµ‹ä¸º Positiveï¼ˆTPï¼‰ï¼Œè¿˜æœ‰70ä¸ªè¢«é”™è¯¯ï¼ˆFalseï¼‰é¢„æµ‹ä¸º Negativeï¼ˆFalse Negativeï¼‰ï¼Œé‚£ä¹ˆæ­¤æ—¶çš„ Recall ä¸º50%ã€‚</p>\n<p>J &amp; F æŒ‡æ ‡çš„è®¡ç®—ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">from</span> skimage.morphology <span class=\"keyword\">import</span> binary_dilation, disk</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">db_eval_iou</span>(<span class=\"params\">annotation, segmentation</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    Compute region similarity as the Jaccard Index.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">        annotation   (ndarray): binary annotation   map.</span></span><br><span class=\"line\"><span class=\"string\">        segmentation (ndarray): binary segmentation map.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Return:</span></span><br><span class=\"line\"><span class=\"string\">        jaccard (float): region similarity</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    annotation = annotation.astype(np.bool_)</span><br><span class=\"line\">    segmentation = segmentation.astype(np.bool_)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> np.isclose(np.<span class=\"built_in\">sum</span>(annotation), <span class=\"number\">0</span>) <span class=\"keyword\">and</span> np.isclose(np.<span class=\"built_in\">sum</span>(segmentation), <span class=\"number\">0</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> np.<span class=\"built_in\">sum</span>((annotation &amp; segmentation)) / np.<span class=\"built_in\">sum</span>((annotation | segmentation), dtype=np.float32)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">db_eval_boundary</span>(<span class=\"params\">foreground_mask, gt_mask, bound_th=<span class=\"number\">0.008</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    Compute mean, recall and decay from per-frame evaluation.</span></span><br><span class=\"line\"><span class=\"string\">    Calculates precision/recall for boundaries between foreground_mask and</span></span><br><span class=\"line\"><span class=\"string\">    gt_mask using morphological operators to speed it up.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">        foreground_mask (ndarray): binary segmentation image.</span></span><br><span class=\"line\"><span class=\"string\">        gt_mask         (ndarray): binary annotated image.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">        F (float): boundaries F-measure</span></span><br><span class=\"line\"><span class=\"string\">        P (float): boundaries precision</span></span><br><span class=\"line\"><span class=\"string\">        R (float): boundaries recall</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> np.atleast_3d(foreground_mask).shape[<span class=\"number\">2</span>] == <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    bound_pix = bound_th <span class=\"keyword\">if</span> bound_th &gt;= <span class=\"number\">1</span> <span class=\"keyword\">else</span> \\</span><br><span class=\"line\">        np.ceil(bound_th * np.linalg.norm(foreground_mask.shape))  <span class=\"comment\"># np.linalg.normè®¡ç®—èŒƒæ•°ï¼Œé»˜è®¤ä¸ºL2èŒƒæ•°</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Get the pixel boundaries of both masks</span></span><br><span class=\"line\">    fg_boundary = seg2bmap(foreground_mask)  <span class=\"comment\"># å°†è¾¹ç•Œç½®ä¸ºTrue</span></span><br><span class=\"line\">    gt_boundary = seg2bmap(gt_mask)</span><br><span class=\"line\"></span><br><span class=\"line\">    fg_dil = binary_dilation(fg_boundary, disk(bound_pix))  <span class=\"comment\"># äºŒå€¼åŒ–è†¨èƒ€</span></span><br><span class=\"line\">    gt_dil = binary_dilation(gt_boundary, disk(bound_pix))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Get the intersection</span></span><br><span class=\"line\">    gt_match = gt_boundary * fg_dil  <span class=\"comment\"># è®¡ç®—GTä¸­ä¸FGè¾¹ç¼˜åŒ¹é…çš„åƒç´ </span></span><br><span class=\"line\">    fg_match = fg_boundary * gt_dil  <span class=\"comment\"># è®¡ç®—FGä¸­ä¸GTè¾¹ç¼˜åŒ¹é…çš„åƒç´ </span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Area of the intersection</span></span><br><span class=\"line\">    n_fg = np.<span class=\"built_in\">sum</span>(fg_boundary)  <span class=\"comment\"># FGè¾¹ç¼˜åƒç´ æ•°é‡</span></span><br><span class=\"line\">    n_gt = np.<span class=\"built_in\">sum</span>(gt_boundary)  <span class=\"comment\"># GTè¾¹ç¼˜åƒç´ æ•°é‡</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#% Compute precision and recall</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> n_fg == <span class=\"number\">0</span> <span class=\"keyword\">and</span> n_gt &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        precision = <span class=\"number\">1</span></span><br><span class=\"line\">        recall = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> n_fg &gt; <span class=\"number\">0</span> <span class=\"keyword\">and</span> n_gt == <span class=\"number\">0</span>:</span><br><span class=\"line\">        precision = <span class=\"number\">0</span></span><br><span class=\"line\">        recall = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> n_fg == <span class=\"number\">0</span> <span class=\"keyword\">and</span> n_gt == <span class=\"number\">0</span>:</span><br><span class=\"line\">        precision = <span class=\"number\">1</span></span><br><span class=\"line\">        recall = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        precision = np.<span class=\"built_in\">sum</span>(fg_match) / <span class=\"built_in\">float</span>(n_fg)</span><br><span class=\"line\">        recall = np.<span class=\"built_in\">sum</span>(gt_match) / <span class=\"built_in\">float</span>(n_gt)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Compute F measure</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> precision + recall == <span class=\"number\">0</span>:</span><br><span class=\"line\">        F_score = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        F_score = <span class=\"number\">2</span> * precision * recall / (precision + recall)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> F_score</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">seg2bmap</span>(<span class=\"params\">seg, width=<span class=\"literal\">None</span>, height=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    From a segmentation, compute a binary boundary map with 1 pixel wide</span></span><br><span class=\"line\"><span class=\"string\">    boundaries.  The boundary pixels are offset by 1/2 pixel towards the</span></span><br><span class=\"line\"><span class=\"string\">    origin from the actual segment boundary.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">        seg     : Segments labeled from 1..k.</span></span><br><span class=\"line\"><span class=\"string\">        width      :\tWidth of desired bmap  &lt;= seg.shape[1]</span></span><br><span class=\"line\"><span class=\"string\">        height  :    Height of desired bmap &lt;= seg.shape[0]</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">        bmap (ndarray):    Binary boundary map.</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    seg = seg.astype(np.bool_)</span><br><span class=\"line\">    seg[seg &gt; <span class=\"number\">0</span>] = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> np.atleast_3d(seg).shape[<span class=\"number\">2</span>] == <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    width = seg.shape[<span class=\"number\">1</span>] <span class=\"keyword\">if</span> width <span class=\"keyword\">is</span> <span class=\"literal\">None</span> <span class=\"keyword\">else</span> width</span><br><span class=\"line\">    height = seg.shape[<span class=\"number\">0</span>] <span class=\"keyword\">if</span> height <span class=\"keyword\">is</span> <span class=\"literal\">None</span> <span class=\"keyword\">else</span> height</span><br><span class=\"line\"></span><br><span class=\"line\">    h,w = seg.shape[:<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    ar1 = <span class=\"built_in\">float</span>(width) / <span class=\"built_in\">float</span>(height)</span><br><span class=\"line\">    ar2 = <span class=\"built_in\">float</span>(w) / <span class=\"built_in\">float</span>(h)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> <span class=\"keyword\">not</span> (width &gt; w | height &gt; h | <span class=\"built_in\">abs</span>(ar1 - ar2) &gt; <span class=\"number\">0.01</span>),\\</span><br><span class=\"line\">            <span class=\"string\">&#x27;Can&#x27;</span><span class=\"string\">&#x27;t convert %dx%d seg to %dx%d bmap.&#x27;</span>%(w, h, width, height)</span><br><span class=\"line\"></span><br><span class=\"line\">    e = np.zeros_like(seg)</span><br><span class=\"line\">    s = np.zeros_like(seg)</span><br><span class=\"line\">    se = np.zeros_like(seg)</span><br><span class=\"line\"></span><br><span class=\"line\">    e[:, :-<span class=\"number\">1</span>] = seg[:, <span class=\"number\">1</span>:]</span><br><span class=\"line\">    s[:-<span class=\"number\">1</span>, :] = seg[<span class=\"number\">1</span>:, :]</span><br><span class=\"line\">    se[:-<span class=\"number\">1</span>, :-<span class=\"number\">1</span>] = seg[<span class=\"number\">1</span>:, <span class=\"number\">1</span>:]</span><br><span class=\"line\"></span><br><span class=\"line\">    b = seg^e | seg^s | seg^se</span><br><span class=\"line\">    b[-<span class=\"number\">1</span>, :] = seg[-<span class=\"number\">1</span>, :]^e[-<span class=\"number\">1</span>, :]</span><br><span class=\"line\">    b[:, -<span class=\"number\">1</span>] = seg[:, -<span class=\"number\">1</span>]^s[:, -<span class=\"number\">1</span>]</span><br><span class=\"line\">    b[-<span class=\"number\">1</span>, -<span class=\"number\">1</span>] = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> w == width <span class=\"keyword\">and</span> h == height:</span><br><span class=\"line\">        bmap = b</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        bmap = np.zeros((height, width))</span><br><span class=\"line\">        <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(w):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(h):</span><br><span class=\"line\">                <span class=\"keyword\">if</span> b[y, x]:</span><br><span class=\"line\">                    j = <span class=\"number\">1</span> + math.floor((y - <span class=\"number\">1</span>) + height / h)</span><br><span class=\"line\">                    i = <span class=\"number\">1</span> + math.floor((x - <span class=\"number\">1</span>) + width / h)</span><br><span class=\"line\">                    bmap[j, i] = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> bmap</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">database_path = <span class=\"string\">&#x27;../data/mask_database/&#x27;</span></span><br><span class=\"line\">test_path = <span class=\"string\">&#x27;../data/mask_test/&#x27;</span></span><br><span class=\"line\">database_img_name_list = os.listdir(database_path)</span><br><span class=\"line\">test_img_name_list = os.listdir(test_path)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> test_img_name <span class=\"keyword\">in</span> test_img_name_list:</span><br><span class=\"line\">    test_img = Image.<span class=\"built_in\">open</span>(test_path + test_img_name)</span><br><span class=\"line\">    h, w = test_img.size</span><br><span class=\"line\">    test_img = np.asarray(test_img)</span><br><span class=\"line\"></span><br><span class=\"line\">    best_iou, best_F, best_iou_dbname, best_F_dbname = <span class=\"number\">0.0</span>, <span class=\"number\">0.0</span>, <span class=\"literal\">None</span>, <span class=\"literal\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> database_img_name <span class=\"keyword\">in</span> database_img_name_list:</span><br><span class=\"line\">        database_img = Image.<span class=\"built_in\">open</span>(database_path + database_img_name).resize((h, w))</span><br><span class=\"line\">        database_img = np.asarray(database_img)</span><br><span class=\"line\"></span><br><span class=\"line\">        iou = db_eval_iou(test_img, database_img)</span><br><span class=\"line\">        F_score = db_eval_boundary(test_img, database_img)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> iou &gt; best_iou:</span><br><span class=\"line\">            best_iou = iou</span><br><span class=\"line\">            best_iou_dbname = database_img_name</span><br><span class=\"line\">        <span class=\"keyword\">if</span> F_score &gt; best_F:</span><br><span class=\"line\">            best_F = F_score</span><br><span class=\"line\">            best_F_dbname = database_img_name</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;[<span class=\"subst\">&#123;test_img_name&#125;</span>] best iou: <span class=\"subst\">&#123;best_iou:<span class=\"number\">.4</span>f&#125;</span> (<span class=\"subst\">&#123;best_iou_dbname&#125;</span>), best F: <span class=\"subst\">&#123;best_F:<span class=\"number\">.4</span>f&#125;</span> (<span class=\"subst\">&#123;best_F_dbname&#125;</span>)&#x27;</span>)</span><br><span class=\"line\">    <span class=\"comment\"># [0_70.png] best iou: 0.7433 (0_9_156_197_151.png), best F: 0.2681 (0_2_152_212_77.png)</span></span><br><span class=\"line\">    <span class=\"comment\"># [0_71.png] best iou: 0.9399 (0_3_140_238_157.png), best F: 0.7001 (0_3_140_238_157.png)</span></span><br><span class=\"line\">    <span class=\"comment\"># [0_72.png] best iou: 0.7066 (0_10_190_185_95.png), best F: 0.2735 (0_7_93_244_223.png)</span></span><br><span class=\"line\">    <span class=\"comment\"># [0_75.png] best iou: 0.9089 (0_5_241_130_227.png), best F: 0.5160 (0_5_241_130_227.png)</span></span><br><span class=\"line\">    <span class=\"comment\"># [0_77.png] best iou: 0.5177 (0_18_252_79_113.png), best F: 0.2171 (0_1_245_116_182.png)</span></span><br><span class=\"line\">    <span class=\"comment\"># [0_78.png] best iou: 0.7393 (0_4_251_231_252.png), best F: 0.2872 (0_9_156_197_151.png)</span></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/6828.html",
            "url": "https://asanosaki.github.io/posts/6828.html",
            "title": "DeAOTè§†é¢‘è¿½è¸ªè®ºæ–‡é˜…è¯»ç¬”è®°",
            "date_published": "2023-08-08T05:58:00.000Z",
            "content_html": "<blockquote>\n<p>æœ¬æ–‡è®°å½• DeAOT è§†é¢‘è¿½è¸ªè®ºæ–‡çš„é˜…è¯»ç¬”è®°ã€‚<br>\næ¶‰åŠçš„ç›¸å…³çŸ¥è¯†ç‚¹ä¸ºï¼šAOTï¼ˆAssociating Objects with Transformers for Video Object Segmentationï¼‰ã€DeAOTï¼ˆDecoupling Features in Hierarchical Propagation for Video Object Segmentationï¼‰ã€FPNï¼ˆFeature Pyramid Networks for Object Detectionï¼‰ã€Depth-wise Convolutionã€DropPathã€GroupNormã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-ç›¸å…³çŸ¥è¯†\">1. ç›¸å…³çŸ¥è¯†</h2>\n<h3 id=\"1-1-Depth-wiseå·ç§¯\">1.1 Depth-wiseå·ç§¯</h3>\n<p>Depth-wiseï¼ˆDWï¼‰å·ç§¯ä¸ Point-wiseï¼ˆPWï¼‰å·ç§¯ï¼Œåˆèµ·æ¥è¢«ç§°ä½œ Depth-wise Separable Convolutionï¼Œè¯¥ç»“æ„å’Œå¸¸è§„å·ç§¯æ“ä½œç±»ä¼¼ï¼Œå¯ç”¨æ¥æå–ç‰¹å¾ï¼Œä½†ç›¸æ¯”äºå¸¸è§„å·ç§¯æ“ä½œï¼Œå…¶<strong>å‚æ•°é‡å’Œè¿ç®—æˆæœ¬è¾ƒä½</strong>ã€‚æ‰€ä»¥åœ¨ä¸€äº›è½»é‡çº§ç½‘ç»œä¸­ä¼šç¢°åˆ°è¿™ç§ç»“æ„ï¼Œå¦‚ MobileNetã€‚</p>\n<p>Depth-wise Convolution çš„ä¸€ä¸ªå·ç§¯æ ¸è´Ÿè´£ä¸€ä¸ªé€šé“ï¼Œå³ä¸€ä¸ªé€šé“åªè¢«ä¸€ä¸ªå•é€šé“çš„å·ç§¯æ ¸å·ç§¯ï¼Œè€Œå¸¸è§„å·ç§¯æ¯ä¸ªå·ç§¯æ ¸æ˜¯åŒæ—¶æ“ä½œè¾“å…¥å›¾ç‰‡çš„æ¯ä¸ªé€šé“ï¼Œå³æ¯ä¸ªå·ç§¯æ ¸çš„é€šé“æ•°ä¸å›¾ç‰‡çš„é€šé“æ•°ç›¸åŒã€‚</p>\n<p>Depth-wise Convolution å®Œæˆåçš„ Feature Map æ•°é‡ä¸è¾“å…¥å±‚çš„é€šé“æ•°ç›¸åŒï¼Œæ— æ³•æ‰©å±• Feature Mapã€‚è€Œä¸”è¿™ç§è¿ç®—å¯¹è¾“å…¥å±‚çš„æ¯ä¸ªé€šé“<strong>ç‹¬ç«‹</strong>è¿›è¡Œå·ç§¯è¿ç®—ï¼Œæ²¡æœ‰æœ‰æ•ˆåœ°åˆ©ç”¨ä¸åŒé€šé“åœ¨ç›¸åŒç©ºé—´ä½ç½®ä¸Šçš„ç‰¹å¾ä¿¡æ¯ã€‚å› æ­¤éœ€è¦Point-wise Convolution æ¥å°†è¿™äº› Feature Map è¿›è¡Œç»„åˆç”Ÿæˆæ–°çš„ Feature Mapã€‚</p>\n<p>Depth-wise Convolution ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Depth-wiseå·ç§¯ï¼Œè¾“å‡ºç»´åº¦å’Œè¾“å…¥ç»´åº¦ç›¸åŒ</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">DWConv2d</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, indim, dropout=<span class=\"number\">0.1</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"comment\"># å½“groups=in_channelæ—¶ï¼Œæ˜¯åœ¨åšDepth-wise Conv</span></span><br><span class=\"line\">        self.conv = nn.Conv2d(indim, indim, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"number\">1</span>, groups=indim, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.dropout = nn.Dropout2d(p=dropout, inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):  <span class=\"comment\"># x.shape: (bsz, c, h, w)</span></span><br><span class=\"line\">        out = self.dropout(self.conv(x))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\">dwconv2d = DWConv2d(indim=<span class=\"number\">3</span>)</span><br><span class=\"line\">x = torch.randn(<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">10</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(dwconv2d(x).shape)  <span class=\"comment\"># torch.Size([1, 3, 10, 10])</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"1-2-DropPath\">1.2 DropPath</h3>\n<p>DropPath æ˜¯ä¸€ç§é’ˆå¯¹<strong>åˆ†æ”¯</strong>ç½‘ç»œè€Œæå‡ºçš„ç½‘ç»œæ­£åˆ™åŒ–æ–¹æ³•ï¼Œä½œç”¨æ˜¯å°†æ·±åº¦å­¦ä¹ ç½‘ç»œä¸­çš„å¤šåˆ†æ”¯ç»“æ„éšæœºåˆ é™¤ã€‚DropPath ä½œç”¨çš„æ˜¯ç½‘ç»œåˆ†æ”¯ï¼Œè€Œ DropOut ä½œç”¨çš„æ˜¯ Feature Mapï¼ŒDropConnect ä½œç”¨çš„æ˜¯å‚æ•°ã€‚</p>\n<p>ç®€å•æ¥è¯´ï¼ŒDropPath çš„è¾“å‡ºæ˜¯éšæœºå°†ä¸€ä¸ª batch ä¸­æ‰€æœ‰çš„ç¥ç»å…ƒå‡è®¾ç½®ä¸º0ï¼›è€Œåœ¨ DropOut ä¸­ï¼Œæ˜¯åœ¨æ¯ä¸ª batch ä¸­éšæœºé€‰æ‹©ç¥ç»å…ƒè®¾ç½®ä¸º0ã€‚</p>\n<p>DropPath ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">DropPath</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, drop_prob=<span class=\"literal\">None</span>, batch_dim=<span class=\"number\">0</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(DropPath, self).__init__()</span><br><span class=\"line\">        self.drop_prob = drop_prob  <span class=\"comment\"># ä¸¢å¼ƒç‡ï¼Œå‡è®¾æ˜¯0.5</span></span><br><span class=\"line\">        self.batch_dim = batch_dim  <span class=\"comment\"># batchåœ¨ç¬¬å‡ ç»´ï¼Œå‡è®¾æ˜¯0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.drop_path(x, self.drop_prob)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">drop_path</span>(<span class=\"params\">self, x, drop_prob</span>):  <span class=\"comment\"># x.shape: (hw, bsz, c)</span></span><br><span class=\"line\">        <span class=\"comment\"># ä¸¢å¼ƒç‡ä¸º0æˆ–è€…ä¸æ˜¯åœ¨è®­ç»ƒæ—¶ç›´æ¥è¿”å›x</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> drop_prob == <span class=\"number\">0.</span> <span class=\"keyword\">or</span> <span class=\"keyword\">not</span> self.training:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\">        keep_prob = <span class=\"number\">1</span> - drop_prob  <span class=\"comment\"># ä¿æŒç‡ï¼Œ0.5</span></span><br><span class=\"line\">        shape = [<span class=\"number\">1</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(x.ndim)]  <span class=\"comment\"># [1, 1, 1]</span></span><br><span class=\"line\">        shape[self.batch_dim] = x.shape[self.batch_dim]  <span class=\"comment\"># [bsz, 1, 1]</span></span><br><span class=\"line\">        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)  <span class=\"comment\"># 0~1ä¹‹é—´çš„å‡åŒ€åˆ†å¸ƒ</span></span><br><span class=\"line\">        random_tensor.floor_()  <span class=\"comment\"># ä¸‹å–æ•´ï¼Œéšæœºå‡ºæ¥çš„å¤§äºç­‰äº0.5çš„æ•°éƒ½ä¸º1ï¼Œç¡®å®šä¿ç•™å“ªäº›batch</span></span><br><span class=\"line\">        output = x.div(keep_prob) * random_tensor  <span class=\"comment\"># é™¤ä»¥keep_probæ˜¯ä¸ºäº†è®©è®­ç»ƒå’Œæµ‹è¯•æ—¶çš„æœŸæœ›ä¿æŒä¸€è‡´</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">droppath = DropPath(drop_prob=<span class=\"number\">0.5</span>, batch_dim=<span class=\"number\">0</span>)</span><br><span class=\"line\">a = torch.randn(<span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(droppath(a))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[-0.6209, -5.4889, -1.9857],</span></span><br><span class=\"line\"><span class=\"comment\">#          [ 0.1626,  6.0644,  0.8875]],</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#         [[ 0.0000, -0.0000,  0.0000],</span></span><br><span class=\"line\"><span class=\"comment\">#          [ 0.0000, -0.0000,  0.0000]],</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#         [[-0.1041,  0.4921,  0.3389],</span></span><br><span class=\"line\"><span class=\"comment\">#          [-2.0490, -0.0399, -0.1521]]])</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"1-3-Group-Normalization\">1.3 Group Normalization</h3>\n<p>BN å…¨åæ˜¯ Batch Normalizationï¼Œè§åçŸ¥æ„ï¼Œå…¶æ˜¯ä¸€ç§å½’ä¸€åŒ–æ–¹å¼ï¼Œè€Œä¸”æ˜¯ä»¥ batch çš„ç»´åº¦åšå½’ä¸€åŒ–ï¼Œé‚£ä¹ˆé—®é¢˜å°±æ¥äº†ï¼Œæ­¤å½’ä¸€åŒ–æ–¹å¼å¦‚æœä½¿ç”¨è¿‡å°çš„ batch size ä¼šå¯¼è‡´å…¶æ€§èƒ½ä¸‹é™ï¼Œä¸€èˆ¬æ¥è¯´æ¯ä¸ª GPU ä¸Šçš„ batch size è®¾ä¸º32æœ€åˆé€‚ï¼Œä½†æ˜¯å¯¹äºä¸€äº›å…¶ä»–æ·±åº¦å­¦ä¹ ä»»åŠ¡ batch size å¾€å¾€åªæœ‰1æˆ–2ï¼Œæ¯”å¦‚ç›®æ ‡æ£€æµ‹ï¼Œå›¾åƒåˆ†å‰²ï¼Œè§†é¢‘åˆ†ç±»ä¸Šï¼Œè¾“å…¥çš„å›¾åƒæ•°æ®å¾ˆå¤§ï¼Œè¾ƒå¤§çš„ batch size æ˜¾å­˜åƒä¸æ¶ˆã€‚</p>\n<p>å¦å¤–ï¼ŒBatch Normalization æ˜¯åœ¨ batch è¿™ä¸ªç»´åº¦ä¸Šåš Normalizationï¼Œä½†æ˜¯è¿™ä¸ªç»´åº¦å¹¶<strong>ä¸æ˜¯å›ºå®šä¸å˜çš„</strong>ï¼Œæ¯”å¦‚è®­ç»ƒå’Œæµ‹è¯•æ—¶ä¸€èˆ¬ä¸ä¸€æ ·ï¼Œä¸€èˆ¬éƒ½æ˜¯è®­ç»ƒçš„æ—¶å€™åœ¨è®­ç»ƒé›†ä¸Šé€šè¿‡<strong>æ»‘åŠ¨å¹³å‡</strong>é¢„å…ˆè®¡ç®—å¥½å¹³å‡ï¼ˆmeanï¼‰ï¼Œå’Œæ–¹å·®ï¼ˆvarianceï¼‰å‚æ•°ï¼Œåœ¨æµ‹è¯•çš„æ—¶å€™ï¼Œä¸å†è®¡ç®—è¿™äº›å€¼ï¼Œè€Œæ˜¯ç›´æ¥è°ƒç”¨è¿™äº›é¢„è®¡ç®—å¥½çš„å‚æ•°æ¥ç”¨ã€‚ä½†æ˜¯ï¼Œå½“è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®åˆ†å¸ƒæœ‰å·®åˆ«æ—¶ï¼Œè®­ç»ƒæœºä¸Šé¢„è®¡ç®—å¥½çš„æ•°æ®å¹¶ä¸èƒ½ä»£è¡¨æµ‹è¯•æ•°æ®ï¼Œè¿™å°±å¯¼è‡´åœ¨è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•è¿™ä¸‰ä¸ªé˜¶æ®µå­˜åœ¨ inconsistencyï¼ˆä¸ä¸€è‡´æ€§ï¼‰ã€‚</p>\n<p>Group Normalizationï¼ˆGNï¼‰é¦–å…ˆå°† channel åˆ†ä¸ºè®¸å¤šç»„ï¼ˆgroupï¼‰ï¼Œå¯¹æ¯ä¸€ç»„åšå½’ä¸€åŒ–ï¼Œå³å…ˆå°† feature çš„ç»´åº¦ç”± <code>[N, C, H, W]</code> reshape ä¸º <code>[N, G, C/G, H, W]</code>ï¼Œå½’ä¸€åŒ–çš„ç»´åº¦ä¸º <code>[C/G, H, W]</code>ã€‚äº‹å®ä¸Šï¼ŒGN çš„æç«¯æƒ…å†µå°±æ˜¯ LNï¼ˆLayer Normalizationï¼‰å’Œ INï¼ˆInstance Normalizationï¼‰ï¼Œåˆ†åˆ«å¯¹åº” <code>G = 1</code> å’Œ <code>G = C</code>ï¼Œä½œè€…åœ¨è®ºæ–‡ä¸­ç»™å‡º G è®¾ä¸º32è¾ƒå¥½ã€‚</p>\n<p>Group Normalization ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è‡ªå·±å®ç°GN</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GroupNorm</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, num_channels, num_groups=<span class=\"number\">32</span>, eps=<span class=\"number\">1e-5</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GroupNorm, self).__init__()</span><br><span class=\"line\">        self.gamma = nn.Parameter(torch.ones(<span class=\"number\">1</span>, num_groups, <span class=\"number\">1</span>))</span><br><span class=\"line\">        self.beta = nn.Parameter(torch.zeros(<span class=\"number\">1</span>, num_groups, <span class=\"number\">1</span>))</span><br><span class=\"line\">        self.num_groups = num_groups</span><br><span class=\"line\">        self.eps = eps</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):  <span class=\"comment\"># x.shape: (N, C, H, W)</span></span><br><span class=\"line\">        N, C, H, W = x.size()</span><br><span class=\"line\">        G = self.num_groups</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> C % G == <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">        x = x.view(N, G, -<span class=\"number\">1</span>)</span><br><span class=\"line\">        mean = x.mean(-<span class=\"number\">1</span>, keepdim=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        std = x.std(-<span class=\"number\">1</span>, keepdim=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        x = self.gamma * (x - mean) / (std + self.eps) + self.beta</span><br><span class=\"line\">        x = x.view(N, C, H, W)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.randn(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">gn = GroupNorm(<span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">x_gn = gn(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_gn)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[[-0.1165, -0.5803,  0.7635],</span></span><br><span class=\"line\"><span class=\"comment\">#           [-0.2374, -1.3281,  1.4988]],</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#          [[ 0.0982, -0.3936, -1.3941],</span></span><br><span class=\"line\"><span class=\"comment\">#           [-0.5678,  1.2321,  1.0253]]]], grad_fn=&lt;ViewBackward0&gt;)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_gn.mean((<span class=\"number\">2</span>, <span class=\"number\">3</span>)))  <span class=\"comment\"># tensor([[-4.9671e-09,  9.9341e-09]], grad_fn=&lt;MeanBackward1&gt;)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_gn.var((<span class=\"number\">2</span>, <span class=\"number\">3</span>)))  <span class=\"comment\"># tensor([[1.0000, 1.0000]], grad_fn=&lt;VarBackward0&gt;)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ä½¿ç”¨torch.nnä¸­çš„GN</span></span><br><span class=\"line\">torch_gn = nn.GroupNorm(num_groups=<span class=\"number\">2</span>, num_channels=<span class=\"number\">2</span>)</span><br><span class=\"line\">x_torch_gn = torch_gn(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_torch_gn)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[[-0.1277, -0.6357,  0.8363],</span></span><br><span class=\"line\"><span class=\"comment\">#           [-0.2601, -1.4548,  1.6419]],</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#          [[ 0.1076, -0.4312, -1.5272],</span></span><br><span class=\"line\"><span class=\"comment\">#           [-0.6220,  1.3497,  1.1232]]]], grad_fn=&lt;NativeGroupNormBackward0&gt;)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_torch_gn.mean((<span class=\"number\">2</span>, <span class=\"number\">3</span>)))  <span class=\"comment\"># tensor([[-2.9802e-08,  1.9868e-08]], grad_fn=&lt;MeanBackward1&gt;)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_torch_gn.var((<span class=\"number\">2</span>, <span class=\"number\">3</span>)))  <span class=\"comment\"># tensor([[1.2000, 1.2000]], grad_fn=&lt;VarBackward0&gt;)</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"1-4-FPNç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ\">1.4 FPNç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ</h3>\n<p>ç›®æ ‡çš„å¤šå°ºåº¦ä¸€ç›´æ˜¯ç›®æ ‡æ£€æµ‹ç®—æ³•æä¸ºæ£˜æ‰‹çš„é—®é¢˜ã€‚åƒ Fast R-CNNï¼ŒYOLO è¿™äº›åªæ˜¯åˆ©ç”¨æ·±å±‚ç½‘ç»œè¿›è¡Œæ£€æµ‹çš„ç®—æ³•ï¼Œæ˜¯å¾ˆéš¾æŠŠå°ç›®æ ‡ç‰©ä½“æ£€æµ‹å¥½çš„ã€‚å› ä¸ºå°ç›®æ ‡ç‰©ä½“æœ¬èº«çš„åƒç´ å°±æ¯”è¾ƒå°‘ï¼Œéšç€ä¸‹é‡‡æ ·çš„ç´¯ç§¯ï¼Œå®ƒçš„ç‰¹å¾æ›´å®¹æ˜“è¢«ä¸¢å¤±ã€‚</p>\n<p>ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œï¼ˆFeature Pyramid Networkï¼ŒFPNï¼‰æ˜¯ä¸€ä¸ªåœ¨ç‰¹å¾å°ºåº¦çš„é‡‘å­—å¡”æ“ä½œï¼Œå®ƒæ˜¯é€šè¿‡å°†<strong>è‡ªåº•å‘ä¸Š</strong>ï¼ˆBottom-upï¼‰å’Œ<strong>è‡ªé¡¶å‘ä¸‹</strong>ï¼ˆTop-downï¼‰çš„ç‰¹å¾å›¾è¿›è¡Œ<strong>èåˆ</strong>æ¥å®ç°ç‰¹å¾é‡‘å­—å¡”æ“ä½œçš„ã€‚FPN æä¾›çš„æ˜¯ä¸€ä¸ªç‰¹å¾èåˆçš„æœºåˆ¶ï¼Œå¹¶æ²¡æœ‰å¼•å…¥å¤ªå¤šçš„å‚æ•°ï¼Œå®ç°äº†ä»¥å¢åŠ æå°è®¡ç®—ä»£ä»·çš„æƒ…å†µä¸‹æå‡å¯¹å¤šå°ºåº¦ç›®æ ‡çš„æ£€æµ‹èƒ½åŠ›ã€‚</p>\n<p>è‡ªåº•å‘ä¸Šå³æ˜¯å·ç§¯ç½‘ç»œçš„å‰å‘è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸åŒçš„éª¨å¹²ç½‘ç»œï¼Œä¾‹å¦‚ ResNet-50 æˆ–è€… ResNet-101ã€‚å‰å‘ç½‘ç»œçš„è¿”å›å€¼ä¾æ¬¡æ˜¯ C2ã€C3ã€C4ã€C5ï¼Œæ˜¯æ¯æ¬¡æ± åŒ–ä¹‹åå¾—åˆ°çš„ Feature Mapã€‚</p>\n<p>é€šè¿‡è‡ªåº•å‘ä¸Šè·¯å¾„ï¼ŒFPN å¾—åˆ°äº†å››ç»„ Feature Mapã€‚æµ…å±‚çš„ Feature Mapï¼Œä¾‹å¦‚ C2 å«æœ‰æ›´å¤šçš„åº•å±‚ä¿¡æ¯ï¼ˆçº¹ç†ï¼Œé¢œè‰²ç­‰ï¼‰ï¼Œè€Œæ·±å±‚çš„ Feature Map å¦‚ C5 å«æœ‰æ›´å¤šçš„è¯­ä¹‰ä¿¡æ¯ã€‚ä¸ºäº†å°†è¿™å››ç»„å€¾å‘ä¸åŒç‰¹å¾çš„ Feature Map ç»„åˆèµ·æ¥ï¼ŒFPN ä½¿ç”¨äº†è‡ªé¡¶å‘ä¸‹åŠ<strong>æ¨ªå‘è¿æ¥</strong>çš„ç­–ç•¥ï¼Œæœ€ç»ˆå¾—åˆ° P2ã€P3ã€P4ã€P5 å››ä¸ªè¾“å‡ºã€‚</p>\n<p>æœ€åï¼ŒFPN åœ¨ P2ã€P3ã€P4ã€P5 ä¹‹åå‡æ¥äº†ä¸€ä¸ª 3*3 Conv æ“ä½œï¼Œè¯¥å·ç§¯æ“ä½œæ˜¯ä¸ºäº†å‡è½»ä¸Šé‡‡æ ·çš„<strong>æ··å æ•ˆåº”</strong>ï¼ˆaliasing effectï¼‰ã€‚</p>\n<p>FPN å’Œ U-Net æœ€å¤§çš„ä¸åŒæ˜¯å®ƒçš„å¤šä¸ªå±‚çº§çš„éƒ½ä¼šæœ‰å„è‡ªçš„è¾“å‡ºå±‚ï¼Œè€Œæ¯ä¸ªè¾“å‡ºå±‚éƒ½æœ‰ä¸åŒå°ºåº¦çš„æ„Ÿå—é‡ã€‚ä¸€ä¸ªæ¯”è¾ƒç²—æš´çš„æ–¹å¼æ˜¯æ¯ä¸€å±‚éƒ½é¢„æµ‹æ‰€æœ‰çš„æ ·æœ¬ï¼Œè€Œå¦ä¸€ä¸ªæ›´å¥½çš„é€‰æ‹©æ˜¯æ ¹æ®ä¸€äº›å¯èƒ½å­˜åœ¨çš„å…ˆéªŒçŸ¥è¯†é€‰æ‹©ä¸€ä¸ªæœ€å¥½çš„å±‚ã€‚</p>\n<p>FPN ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Bottleneck</span>(nn.Module):</span><br><span class=\"line\">    expansion = <span class=\"number\">4</span>  <span class=\"comment\"># æ®‹å·®å—ç¬¬3ä¸ªå·ç§¯å±‚çš„é€šé“è†¨èƒ€å€ç‡</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_channels, channels, stride=<span class=\"number\">1</span>, downsample=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Bottleneck, self).__init__()</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=<span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.bn1 = nn.BatchNorm2d(channels)</span><br><span class=\"line\">        self.conv2 = nn.Conv2d(channels, channels, kernel_size=<span class=\"number\">3</span>, stride=stride, padding=<span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.bn2 = nn.BatchNorm2d(channels)</span><br><span class=\"line\">        self.conv3 = nn.Conv2d(channels, self.expansion * channels, kernel_size=<span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.bn3 = nn.BatchNorm2d(self.expansion * channels)</span><br><span class=\"line\">        self.relu = nn.ReLU(inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        self.downsample = downsample</span><br><span class=\"line\">        self.stride = stride</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        residual = x  <span class=\"comment\"># å°†åŸå§‹è¾“å…¥æš‚å­˜ä¸ºshortcutçš„è¾“å‡º</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.downsample <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:  <span class=\"comment\"># å¦‚æœéœ€è¦ä¸‹é‡‡æ ·ï¼Œé‚£ä¹ˆshortcutåï¼šH/2ï¼ŒW/2ã€‚Cï¼šout_channel -&gt; 4 * out_channel</span></span><br><span class=\"line\">            residual = self.downsample(x)</span><br><span class=\"line\"></span><br><span class=\"line\">        out = self.relu(self.bn1(self.conv1(x)))</span><br><span class=\"line\">        out = self.relu(self.bn2(self.conv2(out)))</span><br><span class=\"line\">        out = self.bn3(self.conv3(out))</span><br><span class=\"line\"></span><br><span class=\"line\">        out += residual  <span class=\"comment\"># æ®‹å·®è¿æ¥</span></span><br><span class=\"line\">        out = self.relu(out)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">FPN</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, block, layers</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(FPN, self).__init__()</span><br><span class=\"line\">        self.inchannels = <span class=\"number\">64</span></span><br><span class=\"line\"></span><br><span class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">7</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">3</span>, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.bn1 = nn.BatchNorm2d(<span class=\"number\">64</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        self.relu = nn.ReLU(inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        self.maxpool = nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Bottom-up layers</span></span><br><span class=\"line\">        self.layer1 = self._make_layer(block, <span class=\"number\">64</span>, layers[<span class=\"number\">0</span>])</span><br><span class=\"line\">        self.layer2 = self._make_layer(block, <span class=\"number\">128</span>, layers[<span class=\"number\">1</span>], stride=<span class=\"number\">2</span>)</span><br><span class=\"line\">        self.layer3 = self._make_layer(block, <span class=\"number\">256</span>, layers[<span class=\"number\">2</span>], stride=<span class=\"number\">2</span>)</span><br><span class=\"line\">        self.layer4 = self._make_layer(block, <span class=\"number\">512</span>, layers[<span class=\"number\">3</span>], stride=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Top layer</span></span><br><span class=\"line\">        self.toplayer = nn.Conv2d(<span class=\"number\">2048</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)  <span class=\"comment\"># Reduce channels</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Lateral layers</span></span><br><span class=\"line\">        self.latlayer1 = nn.Conv2d(<span class=\"number\">1024</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\">        self.latlayer2 = nn.Conv2d(<span class=\"number\">512</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\">        self.latlayer3 = nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Smooth layers</span></span><br><span class=\"line\">        self.smooth1 = nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.smooth2 = nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.smooth3 = nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> m <span class=\"keyword\">in</span> self.modules():</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(m, nn.Conv2d):</span><br><span class=\"line\">                n = m.kernel_size[<span class=\"number\">0</span>] * m.kernel_size[<span class=\"number\">1</span>] * m.out_channels</span><br><span class=\"line\">                m.weight.data.normal_(<span class=\"number\">0</span>, math.sqrt(<span class=\"number\">2.</span> / n))</span><br><span class=\"line\">            <span class=\"keyword\">elif</span> <span class=\"built_in\">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class=\"line\">                m.weight.data.fill_(<span class=\"number\">1</span>)</span><br><span class=\"line\">                m.bias.data.zero_()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">_make_layer</span>(<span class=\"params\">self, block, channel, block_num, stride=<span class=\"number\">1</span></span>):</span><br><span class=\"line\">        downsample = <span class=\"literal\">None</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> stride != <span class=\"number\">1</span> <span class=\"keyword\">or</span> self.inchannels != channel * block.expansion:</span><br><span class=\"line\">            downsample = nn.Sequential(</span><br><span class=\"line\">                nn.Conv2d(self.inchannels, block.expansion * channel, kernel_size=<span class=\"number\">1</span>, stride=stride, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                nn.BatchNorm2d(block.expansion * channel)</span><br><span class=\"line\">            )</span><br><span class=\"line\">        layers = []</span><br><span class=\"line\">        layers.append(block(self.inchannels, channel, stride, downsample))</span><br><span class=\"line\">        self.inchannels = channel * block.expansion</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, block_num):</span><br><span class=\"line\">            layers.append(block(self.inchannels, channel))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> nn.Sequential(*layers)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">_upsample_add</span>(<span class=\"params\">self, x, y</span>):  <span class=\"comment\"># å°†xä¸Šé‡‡æ ·æˆyçš„sizeåä¸yç›¸åŠ </span></span><br><span class=\"line\">        _, _, H, W = y.size()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> F.interpolate(x, size=(H, W), mode=<span class=\"string\">&#x27;bilinear&#x27;</span>) + y</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):  <span class=\"comment\"># (bsz, 3, h, w)</span></span><br><span class=\"line\">        <span class=\"comment\"># Bottom-up</span></span><br><span class=\"line\">        x = self.conv1(x)  <span class=\"comment\"># (bsz, 64, h/2, w/2)</span></span><br><span class=\"line\">        x = self.bn1(x)</span><br><span class=\"line\">        x = self.relu(x)</span><br><span class=\"line\">        c1 = self.maxpool(x)  <span class=\"comment\"># (bsz, 64, h/4, w/4)</span></span><br><span class=\"line\"></span><br><span class=\"line\">        c2 = self.layer1(c1)  <span class=\"comment\"># (bsz, 256, h/4, w/4)</span></span><br><span class=\"line\">        c3 = self.layer2(c2)  <span class=\"comment\"># (bsz, 512, h/8, w/8)</span></span><br><span class=\"line\">        c4 = self.layer3(c3)  <span class=\"comment\"># (bsz, 1024, h/16, w/16)</span></span><br><span class=\"line\">        c5 = self.layer4(c4)  <span class=\"comment\"># (bsz, 2048, h/32, w/32)</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Top-down</span></span><br><span class=\"line\">        p5 = self.toplayer(c5)  <span class=\"comment\"># (bsz, 256, h/32, w/32)</span></span><br><span class=\"line\">        p4 = self._upsample_add(p5, self.latlayer1(c4))  <span class=\"comment\"># (bsz, 256, h/16, w/16)</span></span><br><span class=\"line\">        p3 = self._upsample_add(p4, self.latlayer2(c3))  <span class=\"comment\"># (bsz, 256, h/8, w/8)</span></span><br><span class=\"line\">        p2 = self._upsample_add(p3, self.latlayer3(c2))  <span class=\"comment\"># (bsz, 256, h/4, w/4)</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Smooth</span></span><br><span class=\"line\">        p4 = self.smooth1(p4)  <span class=\"comment\"># (bsz, 256, h/16, w/16)</span></span><br><span class=\"line\">        p3 = self.smooth2(p3)  <span class=\"comment\"># (bsz, 256, h/8, w/8)</span></span><br><span class=\"line\">        p2 = self.smooth3(p2)  <span class=\"comment\"># (bsz, 256, h/4, w/4)</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> p2, p3, p4, p5</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">FPN101</span>():</span><br><span class=\"line\">    <span class=\"keyword\">return</span> FPN(Bottleneck, [<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">fpn_101 = FPN101()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.randn(<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>)</span><br><span class=\"line\">output_p2, output_p3, output_p4, output_p5 = fpn_101(<span class=\"built_in\">input</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output_p2.shape)  <span class=\"comment\"># torch.Size([1, 256, 64, 64])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(output_p3.shape)  <span class=\"comment\"># torch.Size([1, 256, 32, 32])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(output_p4.shape)  <span class=\"comment\"># torch.Size([1, 256, 16, 16])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(output_p5.shape)  <span class=\"comment\"># torch.Size([1, 256, 8, 8])</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"2-åŠç›‘ç£VOSä¸AOTæ¨¡å‹\">2. åŠç›‘ç£VOSä¸AOTæ¨¡å‹</h2>\n<h3 id=\"2-1-VOSä¸AOTç®€ä»‹\">2.1 VOSä¸AOTç®€ä»‹</h3>\n<p>è§†é¢‘å¯¹è±¡åˆ†å‰²ï¼ˆVOSï¼‰æ—¨åœ¨è¯†åˆ«å’Œåˆ†å‰²ç»™å®šè§†é¢‘ä¸­çš„ä¸€ä¸ªæˆ–å¤šä¸ªæ„Ÿå…´è¶£çš„å¯¹è±¡ï¼ŒåŠç›‘ç£ VOS éœ€è¦ç®—æ³•åœ¨ç»™å®šä¸€å¸§æˆ–å¤šå¸§çš„<strong>å¯¹è±¡æ³¨é‡Šæ©ç </strong>çš„æƒ…å†µä¸‹è·Ÿè¸ªå’Œåˆ†å‰²æ•´ä¸ªè§†é¢‘åºåˆ—ä¸­çš„å¯¹è±¡ã€‚</p>\n<p>æ­¤å‰æœ€å…ˆè¿›çš„æ–¹æ³•å­¦ä¹ ç”¨å•ä¸ªæ­£ç›®æ ‡è§£ç ç‰¹å¾ï¼Œå› æ­¤å¿…é¡»åœ¨å¤šç›®æ ‡åœºæ™¯ä¸‹å•ç‹¬åŒ¹é…å’Œåˆ†å‰²æ¯ä¸ªç›®æ ‡ï¼Œæ¶ˆè€—å¤šå€çš„è®¡ç®—èµ„æºã€‚æˆ‘ä»¬æå‡º Associating Objects with Transformersï¼ˆAOTï¼‰æ–¹æ³•æ¥<strong>ç»Ÿä¸€åŒ¹é…å’Œè§£ç å¤šä¸ªå¯¹è±¡</strong>ã€‚AOT é‡‡ç”¨ Identification æœºåˆ¶å°†<strong>å¤šä¸ªç›®æ ‡</strong>å…³è”åˆ°<strong>åŒä¸€é«˜ç»´åµŒå…¥ç©ºé—´</strong>ä¸­ã€‚å› æ­¤å¯ä»¥åƒå¤„ç†å•ä¸ªå¯¹è±¡ä¸€æ ·é«˜æ•ˆåœ°åŒæ—¶å¤„ç†å¤šä¸ªå¯¹è±¡çš„åŒ¹é…å’Œåˆ†å‰²è§£ç ã€‚</p>\n<p>AOT æ–¹æ³•å°†<strong>åˆ†å±‚ä¼ æ’­</strong>å¼•å…¥åˆ° VOS ä¸­ã€‚åˆ†å±‚ä¼ æ’­å¯ä»¥é€æ¸å°† ID ä¿¡æ¯ä»è¿‡å»çš„å¸§ä¼ æ’­åˆ°å½“å‰å¸§ï¼Œå¹¶å°†å½“å‰å¸§çš„ç‰¹å¾ä» object-agnosticï¼ˆå¯¹è±¡ä¸å¯çŸ¥ï¼‰è½¬ç§»åˆ° object-specificï¼ˆå¯¹è±¡ç‰¹å®šï¼‰ã€‚</p>\n<h3 id=\"2-2-ID-æœºåˆ¶\">2.2 ID æœºåˆ¶</h3>\n<p>ID æœºåˆ¶ä¸ºæ¯ä¸ªç›®æ ‡åˆ†é…å”¯ä¸€çš„ ID ä¿¡æ¯ï¼Œå¹¶å°†ä»»æ„æ•°é‡ï¼ˆè¦æ±‚å°äºé¢„å®šä¹‰çš„å¤§é‡ï¼‰ç›®æ ‡çš„ mask åµŒå…¥åˆ°åŒä¸€é«˜ç»´ç©ºé—´ä¸­ã€‚å› æ­¤ï¼Œç½‘ç»œå¯ä»¥å­¦ä¹ æ‰€æœ‰ç›®æ ‡ä¹‹é—´çš„å…³è”æˆ–ç›¸å…³æ€§ã€‚æ­¤å¤–ï¼Œå¯ä»¥åˆ©ç”¨åˆ†é…çš„ ID ä¿¡æ¯ç›´æ¥è§£ç å¤šå¯¹è±¡åˆ†å‰²ã€‚</p>\n<p>æˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ªèº«ä»½åº“ï¼ˆID Bankï¼‰ï¼Œå…¶ä¸­å­˜å‚¨ M ä¸ªå…·æœ‰ C ç»´çš„è¯†åˆ«å‘é‡ã€‚ä¸ºäº†åµŒå…¥å¤šä¸ªä¸åŒçš„ç›®æ ‡æ©ç ï¼Œæ¯ä¸ªç›®æ ‡å°†è¢«<strong>éšæœº</strong>åˆ†é…ä¸€ä¸ªä¸åŒçš„è¯†åˆ«å‘é‡ã€‚</p>\n<h3 id=\"2-3-Long-Short-Term-Transformerï¼ˆLSTTï¼‰\">2.3 Long Short-Term Transformerï¼ˆLSTTï¼‰</h3>\n<p>æœ¬æ–‡è®¾è®¡é•¿çŸ­æœŸ Transformerï¼ˆLSTTï¼‰ç”¨äºæ„å»º<strong>åˆ†å±‚å¯¹è±¡åŒ¹é…å’Œä¼ æ’­</strong>ã€‚æ¯ä¸ª LSTT å—éƒ½åˆ©ç”¨<strong>é•¿æœŸæ³¨æ„åŠ›</strong>æ¥åŒ¹é…<strong>ç¬¬ä¸€å¸§</strong>çš„åµŒå…¥ï¼Œå¹¶åˆ©ç”¨<strong>çŸ­æœŸæ³¨æ„åŠ›</strong>æ¥åŒ¹é…<strong>å¤šä¸ªé™„è¿‘å¸§</strong>çš„åµŒå…¥ã€‚ä¸ä»…åˆ©ç”¨ä¸€ä¸ªæ³¨æ„åŠ›å±‚çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬å‘ç°åˆ†å±‚æ³¨æ„åŠ›ç»“æ„åœ¨<strong>å…³è”å¤šä¸ªå¯¹è±¡</strong>æ–¹é¢æ›´æœ‰æ•ˆã€‚</p>\n<p>LSTT é¦–å…ˆé‡‡ç”¨è‡ªæ³¨æ„åŠ›å±‚ï¼Œè´Ÿè´£å­¦ä¹ <strong>å½“å‰å¸§å†…ç›®æ ‡ä¹‹é—´</strong>çš„å…³è”æˆ–ç›¸å…³æ€§ã€‚æ­¤å¤–ï¼ŒLSTT è¿˜å¼•å…¥äº†é•¿æœŸæ³¨æ„åŠ›å’ŒçŸ­æœŸæ³¨æ„åŠ›ï¼Œå‰è€…ç”¨äºèšåˆæ¥è‡ªé•¿æœŸ<strong>è®°å¿†å¸§çš„ç›®æ ‡ä¿¡æ¯</strong>ï¼Œåè€…èƒ½å¤Ÿä»é‚»è¿‘çš„çŸ­æœŸå¸§å­¦ä¹ <strong>æ—¶é—´å¹³æ»‘æ€§</strong>ã€‚æ‰€æœ‰æ³¨æ„åŠ›æ¨¡å—éƒ½æ˜¯ä»¥<strong>å¤šå¤´æ³¨æ„åŠ›</strong>çš„å½¢å¼å®ç°çš„ï¼Œå³å¤šä¸ªæ³¨æ„åŠ›æ¨¡å—åè·Ÿä¸²è”å’Œçº¿æ€§æŠ•å½±ã€‚</p>\n<p>é•¿æœŸæ³¨æ„åŠ›è´Ÿè´£å°†ç›®æ ‡çš„ä¿¡æ¯ä»è¿‡å»çš„è®°å¿†å¸§ï¼ˆåŒ…å«å‚è€ƒå¸§å’Œå­˜å‚¨çš„é¢„æµ‹å¸§ï¼‰èšåˆåˆ°å½“å‰å¸§ã€‚ç”±äºå½“å‰å¸§å’Œè¿‡å»å¸§ä¹‹é—´çš„æ—¶é—´é—´éš”æ˜¯å¯å˜çš„å¹¶ä¸”å¯ä»¥æ˜¯é•¿æœŸçš„ï¼Œå› æ­¤<strong>æ—¶é—´å¹³æ»‘æ€§éš¾ä»¥ä¿è¯</strong>ã€‚å› æ­¤ï¼Œé•¿æœŸæ³¨æ„åŠ›é‡‡ç”¨<strong>éå±€éƒ¨</strong>æ³¨æ„åŠ›ã€‚</p>\n<p>çŸ­æœŸæ³¨æ„åŠ›ç”¨äºèšåˆæ¯ä¸ªå½“å‰å¸§ä½ç½®çš„æ—¶ç©ºé‚»åŸŸä¸­çš„ä¿¡æ¯ã€‚ç›´è§‚ä¸Šï¼Œå¤šä¸ªè¿ç»­è§†é¢‘å¸§ä¹‹é—´çš„å›¾åƒå˜åŒ–å§‹ç»ˆæ˜¯<strong>å¹³æ»‘ä¸”è¿ç»­</strong>çš„ã€‚å› æ­¤ï¼Œè¿ç»­å¸§ä¸­çš„ç›®æ ‡åŒ¹é…å’Œä¼ æ’­å¯ä»¥<strong>é™åˆ¶åœ¨å°çš„æ—¶ç©ºé‚»åŸŸå†…</strong>ï¼Œä»è€Œæ¯”éå±€éƒ¨è¿‡ç¨‹å…·æœ‰æ›´å¥½çš„æ•ˆç‡ã€‚</p>\n<h2 id=\"ä¸‰ã€DeAOT\">ä¸‰ã€DeAOT</h2>\n<p>æœ¬æ–‡é‡ç‚¹æ˜¯ä¸º<strong>åŠç›‘ç£è§†é¢‘å¯¹è±¡åˆ†å‰²</strong>ï¼ˆVOSï¼‰å¼€å‘ä¸€ç§æ›´æœ‰æ•ˆçš„åˆ†å±‚ä¼ æ’­æ–¹æ³•ã€‚åœ¨ AOT æ–¹æ³•ä¸­ object-specific ä¿¡æ¯çš„å¢åŠ å°†ä¸å¯é¿å…åœ°å¯¼è‡´æ·±å±‚ä¼ æ’­å±‚ä¸­ object-agnostic çš„è§†è§‰ä¿¡æ¯çš„ä¸¢å¤±ã€‚ä¸ºäº†è§£å†³è¿™æ ·çš„é—®é¢˜å¹¶è¿›ä¸€æ­¥ä¿ƒè¿›è§†è§‰åµŒå…¥çš„å­¦ä¹ ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§<strong>åˆ†å±‚ä¼ æ’­ä¸­çš„è§£è€¦ç‰¹å¾</strong>ï¼ˆDeAOTï¼‰æ–¹æ³•ã€‚DeAOT é€šè¿‡åœ¨ä¸¤ä¸ª<strong>ç‹¬ç«‹</strong>çš„åˆ†æ”¯ä¸­å¤„ç† object-agnostic å’Œ object-specific çš„åµŒå…¥æ¥è§£è€¦å®ƒä»¬çš„åˆ†å±‚ä¼ æ’­ã€‚å…¶æ¬¡ï¼Œä¸ºäº†è¡¥å¿åŒåˆ†æ”¯ä¼ æ’­çš„é¢å¤–è®¡ç®—ï¼Œè®¾è®¡äº†ä¸€ç§ç”¨äºæ„é€ åˆ†å±‚ä¼ æ’­çš„æœ‰æ•ˆæ¨¡å— GPMï¼ˆé—¨æ§ä¼ æ’­æ¨¡å—ï¼‰ï¼Œå®ƒæ˜¯é€šè¿‡<strong>å•å¤´æ³¨æ„åŠ›</strong>ç²¾å¿ƒè®¾è®¡çš„ã€‚</p>\n<h3 id=\"3-1-åˆ†å±‚åŒåˆ†æ”¯ä¼ æ’­\">3.1 åˆ†å±‚åŒåˆ†æ”¯ä¼ æ’­</h3>\n<p>DeAOT åœ¨ä¸¤ä¸ª<strong>å¹¶è¡Œåˆ†æ”¯</strong>ä¸­ä¼ æ’­å¯¹è±¡çš„è§†è§‰ç‰¹å¾ï¼ˆvisual featuresï¼‰å’Œæ©ç ï¼ˆmask featuresï¼‰ç‰¹å¾ã€‚å…·ä½“æ¥è¯´ï¼Œè§†è§‰åˆ†æ”¯è´Ÿè´£åŒ¹é…å¯¹è±¡ã€æ”¶é›†è¿‡å»çš„è§†è§‰ä¿¡æ¯å¹¶æç‚¼å¯¹è±¡ç‰¹å¾ã€‚ä¸ºäº†é‡æ–°è¯†åˆ«å¯¹è±¡ï¼ŒID åˆ†æ”¯<strong>é‡ç”¨</strong>è§†è§‰åˆ†æ”¯è®¡ç®—çš„<strong>åŒ¹é…å›¾</strong>ï¼ˆæ³¨æ„åŠ›å›¾ï¼‰ï¼Œå°† ID åµŒå…¥ï¼ˆç”± AOT ä¸­çš„ ID æœºåˆ¶ç¼–ç ï¼‰ä»è¿‡å»çš„å¸§ä¼ æ’­åˆ°å½“å‰å¸§ã€‚ä¸¤ä¸ªåˆ†æ”¯å…±äº«ç›¸åŒçš„å…·æœ‰ L ä¸ªä¼ æ’­å±‚çš„å±‚æ¬¡ç»“æ„ã€‚</p>\n<h3 id=\"3-2-é—¨æ§ä¼ æ’­æ¨¡å—GPM\">3.2 é—¨æ§ä¼ æ’­æ¨¡å—GPM</h3>\n<p>é—¨æ§ä¼ æ’­å‡½æ•°é¦–å…ˆé€šè¿‡ä½¿ç”¨<strong>æ¡ä»¶é—¨</strong>æ¥å¢å¼ºåŸºäºæ³¨æ„åŠ›çš„ä¼ æ’­ï¼Œæ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨ Depth-wise å·ç§¯ä»¥<strong>è½»é‡çº§</strong>æ–¹å¼å¢å¼ºå±€éƒ¨ç©ºé—´ä¸Šä¸‹æ–‡çš„å»ºæ¨¡ã€‚</p>\n<p>é—¨æ§ä¼ æ’­æ¨¡å—ç”±ä¸‰ç§é—¨æ§ä¼ æ’­ç»„æˆï¼šè‡ªä¼ æ’­ã€é•¿æœŸä¼ æ’­ã€çŸ­æœŸä¼ æ’­ã€‚ä¸ LSTT ç›¸æ¯”ï¼ŒGPM å»æ‰äº†å‰é¦ˆæ¨¡å—ï¼Œè¿›ä¸€æ­¥èŠ‚çœäº†è®¡ç®—é‡å’Œå‚æ•°ã€‚æ‰€æœ‰ä¼ æ’­è¿‡ç¨‹éƒ½é‡‡ç”¨é—¨æ§ä¼ æ’­å‡½æ•°ã€‚</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/6211.html",
            "url": "https://asanosaki.github.io/posts/6211.html",
            "title": "Kaggleé¡¹ç›®å®æˆ˜",
            "date_published": "2023-05-30T01:45:00.000Z",
            "content_html": "<blockquote>\n<p>è®°å½• Kaggle ä¸­çš„ä¸€äº›ç»å…¸ç«èµ›ï¼Œä¹Ÿå½“åšè‡ªå·±çš„ç»ƒæ‰‹å°é¡¹ç›®ã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-å®æˆ˜Kaggleæ¯”èµ›ï¼šé¢„æµ‹æˆ¿ä»·\">1. å®æˆ˜Kaggleæ¯”èµ›ï¼šé¢„æµ‹æˆ¿ä»·</h2>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># æ¯”èµ›é“¾æ¥ï¼šhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> hashlib</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> tarfile</span><br><span class=\"line\"><span class=\"keyword\">import</span> zipfile</span><br><span class=\"line\"><span class=\"keyword\">import</span> requests</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"></span><br><span class=\"line\">DATA_HUB = <span class=\"built_in\">dict</span>()</span><br><span class=\"line\">DATA_URL = <span class=\"string\">&#x27;http://d2l-data.s3-accelerate.amazonaws.com/&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download</span>(<span class=\"params\">name, cache_dir=os.path.join(<span class=\"params\"><span class=\"string\">&#x27;..&#x27;</span>, <span class=\"string\">&#x27;data&#x27;</span></span>)</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä¸‹è½½ä¸€ä¸ªDATA_HUBä¸­çš„æ–‡ä»¶ï¼Œè¿”å›æœ¬åœ°æ–‡ä»¶å&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> name <span class=\"keyword\">in</span> DATA_HUB, <span class=\"string\">f&quot;<span class=\"subst\">&#123;name&#125;</span> ä¸å­˜åœ¨äº <span class=\"subst\">&#123;DATA_HUB&#125;</span>&quot;</span></span><br><span class=\"line\">    url, sha1_hash = DATA_HUB[name]</span><br><span class=\"line\">    os.makedirs(cache_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    fname = os.path.join(cache_dir, url.split(<span class=\"string\">&#x27;/&#x27;</span>)[-<span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"keyword\">if</span> os.path.exists(fname):</span><br><span class=\"line\">        sha1 = hashlib.sha1()</span><br><span class=\"line\">        <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(fname, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            <span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">                data = f.read(<span class=\"number\">1048576</span>)</span><br><span class=\"line\">                <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> data:</span><br><span class=\"line\">                    <span class=\"keyword\">break</span></span><br><span class=\"line\">                sha1.update(data)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> sha1.hexdigest() == sha1_hash:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> fname  <span class=\"comment\"># å‘½ä¸­ç¼“å­˜</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;æ­£åœ¨ä»<span class=\"subst\">&#123;url&#125;</span>ä¸‹è½½<span class=\"subst\">&#123;fname&#125;</span>...&#x27;</span>)</span><br><span class=\"line\">    r = requests.get(url, stream=<span class=\"literal\">True</span>, verify=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(fname, <span class=\"string\">&#x27;wb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        f.write(r.content)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> fname</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_extract</span>(<span class=\"params\">name, folder=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä¸‹è½½å¹¶è§£å‹zip/taræ–‡ä»¶&quot;&quot;&quot;</span></span><br><span class=\"line\">    fname = download(name)</span><br><span class=\"line\">    base_dir = os.path.dirname(fname)</span><br><span class=\"line\">    data_dir, ext = os.path.splitext(fname)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> ext == <span class=\"string\">&#x27;.zip&#x27;</span>:</span><br><span class=\"line\">        fp = zipfile.ZipFile(fname, <span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> ext <span class=\"keyword\">in</span> (<span class=\"string\">&#x27;.tar&#x27;</span>, <span class=\"string\">&#x27;.gz&#x27;</span>):</span><br><span class=\"line\">        fp = tarfile.<span class=\"built_in\">open</span>(fname, <span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> <span class=\"literal\">False</span>, <span class=\"string\">&#x27;åªæœ‰zip/taræ–‡ä»¶å¯ä»¥è¢«è§£å‹ç¼©&#x27;</span></span><br><span class=\"line\">    fp.extractall(base_dir)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> os.path.join(base_dir, folder) <span class=\"keyword\">if</span> folder <span class=\"keyword\">else</span> data_dir</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">download_all</span>():</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä¸‹è½½DATA_HUBä¸­çš„æ‰€æœ‰æ–‡ä»¶&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> name <span class=\"keyword\">in</span> DATA_HUB:</span><br><span class=\"line\">        download(name)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ä¸‹è½½å¹¶ç¼“å­˜Kaggleæˆ¿å±‹æ•°æ®é›†</span></span><br><span class=\"line\">DATA_HUB[<span class=\"string\">&#x27;kaggle_house_train&#x27;</span>] = (DATA_URL + <span class=\"string\">&#x27;kaggle_house_pred_train.csv&#x27;</span>, <span class=\"string\">&#x27;585e9cc93e70b39160e7921475f9bcd7d31219ce&#x27;</span>)</span><br><span class=\"line\">DATA_HUB[<span class=\"string\">&#x27;kaggle_house_test&#x27;</span>] = (DATA_URL + <span class=\"string\">&#x27;kaggle_house_pred_test.csv&#x27;</span>, <span class=\"string\">&#x27;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ä½¿ç”¨pandasåˆ†åˆ«åŠ è½½åŒ…å«è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®çš„ä¸¤ä¸ªCSVæ–‡ä»¶</span></span><br><span class=\"line\">train_data = pd.read_csv(download(<span class=\"string\">&#x27;kaggle_house_train&#x27;</span>))</span><br><span class=\"line\">test_data = pd.read_csv(download(<span class=\"string\">&#x27;kaggle_house_test&#x27;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è®­ç»ƒæ•°æ®é›†åŒ…æ‹¬1460ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬80ä¸ªç‰¹å¾å’Œ1ä¸ªæ ‡ç­¾ï¼Œè€Œæµ‹è¯•æ•°æ®é›†åŒ…å«1459ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬80ä¸ªç‰¹å¾</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(train_data.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(test_data.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># çœ‹çœ‹å‰å››ä¸ªå’Œæœ€åä¸¤ä¸ªç‰¹å¾ï¼Œä»¥åŠç›¸åº”æ ‡ç­¾ï¼ˆæˆ¿ä»·ï¼‰</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(train_data.iloc[<span class=\"number\">0</span>:<span class=\"number\">4</span>, [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, -<span class=\"number\">3</span>, -<span class=\"number\">2</span>, -<span class=\"number\">1</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># åœ¨æ¯ä¸ªæ ·æœ¬ä¸­ï¼Œç¬¬ä¸€ä¸ªç‰¹å¾æ˜¯IDï¼Œè¿™æœ‰åŠ©äºæ¨¡å‹è¯†åˆ«æ¯ä¸ªè®­ç»ƒæ ·æœ¬ã€‚è™½ç„¶è¿™å¾ˆæ–¹ä¾¿ï¼Œä½†å®ƒä¸æºå¸¦ä»»ä½•ç”¨äºé¢„æµ‹çš„ä¿¡æ¯ã€‚å› æ­¤ï¼Œåœ¨å°†æ•°æ®æä¾›ç»™æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬å°†å…¶ä»æ•°æ®é›†ä¸­åˆ é™¤</span></span><br><span class=\"line\">all_features = pd.concat((train_data.iloc[:, <span class=\"number\">1</span>:-<span class=\"number\">1</span>], test_data.iloc[:, <span class=\"number\">1</span>:]))  <span class=\"comment\"># trainæ•°æ®çš„æœ€åä¸€åˆ—ä¸ºlabel</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># åœ¨å¼€å§‹å»ºæ¨¡ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ‰€æœ‰ç¼ºå¤±çš„å€¼æ›¿æ¢ä¸ºç›¸åº”ç‰¹å¾çš„å¹³å‡å€¼</span></span><br><span class=\"line\"><span class=\"comment\"># è‹¥æ— æ³•è·å¾—æµ‹è¯•æ•°æ®ï¼Œåˆ™å¯æ ¹æ®è®­ç»ƒæ•°æ®è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®</span></span><br><span class=\"line\">numeric_features = all_features.dtypes[all_features.dtypes != <span class=\"string\">&#x27;object&#x27;</span>].index  <span class=\"comment\"># æ•°å€¼ç±»å‹ç‰¹å¾çš„ä¸‹æ ‡</span></span><br><span class=\"line\">all_features[numeric_features] = all_features[numeric_features].apply(<span class=\"keyword\">lambda</span> x: (x - x.mean()) / (x.std()))  <span class=\"comment\"># å°†æ‰€æœ‰æ•°å€¼ç‰¹å¾çš„å‡å€¼å˜æˆ0ï¼Œæ–¹å·®å˜æˆ1</span></span><br><span class=\"line\"><span class=\"comment\"># åœ¨æ ‡å‡†åŒ–æ•°æ®ä¹‹åï¼Œæ‰€æœ‰å‡å€¼æ¶ˆå¤±ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†ç¼ºå¤±å€¼è®¾ç½®ä¸º0</span></span><br><span class=\"line\">all_features[numeric_features] = all_features[numeric_features].fillna(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¤„ç†ç¦»æ•£å€¼ã€‚è¿™åŒ…æ‹¬è¯¸å¦‚â€œMSZoningâ€ä¹‹ç±»çš„ç‰¹å¾ã€‚æˆ‘ä»¬ç”¨ç‹¬çƒ­ç¼–ç æ›¿æ¢å®ƒä»¬ï¼Œpandasè½¯ä»¶åŒ…ä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬å®ç°è¿™ä¸€ç‚¹</span></span><br><span class=\"line\"><span class=\"comment\"># dummy_na=Trueå°†&#x27;na&#x27;ï¼ˆç¼ºå¤±å€¼ï¼‰è§†ä¸ºæœ‰æ•ˆçš„ç‰¹å¾å€¼ï¼Œå¹¶ä¸ºå…¶åˆ›å»ºæŒ‡ç¤ºç¬¦ç‰¹å¾</span></span><br><span class=\"line\">all_features = pd.get_dummies(all_features, dummy_na=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(all_features.shape)  <span class=\"comment\"># (2919, 331)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># é€šè¿‡valueså±æ€§ï¼Œæˆ‘ä»¬å¯ä»¥ä»pandasæ ¼å¼ä¸­æå–NumPyæ ¼å¼ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå¼ é‡è¡¨ç¤ºç”¨äºè®­ç»ƒ</span></span><br><span class=\"line\">n_train = train_data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)</span><br><span class=\"line\">test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)</span><br><span class=\"line\">train_labels = torch.tensor(train_data.SalePrice.values.reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>), dtype=torch.float32)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è®­ç»ƒ</span></span><br><span class=\"line\">loss_function = nn.MSELoss()</span><br><span class=\"line\">in_features = train_features.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">net = nn.Sequential(nn.Linear(in_features, <span class=\"number\">128</span>),</span><br><span class=\"line\">                    nn.ReLU(),</span><br><span class=\"line\">                    nn.Dropout(<span class=\"number\">0.1</span>),</span><br><span class=\"line\">                    nn.Linear(<span class=\"number\">128</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æˆ¿ä»·å°±åƒè‚¡ç¥¨ä»·æ ¼ä¸€æ ·ï¼Œæˆ‘ä»¬å…³å¿ƒçš„æ˜¯ç›¸å¯¹æ•°é‡ï¼Œè€Œä¸æ˜¯ç»å¯¹æ•°é‡ï¼Œæˆ‘ä»¬æ›´å…³å¿ƒç›¸å¯¹è¯¯å·®ï¼Œå³ï¼š(çœŸå®å€¼-é¢„æµ‹å€¼)/çœŸå®å€¼ï¼Œè§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯ç”¨ä»·æ ¼é¢„æµ‹çš„å¯¹æ•°æ¥è¡¡é‡å·®å¼‚</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">log_rmse</span>(<span class=\"params\">net, features, labels</span>):</span><br><span class=\"line\">    <span class=\"comment\"># ä¸ºäº†åœ¨å–å¯¹æ•°æ—¶è¿›ä¸€æ­¥ç¨³å®šè¯¥å€¼ï¼Œå°†å°äº1çš„å€¼è®¾ç½®ä¸º1</span></span><br><span class=\"line\">    clipped_preds = torch.clamp(net(features), <span class=\"number\">1</span>, <span class=\"built_in\">float</span>(<span class=\"string\">&#x27;inf&#x27;</span>))  <span class=\"comment\"># å°†infå˜æˆ1</span></span><br><span class=\"line\">    rmse = torch.sqrt(loss_function(torch.log(clipped_preds), torch.log(labels)))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> rmse.item()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_array</span>(<span class=\"params\">data_arrays, batch_size, is_train=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">    dataset = data.TensorDataset(*data_arrays)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(dataset, batch_size, shuffle=is_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class=\"line\">    train_ls, test_ls = [], []</span><br><span class=\"line\">    train_iter = load_array((train_features, train_labels), batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\">    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)  <span class=\"comment\"># è¿™é‡Œä½¿ç”¨çš„æ˜¯Adamä¼˜åŒ–ç®—æ³•</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            loss = loss_function(net(X), y)</span><br><span class=\"line\">            loss.backward()</span><br><span class=\"line\">            optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">        train_ls.append(log_rmse(net, train_features, train_labels))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> test_labels <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            test_ls.append(log_rmse(net, test_features, test_labels))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_ls, test_ls</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># KæŠ˜äº¤å‰éªŒè¯ï¼Œæœ‰åŠ©äºæ¨¡å‹é€‰æ‹©å’Œè¶…å‚æ•°è°ƒæ•´ï¼Œé¦–å…ˆéœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œåœ¨KæŠ˜äº¤å‰éªŒè¯è¿‡ç¨‹ä¸­è¿”å›ç¬¬iæŠ˜çš„æ•°æ®</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_k_fold_data</span>(<span class=\"params\">k, i, X, y</span>):</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> k &gt; <span class=\"number\">1</span></span><br><span class=\"line\">    fold_size = X.shape[<span class=\"number\">0</span>] // k  <span class=\"comment\"># æ¯ä¸€æŠ˜çš„å¤§å°</span></span><br><span class=\"line\">    X_train, y_train = <span class=\"literal\">None</span>, <span class=\"literal\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(k):  <span class=\"comment\"># åˆ†æˆkä»½</span></span><br><span class=\"line\">        idx = <span class=\"built_in\">slice</span>(j * fold_size, (j + <span class=\"number\">1</span>) * fold_size)</span><br><span class=\"line\">        X_part, y_part = X[idx, :], y[idx]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> j == i:  <span class=\"comment\"># å°†ç¬¬iæŠ˜çš„æ•°æ®ä½œä¸ºéªŒè¯æ•°æ®</span></span><br><span class=\"line\">            X_valid, y_valid = X_part, y_part</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> X_train <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            X_train, y_train = X_part, y_part</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            X_train = torch.cat([X_train, X_part], <span class=\"number\">0</span>)</span><br><span class=\"line\">            y_train = torch.cat([y_train, y_part], <span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> X_train, y_train, X_valid, y_valid</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">k_fold</span>(<span class=\"params\">k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class=\"line\">    train_l_sum, valid_l_sum = <span class=\"number\">0</span>, <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(k):</span><br><span class=\"line\">        data = get_k_fold_data(k, i, X_train, y_train)</span><br><span class=\"line\">        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)</span><br><span class=\"line\">        train_l_sum += train_ls[-<span class=\"number\">1</span>]</span><br><span class=\"line\">        valid_l_sum += valid_ls[-<span class=\"number\">1</span>]</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;æŠ˜<span class=\"subst\">&#123;i + <span class=\"number\">1</span>&#125;</span>ï¼Œè®­ç»ƒlog rmse: <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_ls[-<span class=\"number\">1</span>]):f&#125;</span>ï¼ŒéªŒè¯log rmse: <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(valid_ls[-<span class=\"number\">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_l_sum / k, valid_l_sum / k</span><br><span class=\"line\"></span><br><span class=\"line\">k, num_epochs, lr, weight_decay, batch_size = <span class=\"number\">5</span>, <span class=\"number\">250</span>, <span class=\"number\">0.5</span>, <span class=\"number\">1e-3</span>, <span class=\"number\">32</span></span><br><span class=\"line\"></span><br><span class=\"line\">train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;k&#125;</span>-æŠ˜éªŒè¯: å¹³å‡è®­ç»ƒlog rmse: <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_l):f&#125;</span>ï¼Œ&#x27;</span><span class=\"string\">f&#x27;å¹³å‡éªŒè¯log rmse: <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(valid_l):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ä½¿ç”¨æ‰€æœ‰æ•°æ®å¯¹å…¶è¿›è¡Œè®­ç»ƒ</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_and_pred</span>(<span class=\"params\">train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size</span>):</span><br><span class=\"line\">    train_ls, _ = train(net, train_features, train_labels, <span class=\"literal\">None</span>, <span class=\"literal\">None</span>, num_epochs, lr, weight_decay, batch_size)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;è®­ç»ƒlog rmse: <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_ls[-<span class=\"number\">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">    <span class=\"comment\"># å°†ç½‘ç»œåº”ç”¨äºæµ‹è¯•é›†</span></span><br><span class=\"line\">    preds = net(test_features).detach().numpy()</span><br><span class=\"line\">    <span class=\"comment\"># å°†å…¶é‡æ–°æ ¼å¼åŒ–ä»¥å¯¼å‡ºåˆ°Kaggleï¼Œå°†é¢„æµ‹ä¿å­˜åœ¨CSVæ–‡ä»¶ä¸­å¯ä»¥ç®€åŒ–å°†ç»“æœä¸Šä¼ åˆ°Kaggleçš„è¿‡ç¨‹</span></span><br><span class=\"line\">    test_data[<span class=\"string\">&#x27;SalePrice&#x27;</span>] = pd.Series(preds.reshape(<span class=\"number\">1</span>, -<span class=\"number\">1</span>)[<span class=\"number\">0</span>])</span><br><span class=\"line\">    submission = pd.concat([test_data[<span class=\"string\">&#x27;Id&#x27;</span>], test_data[<span class=\"string\">&#x27;SalePrice&#x27;</span>]], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    submission.to_csv(<span class=\"string\">&#x27;../data/submission.csv&#x27;</span>, index=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size)</span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/39408.html",
            "url": "https://asanosaki.github.io/posts/39408.html",
            "title": "åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ç¬”è®°(ææ²)-æ³¨æ„åŠ›æœºåˆ¶",
            "date_published": "2023-05-21T09:57:00.000Z",
            "content_html": "<blockquote>\n<p>ææ²åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆPyTorchï¼‰è¯¾ç¨‹å­¦ä¹ ç¬”è®°ç¬¬åç« ï¼šæ³¨æ„åŠ›æœºåˆ¶ã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-æ³¨æ„åŠ›æç¤º\">1. æ³¨æ„åŠ›æç¤º</h2>\n<p>æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention Mechanismï¼‰æ˜¯äººä»¬åœ¨æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­åµŒå…¥çš„ä¸€ç§ç‰¹æ®Šç»“æ„ï¼Œç”¨æ¥è‡ªåŠ¨å­¦ä¹ å’Œè®¡ç®—<strong>è¾“å…¥æ•°æ®å¯¹è¾“å‡ºæ•°æ®çš„è´¡çŒ®</strong>å¤§å°ã€‚</p>\n<p><strong>éè‡ªä¸»æ€§æç¤º</strong>æ˜¯åŸºäºç¯å¢ƒä¸­ç‰©ä½“çš„çªå‡ºæ€§å’Œæ˜“è§æ€§ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œå‡å¦‚æˆ‘ä»¬é¢å‰æœ‰äº”ä¸ªç‰©å“ï¼šä¸€ä»½æŠ¥çº¸ã€ä¸€ç¯‡ç ”ç©¶è®ºæ–‡ã€ä¸€æ¯å’–å•¡ã€ä¸€æœ¬ç¬”è®°æœ¬å’Œä¸€æœ¬ä¹¦ï¼Œæ‰€æœ‰çº¸åˆ¶å“éƒ½æ˜¯é»‘ç™½å°åˆ·çš„ï¼Œä½†å’–å•¡æ¯æ˜¯çº¢è‰²çš„ã€‚æ¢å¥è¯è¯´ï¼Œè¿™ä¸ªå’–å•¡æ¯åœ¨è¿™ç§è§†è§‰ç¯å¢ƒä¸­æ˜¯çªå‡ºå’Œæ˜¾çœ¼çš„ï¼Œä¸ç”±è‡ªä¸»åœ°å¼•èµ·äººä»¬çš„æ³¨æ„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¼šæŠŠè§†åŠ›æœ€æ•é”çš„åœ°æ–¹æ”¾åˆ°å’–å•¡ä¸Šã€‚å–å’–å•¡åï¼Œæˆ‘ä»¬ä¼šå˜å¾—å…´å¥‹å¹¶æƒ³è¯»ä¹¦ï¼Œæ‰€ä»¥è½¬è¿‡å¤´ï¼Œé‡æ–°èšç„¦çœ¼ç›ï¼Œç„¶åçœ‹çœ‹ä¹¦ï¼Œä¸å’–å•¡æ¯æ˜¯ç”±äºçªå‡ºæ€§å¯¼è‡´çš„é€‰æ‹©ä¸åŒï¼Œæ­¤æ—¶é€‰æ‹©ä¹¦æ˜¯å—åˆ°äº†<strong>è®¤çŸ¥å’Œæ„è¯†</strong>çš„æ§åˆ¶ï¼Œå› æ­¤æ³¨æ„åŠ›åœ¨åŸºäº<strong>è‡ªä¸»æ€§æç¤º</strong>å»è¾…åŠ©é€‰æ‹©æ—¶å°†æ›´ä¸ºè°¨æ…ã€‚å—è¯•è€…çš„ä¸»è§‚æ„æ„¿æ¨åŠ¨ï¼Œé€‰æ‹©çš„åŠ›é‡ä¹Ÿå°±æ›´å¼ºå¤§ã€‚è‡ªä¸»æ€§çš„ä¸éè‡ªä¸»æ€§çš„æ³¨æ„åŠ›æç¤ºè§£é‡Šäº†äººç±»çš„æ³¨æ„åŠ›çš„æ–¹å¼ï¼Œä¸‹é¢æ¥çœ‹çœ‹å¦‚ä½•é€šè¿‡è¿™ä¸¤ç§æ³¨æ„åŠ›æç¤ºï¼Œç”¨ç¥ç»ç½‘ç»œæ¥è®¾è®¡æ³¨æ„åŠ›æœºåˆ¶çš„æ¡†æ¶ã€‚</p>\n<p>é¦–å…ˆï¼Œè€ƒè™‘ä¸€ä¸ªç›¸å¯¹ç®€å•çš„çŠ¶å†µï¼Œå³åªä½¿ç”¨éè‡ªä¸»æ€§æç¤ºã€‚è¦æƒ³å°†é€‰æ‹©åå‘äºæ„Ÿå®˜è¾“å…¥ï¼Œåˆ™å¯ä»¥ç®€å•åœ°ä½¿ç”¨å‚æ•°åŒ–çš„å…¨è¿æ¥å±‚ï¼Œç”šè‡³æ˜¯éå‚æ•°åŒ–çš„æœ€å¤§æ±‡èšå±‚æˆ–å¹³å‡æ±‡èšå±‚ã€‚</p>\n<p>å› æ­¤ï¼Œâ€œæ˜¯å¦åŒ…å«è‡ªä¸»æ€§æç¤ºâ€å°†æ³¨æ„åŠ›æœºåˆ¶ä¸å…¨è¿æ¥å±‚æˆ–æ±‡èšå±‚åŒºåˆ«å¼€æ¥ã€‚åœ¨æ³¨æ„åŠ›æœºåˆ¶çš„èƒŒæ™¯ä¸‹ï¼Œè‡ªä¸»æ€§æç¤ºè¢«ç§°ä¸º<strong>æŸ¥è¯¢</strong>ï¼ˆqueryï¼‰ã€‚ç»™å®šä»»ä½•æŸ¥è¯¢ï¼Œæ³¨æ„åŠ›æœºåˆ¶é€šè¿‡æ³¨æ„åŠ›æ±‡èšï¼ˆattention poolingï¼‰å°†é€‰æ‹©å¼•å¯¼è‡³æ„Ÿå®˜è¾“å…¥ï¼ˆsensory inputsï¼Œä¾‹å¦‚ä¸­é—´ç‰¹å¾è¡¨ç¤ºï¼‰ã€‚åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œè¿™äº›æ„Ÿå®˜è¾“å…¥è¢«ç§°ä¸º<strong>å€¼</strong>ï¼ˆvalueï¼‰ã€‚æ›´é€šä¿—çš„è§£é‡Šï¼Œæ¯ä¸ªå€¼éƒ½ä¸ä¸€ä¸ª<strong>é”®</strong>ï¼ˆkeyï¼‰é…å¯¹ï¼Œè¿™å¯ä»¥æƒ³è±¡ä¸ºæ„Ÿå®˜è¾“å…¥çš„éè‡ªä¸»æç¤ºã€‚å¯ä»¥é€šè¿‡è®¾è®¡æ³¨æ„åŠ›æ±‡èšçš„æ–¹å¼ï¼Œä¾¿äºç»™å®šçš„æŸ¥è¯¢ï¼ˆè‡ªä¸»æ€§æç¤ºï¼‰ä¸é”®ï¼ˆéè‡ªä¸»æ€§æç¤ºï¼‰è¿›è¡ŒåŒ¹é…ï¼Œè¿™å°†å¼•å¯¼å¾—å‡ºæœ€åŒ¹é…çš„å€¼ï¼ˆæ„Ÿå®˜è¾“å…¥ï¼‰ã€‚</p>\n<p>å¹³å‡æ±‡èšå±‚å¯ä»¥è¢«è§†ä¸ºè¾“å…¥çš„åŠ æƒå¹³å‡å€¼ï¼Œå…¶ä¸­å„è¾“å…¥çš„æƒé‡æ˜¯ä¸€æ ·çš„ã€‚å®é™…ä¸Šï¼Œæ³¨æ„åŠ›æ±‡èšå¾—åˆ°çš„æ˜¯åŠ æƒå¹³å‡çš„æ€»å’Œå€¼ï¼Œå…¶ä¸­æƒé‡æ˜¯åœ¨ç»™å®šçš„æŸ¥è¯¢å’Œä¸åŒçš„é”®ä¹‹é—´è®¡ç®—å¾—å‡ºçš„ã€‚ä¸ºäº†å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡ï¼Œéœ€è¦å®šä¹‰ä¸€ä¸ª <code>show_heatmaps</code> å‡½æ•°ï¼Œå…¶è¾“å…¥ <code>matrices</code> çš„å½¢çŠ¶æ˜¯ <code>(è¦æ˜¾ç¤ºçš„è¡Œæ•°, è¦æ˜¾ç¤ºçš„åˆ—æ•°, æŸ¥è¯¢çš„æ•°ç›®, é”®çš„æ•°ç›®)</code>ã€‚ä¸‹é¢ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­è¿›è¡Œæ¼”ç¤ºï¼Œåœ¨æœ¬ä¾‹å­ä¸­ï¼Œä»…å½“æŸ¥è¯¢å’Œé”®ç›¸åŒæ—¶ï¼Œæ³¨æ„åŠ›æƒé‡ä¸º1ï¼Œå¦åˆ™ä¸º0ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">show_heatmaps</span>(<span class=\"params\">matrices, xlabel, ylabel, titles=<span class=\"literal\">None</span>, figsize=(<span class=\"params\"><span class=\"number\">8</span>, <span class=\"number\">6</span></span>), cmap=<span class=\"string\">&#x27;Reds&#x27;</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;æ˜¾ç¤ºçŸ©é˜µçƒ­å›¾&quot;&quot;&quot;</span></span><br><span class=\"line\">    d2l.use_svg_display()</span><br><span class=\"line\">    num_rows, num_cols = matrices.shape[<span class=\"number\">0</span>], matrices.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize, sharex=<span class=\"literal\">True</span>, sharey=<span class=\"literal\">True</span>, squeeze=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, (row_axes, row_matrices) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(<span class=\"built_in\">zip</span>(axes, matrices)):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j, (ax, matrix) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(<span class=\"built_in\">zip</span>(row_axes, row_matrices)):</span><br><span class=\"line\">            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> i == num_rows - <span class=\"number\">1</span>:</span><br><span class=\"line\">                ax.set_xlabel(xlabel)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> j == <span class=\"number\">0</span>:</span><br><span class=\"line\">                ax.set_ylabel(ylabel)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> titles:</span><br><span class=\"line\">                ax.set_title(titles[j])</span><br><span class=\"line\">    fig.colorbar(pcm, ax=axes, shrink=<span class=\"number\">0.6</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">attention_weights = torch.eye(<span class=\"number\">10</span>).reshape((<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">10</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">show_heatmaps(attention_weights, xlabel=<span class=\"string\">&#x27;Keys&#x27;</span>, ylabel=<span class=\"string\">&#x27;Queries&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>æ­¤å¤–å¯ä»¥ä½¿ç”¨ Plotly ç»˜åˆ¶çƒ­åŠ›å›¾ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> plotly.graph_objects <span class=\"keyword\">as</span> go</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">show_plotly_heatmaps</span>(<span class=\"params\">x=<span class=\"literal\">None</span>, y=<span class=\"literal\">None</span>, z=<span class=\"literal\">None</span>, colorscale=<span class=\"string\">&#x27;reds&#x27;</span>, width=<span class=\"number\">600</span>, height=<span class=\"number\">600</span>, title=<span class=\"literal\">None</span>, xtitle=<span class=\"literal\">None</span>, ytitle=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    heatmap_fig = go.Figure(</span><br><span class=\"line\">        data=[</span><br><span class=\"line\">            go.Heatmap(x=x, y=y, z=z, colorscale=colorscale)</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    heatmap_fig.update_layout(</span><br><span class=\"line\">        autosize=<span class=\"literal\">False</span>, width=width, height=height,</span><br><span class=\"line\">        title=title,</span><br><span class=\"line\">        xaxis=<span class=\"built_in\">dict</span>(title=xtitle), yaxis=<span class=\"built_in\">dict</span>(title=ytitle),</span><br><span class=\"line\">        showlegend=<span class=\"literal\">True</span></span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    heatmap_fig.show()</span><br><span class=\"line\"></span><br><span class=\"line\">attention_weights = torch.eye(<span class=\"number\">10</span>)</span><br><span class=\"line\">show_plotly_heatmaps(z=attention_weights, title=<span class=\"string\">&#x27;Attention Weights Heatmap&#x27;</span>, xtitle=<span class=\"string\">&#x27;Keys&#x27;</span>, ytitle=<span class=\"string\">&#x27;Queries&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-æ³¨æ„åŠ›æ±‡èšï¼šNadaraya-Watsonæ ¸å›å½’\">2. æ³¨æ„åŠ›æ±‡èšï¼šNadaraya-Watsonæ ¸å›å½’</h2>\n<p>ä¸ŠèŠ‚ä»‹ç»äº†æ¡†æ¶ä¸‹çš„æ³¨æ„åŠ›æœºåˆ¶çš„ä¸»è¦æˆåˆ†ï¼šæŸ¥è¯¢ï¼ˆè‡ªä¸»æç¤ºï¼‰å’Œé”®ï¼ˆéè‡ªä¸»æç¤ºï¼‰ä¹‹é—´çš„äº¤äº’å½¢æˆäº†æ³¨æ„åŠ›æ±‡èšï¼›æ³¨æ„åŠ›æ±‡èšæœ‰é€‰æ‹©åœ°èšåˆäº†å€¼ï¼ˆæ„Ÿå®˜è¾“å…¥ï¼‰ä»¥ç”Ÿæˆæœ€ç»ˆçš„è¾“å‡ºã€‚æœ¬èŠ‚å°†ä»‹ç»æ³¨æ„åŠ›æ±‡èšçš„æ›´å¤šç»†èŠ‚ï¼Œä»¥ä¾¿ä»å®è§‚ä¸Šäº†è§£æ³¨æ„åŠ›æœºåˆ¶åœ¨å®è·µä¸­çš„è¿ä½œæ–¹å¼ã€‚å…·ä½“æ¥è¯´ï¼Œ1964å¹´æå‡ºçš„ Nadaraya-Watson æ ¸å›å½’æ¨¡å‹æ˜¯ä¸€ä¸ªç®€å•ä½†å®Œæ•´çš„ä¾‹å­ï¼Œå¯ä»¥ç”¨äºæ¼”ç¤ºå…·æœ‰æ³¨æ„åŠ›æœºåˆ¶çš„æœºå™¨å­¦ä¹ ï¼Œå…¶ç†è®ºä»‹ç»å¯è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_attention-mechanisms/nadaraya-waston.html\">æ³¨æ„åŠ›æ±‡èšï¼šNadaraya-Watsonæ ¸å›å½’</a>ã€‚</p>\n<p>é¦–å…ˆç”Ÿæˆä¸€ä¸ªéçº¿æ€§å‡½æ•°çš„äººå·¥æ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">n_train = <span class=\"number\">50</span>  <span class=\"comment\"># è®­ç»ƒæ ·æœ¬æ•°</span></span><br><span class=\"line\">x_train, _ = torch.sort(torch.rand(n_train) * <span class=\"number\">5</span>)  <span class=\"comment\"># æ’åºåçš„è®­ç»ƒæ ·æœ¬</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">2</span> * torch.sin(x) + x**<span class=\"number\">0.8</span></span><br><span class=\"line\"></span><br><span class=\"line\">y_train = f(x_train) + torch.normal(<span class=\"number\">0.0</span>, <span class=\"number\">0.5</span>, (n_train,))  <span class=\"comment\"># è®­ç»ƒæ ·æœ¬çš„è¾“å‡º</span></span><br><span class=\"line\">x_test = torch.arange(<span class=\"number\">0</span>, <span class=\"number\">5</span>, <span class=\"number\">0.1</span>)  <span class=\"comment\"># æµ‹è¯•æ ·æœ¬</span></span><br><span class=\"line\">y_truth = f(x_test)  <span class=\"comment\"># æµ‹è¯•æ ·æœ¬çš„çœŸå®è¾“å‡º</span></span><br><span class=\"line\">n_test = <span class=\"built_in\">len</span>(x_test)  <span class=\"comment\"># æµ‹è¯•æ ·æœ¬æ•°</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(n_test)  <span class=\"comment\"># 50</span></span><br></pre></td></tr></table></figure>\n<p>å‡½æ•° <code>plot_kernel_reg</code> å°†ç»˜åˆ¶æ‰€æœ‰çš„è®­ç»ƒæ ·æœ¬ï¼ˆæ ·æœ¬ç”±åœ†åœˆè¡¨ç¤ºï¼‰ï¼Œä¸å¸¦å™ªå£°é¡¹çš„çœŸå®æ•°æ®ç”Ÿæˆå‡½æ•°ï¼ˆæ ‡è®°ä¸º <code>Truth</code>ï¼‰ï¼Œä»¥åŠå­¦ä¹ å¾—åˆ°çš„é¢„æµ‹å‡½æ•°ï¼ˆæ ‡è®°ä¸º <code>Pred</code>ï¼‰ã€‚å…ˆä½¿ç”¨æœ€ç®€å•çš„ä¼°è®¡å™¨æ¥è§£å†³å›å½’é—®é¢˜ï¼Œå³åŸºäºå¹³å‡æ±‡èšæ¥è®¡ç®—æ‰€æœ‰è®­ç»ƒæ ·æœ¬è¾“å‡ºå€¼çš„å¹³å‡å€¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot_kernel_reg</span>(<span class=\"params\">y_hat</span>):</span><br><span class=\"line\">    fig = go.Figure(</span><br><span class=\"line\">        data=[</span><br><span class=\"line\">            go.Scatter(x=x_test, y=y_truth, mode=<span class=\"string\">&#x27;lines&#x27;</span>, name=<span class=\"string\">&#x27;Truth&#x27;</span>),</span><br><span class=\"line\">            go.Scatter(x=x_test, y=y_hat, mode=<span class=\"string\">&#x27;lines&#x27;</span>, name=<span class=\"string\">&#x27;Pred&#x27;</span>),</span><br><span class=\"line\">            go.Scatter(x=x_train, y=y_train, mode=<span class=\"string\">&#x27;markers&#x27;</span>, name=<span class=\"string\">&#x27;Sample&#x27;</span>, opacity=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    fig.update_layout(</span><br><span class=\"line\">        autosize=<span class=\"literal\">False</span>, width=<span class=\"number\">1200</span>, height=<span class=\"number\">800</span>,</span><br><span class=\"line\">        xaxis=<span class=\"built_in\">dict</span>(title=<span class=\"string\">&#x27;x&#x27;</span>), yaxis=<span class=\"built_in\">dict</span>(title=<span class=\"string\">&#x27;y&#x27;</span>),</span><br><span class=\"line\">        showlegend=<span class=\"literal\">True</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    fig.show()</span><br><span class=\"line\">    <span class=\"comment\"># d2l.plot(x_test, [y_truth, y_hat], &#x27;x&#x27;, &#x27;y&#x27;, legend=[&#x27;Truth&#x27;, &#x27;Pred&#x27;],</span></span><br><span class=\"line\">    <span class=\"comment\">#          xlim=[0, 5], ylim=[-1, 5])</span></span><br><span class=\"line\">    <span class=\"comment\"># d2l.plt.plot(x_train, y_train, &#x27;o&#x27;, alpha=0.5)</span></span><br><span class=\"line\"></span><br><span class=\"line\">y_hat = torch.repeat_interleave(y_train.mean(), n_test)</span><br><span class=\"line\">plot_kernel_reg(y_hat)</span><br></pre></td></tr></table></figure>\n<p>æ˜¾ç„¶ï¼Œå¹³å‡æ±‡èšå¿½ç•¥äº†è¾“å…¥ï¼ŒNadaraya-Watson æ ¸å›å½’æ ¹æ®è¾“å…¥çš„ä½ç½®å¯¹è¾“å‡ºè¿›è¡ŒåŠ æƒï¼Œæ˜¯ä¸€ä¸ªéå‚æ•°æ¨¡å‹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åŸºäºè¿™ä¸ªéå‚æ•°çš„æ³¨æ„åŠ›æ±‡èšæ¨¡å‹æ¥ç»˜åˆ¶é¢„æµ‹ç»“æœã€‚ä»ç»˜åˆ¶çš„ç»“æœä¼šå‘ç°æ–°çš„æ¨¡å‹é¢„æµ‹çº¿æ˜¯å¹³æ»‘çš„ï¼Œå¹¶ä¸”æ¯”å¹³å‡æ±‡èšçš„é¢„æµ‹æ›´æ¥è¿‘çœŸå®ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># X_repeat.shape: (n_test, n_train)</span></span><br><span class=\"line\"><span class=\"comment\"># æ¯ä¸€è¡Œéƒ½åŒ…å«ç€ç›¸åŒçš„æµ‹è¯•è¾“å…¥ï¼ˆä¾‹å¦‚ï¼šåŒæ ·çš„æŸ¥è¯¢ï¼‰</span></span><br><span class=\"line\">X_repeat = x_test.repeat_interleave(n_train).reshape((-<span class=\"number\">1</span>, n_train))</span><br><span class=\"line\"><span class=\"comment\"># x_trainåŒ…å«ç€é”®ï¼Œattention_weights.shape: (n_test, n_train)</span></span><br><span class=\"line\"><span class=\"comment\"># æ¯ä¸€è¡Œéƒ½åŒ…å«ç€è¦åœ¨ç»™å®šçš„æ¯ä¸ªæŸ¥è¯¢çš„å€¼ï¼ˆy_trainï¼‰ä¹‹é—´åˆ†é…çš„æ³¨æ„åŠ›æƒé‡</span></span><br><span class=\"line\">attention_weights = nn.functional.softmax(-(X_repeat - x_train)**<span class=\"number\">2</span> / <span class=\"number\">2</span>, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># y_hatçš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯å€¼çš„åŠ æƒå¹³å‡å€¼ï¼Œå…¶ä¸­çš„æƒé‡æ˜¯æ³¨æ„åŠ›æƒé‡</span></span><br><span class=\"line\">y_hat = torch.matmul(attention_weights, y_train)  <span class=\"comment\"># y_hat.shape: torch.Size([50])</span></span><br><span class=\"line\">plot_kernel_reg(y_hat)</span><br></pre></td></tr></table></figure>\n<p>éå‚æ•°çš„ Nadaraya-Watson æ ¸å›å½’å…·æœ‰ä¸€è‡´æ€§ï¼ˆconsistencyï¼‰çš„ä¼˜ç‚¹ï¼šå¦‚æœæœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œæ­¤æ¨¡å‹ä¼šæ”¶æ•›åˆ°æœ€ä¼˜ç»“æœã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬è¿˜æ˜¯å¯ä»¥è½»æ¾åœ°å°†å¯å­¦ä¹ çš„å‚æ•°é›†æˆåˆ°æ³¨æ„åŠ›æ±‡èšä¸­ã€‚</p>\n<p>ä¸ºäº†æ›´æœ‰æ•ˆåœ°è®¡ç®—å°æ‰¹é‡æ•°æ®çš„æ³¨æ„åŠ›ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨æ·±åº¦å­¦ä¹ å¼€å‘æ¡†æ¶ä¸­æä¾›çš„æ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = torch.ones((<span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">Y = torch.ones((<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.bmm(X, Y).shape)  <span class=\"comment\"># torch.Size([2, 1, 6])</span></span><br></pre></td></tr></table></figure>\n<p>åœ¨æ³¨æ„åŠ›æœºåˆ¶çš„èƒŒæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å°æ‰¹é‡çŸ©é˜µä¹˜æ³•æ¥è®¡ç®—å°æ‰¹é‡æ•°æ®ä¸­çš„åŠ æƒå¹³å‡å€¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">weights = torch.ones((<span class=\"number\">2</span>, <span class=\"number\">10</span>)) * <span class=\"number\">0.1</span></span><br><span class=\"line\">values = torch.arange(<span class=\"number\">20.0</span>).reshape((<span class=\"number\">2</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.bmm(weights.unsqueeze(<span class=\"number\">1</span>), values.unsqueeze(-<span class=\"number\">1</span>)))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[ 4.5000]],</span></span><br><span class=\"line\"><span class=\"comment\">#         [[14.5000]]])</span></span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰ Nadaraya-Watson æ ¸å›å½’çš„å¸¦å‚æ•°ç‰ˆæœ¬ä¸ºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">NWKernelRegression</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__(**kwargs)</span><br><span class=\"line\">        self.w = nn.Parameter(torch.rand((<span class=\"number\">1</span>,), requires_grad=<span class=\"literal\">True</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, queries, keys, values</span>):</span><br><span class=\"line\">        <span class=\"comment\"># querieså’Œattention_weightsçš„å½¢çŠ¶ä¸º: (æŸ¥è¯¢ä¸ªæ•°, â€œé”®-å€¼â€å¯¹ä¸ªæ•°)</span></span><br><span class=\"line\">        queries = queries.repeat_interleave(keys.shape[<span class=\"number\">1</span>]).reshape((-<span class=\"number\">1</span>, keys.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">        self.attention_weights = nn.functional.softmax(-((queries - keys) * self.w)**<span class=\"number\">2</span> / <span class=\"number\">2</span>, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># valuesçš„å½¢çŠ¶ä¸º: (æŸ¥è¯¢ä¸ªæ•°, â€œé”®-å€¼â€å¯¹ä¸ªæ•°)</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.bmm(self.attention_weights.unsqueeze(<span class=\"number\">1</span>), values.unsqueeze(-<span class=\"number\">1</span>)).reshape(-<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥ï¼Œå°†è®­ç»ƒæ•°æ®é›†å˜æ¢ä¸ºé”®å’Œå€¼ç”¨äºè®­ç»ƒæ³¨æ„åŠ›æ¨¡å‹ã€‚åœ¨å¸¦å‚æ•°çš„æ³¨æ„åŠ›æ±‡èšæ¨¡å‹ä¸­ï¼Œä»»ä½•ä¸€ä¸ªè®­ç»ƒæ ·æœ¬çš„è¾“å…¥éƒ½ä¼šå’Œé™¤è‡ªå·±ä»¥å¤–çš„æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„â€œé”®-å€¼â€å¯¹è¿›è¡Œè®¡ç®—ï¼Œä»è€Œå¾—åˆ°å…¶å¯¹åº”çš„é¢„æµ‹è¾“å‡ºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># X_tile.shape: (n_train, n_train)ï¼Œæ¯ä¸€è¡Œéƒ½åŒ…å«ç€ç›¸åŒçš„è®­ç»ƒè¾“å…¥</span></span><br><span class=\"line\">X_tile = x_train.repeat(n_train, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># Y_tile.shape: (n_train, n_train)ï¼Œæ¯ä¸€è¡Œéƒ½åŒ…å«ç€ç›¸åŒçš„è®­ç»ƒè¾“å‡º</span></span><br><span class=\"line\">Y_tile = y_train.repeat(n_train, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># keys.shape: (n_train, n_train-1)ï¼Œå°†å¯¹è§’çº¿å…ƒç´ ç­›å»</span></span><br><span class=\"line\">keys = X_tile[(<span class=\"number\">1</span> - torch.eye(n_train)).<span class=\"built_in\">type</span>(torch.<span class=\"built_in\">bool</span>)].reshape((n_train, -<span class=\"number\">1</span>))</span><br><span class=\"line\"><span class=\"comment\"># values.shape: (n_train, n_train-1)ï¼Œå°†å¯¹è§’çº¿å…ƒç´ ç­›å»</span></span><br><span class=\"line\">values = Y_tile[(<span class=\"number\">1</span> - torch.eye(n_train)).<span class=\"built_in\">type</span>(torch.<span class=\"built_in\">bool</span>)].reshape((n_train, -<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p>è®­ç»ƒå¸¦å‚æ•°çš„æ³¨æ„åŠ›æ±‡èšæ¨¡å‹æ—¶ï¼Œä½¿ç”¨å¹³æ–¹æŸå¤±å‡½æ•°å’Œéšæœºæ¢¯åº¦ä¸‹é™ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net = NWKernelRegression()</span><br><span class=\"line\">loss_function = nn.MSELoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\">optimizer = torch.optim.SGD(net.parameters(), lr=<span class=\"number\">0.01</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">20</span>):</span><br><span class=\"line\">    optimizer.zero_grad()</span><br><span class=\"line\">    loss = loss_function(net(x_train, keys, values), y_train)</span><br><span class=\"line\">    loss.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\">    optimizer.step()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;epoch <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>&#125;</span>, loss <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(loss.<span class=\"built_in\">sum</span>()):<span class=\"number\">.6</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>è®­ç»ƒå®Œå¸¦å‚æ•°çš„æ³¨æ„åŠ›æ±‡èšæ¨¡å‹åå¯ä»¥å‘ç°ï¼šåœ¨å°è¯•æ‹Ÿåˆå¸¦å™ªå£°çš„è®­ç»ƒæ•°æ®æ—¶ï¼Œé¢„æµ‹ç»“æœç»˜åˆ¶çš„çº¿ä¸å¦‚ä¹‹å‰éå‚æ•°æ¨¡å‹çš„å¹³æ»‘ï¼Œå› ä¸ºä¸éå‚æ•°çš„æ³¨æ„åŠ›æ±‡èšæ¨¡å‹ç›¸æ¯”ï¼Œå¸¦å‚æ•°çš„æ¨¡å‹åŠ å…¥å¯å­¦ä¹ çš„å‚æ•°åï¼Œæ›²çº¿åœ¨æ³¨æ„åŠ›æƒé‡è¾ƒå¤§çš„åŒºåŸŸå˜å¾—æ›´ä¸å¹³æ»‘ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># keys.shape: (n_test, n_train)ï¼Œæ¯ä¸€è¡ŒåŒ…å«ç€ç›¸åŒçš„è®­ç»ƒè¾“å…¥ï¼ˆä¾‹å¦‚ï¼Œç›¸åŒçš„é”®ï¼‰</span></span><br><span class=\"line\">keys = x_train.repeat(n_test, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># value.shape: (n_test, n_train)</span></span><br><span class=\"line\">values = y_train.repeat(n_test, <span class=\"number\">1</span>)</span><br><span class=\"line\">y_hat = net(x_test, keys, values).detach()</span><br><span class=\"line\">plot_kernel_reg(y_hat)</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°\">3. æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°</h2>\n<p>åœ¨ä¸Šä¸€èŠ‚ä¸­ä½¿ç”¨äº†é«˜æ–¯æ ¸æ¥å¯¹æŸ¥è¯¢å’Œé”®ä¹‹é—´çš„å…³ç³»å»ºæ¨¡ã€‚é«˜æ–¯æ ¸çš„æŒ‡æ•°éƒ¨åˆ†å¯ä»¥è§†ä¸ºæ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ï¼ˆattention scoring functionï¼‰ï¼Œç®€ç§°<strong>è¯„åˆ†å‡½æ•°</strong>ï¼ˆscoring functionï¼‰ï¼Œç„¶åæŠŠè¿™ä¸ªå‡½æ•°çš„è¾“å‡ºç»“æœè¾“å…¥åˆ° Softmax å‡½æ•°ä¸­è¿›è¡Œè¿ç®—ã€‚é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œå°†å¾—åˆ°ä¸é”®å¯¹åº”çš„å€¼çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆå³æ³¨æ„åŠ›æƒé‡ï¼‰ã€‚æœ€åï¼Œæ³¨æ„åŠ›æ±‡èšçš„è¾“å‡ºå°±æ˜¯åŸºäºè¿™äº›æ³¨æ„åŠ›æƒé‡çš„å€¼çš„åŠ æƒå’Œã€‚</p>\n<p>é€‰æ‹©ä¸åŒçš„æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ä¼šå¯¼è‡´ä¸åŒçš„æ³¨æ„åŠ›æ±‡èšæ“ä½œã€‚æœ¬èŠ‚å°†ä»‹ç»ä¸¤ä¸ªæµè¡Œçš„è¯„åˆ†å‡½æ•°ï¼Œç¨åå°†ç”¨ä»–ä»¬æ¥å®ç°æ›´å¤æ‚çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚</p>\n<p>æ­£å¦‚ä¸Šé¢æåˆ°çš„ï¼ŒSoftmax æ“ä½œç”¨äºè¾“å‡ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒä½œä¸ºæ³¨æ„åŠ›æƒé‡ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¹¶éæ‰€æœ‰çš„å€¼éƒ½åº”è¯¥è¢«çº³å…¥åˆ°æ³¨æ„åŠ›æ±‡èšä¸­ã€‚ä¾‹å¦‚ï¼Œä¸ºäº†åœ¨æœºå™¨ç¿»è¯‘ä¸­é«˜æ•ˆå¤„ç†å°æ‰¹é‡æ•°æ®é›†ï¼ŒæŸäº›æ–‡æœ¬åºåˆ—è¢«å¡«å……äº†æ²¡æœ‰æ„ä¹‰çš„ç‰¹æ®Šè¯å…ƒã€‚ä¸ºäº†ä»…å°†æœ‰æ„ä¹‰çš„è¯å…ƒä½œä¸ºå€¼æ¥è·å–æ³¨æ„åŠ›æ±‡èšï¼Œå¯ä»¥æŒ‡å®šä¸€ä¸ªæœ‰æ•ˆåºåˆ—é•¿åº¦ï¼ˆå³è¯å…ƒçš„ä¸ªæ•°ï¼‰ï¼Œä»¥ä¾¿åœ¨è®¡ç®— Softmax æ—¶è¿‡æ»¤æ‰è¶…å‡ºæŒ‡å®šèŒƒå›´çš„ä½ç½®ã€‚ä¸‹é¢çš„ <code>masked_softmax</code> å‡½æ•°å®ç°äº†è¿™æ ·çš„æ©è”½ Softmax æ“ä½œï¼ˆmasked softmax operationï¼‰ï¼Œå…¶ä¸­ä»»ä½•è¶…å‡ºæœ‰æ•ˆé•¿åº¦çš„ä½ç½®éƒ½è¢«æ©è”½å¹¶ç½®ä¸º0ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">masked_softmax</span>(<span class=\"params\">X, valid_lens</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;é€šè¿‡åœ¨æœ€åä¸€ä¸ªè½´ä¸Šæ©è”½å…ƒç´ æ¥æ‰§è¡Œsoftmaxæ“ä½œ&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># X: 3Då¼ é‡ï¼Œvalid_lens: 1Dæˆ–2Då¼ é‡</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> valid_lens <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> nn.functional.softmax(X, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        shape = X.shape</span><br><span class=\"line\">        <span class=\"keyword\">if</span> valid_lens.dim() == <span class=\"number\">1</span>:</span><br><span class=\"line\">            valid_lens = torch.repeat_interleave(valid_lens, shape[<span class=\"number\">1</span>])  <span class=\"comment\"># [a, b] -&gt; [a, a, ..., b, b, ...]</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            valid_lens = valid_lens.reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># æœ€åä¸€è½´ä¸Šè¢«æ©è”½çš„å…ƒç´ ä½¿ç”¨ä¸€ä¸ªéå¸¸å¤§çš„è´Ÿå€¼æ›¿æ¢ï¼Œä»è€Œå…¶softmaxè¾“å‡ºä¸º0</span></span><br><span class=\"line\">        X = d2l.sequence_mask(X.reshape(-<span class=\"number\">1</span>, shape[-<span class=\"number\">1</span>]), valid_lens, value=-<span class=\"number\">1e6</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> nn.functional.softmax(X.reshape(shape), dim=-<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<p>ä¸ºäº†æ¼”ç¤ºæ­¤å‡½æ•°æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œè€ƒè™‘ç”±ä¸¤ä¸ª2*4çŸ©é˜µè¡¨ç¤ºçš„æ ·æœ¬ï¼Œè¿™ä¸¤ä¸ªæ ·æœ¬çš„æœ‰æ•ˆé•¿åº¦åˆ†åˆ«ä¸º2å’Œ3ã€‚ç»è¿‡æ©è”½ Softmax æ“ä½œï¼Œè¶…å‡ºæœ‰æ•ˆé•¿åº¦çš„å€¼éƒ½è¢«æ©è”½ä¸º0ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(masked_softmax(torch.rand(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>), torch.tensor([<span class=\"number\">2</span>, <span class=\"number\">3</span>])))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[0.3292, 0.6708, 0.0000, 0.0000],</span></span><br><span class=\"line\"><span class=\"comment\">#          [0.5249, 0.4751, 0.0000, 0.0000]],</span></span><br><span class=\"line\"><span class=\"comment\">#         [[0.3104, 0.4577, 0.2318, 0.0000],</span></span><br><span class=\"line\"><span class=\"comment\">#          [0.3227, 0.3408, 0.3365, 0.0000]]])</span></span><br></pre></td></tr></table></figure>\n<p>åŒæ ·ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨äºŒç»´å¼ é‡ï¼Œä¸ºçŸ©é˜µæ ·æœ¬ä¸­çš„æ¯ä¸€è¡ŒæŒ‡å®šæœ‰æ•ˆé•¿åº¦ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(masked_softmax(torch.rand(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>), torch.tensor([[<span class=\"number\">1</span>, <span class=\"number\">3</span>], [<span class=\"number\">2</span>, <span class=\"number\">4</span>]])))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[1.0000, 0.0000, 0.0000, 0.0000],</span></span><br><span class=\"line\"><span class=\"comment\">#          [0.4203, 0.2752, 0.3045, 0.0000]],</span></span><br><span class=\"line\"><span class=\"comment\">#         [[0.4234, 0.5766, 0.0000, 0.0000],</span></span><br><span class=\"line\"><span class=\"comment\">#          [0.2979, 0.1618, 0.2246, 0.3157]]])</span></span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥å°†ä»‹ç»åŠ æ€§æ³¨æ„åŠ›ä¸ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ï¼Œå…¶ç†è®ºåˆ†æå¯è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_attention-mechanisms/attention-scoring-functions.html\">æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°</a>ã€‚</p>\n<p>ä¸€èˆ¬æ¥è¯´ï¼Œå½“æŸ¥è¯¢å’Œé”®æ˜¯ä¸åŒé•¿åº¦çš„çŸ¢é‡æ—¶ï¼Œå¯ä»¥ä½¿ç”¨åŠ æ€§æ³¨æ„åŠ›ä½œä¸ºè¯„åˆ†å‡½æ•°ã€‚å°†æŸ¥è¯¢å’Œé”®è¿ç»“èµ·æ¥åè¾“å…¥åˆ°ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ä¸­ï¼Œæ„ŸçŸ¥æœºåŒ…å«ä¸€ä¸ªéšè—å±‚ï¼Œå…¶éšè—å•å…ƒæ•°æ˜¯ä¸€ä¸ªè¶…å‚æ•°ã€‚é€šè¿‡ä½¿ç”¨ <code>tanh</code> ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå¹¶ä¸”ç¦ç”¨åç½®é¡¹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">AdditiveAttention</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;åŠ æ€§æ³¨æ„åŠ›&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, key_size, query_size, num_hiddens, dropout, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(AdditiveAttention, self).__init__(**kwargs)</span><br><span class=\"line\">        self.W_k = nn.Linear(key_size, num_hiddens, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.W_q = nn.Linear(query_size, num_hiddens, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.w_v = nn.Linear(num_hiddens, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.dropout = nn.Dropout(dropout)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, queries, keys, values, valid_lens</span>):</span><br><span class=\"line\">        queries, keys = self.W_q(queries), self.W_k(keys)  <span class=\"comment\"># (2, 1, 8), (2, 10, 8)</span></span><br><span class=\"line\">        <span class=\"comment\"># ç»´åº¦æ‰©å±•åä½¿ç”¨å¹¿æ’­æ–¹å¼è¿›è¡Œæ±‚å’Œ</span></span><br><span class=\"line\">        <span class=\"comment\"># æ‰©å±•åçš„queries.shape: (batch_size, æŸ¥è¯¢çš„ä¸ªæ•°, 1, num_hidden)</span></span><br><span class=\"line\">        <span class=\"comment\"># æ‰©å±•åçš„key.shape: (batch_size, 1, â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, num_hiddens)</span></span><br><span class=\"line\">        features = queries.unsqueeze(<span class=\"number\">2</span>) + keys.unsqueeze(<span class=\"number\">1</span>)</span><br><span class=\"line\">        features = torch.tanh(features)  <span class=\"comment\"># (2, 1, 10, 8)</span></span><br><span class=\"line\">        <span class=\"comment\"># self.w_vä»…æœ‰ä¸€ä¸ªè¾“å‡ºï¼Œå› æ­¤ä»å½¢çŠ¶ä¸­ç§»é™¤æœ€åé‚£ä¸ªå¤§å°ä¸º1çš„ç»´åº¦</span></span><br><span class=\"line\">        <span class=\"comment\"># scores.shape: (batch_size, æŸ¥è¯¢çš„ä¸ªæ•°, â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°)</span></span><br><span class=\"line\">        scores = self.w_v(features).squeeze(-<span class=\"number\">1</span>)  <span class=\"comment\"># (2, 1, 10, 1) -&gt; (2, 1, 10)</span></span><br><span class=\"line\">        self.attention_weights = masked_softmax(scores, valid_lens)  <span class=\"comment\"># (2, 1, 10)</span></span><br><span class=\"line\">        <span class=\"comment\"># values.shape: (batch_size, â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, å€¼çš„ç»´åº¦)</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.bmm(self.dropout(self.attention_weights), values)</span><br><span class=\"line\"></span><br><span class=\"line\">queries, keys = torch.normal(<span class=\"number\">0</span>, <span class=\"number\">1</span>, (<span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">20</span>)), torch.ones((<span class=\"number\">2</span>, <span class=\"number\">10</span>, <span class=\"number\">2</span>))</span><br><span class=\"line\"><span class=\"comment\"># valuesçš„å°æ‰¹é‡ï¼Œä¸¤ä¸ªå€¼çŸ©é˜µæ˜¯ç›¸åŒçš„</span></span><br><span class=\"line\">values = torch.arange(<span class=\"number\">40</span>, dtype=torch.float32).reshape(<span class=\"number\">1</span>, <span class=\"number\">10</span>, <span class=\"number\">4</span>).repeat(<span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">valid_lens = torch.tensor([<span class=\"number\">2</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">attention = AdditiveAttention(key_size=<span class=\"number\">2</span>, query_size=<span class=\"number\">20</span>, num_hiddens=<span class=\"number\">8</span>, dropout=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">attention.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(attention(queries, keys, values, valid_lens))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],</span></span><br><span class=\"line\"><span class=\"comment\">#         [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=&lt;BmmBackward0&gt;)</span></span><br></pre></td></tr></table></figure>\n<p>å°½ç®¡åŠ æ€§æ³¨æ„åŠ›åŒ…å«äº†å¯å­¦ä¹ çš„å‚æ•°ï¼Œä½†ç”±äºæœ¬ä¾‹å­ä¸­æ¯ä¸ªé”®éƒ½æ˜¯ç›¸åŒçš„ï¼Œæ‰€ä»¥æ³¨æ„åŠ›æƒé‡æ˜¯å‡åŒ€çš„ï¼Œç”±æŒ‡å®šçš„æœ‰æ•ˆé•¿åº¦å†³å®šï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># show_plotly_heatmapså‡½æ•°åœ¨ç¬¬ä¸€èŠ‚ä¸­å®šä¹‰</span></span><br><span class=\"line\">show_plotly_heatmaps(z=attention.attention_weights.detach().reshape((<span class=\"number\">2</span>, <span class=\"number\">10</span>)), height=<span class=\"number\">300</span>, xtitle=<span class=\"string\">&#x27;Keys&#x27;</span>, ytitle=<span class=\"string\">&#x27;Queries&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>ä½¿ç”¨ç‚¹ç§¯å¯ä»¥å¾—åˆ°è®¡ç®—æ•ˆç‡æ›´é«˜çš„è¯„åˆ†å‡½æ•°ï¼Œä½†æ˜¯ç‚¹ç§¯æ“ä½œè¦æ±‚æŸ¥è¯¢å’Œé”®å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼Œä¸ºäº†æ¼”ç¤º <code>DotProductAttention</code> ç±»ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸å…ˆå‰åŠ æ€§æ³¨æ„åŠ›ä¾‹å­ä¸­ç›¸åŒçš„é”®ã€å€¼å’Œæœ‰æ•ˆé•¿åº¦ã€‚å¯¹äºç‚¹ç§¯æ“ä½œï¼Œæˆ‘ä»¬ä»¤æŸ¥è¯¢çš„ç‰¹å¾ç»´åº¦ä¸é”®çš„ç‰¹å¾ç»´åº¦å¤§å°ç›¸åŒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">DotProductAttention</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, dropout, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(DotProductAttention, self).__init__(**kwargs)</span><br><span class=\"line\">        self.dropout = nn.Dropout(dropout)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># queries.shape: (batch_size, æŸ¥è¯¢çš„ä¸ªæ•°, d)</span></span><br><span class=\"line\">    <span class=\"comment\"># keys.shape: (batch_size, â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, d)</span></span><br><span class=\"line\">    <span class=\"comment\"># values.shape: (batch_size, â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, å€¼çš„ç»´åº¦)</span></span><br><span class=\"line\">    <span class=\"comment\"># valid_lens.shape: (batch_size,)æˆ–è€…(batch_size, æŸ¥è¯¢çš„ä¸ªæ•°)</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, queries, keys, values, valid_lens=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        d = queries.shape[-<span class=\"number\">1</span>]</span><br><span class=\"line\">        scores = torch.bmm(queries, keys.transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)) / math.sqrt(d)</span><br><span class=\"line\">        self.attention_weights = masked_softmax(scores, valid_lens)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.bmm(self.dropout(self.attention_weights), values)</span><br><span class=\"line\"></span><br><span class=\"line\">queries = torch.normal(<span class=\"number\">0</span>, <span class=\"number\">1</span>, (<span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>))</span><br><span class=\"line\">attention = DotProductAttention(dropout=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">attention.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(attention(queries, keys, values, valid_lens))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],</span></span><br><span class=\"line\"><span class=\"comment\">#         [[10.0000, 11.0000, 12.0000, 13.0000]]])</span></span><br></pre></td></tr></table></figure>\n<p>ä¸åŠ æ€§æ³¨æ„åŠ›æ¼”ç¤ºç›¸åŒï¼Œç”±äºé”®åŒ…å«çš„æ˜¯ç›¸åŒçš„å…ƒç´ ï¼Œè€Œè¿™äº›å…ƒç´ æ— æ³•é€šè¿‡ä»»ä½•æŸ¥è¯¢è¿›è¡ŒåŒºåˆ†ï¼Œå› æ­¤è·å¾—äº†å‡åŒ€çš„æ³¨æ„åŠ›æƒé‡ã€‚</p>\n<h2 id=\"4-Bahdanauæ³¨æ„åŠ›ï¼ˆä½¿ç”¨æ³¨æ„åŠ›çš„seq2seqï¼‰\">4. Bahdanauæ³¨æ„åŠ›ï¼ˆä½¿ç”¨æ³¨æ„åŠ›çš„seq2seqï¼‰</h2>\n<p>Bahdanau æ³¨æ„åŠ›æ¨¡å‹çš„åŸç†å¯è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_attention-mechanisms/bahdanau-attention.html\">Bahdanau æ³¨æ„åŠ›</a>ã€‚</p>\n<p>ä¸‹é¢çœ‹çœ‹å¦‚ä½•å®šä¹‰ Bahdanau æ³¨æ„åŠ›ï¼Œå®ç°å¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨-è§£ç å™¨ã€‚å…¶å®ï¼Œæˆ‘ä»¬åªéœ€é‡æ–°å®šä¹‰è§£ç å™¨å³å¯ã€‚ä¸ºäº†æ›´æ–¹ä¾¿åœ°æ˜¾ç¤ºå­¦ä¹ çš„æ³¨æ„åŠ›æƒé‡ï¼Œä»¥ä¸‹ <code>AttentionDecoder</code> ç±»å®šä¹‰äº†å¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶è§£ç å™¨çš„åŸºæœ¬æ¥å£ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\">sys.path.append(<span class=\"string\">&quot;..&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">from</span> util.functions <span class=\"keyword\">import</span> train_seq2seq, predict_seq2seq, bleu, show_plotly_heatmaps</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">AttentionDecoder</span>(d2l.Decoder):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶è§£ç å™¨çš„åŸºæœ¬æ¥å£&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(AttentionDecoder, self).__init__(**kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @property</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">attention_weights</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬åœ¨æ¥ä¸‹æ¥çš„ <code>Seq2SeqAttentionDecoder</code> ç±»ä¸­å®ç°å¸¦æœ‰ Bahdanau æ³¨æ„åŠ›çš„å¾ªç¯ç¥ç»ç½‘ç»œè§£ç å™¨ã€‚é¦–å…ˆï¼Œåˆå§‹åŒ–è§£ç å™¨çš„çŠ¶æ€ï¼Œéœ€è¦ä¸‹é¢çš„è¾“å…¥ï¼š</p>\n<ul>\n<li>ç¼–ç å™¨åœ¨æ‰€æœ‰æ—¶é—´æ­¥çš„æœ€ç»ˆå±‚éšçŠ¶æ€ï¼Œå°†ä½œä¸ºæ³¨æ„åŠ›çš„é”®å’Œå€¼ï¼›</li>\n<li>ä¸Šä¸€æ—¶é—´æ­¥çš„ç¼–ç å™¨å…¨å±‚éšçŠ¶æ€ï¼Œå°†ä½œä¸ºåˆå§‹åŒ–è§£ç å™¨çš„éšçŠ¶æ€ï¼›</li>\n<li>ç¼–ç å™¨æœ‰æ•ˆé•¿åº¦ï¼ˆæ’é™¤åœ¨æ³¨æ„åŠ›æ± ä¸­å¡«å……è¯å…ƒï¼‰ã€‚</li>\n</ul>\n<p>åœ¨æ¯ä¸ªè§£ç æ—¶é—´æ­¥éª¤ä¸­ï¼Œè§£ç å™¨ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„æœ€ç»ˆå±‚éšçŠ¶æ€å°†ç”¨ä½œæŸ¥è¯¢ã€‚å› æ­¤ï¼Œæ³¨æ„åŠ›è¾“å‡ºå’Œè¾“å…¥åµŒå…¥éƒ½è¿ç»“ä¸ºå¾ªç¯ç¥ç»ç½‘ç»œè§£ç å™¨çš„è¾“å…¥ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Seq2SeqAttentionDecoder</span>(<span class=\"title class_ inherited__\">AttentionDecoder</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, vocab_size, embed_size, num_hiddens, num_layers, dropout=<span class=\"number\">0</span>, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Seq2SeqAttentionDecoder, self).__init__(**kwargs)</span><br><span class=\"line\">        self.attention = d2l.AdditiveAttention(num_hiddens, num_hiddens, num_hiddens, dropout)</span><br><span class=\"line\">        self.embedding = nn.Embedding(vocab_size, embed_size)</span><br><span class=\"line\">        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)</span><br><span class=\"line\">        self.dense = nn.Linear(num_hiddens, vocab_size)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">init_state</span>(<span class=\"params\">self, enc_outputs, enc_valid_lens, *args</span>):</span><br><span class=\"line\">        <span class=\"comment\"># outputs.shape: (batch_size, num_steps, num_hiddens)</span></span><br><span class=\"line\">        <span class=\"comment\"># hidden_state.shape: (num_layers, batch_size, num_hiddens)</span></span><br><span class=\"line\">        outputs, hidden_state = enc_outputs</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (outputs.permute(<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">2</span>), hidden_state, enc_valid_lens)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, state</span>):</span><br><span class=\"line\">        <span class=\"comment\"># enc_outputs.shape: (batch_size, num_steps, num_hiddens)</span></span><br><span class=\"line\">        <span class=\"comment\"># hidden_state.shape: (num_layers, batch_size, num_hiddens)</span></span><br><span class=\"line\">        enc_outputs, hidden_state, enc_valid_lens = state</span><br><span class=\"line\">        X = self.embedding(X).permute(<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">2</span>)  <span class=\"comment\"># X.shape: (num_steps, batch_size, embed_size)</span></span><br><span class=\"line\">        outputs, self._attention_weights = [], []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> X:</span><br><span class=\"line\">            <span class=\"comment\"># query.shape: (batch_size, 1, num_hiddens)</span></span><br><span class=\"line\">            query = torch.unsqueeze(hidden_state[-<span class=\"number\">1</span>], dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">            <span class=\"comment\"># context.shape: (batch_size, 1, num_hiddens)</span></span><br><span class=\"line\">            context = self.attention(query, enc_outputs, enc_outputs, enc_valid_lens)</span><br><span class=\"line\">            <span class=\"comment\"># åœ¨ç‰¹å¾ç»´åº¦ä¸Šè¿ç»“</span></span><br><span class=\"line\">            x = torch.cat((context, torch.unsqueeze(x, dim=<span class=\"number\">1</span>)), dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">            <span class=\"comment\"># å°†xå˜å½¢ä¸º(1, batch_size, embed_size + num_hiddens)</span></span><br><span class=\"line\">            out, hidden_state = self.rnn(x.permute(<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">2</span>), hidden_state)</span><br><span class=\"line\">            outputs.append(out)</span><br><span class=\"line\">            self._attention_weights.append(self.attention.attention_weights)</span><br><span class=\"line\">        <span class=\"comment\"># å…¨è¿æ¥å±‚å˜æ¢åï¼Œoutputsçš„å½¢çŠ¶ä¸º(num_steps, batch_size, vocab_size)</span></span><br><span class=\"line\">        outputs = self.dense(torch.cat(outputs, dim=<span class=\"number\">0</span>))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> outputs.permute(<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">2</span>), [enc_outputs, hidden_state, enc_valid_lens]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @property</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">attention_weights</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self._attention_weights</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥ï¼Œä½¿ç”¨åŒ…å«7ä¸ªæ—¶é—´æ­¥çš„4ä¸ªåºåˆ—è¾“å…¥çš„å°æ‰¹é‡æµ‹è¯• Bahdanau æ³¨æ„åŠ›è§£ç å™¨ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">encoder = d2l.Seq2SeqEncoder(vocab_size=<span class=\"number\">10</span>, embed_size=<span class=\"number\">8</span>, num_hiddens=<span class=\"number\">16</span>, num_layers=<span class=\"number\">2</span>)</span><br><span class=\"line\">encoder.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">decoder = Seq2SeqAttentionDecoder(vocab_size=<span class=\"number\">10</span>, embed_size=<span class=\"number\">8</span>, num_hiddens=<span class=\"number\">16</span>, num_layers=<span class=\"number\">2</span>)</span><br><span class=\"line\">decoder.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">X = torch.zeros((<span class=\"number\">4</span>, <span class=\"number\">7</span>), dtype=torch.long)  <span class=\"comment\"># (batch_size, num_steps)</span></span><br><span class=\"line\">state = decoder.init_state(encoder(X), <span class=\"literal\">None</span>)</span><br><span class=\"line\">output, state = decoder(X, state)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output.shape, <span class=\"built_in\">len</span>(state), state[<span class=\"number\">0</span>].shape, <span class=\"built_in\">len</span>(state[<span class=\"number\">1</span>]), state[<span class=\"number\">1</span>][<span class=\"number\">0</span>].shape)</span><br><span class=\"line\"><span class=\"comment\"># torch.Size([4, 7, 10]) 3 torch.Size([4, 7, 16]) 2 torch.Size([4, 16])</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬åœ¨è¿™é‡ŒæŒ‡å®šè¶…å‚æ•°ï¼Œå®ä¾‹åŒ–ä¸€ä¸ªå¸¦æœ‰ Bahdanau æ³¨æ„åŠ›çš„ç¼–ç å™¨å’Œè§£ç å™¨ï¼Œå¹¶å¯¹è¿™ä¸ªæ¨¡å‹è¿›è¡Œæœºå™¨ç¿»è¯‘è®­ç»ƒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">embed_size, num_hiddens, num_layers, dropout = <span class=\"number\">32</span>, <span class=\"number\">32</span>, <span class=\"number\">2</span>, <span class=\"number\">0.1</span></span><br><span class=\"line\">batch_size, num_steps, lr, num_epochs = <span class=\"number\">64</span>, <span class=\"number\">10</span>, <span class=\"number\">0.005</span>, <span class=\"number\">300</span></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)</span><br><span class=\"line\">encoder = d2l.Seq2SeqEncoder(<span class=\"built_in\">len</span>(src_vocab), embed_size, num_hiddens, num_layers, dropout)</span><br><span class=\"line\">decoder = Seq2SeqAttentionDecoder(<span class=\"built_in\">len</span>(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)</span><br><span class=\"line\">net = d2l.EncoderDecoder(encoder, decoder)</span><br><span class=\"line\">train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device, <span class=\"string\">&#x27;../logs/Bahdanau_seq2seq_train_log&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>æ¨¡å‹è®­ç»ƒåï¼Œæˆ‘ä»¬ç”¨å®ƒå°†å‡ ä¸ªè‹±è¯­å¥å­ç¿»è¯‘æˆæ³•è¯­å¹¶è®¡ç®—å®ƒä»¬çš„ BLEU åˆ†æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">engs = [<span class=\"string\">&#x27;go .&#x27;</span>, <span class=\"string\">&quot;i lost .&quot;</span>, <span class=\"string\">&#x27;he\\&#x27;s calm .&#x27;</span>, <span class=\"string\">&#x27;i\\&#x27;m home .&#x27;</span>]</span><br><span class=\"line\">fras = [<span class=\"string\">&#x27;va !&#x27;</span>, <span class=\"string\">&#x27;j\\&#x27;ai perdu .&#x27;</span>, <span class=\"string\">&#x27;il est calme .&#x27;</span>, <span class=\"string\">&#x27;je suis chez moi .&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> eng, fra <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(engs, fras):</span><br><span class=\"line\">    translation, dec_attention_weight_seq = predict_seq2seq(net, eng, src_vocab, tgt_vocab, num_steps, device, <span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;eng&#125;</span> =&gt; <span class=\"subst\">&#123;translation&#125;</span>, bleu <span class=\"subst\">&#123;bleu(translation, fra, k=<span class=\"number\">2</span>):<span class=\"number\">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>è®­ç»ƒç»“æŸåï¼Œä¸‹é¢é€šè¿‡å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡ä¼šå‘ç°æ¯ä¸ªæŸ¥è¯¢éƒ½ä¼šåœ¨é”®å€¼å¯¹ä¸Šåˆ†é…ä¸åŒçš„æƒé‡ï¼Œè¿™è¯´æ˜åœ¨æ¯ä¸ªè§£ç æ­¥ä¸­ï¼Œè¾“å…¥åºåˆ—çš„ä¸åŒéƒ¨åˆ†è¢«é€‰æ‹©æ€§åœ°èšé›†åœ¨æ³¨æ„åŠ›æ± ä¸­ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">attention_weights = torch.cat([step[<span class=\"number\">0</span>][<span class=\"number\">0</span>][<span class=\"number\">0</span>] <span class=\"keyword\">for</span> step <span class=\"keyword\">in</span> dec_attention_weight_seq], <span class=\"number\">0</span>).reshape((-<span class=\"number\">1</span>, num_steps))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># åŠ ä¸Šä¸€ä¸ªåŒ…å«åºåˆ—ç»“æŸè¯å…ƒ</span></span><br><span class=\"line\">show_plotly_heatmaps(z=attention_weights[:, :<span class=\"built_in\">len</span>(engs[-<span class=\"number\">1</span>].split()) + <span class=\"number\">1</span>].cpu().detach(), xtitle=<span class=\"string\">&#x27;Keys&#x27;</span>, ytitle=<span class=\"string\">&#x27;Queries&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"5-å¤šå¤´æ³¨æ„åŠ›\">5. å¤šå¤´æ³¨æ„åŠ›</h2>\n<p>åœ¨å®è·µä¸­ï¼Œå½“ç»™å®šç›¸åŒçš„æŸ¥è¯¢ã€é”®å’Œå€¼çš„é›†åˆæ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹å¯ä»¥åŸºäºç›¸åŒçš„æ³¨æ„åŠ›æœºåˆ¶å­¦ä¹ åˆ°ä¸åŒçš„è¡Œä¸ºï¼Œç„¶åå°†ä¸åŒçš„è¡Œä¸ºä½œä¸ºçŸ¥è¯†ç»„åˆèµ·æ¥ï¼Œæ•è·åºåˆ—å†…å„ç§èŒƒå›´çš„ä¾èµ–å…³ç³»ï¼ˆä¾‹å¦‚ï¼ŒçŸ­è·ç¦»ä¾èµ–å’Œé•¿è·ç¦»ä¾èµ–å…³ç³»ï¼‰ã€‚å› æ­¤ï¼Œå…è®¸æ³¨æ„åŠ›æœºåˆ¶ç»„åˆä½¿ç”¨æŸ¥è¯¢ã€é”®å’Œå€¼çš„ä¸åŒ<strong>å­ç©ºé—´è¡¨ç¤º</strong>ï¼ˆrepresentation subspacesï¼‰å¯èƒ½æ˜¯æœ‰ç›Šçš„ã€‚</p>\n<p>ä¸ºæ­¤ï¼Œä¸å…¶åªä½¿ç”¨å•ç‹¬ä¸€ä¸ªæ³¨æ„åŠ›æ±‡èšï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ç‹¬ç«‹å­¦ä¹ å¾—åˆ°çš„ <code>h</code> ç»„ä¸åŒçš„<strong>çº¿æ€§æŠ•å½±</strong>ï¼ˆlinear projectionsï¼‰æ¥å˜æ¢æŸ¥è¯¢ã€é”®å’Œå€¼ã€‚ç„¶åï¼Œè¿™ <code>h</code> ç»„å˜æ¢åçš„æŸ¥è¯¢ã€é”®å’Œå€¼å°†å¹¶è¡Œåœ°é€åˆ°æ³¨æ„åŠ›æ±‡èšä¸­ã€‚æœ€åï¼Œå°†è¿™ <code>h</code> ä¸ªæ³¨æ„åŠ›æ±‡èšçš„è¾“å‡ºæ‹¼æ¥åœ¨ä¸€èµ·ï¼Œå¹¶ä¸”é€šè¿‡å¦ä¸€ä¸ªå¯ä»¥å­¦ä¹ çš„çº¿æ€§æŠ•å½±è¿›è¡Œå˜æ¢ï¼Œä»¥äº§ç”Ÿæœ€ç»ˆè¾“å‡ºã€‚è¿™ç§è®¾è®¡è¢«ç§°ä¸º<strong>å¤šå¤´æ³¨æ„åŠ›</strong>ï¼ˆmultihead attentionï¼‰ã€‚å¯¹äº <code>h</code> ä¸ªæ³¨æ„åŠ›æ±‡èšè¾“å‡ºï¼Œæ¯ä¸€ä¸ªæ³¨æ„åŠ›æ±‡èšéƒ½è¢«ç§°ä½œä¸€ä¸ª<strong>å¤´</strong>ï¼ˆheadï¼‰ã€‚åŸºäºè¿™ç§è®¾è®¡ï¼Œæ¯ä¸ªå¤´éƒ½å¯èƒ½ä¼šå…³æ³¨è¾“å…¥çš„ä¸åŒéƒ¨åˆ†ï¼Œå¯ä»¥è¡¨ç¤ºæ¯”ç®€å•åŠ æƒå¹³å‡å€¼æ›´å¤æ‚çš„å‡½æ•°ã€‚</p>\n<p>å¤šå¤´æ³¨æ„åŠ›æ¨¡å‹çš„åŸç†å¯è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_attention-mechanisms/multihead-attention.html\">å¤šå¤´æ³¨æ„åŠ›</a>ã€‚</p>\n<p>åœ¨å®ç°è¿‡ç¨‹ä¸­é€šå¸¸é€‰æ‹©ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ä½œä¸ºæ¯ä¸€ä¸ªæ³¨æ„åŠ›å¤´ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MultiHeadAttention</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å¤šå¤´æ³¨æ„åŠ›&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, key_size, query_size, value_size, num_hiddens, num_heads, dropout, bias=<span class=\"literal\">False</span>, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(MultiHeadAttention, self).__init__(**kwargs)</span><br><span class=\"line\">        self.num_heads = num_heads</span><br><span class=\"line\">        self.attention = d2l.DotProductAttention(dropout)</span><br><span class=\"line\">        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)</span><br><span class=\"line\">        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)</span><br><span class=\"line\">        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)</span><br><span class=\"line\">        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, queries, keys, values, valid_lens</span>):</span><br><span class=\"line\">        <span class=\"comment\"># queries/keys/valuesçš„å½¢çŠ¶: (batch_size, æŸ¥è¯¢æˆ–è€…â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, query_size/key_size/value_size)</span></span><br><span class=\"line\">        <span class=\"comment\"># valid_lensçš„å½¢çŠ¶: (batch_size,)æˆ–(batch_size, æŸ¥è¯¢çš„ä¸ªæ•°)</span></span><br><span class=\"line\">        <span class=\"comment\"># ç»è¿‡å˜æ¢åï¼Œè¾“å‡ºçš„queries/keys/valuesçš„å½¢çŠ¶: (batch_size * num_heads, æŸ¥è¯¢æˆ–è€…â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, num_hiddens / num_heads)</span></span><br><span class=\"line\">        queries = transpose_qkv(self.W_q(queries), self.num_heads)</span><br><span class=\"line\">        keys = transpose_qkv(self.W_k(keys), self.num_heads)</span><br><span class=\"line\">        values = transpose_qkv(self.W_v(values), self.num_heads)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> valid_lens <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            <span class=\"comment\"># åœ¨è½´0ï¼Œå°†æ¯ä¸€é¡¹ï¼ˆæ ‡é‡æˆ–è€…çŸ¢é‡ï¼‰å¤åˆ¶num_headsæ¬¡</span></span><br><span class=\"line\">            valid_lens = torch.repeat_interleave(valid_lens, repeats=self.num_heads, dim=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># outputçš„å½¢çŠ¶: (batch_size * num_heads, æŸ¥è¯¢çš„ä¸ªæ•°, num_hiddens / num_heads)</span></span><br><span class=\"line\">        output = self.attention(queries, keys, values, valid_lens)</span><br><span class=\"line\">        <span class=\"comment\"># output_concatçš„å½¢çŠ¶: (batch_size, æŸ¥è¯¢çš„ä¸ªæ•°, num_hiddens)</span></span><br><span class=\"line\">        output_concat = transpose_output(output, self.num_heads)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.W_o(output_concat)</span><br></pre></td></tr></table></figure>\n<p>ä¸ºäº†èƒ½å¤Ÿä½¿å¤šä¸ªå¤´å¹¶è¡Œè®¡ç®—ï¼Œä¸Šé¢çš„ <code>MultiHeadAttention</code> ç±»å°†ä½¿ç”¨ä¸‹é¢å®šä¹‰çš„ä¸¤ä¸ªè½¬ç½®å‡½æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œ<code>transpose_output</code> å‡½æ•°åè½¬äº† <code>transpose_qkv</code> å‡½æ•°çš„æ“ä½œï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">transpose_qkv</span>(<span class=\"params\">X, num_heads</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä¸ºäº†å¤šæ³¨æ„åŠ›å¤´çš„å¹¶è¡Œè®¡ç®—è€Œå˜æ¢å½¢çŠ¶&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># è¾“å…¥Xçš„å½¢çŠ¶: (batch_size, æŸ¥è¯¢æˆ–è€…â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, num_hiddens)</span></span><br><span class=\"line\">    X = X.reshape(X.shape[<span class=\"number\">0</span>], X.shape[<span class=\"number\">1</span>], num_heads, -<span class=\"number\">1</span>)  <span class=\"comment\"># (batch_size, æŸ¥è¯¢æˆ–è€…â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, num_heads, num_hiddens/num_heads)</span></span><br><span class=\"line\">    X = X.permute(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">3</span>)  <span class=\"comment\"># (batch_size, num_heads, æŸ¥è¯¢æˆ–è€…â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, num_hiddens/num_heads)</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> X.reshape(-<span class=\"number\">1</span>, X.shape[<span class=\"number\">2</span>], X.shape[<span class=\"number\">3</span>])  <span class=\"comment\"># (batch_size*num_heads, æŸ¥è¯¢æˆ–è€…â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, num_hiddens/num_heads)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">transpose_output</span>(<span class=\"params\">X, num_heads</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;é€†è½¬transpose_qkvå‡½æ•°çš„æ“ä½œ&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># è¾“å…¥Xçš„å½¢çŠ¶: (batch_size*num_heads, æŸ¥è¯¢æˆ–è€…â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, num_hiddens/num_heads)</span></span><br><span class=\"line\">    X = X.reshape(-<span class=\"number\">1</span>, num_heads, X.shape[<span class=\"number\">1</span>], X.shape[<span class=\"number\">2</span>])  <span class=\"comment\"># (batch_size, num_heads, æŸ¥è¯¢æˆ–è€…â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, num_hiddens/num_heads)</span></span><br><span class=\"line\">    X = X.permute(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">3</span>)  <span class=\"comment\"># (batch_size, æŸ¥è¯¢æˆ–è€…â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, num_heads, num_hiddens/num_heads)</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> X.reshape(X.shape[<span class=\"number\">0</span>], X.shape[<span class=\"number\">1</span>], -<span class=\"number\">1</span>)  <span class=\"comment\"># (batch_size, æŸ¥è¯¢æˆ–è€…â€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°, num_hiddens)</span></span><br></pre></td></tr></table></figure>\n<p>ä¸‹é¢ä½¿ç”¨é”®å’Œå€¼ç›¸åŒçš„å°ä¾‹å­æ¥æµ‹è¯•æˆ‘ä»¬ç¼–å†™çš„ <code>MultiHeadAttention</code> ç±»ã€‚å¤šå¤´æ³¨æ„åŠ›è¾“å‡ºçš„å½¢çŠ¶æ˜¯ <code>(batch_size, num_queries, num_hiddens)</code>ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_hiddens, num_heads = <span class=\"number\">100</span>, <span class=\"number\">5</span></span><br><span class=\"line\">attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, <span class=\"number\">0.5</span>)</span><br><span class=\"line\">attention.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size, num_queries = <span class=\"number\">2</span>, <span class=\"number\">4</span></span><br><span class=\"line\">num_kvpairs, valid_lens = <span class=\"number\">6</span>, torch.tensor([<span class=\"number\">3</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\">X = torch.ones((batch_size, num_queries, num_hiddens))</span><br><span class=\"line\">Y = torch.ones((batch_size, num_kvpairs, num_hiddens))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(attention(X, Y, Y, valid_lens).shape)  <span class=\"comment\"># torch.Size([2, 4, 100])</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"6-è‡ªæ³¨æ„åŠ›å’Œä½ç½®ç¼–ç \">6. è‡ªæ³¨æ„åŠ›å’Œä½ç½®ç¼–ç </h2>\n<p>åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œç»å¸¸ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æˆ–å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å¯¹åºåˆ—è¿›è¡Œç¼–ç ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œæœ‰äº†æ³¨æ„åŠ›æœºåˆ¶ä¹‹åï¼Œæˆ‘ä»¬å°†è¯å…ƒåºåˆ—è¾“å…¥æ³¨æ„åŠ›æ± åŒ–ä¸­ï¼Œä»¥ä¾¿åŒä¸€ç»„è¯å…ƒåŒæ—¶å……å½“æŸ¥è¯¢ã€é”®å’Œå€¼ã€‚å…·ä½“æ¥è¯´ï¼Œæ¯ä¸ªæŸ¥è¯¢éƒ½ä¼šå…³æ³¨æ‰€æœ‰çš„é”®-å€¼å¯¹å¹¶ç”Ÿæˆä¸€ä¸ªæ³¨æ„åŠ›è¾“å‡ºã€‚å½“æŸ¥è¯¢ã€é”®å’Œå€¼æ¥è‡ªåŒä¸€ç»„è¾“å…¥æ—¶è¢«ç§°ä¸º<strong>è‡ªæ³¨æ„åŠ›</strong>ï¼ˆself-attentionï¼‰ï¼Œä¹Ÿè¢«ç§°ä¸º<strong>å†…éƒ¨æ³¨æ„åŠ›</strong>ï¼ˆintra-attentionï¼‰ã€‚æœ¬èŠ‚å°†ä½¿ç”¨è‡ªæ³¨æ„åŠ›è¿›è¡Œåºåˆ—ç¼–ç ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨åºåˆ—çš„é¡ºåºä½œä¸ºè¡¥å……ä¿¡æ¯ã€‚</p>\n<p>è‡ªæ³¨æ„åŠ›æ¨¡å‹çš„åŸç†å¯è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_attention-mechanisms/self-attention-and-positional-encoding.html\">è‡ªæ³¨æ„åŠ›å’Œä½ç½®ç¼–ç </a>ã€‚</p>\n<p>ä¸‹é¢çš„ä»£ç ç‰‡æ®µæ˜¯åŸºäºå¤šå¤´æ³¨æ„åŠ›å¯¹ä¸€ä¸ªå¼ é‡å®Œæˆè‡ªæ³¨æ„åŠ›çš„è®¡ç®—ï¼Œå¼ é‡çš„å½¢çŠ¶ä¸º <code>(æ‰¹é‡å¤§å°, æ—¶é—´æ­¥çš„æ•°ç›®æˆ–è¯å…ƒåºåˆ—çš„é•¿åº¦, h)</code>ï¼Œè¾“å‡ºä¸è¾“å…¥çš„å¼ é‡å½¢çŠ¶ç›¸åŒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">from</span> util.functions <span class=\"keyword\">import</span> show_plotly_heatmaps</span><br><span class=\"line\"></span><br><span class=\"line\">num_hiddens, num_heads = <span class=\"number\">100</span>, <span class=\"number\">5</span></span><br><span class=\"line\">attention = d2l.MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, <span class=\"number\">0.5</span>)</span><br><span class=\"line\">attention.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size, num_queries, valid_lens = <span class=\"number\">2</span>, <span class=\"number\">4</span>, torch.tensor([<span class=\"number\">3</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\">X = torch.ones((batch_size, num_queries, num_hiddens))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(attention(X, X, X, valid_lens).shape)  <span class=\"comment\"># torch.Size([2, 4, 100])</span></span><br></pre></td></tr></table></figure>\n<p>åœ¨å¤„ç†è¯å…ƒåºåˆ—æ—¶ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œæ˜¯é€ä¸ªçš„é‡å¤åœ°å¤„ç†è¯å…ƒçš„ï¼Œè€Œè‡ªæ³¨æ„åŠ›åˆ™å› ä¸ºå¹¶è¡Œè®¡ç®—è€Œæ”¾å¼ƒäº†é¡ºåºæ“ä½œã€‚ä¸ºäº†ä½¿ç”¨åºåˆ—çš„é¡ºåºä¿¡æ¯ï¼Œé€šè¿‡åœ¨è¾“å…¥è¡¨ç¤ºä¸­æ·»åŠ <strong>ä½ç½®ç¼–ç </strong>ï¼ˆpositional encodingï¼‰æ¥æ³¨å…¥ç»å¯¹çš„æˆ–ç›¸å¯¹çš„ä½ç½®ä¿¡æ¯ã€‚ä½ç½®ç¼–ç å¯ä»¥é€šè¿‡å­¦ä¹ å¾—åˆ°ä¹Ÿå¯ä»¥ç›´æ¥å›ºå®šå¾—åˆ°ã€‚æ¥ä¸‹æ¥æè¿°çš„æ˜¯åŸºäºæ­£å¼¦å‡½æ•°å’Œä½™å¼¦å‡½æ•°çš„å›ºå®šä½ç½®ç¼–ç ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">PositionalEncoding</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä½ç½®ç¼–ç &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, num_hiddens, dropout, max_len=<span class=\"number\">1000</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(PositionalEncoding, self).__init__()</span><br><span class=\"line\">        self.dropout = nn.Dropout(dropout)</span><br><span class=\"line\">        <span class=\"comment\"># åˆ›å»ºä¸€ä¸ªè¶³å¤Ÿé•¿çš„P</span></span><br><span class=\"line\">        self.P = torch.zeros((<span class=\"number\">1</span>, max_len, num_hiddens))</span><br><span class=\"line\">        X = torch.arange(max_len, dtype=torch.float32).reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>) /\\</span><br><span class=\"line\">            torch.<span class=\"built_in\">pow</span>(<span class=\"number\">10000</span>, torch.arange(<span class=\"number\">0</span>, num_hiddens, <span class=\"number\">2</span>, dtype=torch.float32) / num_hiddens)</span><br><span class=\"line\">        self.P[:, :, <span class=\"number\">0</span>::<span class=\"number\">2</span>] = torch.sin(X)</span><br><span class=\"line\">        self.P[:, :, <span class=\"number\">1</span>::<span class=\"number\">2</span>] = torch.cos(X)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        X = X + self.P[:, :X.shape[<span class=\"number\">1</span>], :].to(X.device)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.dropout(X)</span><br></pre></td></tr></table></figure>\n<p>åœ¨ä½ç½®åµŒå…¥çŸ©é˜µ <code>P</code> ä¸­ï¼Œè¡Œä»£è¡¨è¯å…ƒåœ¨åºåˆ—ä¸­çš„ä½ç½®ï¼Œåˆ—ä»£è¡¨ä½ç½®ç¼–ç çš„ä¸åŒç»´åº¦ã€‚ä»ä¸‹é¢çš„ä¾‹å­ä¸­å¯ä»¥çœ‹åˆ°ä½ç½®åµŒå…¥çŸ©é˜µçš„ç¬¬6åˆ—å’Œç¬¬7åˆ—çš„é¢‘ç‡é«˜äºç¬¬8åˆ—å’Œç¬¬9åˆ—ã€‚ç¬¬6åˆ—å’Œç¬¬7åˆ—ä¹‹é—´çš„åç§»é‡ï¼ˆç¬¬8åˆ—å’Œç¬¬9åˆ—ç›¸åŒï¼‰æ˜¯ç”±äºæ­£å¼¦å‡½æ•°å’Œä½™å¼¦å‡½æ•°çš„äº¤æ›¿ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">encoding_dim, num_steps = <span class=\"number\">32</span>, <span class=\"number\">60</span></span><br><span class=\"line\">pos_encoding = PositionalEncoding(encoding_dim, <span class=\"number\">0</span>)</span><br><span class=\"line\">pos_encoding.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">X = pos_encoding(torch.zeros((<span class=\"number\">1</span>, num_steps, encoding_dim)))</span><br><span class=\"line\">P = pos_encoding.P[:, :X.shape[<span class=\"number\">1</span>], :]</span><br><span class=\"line\">d2l.plot(torch.arange(num_steps), P[<span class=\"number\">0</span>, :, <span class=\"number\">6</span>:<span class=\"number\">10</span>].T, xlabel=<span class=\"string\">&#x27;Row (position)&#x27;</span>, figsize=(<span class=\"number\">8</span>, <span class=\"number\">4</span>),</span><br><span class=\"line\">         legend=[<span class=\"string\">&quot;Col %d&quot;</span> % d <span class=\"keyword\">for</span> d <span class=\"keyword\">in</span> torch.arange(<span class=\"number\">6</span>, <span class=\"number\">10</span>)])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>é€šè¿‡ç»˜åˆ¶çƒ­åŠ›å›¾å¯ä»¥çœ‹åˆ°ï¼Œä½ç½®ç¼–ç é€šè¿‡ä½¿ç”¨ä¸‰è§’å‡½æ•°åœ¨ç¼–ç ç»´åº¦ä¸Šé™ä½é¢‘ç‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">P = P[<span class=\"number\">0</span>, :, :]</span><br><span class=\"line\">show_plotly_heatmaps(z=P, xtitle=<span class=\"string\">&#x27;Column (encoding dimension)&#x27;</span>, ytitle=<span class=\"string\">&#x27;Row (position)&#x27;</span>, colorscale=<span class=\"string\">&#x27;Blues&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"7-Transformer\">7. Transformer</h2>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/7592.html",
            "url": "https://asanosaki.github.io/posts/7592.html",
            "title": "åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ç¬”è®°(ææ²)-ç°ä»£å¾ªç¯ç¥ç»ç½‘ç»œ",
            "date_published": "2023-04-11T04:58:00.000Z",
            "content_html": "<blockquote>\n<p>ææ²åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆPyTorchï¼‰è¯¾ç¨‹å­¦ä¹ ç¬”è®°ç¬¬ä¹ç« ï¼šç°ä»£å¾ªç¯ç¥ç»ç½‘ç»œã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-é—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰\">1. é—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰</h2>\n<p>åœ¨<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/bptt.html\">é€šè¿‡æ—¶é—´åå‘ä¼ æ’­</a>ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•åœ¨å¾ªç¯ç¥ç»ç½‘ç»œä¸­è®¡ç®—æ¢¯åº¦ï¼Œä»¥åŠçŸ©é˜µè¿ç»­ä¹˜ç§¯å¯ä»¥å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±æˆ–æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ã€‚ä¸‹é¢æˆ‘ä»¬ç®€å•æ€è€ƒä¸€ä¸‹è¿™ç§æ¢¯åº¦å¼‚å¸¸åœ¨å®è·µä¸­çš„æ„ä¹‰ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šé‡åˆ°ä»¥ä¸‹çš„æƒ…å†µï¼š</p>\n<ul>\n<li>æ—©æœŸè§‚æµ‹å€¼å¯¹é¢„æµ‹æ‰€æœ‰æœªæ¥è§‚æµ‹å€¼å…·æœ‰éå¸¸é‡è¦çš„æ„ä¹‰ã€‚è€ƒè™‘ä¸€ä¸ªæç«¯æƒ…å†µï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªè§‚æµ‹å€¼åŒ…å«ä¸€ä¸ªæ ¡éªŒå’Œï¼Œç›®æ ‡æ˜¯åœ¨åºåˆ—çš„æœ«å°¾è¾¨åˆ«æ ¡éªŒå’Œæ˜¯å¦æ­£ç¡®ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç¬¬ä¸€ä¸ªè¯å…ƒçš„å½±å“è‡³å…³é‡è¦ã€‚æˆ‘ä»¬å¸Œæœ›æœ‰æŸäº›æœºåˆ¶èƒ½å¤Ÿ<strong>åœ¨ä¸€ä¸ªè®°å¿†å…ƒé‡Œå­˜å‚¨é‡è¦çš„æ—©æœŸä¿¡æ¯</strong>ã€‚å¦‚æœæ²¡æœ‰è¿™æ ·çš„æœºåˆ¶ï¼Œæˆ‘ä»¬å°†ä¸å¾—ä¸ç»™è¿™ä¸ªè§‚æµ‹å€¼æŒ‡å®šä¸€ä¸ªéå¸¸å¤§çš„æ¢¯åº¦ï¼Œå› ä¸ºå®ƒä¼šå½±å“æ‰€æœ‰åç»­çš„è§‚æµ‹å€¼ã€‚</li>\n<li>ä¸€äº›è¯å…ƒæ²¡æœ‰ç›¸å…³çš„è§‚æµ‹å€¼ã€‚ä¾‹å¦‚ï¼Œåœ¨å¯¹ç½‘é¡µå†…å®¹è¿›è¡Œæƒ…æ„Ÿåˆ†ææ—¶ï¼Œå¯èƒ½æœ‰ä¸€äº›è¾…åŠ© HTML ä»£ç ä¸ç½‘é¡µä¼ è¾¾çš„æƒ…ç»ªæ— å…³ã€‚æˆ‘ä»¬å¸Œæœ›æœ‰ä¸€äº›æœºåˆ¶æ¥<strong>è·³è¿‡éšçŠ¶æ€è¡¨ç¤ºä¸­çš„æ­¤ç±»è¯å…ƒ</strong>ã€‚</li>\n<li>åºåˆ—çš„å„ä¸ªéƒ¨åˆ†ä¹‹é—´å­˜åœ¨é€»è¾‘ä¸­æ–­ã€‚ä¾‹å¦‚ï¼Œä¹¦çš„ç« èŠ‚ä¹‹é—´å¯èƒ½ä¼šæœ‰è¿‡æ¸¡å­˜åœ¨ï¼Œæˆ–è€…è¯åˆ¸çš„ç†Šå¸‚å’Œç‰›å¸‚ä¹‹é—´å¯èƒ½ä¼šæœ‰è¿‡æ¸¡å­˜åœ¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæœ€å¥½æœ‰ä¸€ç§æ–¹æ³•æ¥<strong>é‡ç½®æˆ‘ä»¬çš„å†…éƒ¨çŠ¶æ€è¡¨ç¤º</strong>ã€‚</li>\n</ul>\n<p>åœ¨å­¦æœ¯ç•Œå·²ç»æå‡ºäº†è®¸å¤šæ–¹æ³•æ¥è§£å†³è¿™ç±»é—®é¢˜ã€‚å…¶ä¸­æœ€æ—©çš„æ–¹æ³•æ˜¯<strong>é•¿çŸ­æœŸè®°å¿†</strong>ï¼ˆlong-short-term memoryï¼ŒLSTMï¼‰ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­è®¨è®ºã€‚<strong>é—¨æ§å¾ªç¯å•å…ƒ</strong>ï¼ˆgated recurrent unitï¼ŒGRUï¼‰æ˜¯ä¸€ä¸ªç¨å¾®ç®€åŒ–çš„å˜ä½“ï¼Œé€šå¸¸èƒ½å¤Ÿæä¾›åŒç­‰çš„æ•ˆæœï¼Œå¹¶ä¸”è®¡ç®—çš„é€Ÿåº¦æ˜æ˜¾æ›´å¿«ã€‚ç”±äºé—¨æ§å¾ªç¯å•å…ƒæ›´ç®€å•ï¼Œæˆ‘ä»¬ä»å®ƒå¼€å§‹è§£è¯»ã€‚</p>\n<p>é—¨æ§å¾ªç¯å•å…ƒä¸æ™®é€šçš„å¾ªç¯ç¥ç»ç½‘ç»œä¹‹é—´çš„å…³é”®åŒºåˆ«åœ¨äºï¼šå‰è€…æ”¯æŒ<strong>éšçŠ¶æ€çš„é—¨æ§</strong>ã€‚è¿™æ„å‘³ç€æ¨¡å‹æœ‰ä¸“é—¨çš„æœºåˆ¶æ¥ç¡®å®šåº”è¯¥ä½•æ—¶æ›´æ–°éšçŠ¶æ€ï¼Œä»¥åŠåº”è¯¥ä½•æ—¶é‡ç½®éšçŠ¶æ€ã€‚è¿™äº›æœºåˆ¶æ˜¯å¯å­¦ä¹ çš„ï¼Œå¹¶ä¸”èƒ½å¤Ÿè§£å†³äº†ä¸Šé¢åˆ—å‡ºçš„é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå¦‚æœç¬¬ä¸€ä¸ªè¯å…ƒéå¸¸é‡è¦ï¼Œæ¨¡å‹å°†å­¦ä¼šåœ¨ç¬¬ä¸€æ¬¡è§‚æµ‹ä¹‹åä¸æ›´æ–°éšçŠ¶æ€ã€‚åŒæ ·ï¼Œæ¨¡å‹ä¹Ÿå¯ä»¥å­¦ä¼šè·³è¿‡ä¸ç›¸å…³çš„ä¸´æ—¶è§‚æµ‹ã€‚æœ€åï¼Œæ¨¡å‹è¿˜å°†å­¦ä¼šåœ¨éœ€è¦çš„æ—¶å€™é‡ç½®éšçŠ¶æ€ã€‚ä¸‹é¢æˆ‘ä»¬å°†è¯¦ç»†è®¨è®ºå„ç±»é—¨æ§ã€‚</p>\n<p>æˆ‘ä»¬é¦–å…ˆä»‹ç»<strong>é‡ç½®é—¨</strong>ï¼ˆreset gateï¼‰å’Œ<strong>æ›´æ–°é—¨</strong>ï¼ˆupdate gateï¼‰ã€‚æˆ‘ä»¬æŠŠå®ƒä»¬è®¾è®¡æˆ <code>(0, 1)</code> åŒºé—´ä¸­çš„å‘é‡ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œ<strong>å‡¸ç»„åˆ</strong>ã€‚é‡ç½®é—¨å…è®¸æˆ‘ä»¬<strong>æ§åˆ¶å¯èƒ½è¿˜æƒ³è®°ä½</strong>çš„è¿‡å»çŠ¶æ€çš„æ•°é‡ï¼›æ›´æ–°é—¨å°†å…è®¸æˆ‘ä»¬<strong>æ§åˆ¶æ–°çŠ¶æ€ä¸­æœ‰å¤šå°‘ä¸ªæ˜¯æ—§çŠ¶æ€çš„å‰¯æœ¬</strong>ã€‚</p>\n<p>æˆ‘ä»¬ä»æ„é€ è¿™äº›é—¨æ§å¼€å§‹ã€‚é‡ç½®é—¨å’Œæ›´æ–°é—¨çš„è¾“å…¥æ˜¯ç”±å½“å‰æ—¶é—´æ­¥çš„è¾“å…¥å’Œå‰ä¸€æ—¶é—´æ­¥çš„éšçŠ¶æ€ç»™å‡ºã€‚ä¸¤ä¸ªé—¨çš„è¾“å‡ºæ˜¯ç”±ä½¿ç”¨ Sigmoid æ¿€æ´»å‡½æ•°çš„ä¸¤ä¸ªå…¨è¿æ¥å±‚ç»™å‡ºã€‚é—¨æ§å¾ªç¯å•å…ƒçš„æ•°å­¦è¡¨è¾¾è¯¦è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-modern/gru.html\">é—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰</a>ã€‚</p>\n<h3 id=\"1-1-é—¨æ§å¾ªç¯å•å…ƒçš„ä»é›¶å¼€å§‹å®ç°\">1.1 é—¨æ§å¾ªç¯å•å…ƒçš„ä»é›¶å¼€å§‹å®ç°</h3>\n<p>ä¸ºäº†æ›´å¥½åœ°ç†è§£é—¨æ§å¾ªç¯å•å…ƒæ¨¡å‹ï¼Œæˆ‘ä»¬ä»é›¶å¼€å§‹å®ç°å®ƒã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è¯»å–ä¸Šä¸€ç« ä¸­ä½¿ç”¨çš„æ—¶é—´æœºå™¨æ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size, num_steps = <span class=\"number\">32</span>, <span class=\"number\">35</span></span><br><span class=\"line\">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br></pre></td></tr></table></figure>\n<p>ä¸‹ä¸€æ­¥æ˜¯åˆå§‹åŒ–æ¨¡å‹å‚æ•°ã€‚æˆ‘ä»¬ä»æ ‡å‡†å·®ä¸º0.01çš„é«˜æ–¯åˆ†å¸ƒä¸­æå–æƒé‡ï¼Œå¹¶å°†åç½®é¡¹è®¾ä¸º0ï¼Œè¶…å‚æ•° <code>num_hiddens</code> å®šä¹‰éšè—å•å…ƒçš„æ•°é‡ï¼Œå®ä¾‹åŒ–ä¸æ›´æ–°é—¨ã€é‡ç½®é—¨ã€å€™é€‰éšçŠ¶æ€å’Œè¾“å‡ºå±‚ç›¸å…³çš„æ‰€æœ‰æƒé‡å’Œåç½®ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_params</span>(<span class=\"params\">vocab_size, num_hiddens, device</span>):</span><br><span class=\"line\">    num_inputs = num_outputs = vocab_size</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">normal</span>(<span class=\"params\">shape</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.randn(size=shape, device=device) * <span class=\"number\">0.01</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">three</span>():</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device))</span><br><span class=\"line\"></span><br><span class=\"line\">    W_xz, W_hz, b_z = three()  <span class=\"comment\"># æ›´æ–°é—¨å‚æ•°</span></span><br><span class=\"line\">    W_xr, W_hr, b_r = three()  <span class=\"comment\"># é‡ç½®é—¨å‚æ•°</span></span><br><span class=\"line\">    W_xh, W_hh, b_h = three()  <span class=\"comment\"># å€™é€‰éšçŠ¶æ€å‚æ•°</span></span><br><span class=\"line\">    <span class=\"comment\"># è¾“å‡ºå±‚å‚æ•°</span></span><br><span class=\"line\">    W_hq = normal((num_hiddens, num_outputs))</span><br><span class=\"line\">    b_q = torch.zeros(num_outputs, device=device)</span><br><span class=\"line\">    <span class=\"comment\"># é™„åŠ æ¢¯åº¦</span></span><br><span class=\"line\">    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> params:</span><br><span class=\"line\">        param.requires_grad_(<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> params</span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æˆ‘ä»¬å°†å®šä¹‰éšçŠ¶æ€çš„åˆå§‹åŒ–å‡½æ•° <code>init_gru_state</code>ã€‚ä¸ä»é›¶å¼€å§‹å®ç° RNN ä¸­å®šä¹‰çš„ <code>init_rnn_state</code> å‡½æ•°ä¸€æ ·ï¼Œæ­¤å‡½æ•°è¿”å›ä¸€ä¸ªå½¢çŠ¶ä¸º <code>(æ‰¹é‡å¤§å°, éšè—å•å…ƒä¸ªæ•°)</code> çš„å¼ é‡ï¼Œå¼ é‡çš„å€¼å…¨éƒ¨ä¸ºé›¶ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_gru_state</span>(<span class=\"params\">batch_size, num_hiddens, device</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (torch.zeros((batch_size, num_hiddens), device=device),)</span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æˆ‘ä»¬å‡†å¤‡å®šä¹‰é—¨æ§å¾ªç¯å•å…ƒæ¨¡å‹ï¼Œæ¨¡å‹çš„æ¶æ„ä¸åŸºæœ¬çš„å¾ªç¯ç¥ç»ç½‘ç»œå•å…ƒæ˜¯ç›¸åŒçš„ï¼Œåªæ˜¯æƒé‡æ›´æ–°å…¬å¼æ›´ä¸ºå¤æ‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">gru</span>(<span class=\"params\">inputs, state, params</span>):</span><br><span class=\"line\">    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params</span><br><span class=\"line\">    H, = state</span><br><span class=\"line\">    outputs = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X <span class=\"keyword\">in</span> inputs:</span><br><span class=\"line\">        Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z)  <span class=\"comment\"># @ä¸ºçŸ©é˜µä¹˜æ³•ï¼Œç›¸å½“äºtorch.mm</span></span><br><span class=\"line\">        R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r)</span><br><span class=\"line\">        H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h)</span><br><span class=\"line\">        H = Z * H + (<span class=\"number\">1</span> - Z) * H_tilda</span><br><span class=\"line\">        Y = H @ W_hq + b_q</span><br><span class=\"line\">        outputs.append(Y)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.cat(outputs, dim=<span class=\"number\">0</span>), (H,)</span><br></pre></td></tr></table></figure>\n<p>è®­ç»ƒå’Œé¢„æµ‹çš„å·¥ä½œæ–¹å¼ä¸ä»é›¶å¼€å§‹å®ç° RNN å®Œå…¨ç›¸åŒã€‚è®­ç»ƒç»“æŸåï¼Œæˆ‘ä»¬åˆ†åˆ«æ‰“å°è¾“å‡ºè®­ç»ƒé›†çš„å›°æƒ‘åº¦ï¼Œä»¥åŠå‰ç¼€ <code>time traveler</code> å’Œ <code>traveler</code> çš„é¢„æµ‹åºåˆ—ä¸Šçš„å›°æƒ‘åº¦ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">num_hiddens, num_epochs, lr = <span class=\"number\">256</span>, <span class=\"number\">500</span>, <span class=\"number\">1</span></span><br><span class=\"line\">net = d2l.RNNModelScratch(<span class=\"built_in\">len</span>(vocab), num_hiddens, device, get_params, init_gru_state, gru)</span><br><span class=\"line\">train(net, train_iter, vocab, lr, num_epochs, device)  <span class=\"comment\"># ä¸ä»é›¶å¼€å§‹å®ç°RNNçš„trainå‡½æ•°ç›¸åŒï¼Œæ­¤å¤„ä¸å†å®ç°</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"1-2-é—¨æ§å¾ªç¯å•å…ƒçš„ç®€æ´å®ç°\">1.2 é—¨æ§å¾ªç¯å•å…ƒçš„ç®€æ´å®ç°</h3>\n<p>é«˜çº§ API åŒ…å«äº†å‰æ–‡ä»‹ç»çš„æ‰€æœ‰é…ç½®ç»†èŠ‚ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç›´æ¥å®ä¾‹åŒ–é—¨æ§å¾ªç¯å•å…ƒæ¨¡å‹ã€‚è¿™æ®µä»£ç çš„è¿è¡Œé€Ÿåº¦è¦å¿«å¾—å¤šï¼Œå› ä¸ºå®ƒä½¿ç”¨çš„æ˜¯ç¼–è¯‘å¥½çš„è¿ç®—ç¬¦è€Œä¸æ˜¯ Python æ¥å¤„ç†ä¹‹å‰é˜è¿°çš„è®¸å¤šç»†èŠ‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">RNNModel</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, rnn_layer, vocab_size, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(RNNModel, self).__init__(**kwargs)</span><br><span class=\"line\">        self.rnn = rnn_layer</span><br><span class=\"line\">        self.vocab_size = vocab_size</span><br><span class=\"line\">        self.num_hiddens = self.rnn.hidden_size</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.rnn.bidirectional:</span><br><span class=\"line\">            self.num_directions = <span class=\"number\">1</span></span><br><span class=\"line\">            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.num_directions = <span class=\"number\">2</span></span><br><span class=\"line\">            self.linear = nn.Linear(self.num_hiddens * <span class=\"number\">2</span>, self.vocab_size)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, inputs, state</span>):</span><br><span class=\"line\">        X = F.one_hot(inputs.T.long(), self.vocab_size)</span><br><span class=\"line\">        X = X.to(torch.float32)</span><br><span class=\"line\">        Y, state = self.rnn(X, state)</span><br><span class=\"line\">        output = self.linear(Y.reshape((-<span class=\"number\">1</span>, Y.shape[-<span class=\"number\">1</span>])))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output, state</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">begin_state</span>(<span class=\"params\">self, device, batch_size=<span class=\"number\">1</span></span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(self.rnn, nn.LSTM):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device),</span><br><span class=\"line\">                    torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device))</span><br><span class=\"line\"></span><br><span class=\"line\">gru_layer = nn.GRU(<span class=\"built_in\">len</span>(vocab), num_hiddens)</span><br><span class=\"line\">net = RNNModel(gru_layer, <span class=\"built_in\">len</span>(vocab))</span><br><span class=\"line\">net = net.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_epoch</span>(<span class=\"params\">net, train_iter, loss_function, optimizer, device, use_random_iter</span>):</span><br><span class=\"line\">    state = <span class=\"literal\">None</span></span><br><span class=\"line\">    train_loss = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, Y <span class=\"keyword\">in</span> tqdm(train_iter):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> state <span class=\"keyword\">is</span> <span class=\"literal\">None</span> <span class=\"keyword\">or</span> use_random_iter:</span><br><span class=\"line\">            state = net.begin_state(batch_size=X.shape[<span class=\"number\">0</span>], device=device)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, nn.Module) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(state, <span class=\"built_in\">tuple</span>):</span><br><span class=\"line\">                state.detach_()</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> state:</span><br><span class=\"line\">                    s.detach_()</span><br><span class=\"line\">        y = Y.T.reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\">        X, y = X.to(device), y.to(device)</span><br><span class=\"line\">        loss_function.to(device)</span><br><span class=\"line\">        y_hat, state = net(X, state)</span><br><span class=\"line\">        loss = loss_function(y_hat, y.long()).mean()</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        d2l.grad_clipping(net, <span class=\"number\">1</span>)</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">        train_loss.append(loss)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> math.exp(<span class=\"built_in\">sum</span>(train_loss) / <span class=\"built_in\">len</span>(train_loss))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_iter, vocab, lr, num_epochs, device, use_random_iter=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\">    loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">    optimizer = torch.optim.SGD(net.parameters(), lr)</span><br><span class=\"line\">    pred = <span class=\"keyword\">lambda</span> prefix: d2l.predict_ch8(prefix, <span class=\"number\">50</span>, net, vocab, device)</span><br><span class=\"line\"></span><br><span class=\"line\">    writer = SummaryWriter(<span class=\"string\">&#x27;../logs/GRU_train_log&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        ppl = train_epoch(net, train_iter, loss_function, optimizer, device, use_random_iter)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % <span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;time traveller&#x27;</span>))</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;Perplexity: <span class=\"subst\">&#123;ppl:<span class=\"number\">.1</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">            writer.add_scalar(<span class=\"string\">&#x27;train_loss&#x27;</span>, ppl, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;time traveller&#x27;</span>))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;traveller&#x27;</span>))</span><br><span class=\"line\">    writer.close()</span><br><span class=\"line\"></span><br><span class=\"line\">train(net, train_iter, vocab, lr, num_epochs, device)</span><br><span class=\"line\"><span class=\"comment\"># Perplexity: 1.0</span></span><br><span class=\"line\"><span class=\"comment\"># time travelleryou can show black is white by argument said filby</span></span><br><span class=\"line\"><span class=\"comment\"># travelleryou can show black is white by argument said filby</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"2-é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰\">2. é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰</h2>\n<p>é•¿æœŸä»¥æ¥ï¼Œéšå˜é‡æ¨¡å‹å­˜åœ¨ç€é•¿æœŸä¿¡æ¯ä¿å­˜å’ŒçŸ­æœŸè¾“å…¥ç¼ºå¤±çš„é—®é¢˜ã€‚è§£å†³è¿™ä¸€é—®é¢˜çš„æœ€æ—©æ–¹æ³•ä¹‹ä¸€æ˜¯é•¿çŸ­æœŸå­˜å‚¨å™¨ï¼ˆlong short-term memoryï¼ŒLSTMï¼‰ã€‚å®ƒæœ‰è®¸å¤šä¸é—¨æ§å¾ªç¯å•å…ƒä¸€æ ·çš„å±æ€§ã€‚</p>\n<p>å¯ä»¥è¯´ï¼Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„è®¾è®¡çµæ„Ÿæ¥è‡ªäºè®¡ç®—æœºçš„é€»è¾‘é—¨ã€‚é•¿çŸ­æœŸè®°å¿†ç½‘ç»œå¼•å…¥äº†è®°å¿†å…ƒï¼ˆmemory cellï¼‰ï¼Œæˆ–ç®€ç§°ä¸ºå•å…ƒï¼ˆcellï¼‰ã€‚æœ‰äº›æ–‡çŒ®è®¤ä¸ºè®°å¿†å…ƒæ˜¯éšçŠ¶æ€çš„ä¸€ç§ç‰¹æ®Šç±»å‹ï¼Œå®ƒä»¬ä¸éšçŠ¶æ€å…·æœ‰ç›¸åŒçš„å½¢çŠ¶ï¼Œå…¶è®¾è®¡ç›®çš„æ˜¯ç”¨äºè®°å½•é™„åŠ çš„ä¿¡æ¯ã€‚ä¸ºäº†æ§åˆ¶è®°å¿†å…ƒï¼Œæˆ‘ä»¬éœ€è¦è®¸å¤šé—¨ã€‚å…¶ä¸­ä¸€ä¸ªé—¨ç”¨æ¥ä»å•å…ƒä¸­è¾“å‡ºæ¡ç›®ï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸º<strong>è¾“å‡ºé—¨</strong>ï¼ˆoutput gateï¼‰ã€‚å¦å¤–ä¸€ä¸ªé—¨ç”¨æ¥å†³å®šä½•æ—¶å°†æ•°æ®è¯»å…¥å•å…ƒï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸º<strong>è¾“å…¥é—¨</strong>ï¼ˆinput gateï¼‰ã€‚æˆ‘ä»¬è¿˜éœ€è¦ä¸€ç§æœºåˆ¶æ¥é‡ç½®å•å…ƒçš„å†…å®¹ï¼Œç”±<strong>é—å¿˜é—¨</strong>ï¼ˆforget gateï¼‰æ¥ç®¡ç†ï¼Œè¿™ç§è®¾è®¡çš„åŠ¨æœºä¸é—¨æ§å¾ªç¯å•å…ƒç›¸åŒï¼Œèƒ½å¤Ÿé€šè¿‡ä¸“ç”¨æœºåˆ¶å†³å®šä»€ä¹ˆæ—¶å€™è®°å¿†æˆ–å¿½ç•¥éšçŠ¶æ€ä¸­çš„è¾“å…¥ã€‚</p>\n<p>é•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„æ•°å­¦è¡¨è¾¾è¯¦è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-modern/lstm.html\">é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰</a>ã€‚</p>\n<h3 id=\"2-1-é•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„ä»é›¶å¼€å§‹å®ç°\">2.1 é•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„ä»é›¶å¼€å§‹å®ç°</h3>\n<p>ç°åœ¨ï¼Œæˆ‘ä»¬ä»é›¶å¼€å§‹å®ç°é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼Œæˆ‘ä»¬é¦–å…ˆåŠ è½½æ—¶å…‰æœºå™¨æ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size, num_steps = <span class=\"number\">32</span>, <span class=\"number\">35</span></span><br><span class=\"line\">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰å’Œåˆå§‹åŒ–æ¨¡å‹å‚æ•°ã€‚å¦‚å‰æ‰€è¿°ï¼Œè¶…å‚æ•° <code>num_hiddens</code> å®šä¹‰éšè—å•å…ƒçš„æ•°é‡ã€‚æˆ‘ä»¬æŒ‰ç…§æ ‡å‡†å·®0.01çš„é«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ–æƒé‡ï¼Œå¹¶å°†åç½®é¡¹è®¾ä¸º0ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_lstm_params</span>(<span class=\"params\">vocab_size, num_hiddens, device</span>):</span><br><span class=\"line\">    num_inputs = num_outputs = vocab_size</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">normal</span>(<span class=\"params\">shape</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.randn(size=shape, device=device) * <span class=\"number\">0.01</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">three</span>():</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device))</span><br><span class=\"line\"></span><br><span class=\"line\">    W_xi, W_hi, b_i = three()  <span class=\"comment\"># è¾“å…¥é—¨å‚æ•°</span></span><br><span class=\"line\">    W_xf, W_hf, b_f = three()  <span class=\"comment\"># é—å¿˜é—¨å‚æ•°</span></span><br><span class=\"line\">    W_xo, W_ho, b_o = three()  <span class=\"comment\"># è¾“å‡ºé—¨å‚æ•°</span></span><br><span class=\"line\">    W_xc, W_hc, b_c = three()  <span class=\"comment\"># å€™é€‰è®°å¿†å…ƒå‚æ•°</span></span><br><span class=\"line\">    <span class=\"comment\"># è¾“å‡ºå±‚å‚æ•°</span></span><br><span class=\"line\">    W_hq = normal((num_hiddens, num_outputs))</span><br><span class=\"line\">    b_q = torch.zeros(num_outputs, device=device)</span><br><span class=\"line\">    <span class=\"comment\"># é™„åŠ æ¢¯åº¦</span></span><br><span class=\"line\">    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> params:</span><br><span class=\"line\">        param.requires_grad_(<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> params</span><br></pre></td></tr></table></figure>\n<p>åœ¨åˆå§‹åŒ–å‡½æ•°ä¸­ï¼Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„éšçŠ¶æ€éœ€è¦è¿”å›ä¸€ä¸ªé¢å¤–çš„è®°å¿†å…ƒï¼Œå•å…ƒçš„å€¼ä¸º0ï¼Œå½¢çŠ¶ä¸º <code>(æ‰¹é‡å¤§å°, éšè—å•å…ƒæ•°)</code>ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹çš„çŠ¶æ€åˆå§‹åŒ–ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_lstm_state</span>(<span class=\"params\">batch_size, num_hiddens, device</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (torch.zeros((batch_size, num_hiddens), device=device),</span><br><span class=\"line\">            torch.zeros((batch_size, num_hiddens), device=device))</span><br></pre></td></tr></table></figure>\n<p>å®é™…æ¨¡å‹çš„å®šä¹‰ä¸æˆ‘ä»¬å‰é¢è®¨è®ºçš„ä¸€æ ·ï¼šæä¾›ä¸‰ä¸ªé—¨å’Œä¸€ä¸ªé¢å¤–çš„è®°å¿†å…ƒã€‚è¯·æ³¨æ„ï¼Œåªæœ‰éšçŠ¶æ€ <code>H</code> æ‰ä¼šä¼ é€’åˆ°è¾“å‡ºå±‚ï¼Œè€Œè®°å¿†å…ƒ <code>C</code> ä¸ç›´æ¥å‚ä¸è¾“å‡ºè®¡ç®—ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">lstm</span>(<span class=\"params\">inputs, state, params</span>):</span><br><span class=\"line\">    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] = params</span><br><span class=\"line\">    (H, C) = state</span><br><span class=\"line\">    outputs = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X <span class=\"keyword\">in</span> inputs:</span><br><span class=\"line\">        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)</span><br><span class=\"line\">        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)</span><br><span class=\"line\">        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)</span><br><span class=\"line\">        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)</span><br><span class=\"line\">        C = F * C + I * C_tilda</span><br><span class=\"line\">        H = O * torch.tanh(C)</span><br><span class=\"line\">        Y = (H @ W_hq) + b_q</span><br><span class=\"line\">        outputs.append(Y)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.cat(outputs, dim=<span class=\"number\">0</span>), (H, C)</span><br></pre></td></tr></table></figure>\n<p>è®©æˆ‘ä»¬é€šè¿‡å®ä¾‹åŒ–ä»é›¶å®ç° RNN ç« èŠ‚ä¸­å¼•å…¥çš„ <code>RNNModelScratch</code> ç±»æ¥è®­ç»ƒä¸€ä¸ªé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼Œå°±å¦‚æˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚ä¸­æ‰€åšçš„ä¸€æ ·ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">num_hiddens, num_epochs, lr = <span class=\"number\">256</span>, <span class=\"number\">500</span>, <span class=\"number\">1</span></span><br><span class=\"line\">net = d2l.RNNModelScratch(<span class=\"built_in\">len</span>(vocab), num_hiddens, device, get_lstm_params, init_lstm_state, lstm)</span><br><span class=\"line\">train(net, train_iter, vocab, lr, num_epochs, device)  <span class=\"comment\"># ä¸ä»é›¶å¼€å§‹å®ç°RNNçš„trainå‡½æ•°ç›¸åŒï¼Œæ­¤å¤„ä¸å†å®ç°</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-é•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„ç®€æ´å®ç°\">2.2 é•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„ç®€æ´å®ç°</h3>\n<p>ä½¿ç”¨é«˜çº§ APIï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥å®ä¾‹åŒ– LSTM æ¨¡å‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">RNNModel</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, rnn_layer, vocab_size, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(RNNModel, self).__init__(**kwargs)</span><br><span class=\"line\">        self.rnn = rnn_layer</span><br><span class=\"line\">        self.vocab_size = vocab_size</span><br><span class=\"line\">        self.num_hiddens = self.rnn.hidden_size</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.rnn.bidirectional:</span><br><span class=\"line\">            self.num_directions = <span class=\"number\">1</span></span><br><span class=\"line\">            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.num_directions = <span class=\"number\">2</span></span><br><span class=\"line\">            self.linear = nn.Linear(self.num_hiddens * <span class=\"number\">2</span>, self.vocab_size)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, inputs, state</span>):</span><br><span class=\"line\">        X = F.one_hot(inputs.T.long(), self.vocab_size)</span><br><span class=\"line\">        X = X.to(torch.float32)</span><br><span class=\"line\">        Y, state = self.rnn(X, state)</span><br><span class=\"line\">        output = self.linear(Y.reshape((-<span class=\"number\">1</span>, Y.shape[-<span class=\"number\">1</span>])))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output, state</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">begin_state</span>(<span class=\"params\">self, device, batch_size=<span class=\"number\">1</span></span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(self.rnn, nn.LSTM):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> (torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device),</span><br><span class=\"line\">                    torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device))</span><br><span class=\"line\"></span><br><span class=\"line\">lstm_layer = nn.LSTM(<span class=\"built_in\">len</span>(vocab), num_hiddens)</span><br><span class=\"line\">net = RNNModel(lstm_layer, <span class=\"built_in\">len</span>(vocab))</span><br><span class=\"line\">net = net.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_epoch</span>(<span class=\"params\">net, train_iter, loss_function, optimizer, device, use_random_iter</span>):</span><br><span class=\"line\">    state = <span class=\"literal\">None</span></span><br><span class=\"line\">    train_loss = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, Y <span class=\"keyword\">in</span> tqdm(train_iter):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> state <span class=\"keyword\">is</span> <span class=\"literal\">None</span> <span class=\"keyword\">or</span> use_random_iter:</span><br><span class=\"line\">            state = net.begin_state(batch_size=X.shape[<span class=\"number\">0</span>], device=device)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, nn.Module) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(state, <span class=\"built_in\">tuple</span>):</span><br><span class=\"line\">                state.detach_()</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> state:</span><br><span class=\"line\">                    s.detach_()</span><br><span class=\"line\">        y = Y.T.reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\">        X, y = X.to(device), y.to(device)</span><br><span class=\"line\">        loss_function.to(device)</span><br><span class=\"line\">        y_hat, state = net(X, state)</span><br><span class=\"line\">        loss = loss_function(y_hat, y.long()).mean()</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        d2l.grad_clipping(net, <span class=\"number\">1</span>)</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">        train_loss.append(loss)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> math.exp(<span class=\"built_in\">sum</span>(train_loss) / <span class=\"built_in\">len</span>(train_loss))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_iter, vocab, lr, num_epochs, device, use_random_iter=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\">    loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">    optimizer = torch.optim.SGD(net.parameters(), lr)</span><br><span class=\"line\">    pred = <span class=\"keyword\">lambda</span> prefix: d2l.predict_ch8(prefix, <span class=\"number\">50</span>, net, vocab, device)</span><br><span class=\"line\"></span><br><span class=\"line\">    writer = SummaryWriter(<span class=\"string\">&#x27;../logs/LSTM_train_log&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        ppl = train_epoch(net, train_iter, loss_function, optimizer, device, use_random_iter)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % <span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;time traveller&#x27;</span>))</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;Perplexity: <span class=\"subst\">&#123;ppl:<span class=\"number\">.1</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">            writer.add_scalar(<span class=\"string\">&#x27;train_loss&#x27;</span>, ppl, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;time traveller&#x27;</span>))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;traveller&#x27;</span>))</span><br><span class=\"line\">    writer.close()</span><br><span class=\"line\"></span><br><span class=\"line\">train(net, train_iter, vocab, lr, num_epochs, device)</span><br><span class=\"line\"><span class=\"comment\"># Perplexity: 1.0</span></span><br><span class=\"line\"><span class=\"comment\"># time traveller for so it will be convenient to speak of himwas e</span></span><br><span class=\"line\"><span class=\"comment\"># travelleryou can show black is white by argument said filby</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"3-æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œ\">3. æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œ</h2>\n<p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬åªè®¨è®ºäº†å…·æœ‰ä¸€ä¸ªå•å‘éšè—å±‚çš„å¾ªç¯ç¥ç»ç½‘ç»œã€‚å…¶ä¸­ï¼Œéšå˜é‡å’Œè§‚æµ‹å€¼ä¸å…·ä½“çš„å‡½æ•°å½¢å¼çš„äº¤äº’æ–¹å¼æ˜¯ç›¸å½“éšæ„çš„ã€‚åªè¦äº¤äº’ç±»å‹å»ºæ¨¡å…·æœ‰è¶³å¤Ÿçš„çµæ´»æ€§ï¼Œè¿™å°±ä¸æ˜¯ä¸€ä¸ªå¤§é—®é¢˜ã€‚ç„¶è€Œï¼Œå¯¹ä¸€ä¸ªå•å±‚æ¥è¯´ï¼Œè¿™å¯èƒ½å…·æœ‰ç›¸å½“çš„æŒ‘æˆ˜æ€§ã€‚ä¹‹å‰åœ¨çº¿æ€§æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ·»åŠ æ›´å¤šçš„å±‚æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è€Œåœ¨å¾ªç¯ç¥ç»ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦ç¡®å®šå¦‚ä½•æ·»åŠ æ›´å¤šçš„å±‚ï¼Œä»¥åŠåœ¨å“ªé‡Œæ·»åŠ é¢å¤–çš„éçº¿æ€§ï¼Œå› æ­¤è¿™ä¸ªé—®é¢˜æœ‰ç‚¹æ£˜æ‰‹ã€‚</p>\n<p>äº‹å®ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å°†å¤šå±‚å¾ªç¯ç¥ç»ç½‘ç»œå †å åœ¨ä¸€èµ·ï¼Œé€šè¿‡å¯¹å‡ ä¸ªç®€å•å±‚çš„ç»„åˆï¼Œäº§ç”Ÿäº†ä¸€ä¸ªçµæ´»çš„æœºåˆ¶ã€‚ç‰¹åˆ«æ˜¯ï¼Œæ•°æ®å¯èƒ½ä¸ä¸åŒå±‚çš„å †å æœ‰å…³ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›ä¿æŒæœ‰å…³é‡‘èå¸‚åœºçŠ¶å†µï¼ˆç†Šå¸‚æˆ–ç‰›å¸‚ï¼‰çš„å®è§‚æ•°æ®å¯ç”¨ï¼Œè€Œå¾®è§‚æ•°æ®åªè®°å½•è¾ƒçŸ­æœŸçš„æ—¶é—´åŠ¨æ€ã€‚</p>\n<p>æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œçš„æ•°å­¦è¡¨è¾¾è¯¦è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-modern/deep-rnn.html\">æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œ</a>ã€‚</p>\n<p>å®ç°å¤šå±‚å¾ªç¯ç¥ç»ç½‘ç»œæ‰€éœ€çš„è®¸å¤šé€»è¾‘ç»†èŠ‚åœ¨é«˜çº§ API ä¸­éƒ½æ˜¯ç°æˆçš„ã€‚ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ä»…ç¤ºèŒƒä½¿ç”¨æ­¤ç±»å†…ç½®å‡½æ•°çš„å®ç°æ–¹å¼ã€‚ä»¥é•¿çŸ­æœŸè®°å¿†ç½‘ç»œæ¨¡å‹ä¸ºä¾‹ï¼Œè¯¥ä»£ç ä¸ä¸Šä¸€èŠ‚ä¸­ä½¿ç”¨çš„ä»£ç éå¸¸ç›¸ä¼¼ï¼Œå®é™…ä¸Šå”¯ä¸€çš„åŒºåˆ«æ˜¯æˆ‘ä»¬æŒ‡å®šäº†å±‚çš„æ•°é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å•ä¸€å±‚è¿™ä¸ªé»˜è®¤å€¼ã€‚åƒå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘ä»¬ä»åŠ è½½æ•°æ®é›†å¼€å§‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size, num_steps = <span class=\"number\">32</span>, <span class=\"number\">35</span></span><br><span class=\"line\">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br></pre></td></tr></table></figure>\n<p>åƒé€‰æ‹©è¶…å‚æ•°è¿™ç±»æ¶æ„å†³ç­–ä¹Ÿè·Ÿä¸Šä¸€èŠ‚ä¸­çš„å†³ç­–éå¸¸ç›¸ä¼¼ã€‚å› ä¸ºæˆ‘ä»¬æœ‰ä¸åŒçš„è¯å…ƒï¼Œæ‰€ä»¥è¾“å…¥å’Œè¾“å‡ºéƒ½é€‰æ‹©ç›¸åŒæ•°é‡ï¼Œå³ <code>vocab_size</code>ã€‚éšè—å•å…ƒçš„æ•°é‡ä»ç„¶æ˜¯256ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯ï¼Œæˆ‘ä»¬ç°åœ¨é€šè¿‡ <code>num_layers</code> çš„å€¼æ¥è®¾å®šéšè—å±‚æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">num_inputs, num_hiddens, num_layers = <span class=\"built_in\">len</span>(vocab), <span class=\"number\">256</span>, <span class=\"number\">2</span></span><br><span class=\"line\">lstm_layer = nn.LSTM(input_size=num_inputs, hidden_size=num_hiddens, num_layers=num_layers)</span><br><span class=\"line\">net = d2l.RNNModel(lstm_layer, <span class=\"built_in\">len</span>(vocab))  <span class=\"comment\"># åŒä¸ŠèŠ‚çš„RNNModel</span></span><br><span class=\"line\">net = net.to(device)</span><br></pre></td></tr></table></figure>\n<p>æœ€åå’Œä¸Šä¸€èŠ‚ä¸€æ ·è®­ç»ƒæ¨¡å‹çœ‹çœ‹æ•ˆæœï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_epochs, lr = <span class=\"number\">500</span>, <span class=\"number\">2</span></span><br><span class=\"line\">train(net, train_iter, vocab, lr * <span class=\"number\">1.0</span>, num_epochs, device)  <span class=\"comment\"># åŒä¸ŠèŠ‚çš„train</span></span><br><span class=\"line\"><span class=\"comment\"># Perplexity: 1.0</span></span><br><span class=\"line\"><span class=\"comment\"># time traveller for so it will be convenient to speak of himwas e</span></span><br><span class=\"line\"><span class=\"comment\"># traveller with a slight accession ofcheerfulness really thi</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"4-åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ\">4. åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ</h2>\n<p>åœ¨åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œä¸­ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„éšçŠ¶æ€ç”±å½“å‰æ—¶é—´æ­¥çš„å‰åæ•°æ®åŒæ—¶å†³å®šï¼Œé€šè¿‡åå‘æ›´æ–°çš„éšè—å±‚æ¥åˆ©ç”¨åå‘æ—¶é—´ä¿¡æ¯ï¼Œé€šå¸¸ç”¨æ¥å¯¹åºåˆ—æŠ½å–ç‰¹å¾ã€å¡«ç©ºï¼Œè€Œ<strong>ä¸æ˜¯é¢„æµ‹æœªæ¥</strong>ã€‚</p>\n<p>åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œçš„æ•°å­¦è¡¨è¾¾è¯¦è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-modern/bi-rnn.html\">åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ</a>ã€‚</p>\n<p>ç”±äºåŒå‘å¾ªç¯ç¥ç»ç½‘ç»œä½¿ç”¨äº†è¿‡å»çš„å’Œæœªæ¥çš„æ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸èƒ½ç›²ç›®åœ°å°†è¿™ä¸€è¯­è¨€æ¨¡å‹åº”ç”¨äºä»»ä½•é¢„æµ‹ä»»åŠ¡ã€‚å°½ç®¡æ¨¡å‹äº§å‡ºçš„å›°æƒ‘åº¦æ˜¯åˆç†çš„ï¼Œè¯¥æ¨¡å‹é¢„æµ‹æœªæ¥è¯å…ƒçš„èƒ½åŠ›å´å¯èƒ½å­˜åœ¨ä¸¥é‡ç¼ºé™·ã€‚æˆ‘ä»¬ç”¨ä¸‹é¢çš„ç¤ºä¾‹ä»£ç å¼•ä»¥ä¸ºæˆ’ï¼Œä»¥é˜²åœ¨é”™è¯¯çš„ç¯å¢ƒä¸­ä½¿ç”¨å®ƒä»¬ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># åŠ è½½æ•°æ®</span></span><br><span class=\"line\">batch_size, num_steps = <span class=\"number\">32</span>, <span class=\"number\">35</span></span><br><span class=\"line\">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># é€šè¿‡è®¾ç½®â€œbidirective=Trueâ€æ¥å®šä¹‰åŒå‘LSTMæ¨¡å‹</span></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">num_inputs, num_hiddens, num_layers = <span class=\"built_in\">len</span>(vocab), <span class=\"number\">256</span>, <span class=\"number\">2</span></span><br><span class=\"line\">lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers, bidirectional=<span class=\"literal\">True</span>)</span><br><span class=\"line\">net = d2l.RNNModel(lstm_layer, <span class=\"built_in\">len</span>(vocab))</span><br><span class=\"line\">net = net.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è®­ç»ƒæ¨¡å‹</span></span><br><span class=\"line\">num_epochs, lr = <span class=\"number\">500</span>, <span class=\"number\">1</span></span><br><span class=\"line\">train(net, train_iter, vocab, lr, num_epochs, device)</span><br><span class=\"line\"><span class=\"comment\"># Perplexity: 1.1</span></span><br><span class=\"line\"><span class=\"comment\"># time travellerererererererererererererererererererererererererer</span></span><br><span class=\"line\"><span class=\"comment\"># travellerererererererererererererererererererererererererer</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"5-æœºå™¨ç¿»è¯‘ä¸æ•°æ®é›†\">5. æœºå™¨ç¿»è¯‘ä¸æ•°æ®é›†</h2>\n<p>è¯­è¨€æ¨¡å‹æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†çš„å…³é”®ï¼Œè€Œæœºå™¨ç¿»è¯‘æ˜¯è¯­è¨€æ¨¡å‹æœ€æˆåŠŸçš„åŸºå‡†æµ‹è¯•ã€‚å› ä¸ºæœºå™¨ç¿»è¯‘æ­£æ˜¯å°†è¾“å…¥åºåˆ—è½¬æ¢æˆè¾“å‡ºåºåˆ—çš„<strong>åºåˆ—è½¬æ¢æ¨¡å‹</strong>ï¼ˆsequence transductionï¼‰çš„æ ¸å¿ƒé—®é¢˜ã€‚</p>\n<p>ä¸è¯­è¨€æ¨¡å‹é‚£ä¸€èŠ‚ä¸­çš„è¯­æ–™åº“æ˜¯å•ä¸€è¯­è¨€çš„è¯­è¨€æ¨¡å‹é—®é¢˜å­˜åœ¨ä¸åŒï¼Œæœºå™¨ç¿»è¯‘çš„æ•°æ®é›†æ˜¯ç”±æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€çš„æ–‡æœ¬åºåˆ—å¯¹ç»„æˆçš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§å®Œå…¨ä¸åŒçš„æ–¹æ³•æ¥é¢„å¤„ç†æœºå™¨ç¿»è¯‘æ•°æ®é›†ï¼Œè€Œä¸æ˜¯å¤ç”¨è¯­è¨€æ¨¡å‹çš„é¢„å¤„ç†ç¨‹åºã€‚</p>\n<p>é¦–å…ˆï¼Œä¸‹è½½ä¸€ä¸ªç”±åŒè¯­å¥å­å¯¹ç»„æˆçš„â€œè‹±-æ³•â€æ•°æ®é›†ï¼Œæ•°æ®é›†ä¸­çš„æ¯ä¸€è¡Œéƒ½æ˜¯åˆ¶è¡¨ç¬¦åˆ†éš”çš„æ–‡æœ¬åºåˆ—å¯¹ï¼Œåºåˆ—å¯¹ç”±è‹±æ–‡æ–‡æœ¬åºåˆ—å’Œç¿»è¯‘åçš„æ³•è¯­æ–‡æœ¬åºåˆ—ç»„æˆã€‚è¯·æ³¨æ„ï¼Œæ¯ä¸ªæ–‡æœ¬åºåˆ—å¯ä»¥æ˜¯ä¸€ä¸ªå¥å­ï¼Œä¹Ÿå¯ä»¥æ˜¯åŒ…å«å¤šä¸ªå¥å­çš„ä¸€ä¸ªæ®µè½ã€‚åœ¨è¿™ä¸ªå°†è‹±è¯­ç¿»è¯‘æˆæ³•è¯­çš„æœºå™¨ç¿»è¯‘é—®é¢˜ä¸­ï¼Œè‹±è¯­æ˜¯æºè¯­è¨€ï¼ˆsource languageï¼‰ï¼Œæ³•è¯­æ˜¯ç›®æ ‡è¯­è¨€ï¼ˆtarget languageï¼‰ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">d2l.DATA_HUB[<span class=\"string\">&#x27;fra-eng&#x27;</span>] = (d2l.DATA_URL + <span class=\"string\">&#x27;fra-eng.zip&#x27;</span>, <span class=\"string\">&#x27;94646ad1522d915e7b0f9296181140edcf86a4f5&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">read_data_nmt</span>():</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è½½å…¥â€œè‹±è¯­-æ³•è¯­â€æ•°æ®é›†&quot;&quot;&quot;</span></span><br><span class=\"line\">    data_dir = d2l.download_extract(<span class=\"string\">&#x27;fra-eng&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(os.path.join(data_dir, <span class=\"string\">&#x27;fra.txt&#x27;</span>), <span class=\"string\">&#x27;r&#x27;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> f.read()</span><br><span class=\"line\"></span><br><span class=\"line\">raw_text = read_data_nmt()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(raw_text[:<span class=\"number\">75</span>])</span><br><span class=\"line\"><span class=\"comment\"># Go.    Va !</span></span><br><span class=\"line\"><span class=\"comment\"># Hi.    Salut !</span></span><br><span class=\"line\"><span class=\"comment\"># Run!    Cours !</span></span><br><span class=\"line\"><span class=\"comment\"># Run!    Courez !</span></span><br><span class=\"line\"><span class=\"comment\"># Who?    Qui ?</span></span><br><span class=\"line\"><span class=\"comment\"># Wow!    Ã‡a alors !</span></span><br></pre></td></tr></table></figure>\n<p>ä¸‹è½½æ•°æ®é›†åï¼ŒåŸå§‹æ–‡æœ¬æ•°æ®éœ€è¦ç»è¿‡å‡ ä¸ªé¢„å¤„ç†æ­¥éª¤ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ç”¨ç©ºæ ¼ä»£æ›¿ä¸é—´æ–­ç©ºæ ¼ï¼ˆnon-breaking spaceï¼‰ï¼Œä½¿ç”¨å°å†™å­—æ¯æ›¿æ¢å¤§å†™å­—æ¯ï¼Œå¹¶åœ¨å•è¯å’Œæ ‡ç‚¹ç¬¦å·ä¹‹é—´æ’å…¥ç©ºæ ¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">preprocess_nmt</span>(<span class=\"params\">text</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;é¢„å¤„ç†â€œè‹±è¯­-æ³•è¯­â€æ•°æ®é›†&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">no_space</span>(<span class=\"params\">char, prev_char</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> char <span class=\"keyword\">in</span> <span class=\"built_in\">set</span>(<span class=\"string\">&#x27;,.!?&#x27;</span>) <span class=\"keyword\">and</span> prev_char != <span class=\"string\">&#x27; &#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># ä½¿ç”¨ç©ºæ ¼æ›¿æ¢ä¸é—´æ–­ç©ºæ ¼ï¼Œä½¿ç”¨å°å†™å­—æ¯æ›¿æ¢å¤§å†™å­—æ¯</span></span><br><span class=\"line\">    text = text.replace(<span class=\"string\">&#x27;\\u202f&#x27;</span>, <span class=\"string\">&#x27; &#x27;</span>).replace(<span class=\"string\">&#x27;\\xa0&#x27;</span>, <span class=\"string\">&#x27; &#x27;</span>).lower()</span><br><span class=\"line\">    <span class=\"comment\"># åœ¨å•è¯å’Œæ ‡ç‚¹ç¬¦å·ä¹‹é—´æ’å…¥ç©ºæ ¼</span></span><br><span class=\"line\">    out = [<span class=\"string\">&#x27; &#x27;</span> + char <span class=\"keyword\">if</span> i &gt; <span class=\"number\">0</span> <span class=\"keyword\">and</span> no_space(char, text[i - <span class=\"number\">1</span>]) <span class=\"keyword\">else</span> char <span class=\"keyword\">for</span> i, char <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(text)]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">&#x27;&#x27;</span>.join(out)</span><br><span class=\"line\"></span><br><span class=\"line\">text = preprocess_nmt(raw_text)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(text[:<span class=\"number\">80</span>])</span><br><span class=\"line\"><span class=\"comment\"># go .    va !</span></span><br><span class=\"line\"><span class=\"comment\"># hi .    salut !</span></span><br><span class=\"line\"><span class=\"comment\"># run !    cours !</span></span><br><span class=\"line\"><span class=\"comment\"># run !    courez !</span></span><br><span class=\"line\"><span class=\"comment\"># who ?    qui ?</span></span><br><span class=\"line\"><span class=\"comment\"># wow !    Ã§a alors !</span></span><br></pre></td></tr></table></figure>\n<p>ä¸ä¹‹å‰çš„å­—ç¬¦çº§è¯å…ƒåŒ–ä¸åŒï¼Œåœ¨æœºå™¨ç¿»è¯‘ä¸­ï¼Œæˆ‘ä»¬æ›´å–œæ¬¢å•è¯çº§è¯å…ƒåŒ–ï¼ˆæœ€å…ˆè¿›çš„æ¨¡å‹å¯èƒ½ä½¿ç”¨æ›´é«˜çº§çš„è¯å…ƒåŒ–æŠ€æœ¯ï¼‰ã€‚ä¸‹é¢çš„ <code>tokenize_nmt</code> å‡½æ•°å¯¹å‰ <code>num_examples</code> ä¸ªæ–‡æœ¬åºåˆ—å¯¹è¿›è¡Œè¯å…ƒåŒ–ï¼Œå…¶ä¸­æ¯ä¸ªè¯å…ƒè¦ä¹ˆæ˜¯ä¸€ä¸ªè¯ï¼Œè¦ä¹ˆæ˜¯ä¸€ä¸ªæ ‡ç‚¹ç¬¦å·ã€‚æ­¤å‡½æ•°è¿”å›ä¸¤ä¸ªè¯å…ƒåˆ—è¡¨ï¼š<code>source</code> å’Œ <code>target</code>ï¼Œ<code>source[i]</code> æ˜¯æºè¯­è¨€ï¼ˆè¿™é‡Œæ˜¯è‹±è¯­ï¼‰ç¬¬ <code>i</code> ä¸ªæ–‡æœ¬åºåˆ—çš„è¯å…ƒåˆ—è¡¨ï¼Œ<code>target[i]</code> æ˜¯ç›®æ ‡è¯­è¨€ï¼ˆè¿™é‡Œæ˜¯æ³•è¯­ï¼‰ç¬¬ <code>i</code> ä¸ªæ–‡æœ¬åºåˆ—çš„è¯å…ƒåˆ—è¡¨ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">tokenize_nmt</span>(<span class=\"params\">text, num_examples=<span class=\"literal\">None</span></span>):  <span class=\"comment\"># num_examplesé™åˆ¶æ•°æ®é›†çš„æ•°é‡</span></span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è¯å…ƒåŒ–â€œè‹±è¯­-æ³•è¯­â€æ•°æ®é›†&quot;&quot;&quot;</span></span><br><span class=\"line\">    source, target = [], []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, line <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(text.split(<span class=\"string\">&#x27;\\n&#x27;</span>)):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> num_examples <span class=\"keyword\">and</span> i &gt; num_examples:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        parts = line.split(<span class=\"string\">&#x27;\\t&#x27;</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(parts) == <span class=\"number\">2</span>:</span><br><span class=\"line\">            source.append(parts[<span class=\"number\">0</span>].split(<span class=\"string\">&#x27; &#x27;</span>))</span><br><span class=\"line\">            target.append(parts[<span class=\"number\">1</span>].split(<span class=\"string\">&#x27; &#x27;</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> source, target</span><br><span class=\"line\"></span><br><span class=\"line\">source, target = tokenize_nmt(text)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(source[:<span class=\"number\">3</span>], target[:<span class=\"number\">3</span>])  <span class=\"comment\"># [[&#x27;go&#x27;, &#x27;.&#x27;], [&#x27;hi&#x27;, &#x27;.&#x27;], [&#x27;run&#x27;, &#x27;!&#x27;]] [[&#x27;va&#x27;, &#x27;!&#x27;], [&#x27;salut&#x27;, &#x27;!&#x27;], [&#x27;cours&#x27;, &#x27;!&#x27;]]</span></span><br></pre></td></tr></table></figure>\n<p>è®©æˆ‘ä»¬ç»˜åˆ¶æ¯ä¸ªæ–‡æœ¬åºåˆ—æ‰€åŒ…å«çš„è¯å…ƒæ•°é‡çš„ç›´æ–¹å›¾ã€‚åœ¨è¿™ä¸ªç®€å•çš„â€œè‹±-æ³•â€æ•°æ®é›†ä¸­ï¼Œå¤§å¤šæ•°æ–‡æœ¬åºåˆ—çš„è¯å…ƒæ•°é‡å°‘äº20ä¸ªï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">show_list_len_pair_hist</span>(<span class=\"params\">legend, title, xlabel, ylabel, xlist, ylist</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ç»˜åˆ¶åˆ—è¡¨é•¿åº¦å¯¹çš„ç›´æ–¹å›¾&quot;&quot;&quot;</span></span><br><span class=\"line\">    plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>), dpi=<span class=\"number\">150</span>)</span><br><span class=\"line\">    _, _, patches = plt.hist([[<span class=\"built_in\">len</span>(l) <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> xlist], [<span class=\"built_in\">len</span>(l) <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> ylist]], edgecolor=<span class=\"string\">&#x27;r&#x27;</span>, alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">    plt.title(title)</span><br><span class=\"line\">    plt.xlabel(xlabel)</span><br><span class=\"line\">    plt.ylabel(ylabel)</span><br><span class=\"line\">    plt.legend(legend)</span><br><span class=\"line\">    <span class=\"comment\"># for patch in patches[1].patches:</span></span><br><span class=\"line\">    <span class=\"comment\">#     patch.set_hatch(&#x27;/&#x27;)  # ç»™ç¬¬äºŒä¸ªlistå¯¹çš„æ¡å½¢è®¾ç½®å¡«å……æ•ˆæœ</span></span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">show_list_len_pair_hist([<span class=\"string\">&#x27;source&#x27;</span>, <span class=\"string\">&#x27;target&#x27;</span>], <span class=\"string\">&#x27;The length of list&#x27;</span>, <span class=\"string\">&#x27;# tokens per sequence&#x27;</span>, <span class=\"string\">&#x27;count&#x27;</span>, source, target)</span><br></pre></td></tr></table></figure>\n<p>ç”±äºæœºå™¨ç¿»è¯‘æ•°æ®é›†ç”±è¯­è¨€å¯¹ç»„æˆï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥åˆ†åˆ«ä¸ºæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€æ„å»ºä¸¤ä¸ªè¯è¡¨ã€‚ä½¿ç”¨å•è¯çº§è¯å…ƒåŒ–æ—¶ï¼Œè¯è¡¨å¤§å°å°†æ˜æ˜¾å¤§äºä½¿ç”¨å­—ç¬¦çº§è¯å…ƒåŒ–æ—¶çš„è¯è¡¨å¤§å°ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œè¿™é‡Œæˆ‘ä»¬å°†å‡ºç°æ¬¡æ•°å°‘äº2æ¬¡çš„ä½é¢‘ç‡è¯å…ƒè§†ä¸ºç›¸åŒçš„æœªçŸ¥ï¼ˆ<code>&lt;unk&gt;</code>ï¼‰è¯å…ƒã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜æŒ‡å®šäº†é¢å¤–çš„ç‰¹å®šè¯å…ƒï¼Œä¾‹å¦‚åœ¨å°æ‰¹é‡æ—¶ç”¨äºå°†åºåˆ—å¡«å……åˆ°ç›¸åŒé•¿åº¦çš„å¡«å……è¯å…ƒï¼ˆ<code>&lt;pad&gt;</code>ï¼‰ï¼Œä»¥åŠåºåˆ—çš„å¼€å§‹è¯å…ƒï¼ˆ<code>&lt;bos&gt;</code>ï¼‰å’Œç»“æŸè¯å…ƒï¼ˆ<code>&lt;eos&gt;</code>ï¼‰ã€‚è¿™äº›ç‰¹æ®Šè¯å…ƒåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­æ¯”è¾ƒå¸¸ç”¨ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">src_vocab = d2l.Vocab(source, min_freq=<span class=\"number\">2</span>, reserved_tokens=[<span class=\"string\">&#x27;&lt;pad&gt;&#x27;</span>, <span class=\"string\">&#x27;&lt;bos&gt;&#x27;</span>, <span class=\"string\">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(src_vocab))  <span class=\"comment\"># 10012</span></span><br></pre></td></tr></table></figure>\n<p>å›æƒ³ä¸€ä¸‹ï¼Œè¯­è¨€æ¨¡å‹ä¸­çš„åºåˆ—æ ·æœ¬éƒ½æœ‰ä¸€ä¸ªå›ºå®šçš„é•¿åº¦ï¼Œæ— è®ºè¿™ä¸ªæ ·æœ¬æ˜¯ä¸€ä¸ªå¥å­çš„ä¸€éƒ¨åˆ†è¿˜æ˜¯è·¨è¶Šäº†å¤šä¸ªå¥å­çš„ä¸€ä¸ªç‰‡æ–­ã€‚è¿™ä¸ªå›ºå®šé•¿åº¦æ˜¯ç”±è¯­è¨€æ¨¡å‹ä¸­çš„ <code>num_steps</code>ï¼ˆæ—¶é—´æ­¥æ•°æˆ–è¯å…ƒæ•°é‡ï¼‰å‚æ•°æŒ‡å®šçš„ã€‚åœ¨æœºå™¨ç¿»è¯‘ä¸­ï¼Œæ¯ä¸ªæ ·æœ¬éƒ½æ˜¯ç”±æºå’Œç›®æ ‡ç»„æˆçš„æ–‡æœ¬åºåˆ—å¯¹ï¼Œå…¶ä¸­çš„æ¯ä¸ªæ–‡æœ¬åºåˆ—å¯èƒ½å…·æœ‰ä¸åŒçš„é•¿åº¦ã€‚</p>\n<p>ä¸ºäº†æé«˜è®¡ç®—æ•ˆç‡ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥é€šè¿‡<strong>æˆªæ–­</strong>ï¼ˆtruncationï¼‰å’Œ<strong>å¡«å……</strong>ï¼ˆpaddingï¼‰æ–¹å¼å®ç°ä¸€æ¬¡åªå¤„ç†ä¸€ä¸ªå°æ‰¹é‡çš„æ–‡æœ¬åºåˆ—ã€‚å‡è®¾åŒä¸€ä¸ªå°æ‰¹é‡ä¸­çš„æ¯ä¸ªåºåˆ—éƒ½åº”è¯¥å…·æœ‰ç›¸åŒçš„é•¿åº¦ <code>num_steps</code>ï¼Œé‚£ä¹ˆå¦‚æœæ–‡æœ¬åºåˆ—çš„è¯å…ƒæ•°ç›®å°‘äº <code>num_steps</code> æ—¶ï¼Œæˆ‘ä»¬å°†ç»§ç»­åœ¨å…¶æœ«å°¾æ·»åŠ ç‰¹å®šçš„ <code>&lt;pad&gt;</code> è¯å…ƒï¼Œç›´åˆ°å…¶é•¿åº¦è¾¾åˆ° <code>num_steps</code>ï¼›åä¹‹ï¼Œæˆ‘ä»¬å°†æˆªæ–­æ–‡æœ¬åºåˆ—æ—¶ï¼Œåªå–å…¶å‰ <code>num_steps</code> ä¸ªè¯å…ƒï¼Œå¹¶ä¸”ä¸¢å¼ƒå‰©ä½™çš„è¯å…ƒã€‚è¿™æ ·ï¼Œæ¯ä¸ªæ–‡æœ¬åºåˆ—å°†å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼Œä»¥ä¾¿ä»¥ç›¸åŒå½¢çŠ¶çš„å°æ‰¹é‡è¿›è¡ŒåŠ è½½ã€‚ä¸‹é¢çš„ <code>truncate_pad</code> å‡½æ•°å°†æˆªæ–­æˆ–å¡«å……æ–‡æœ¬åºåˆ—ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">truncate_pad</span>(<span class=\"params\">line, num_steps, padding_token</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;æˆªæ–­æˆ–å¡«å……æ–‡æœ¬åºåˆ—&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(line) &gt; num_steps:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> line[:num_steps]  <span class=\"comment\"># æˆªæ–­</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> line + [padding_token] * (num_steps - <span class=\"built_in\">len</span>(line))  <span class=\"comment\"># å¡«å……</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(truncate_pad(src_vocab[source[<span class=\"number\">0</span>]], <span class=\"number\">10</span>, src_vocab[<span class=\"string\">&#x27;&lt;pad&gt;&#x27;</span>]))  <span class=\"comment\"># [47, 4, 1, 1, 1, 1, 1, 1, 1, 1]</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå¯ä»¥å°†æ–‡æœ¬åºåˆ—è½¬æ¢æˆå°æ‰¹é‡æ•°æ®é›†ç”¨äºè®­ç»ƒã€‚æˆ‘ä»¬å°†ç‰¹å®šçš„ <code>&lt;eos&gt;</code> è¯å…ƒæ·»åŠ åˆ°æ‰€æœ‰åºåˆ—çš„æœ«å°¾ï¼Œç”¨äºè¡¨ç¤ºåºåˆ—çš„ç»“æŸã€‚å½“æ¨¡å‹é€šè¿‡ä¸€ä¸ªè¯å…ƒæ¥ä¸€ä¸ªè¯å…ƒåœ°ç”Ÿæˆåºåˆ—è¿›è¡Œé¢„æµ‹æ—¶ï¼Œç”Ÿæˆçš„ <code>&lt;eos&gt;</code> è¯å…ƒè¯´æ˜å®Œæˆäº†åºåˆ—è¾“å‡ºå·¥ä½œã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è®°å½•äº†æ¯ä¸ªæ–‡æœ¬åºåˆ—çš„é•¿åº¦ï¼Œç»Ÿè®¡é•¿åº¦æ—¶æ’é™¤äº†å¡«å……è¯å…ƒï¼Œåœ¨ç¨åå°†è¦ä»‹ç»çš„ä¸€äº›æ¨¡å‹ä¼šéœ€è¦è¿™ä¸ªé•¿åº¦ä¿¡æ¯ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">build_array_nmt</span>(<span class=\"params\">lines, vocab, num_steps</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å°†æœºå™¨ç¿»è¯‘çš„æ–‡æœ¬åºåˆ—è½¬æ¢æˆå°æ‰¹é‡&quot;&quot;&quot;</span></span><br><span class=\"line\">    lines = [vocab[l] <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> lines]</span><br><span class=\"line\">    lines = [l + [vocab[<span class=\"string\">&#x27;&lt;eos&gt;&#x27;</span>]] <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> lines]</span><br><span class=\"line\">    array = torch.tensor([truncate_pad(l, num_steps, vocab[<span class=\"string\">&#x27;&lt;pad&gt;&#x27;</span>]) <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> lines])</span><br><span class=\"line\">    valid_len = (array != vocab[<span class=\"string\">&#x27;&lt;pad&gt;&#x27;</span>]).<span class=\"built_in\">type</span>(torch.int32).<span class=\"built_in\">sum</span>(<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> array, valid_len</span><br></pre></td></tr></table></figure>\n<p>æœ€åï¼Œæˆ‘ä»¬å®šä¹‰ <code>load_data_nmt</code> å‡½æ•°æ¥è¿”å›æ•°æ®è¿­ä»£å™¨ï¼Œä»¥åŠæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€çš„ä¸¤ç§è¯è¡¨ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_data_nmt</span>(<span class=\"params\">batch_size, num_steps, num_examples=<span class=\"number\">600</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è¿”å›ç¿»è¯‘æ•°æ®é›†çš„è¿­ä»£å™¨å’Œè¯è¡¨&quot;&quot;&quot;</span></span><br><span class=\"line\">    text = preprocess_nmt(read_data_nmt())</span><br><span class=\"line\">    source, target = tokenize_nmt(text, num_examples)</span><br><span class=\"line\">    src_vocab = d2l.Vocab(source, min_freq=<span class=\"number\">2</span>, reserved_tokens=[<span class=\"string\">&#x27;&lt;pad&gt;&#x27;</span>, <span class=\"string\">&#x27;&lt;bos&gt;&#x27;</span>, <span class=\"string\">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class=\"line\">    tgt_vocab = d2l.Vocab(target, min_freq=<span class=\"number\">2</span>, reserved_tokens=[<span class=\"string\">&#x27;&lt;pad&gt;&#x27;</span>, <span class=\"string\">&#x27;&lt;bos&gt;&#x27;</span>, <span class=\"string\">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class=\"line\">    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)</span><br><span class=\"line\">    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)</span><br><span class=\"line\">    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)</span><br><span class=\"line\">    data_iter = d2l.load_array(data_arrays, batch_size)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data_iter, src_vocab, tgt_vocab</span><br><span class=\"line\"></span><br><span class=\"line\">train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=<span class=\"number\">2</span>, num_steps=<span class=\"number\">8</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> X, X_valid_len, Y, Y_valid_len <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;X:&#x27;</span>, X.<span class=\"built_in\">type</span>(torch.int32))  <span class=\"comment\"># X: tensor([[ 6, 18, 43,  4,  3,  1,  1,  1], [78,  9,  4,  3,  1,  1,  1,  1]], dtype=torch.int32)</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Xçš„æœ‰æ•ˆé•¿åº¦:&#x27;</span>, X_valid_len)  <span class=\"comment\"># Xçš„æœ‰æ•ˆé•¿åº¦: tensor([5, 4])</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Y:&#x27;</span>, Y.<span class=\"built_in\">type</span>(torch.int32))  <span class=\"comment\"># Y: tensor([[ 6,  7, 40,  4,  3,  1,  1,  1], [ 0,  4,  3,  1,  1,  1,  1,  1]], dtype=torch.int32)</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Yçš„æœ‰æ•ˆé•¿åº¦:&#x27;</span>, Y_valid_len)  <span class=\"comment\"># Yçš„æœ‰æ•ˆé•¿åº¦: tensor([5, 3])</span></span><br><span class=\"line\">    <span class=\"keyword\">break</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"6-ç¼–ç å™¨-è§£ç å™¨æ¶æ„\">6. ç¼–ç å™¨-è§£ç å™¨æ¶æ„</h2>\n<p>æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚ä¸­æ‰€è®¨è®ºçš„ï¼Œæœºå™¨ç¿»è¯‘æ˜¯åºåˆ—è½¬æ¢æ¨¡å‹çš„ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼Œå…¶è¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯é•¿åº¦å¯å˜çš„åºåˆ—ã€‚ä¸ºäº†å¤„ç†è¿™ç§ç±»å‹çš„è¾“å…¥å’Œè¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥è®¾è®¡ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶çš„æ¶æ„ï¼šç¬¬ä¸€ä¸ªç»„ä»¶æ˜¯ä¸€ä¸ª<strong>ç¼–ç å™¨</strong>ï¼ˆencoderï¼‰ï¼šå®ƒæ¥å—ä¸€ä¸ª<strong>é•¿åº¦å¯å˜</strong>çš„åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå…·æœ‰<strong>å›ºå®šå½¢çŠ¶</strong>çš„ç¼–ç çŠ¶æ€ã€‚ç¬¬äºŒä¸ªç»„ä»¶æ˜¯<strong>è§£ç å™¨</strong>ï¼ˆdecoderï¼‰ï¼šå®ƒå°†<strong>å›ºå®šå½¢çŠ¶</strong>çš„ç¼–ç çŠ¶æ€æ˜ å°„åˆ°<strong>é•¿åº¦å¯å˜</strong>çš„åºåˆ—ã€‚è¿™è¢«ç§°ä¸ºç¼–ç å™¨-è§£ç å™¨ï¼ˆencoder-decoderï¼‰æ¶æ„ï¼Œç¤ºæ„å›¾å¯è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-modern/encoder-decoder.html\">ç¼–ç å™¨-è§£ç å™¨æ¶æ„</a>ã€‚</p>\n<p>ç”±äºâ€œç¼–ç å™¨-è§£ç å™¨â€æ¶æ„æ˜¯å½¢æˆåç»­ç« èŠ‚ä¸­ä¸åŒåºåˆ—è½¬æ¢æ¨¡å‹çš„åŸºç¡€ï¼Œå› æ­¤æœ¬èŠ‚å°†æŠŠè¿™ä¸ªæ¶æ„è½¬æ¢ä¸ºæ¥å£æ–¹ä¾¿åé¢çš„ä»£ç å®ç°ã€‚</p>\n<p>åœ¨ç¼–ç å™¨æ¥å£ä¸­ï¼Œæˆ‘ä»¬åªæŒ‡å®šé•¿åº¦å¯å˜çš„åºåˆ—ä½œä¸ºç¼–ç å™¨çš„è¾“å…¥ <code>X</code>ã€‚ä»»ä½•ç»§æ‰¿è¿™ä¸ª <code>Encoder</code> åŸºç±»çš„æ¨¡å‹å°†å®Œæˆä»£ç å®ç°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Encoder</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„åŸºæœ¬ç¼–ç å™¨æ¥å£&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Encoder, self).__init__(**kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, *args</span>):</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>\n<p>åœ¨ä¸‹é¢çš„è§£ç å™¨æ¥å£ä¸­ï¼Œæˆ‘ä»¬æ–°å¢ä¸€ä¸ª <code>init_state</code> å‡½æ•°ï¼Œç”¨äºå°†ç¼–ç å™¨çš„è¾“å‡ºï¼ˆenc_outputsï¼‰è½¬æ¢ä¸ºç¼–ç åçš„çŠ¶æ€ã€‚æ³¨æ„ï¼Œæ­¤æ­¥éª¤å¯èƒ½éœ€è¦é¢å¤–çš„è¾“å…¥ï¼Œä¾‹å¦‚è¾“å…¥åºåˆ—çš„æœ‰æ•ˆé•¿åº¦ã€‚ä¸ºäº†é€ä¸ªåœ°ç”Ÿæˆé•¿åº¦å¯å˜çš„è¯å…ƒåºåˆ—ï¼Œè§£ç å™¨åœ¨æ¯ä¸ªæ—¶é—´æ­¥éƒ½ä¼šå°†è¾“å…¥ï¼ˆä¾‹å¦‚åœ¨å‰ä¸€æ—¶é—´æ­¥ç”Ÿæˆçš„è¯å…ƒï¼‰å’Œç¼–ç åçš„çŠ¶æ€æ˜ å°„æˆå½“å‰æ—¶é—´æ­¥çš„è¾“å‡ºè¯å…ƒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Decoder</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„åŸºæœ¬è§£ç å™¨æ¥å£&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Decoder, self).__init__(**kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">init_state</span>(<span class=\"params\">self, enc_outputs, *args</span>):</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> NotImplementedError</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, state</span>):</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>\n<p>æ€»è€Œè¨€ä¹‹ï¼Œâ€œç¼–ç å™¨-è§£ç å™¨â€æ¶æ„åŒ…å«äº†ä¸€ä¸ªç¼–ç å™¨å’Œä¸€ä¸ªè§£ç å™¨ï¼Œå¹¶ä¸”è¿˜æ‹¥æœ‰å¯é€‰çš„é¢å¤–çš„å‚æ•°ã€‚åœ¨å‰å‘ä¼ æ’­ä¸­ï¼Œç¼–ç å™¨çš„è¾“å‡ºç”¨äºç”Ÿæˆç¼–ç çŠ¶æ€ï¼Œè¿™ä¸ªçŠ¶æ€åˆè¢«è§£ç å™¨ä½œä¸ºå…¶è¾“å…¥çš„ä¸€éƒ¨åˆ†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">EncoderDecoder</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„åŸºç±»&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, encoder, decoder, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(EncoderDecoder, self).__init__(**kwargs)</span><br><span class=\"line\">        self.encoder = encoder</span><br><span class=\"line\">        self.decoder = decoder</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, enc_X, dec_X, *args</span>):</span><br><span class=\"line\">        enc_outputs = self.encoder(enc_X, *args)</span><br><span class=\"line\">        dec_state = self.decoder.init_state(enc_outputs, *args)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.decoder(dec_X, dec_state)</span><br></pre></td></tr></table></figure>\n<h2 id=\"7-åºåˆ—åˆ°åºåˆ—å­¦ä¹ ï¼ˆseq2seqï¼‰\">7. åºåˆ—åˆ°åºåˆ—å­¦ä¹ ï¼ˆseq2seqï¼‰</h2>\n<p>éµå¾ªç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„è®¾è®¡åŸåˆ™ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨ä½¿ç”¨é•¿åº¦å¯å˜çš„åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œå°†å…¶è½¬æ¢ä¸ºå›ºå®šå½¢çŠ¶çš„éšçŠ¶æ€ã€‚æ¢è¨€ä¹‹ï¼Œè¾“å…¥åºåˆ—çš„ä¿¡æ¯è¢«ç¼–ç åˆ°å¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨çš„éšçŠ¶æ€ä¸­ã€‚ä¸ºäº†è¿ç»­ç”Ÿæˆè¾“å‡ºåºåˆ—çš„è¯å…ƒï¼Œç‹¬ç«‹çš„å¾ªç¯ç¥ç»ç½‘ç»œè§£ç å™¨æ˜¯åŸºäºè¾“å…¥åºåˆ—çš„ç¼–ç ä¿¡æ¯å’Œè¾“å‡ºåºåˆ—å·²ç»çœ‹è§çš„æˆ–è€…ç”Ÿæˆçš„è¯å…ƒæ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè¯å…ƒã€‚åœ¨æœºå™¨ç¿»è¯‘ä¸­ä½¿ç”¨ä¸¤ä¸ªå¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œåºåˆ—åˆ°åºåˆ—å­¦ä¹ çš„å›¾ç¤ºä»¥åŠç†è®ºä»‹ç»å¯è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-modern/seq2seq.html\">åºåˆ—åˆ°åºåˆ—å­¦ä¹ ï¼ˆseq2seqï¼‰</a>ã€‚</p>\n<p>åœ¨åºåˆ—åˆ°åºåˆ—å­¦ä¹ ä¸­ï¼Œç‰¹å®šçš„ <code>&lt;eos&gt;</code> è¡¨ç¤ºåºåˆ—ç»“æŸè¯å…ƒã€‚ä¸€æ—¦è¾“å‡ºåºåˆ—ç”Ÿæˆæ­¤è¯å…ƒï¼Œæ¨¡å‹å°±ä¼šåœæ­¢é¢„æµ‹ã€‚åœ¨å¾ªç¯ç¥ç»ç½‘ç»œè§£ç å™¨çš„åˆå§‹åŒ–æ—¶é—´æ­¥ï¼Œæœ‰ä¸¤ä¸ªç‰¹å®šçš„è®¾è®¡å†³å®šï¼šé¦–å…ˆï¼Œç‰¹å®šçš„ <code>&lt;bos&gt;</code> è¡¨ç¤ºåºåˆ—å¼€å§‹è¯å…ƒï¼Œå®ƒæ˜¯è§£ç å™¨çš„è¾“å…¥åºåˆ—çš„ç¬¬ä¸€ä¸ªè¯å…ƒã€‚å…¶æ¬¡ï¼Œä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨æœ€ç»ˆçš„éšçŠ¶æ€æ¥åˆå§‹åŒ–è§£ç å™¨çš„éšçŠ¶æ€ã€‚</p>\n<p>ä»æŠ€æœ¯ä¸Šè®²ï¼Œç¼–ç å™¨å°†é•¿åº¦å¯å˜çš„è¾“å…¥åºåˆ—è½¬æ¢æˆå½¢çŠ¶å›ºå®šçš„ä¸Šä¸‹æ–‡å˜é‡ï¼Œå¹¶ä¸”å°†è¾“å…¥åºåˆ—çš„ä¿¡æ¯åœ¨è¯¥ä¸Šä¸‹æ–‡å˜é‡ä¸­è¿›è¡Œç¼–ç ã€‚</p>\n<p>ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®ç°å¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨ã€‚æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†åµŒå…¥å±‚ï¼ˆembedding layerï¼‰æ¥è·å¾—è¾“å…¥åºåˆ—ä¸­æ¯ä¸ªè¯å…ƒçš„ç‰¹å¾å‘é‡ã€‚åµŒå…¥å±‚çš„æƒé‡æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œå…¶è¡Œæ•°ç­‰äºè¾“å…¥è¯è¡¨çš„å¤§å°ï¼ˆvocab_sizeï¼‰ï¼Œå…¶åˆ—æ•°ç­‰äºç‰¹å¾å‘é‡çš„ç»´åº¦ï¼ˆembed_sizeï¼‰ã€‚å¦å¤–ï¼Œæœ¬æ–‡é€‰æ‹©äº†ä¸€ä¸ªå¤šå±‚é—¨æ§å¾ªç¯å•å…ƒæ¥å®ç°ç¼–ç å™¨ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> collections</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Seq2SeqEncoder</span>(d2l.Encoder):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ç”¨äºåºåˆ—åˆ°åºåˆ—å­¦ä¹ çš„å¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, vocab_size, embed_size, num_hiddens, num_layers, dropout=<span class=\"number\">0.</span>, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Seq2SeqEncoder, self).__init__(**kwargs)</span><br><span class=\"line\">        self.embedding = nn.Embedding(vocab_size, embed_size)  <span class=\"comment\"># åµŒå…¥å±‚</span></span><br><span class=\"line\">        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, *args</span>):</span><br><span class=\"line\">        X = self.embedding(X)  <span class=\"comment\"># X.shape: (batch_size, num_steps, embed_size)</span></span><br><span class=\"line\">        X = X.permute(<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">2</span>)  <span class=\"comment\"># åœ¨å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹ä¸­ï¼Œç¬¬ä¸€ä¸ªè½´å¯¹åº”äºæ—¶é—´æ­¥</span></span><br><span class=\"line\">        output, state = self.rnn(X)  <span class=\"comment\"># å¦‚æœæœªæåŠçŠ¶æ€ï¼Œåˆ™é»˜è®¤ä¸º0</span></span><br><span class=\"line\">        <span class=\"comment\"># output.shape: (num_steps, batch_size, num_hiddens)</span></span><br><span class=\"line\">        <span class=\"comment\"># state.shape: (num_layers, batch_size, num_hiddens)</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> output, state</span><br></pre></td></tr></table></figure>\n<p>ä¸‹é¢ï¼Œæˆ‘ä»¬å®ä¾‹åŒ–ä¸Šè¿°ç¼–ç å™¨çš„å®ç°ï¼šæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªä¸¤å±‚é—¨æ§å¾ªç¯å•å…ƒç¼–ç å™¨ï¼Œå…¶éšè—å•å…ƒæ•°ä¸º16ã€‚ç»™å®šä¸€å°æ‰¹é‡çš„è¾“å…¥åºåˆ— <code>X</code>ï¼ˆæ‰¹é‡å¤§å°ä¸º4ï¼Œæ—¶é—´æ­¥ä¸º7ï¼‰ã€‚åœ¨å®Œæˆæ‰€æœ‰æ—¶é—´æ­¥åï¼Œæœ€åä¸€å±‚çš„éšçŠ¶æ€çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå¼ é‡ï¼ˆ<code>output</code> ç”±ç¼–ç å™¨çš„å¾ªç¯å±‚è¿”å›ï¼‰ï¼Œå…¶å½¢çŠ¶ä¸º <code>(æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, éšè—å•å…ƒæ•°)</code>ã€‚</p>\n<p>ç”±äºè¿™é‡Œä½¿ç”¨çš„æ˜¯é—¨æ§å¾ªç¯å•å…ƒï¼Œæ‰€ä»¥åœ¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„å¤šå±‚éšçŠ¶æ€çš„å½¢çŠ¶æ˜¯ <code>(éšè—å±‚çš„æ•°é‡, æ‰¹é‡å¤§å°, éšè—å•å…ƒçš„æ•°é‡)</code>ã€‚å¦‚æœä½¿ç”¨é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼Œ<code>state</code> ä¸­è¿˜å°†åŒ…å«è®°å¿†å•å…ƒä¿¡æ¯ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">encoder = Seq2SeqEncoder(vocab_size=<span class=\"number\">10</span>, embed_size=<span class=\"number\">8</span>, num_hiddens=<span class=\"number\">16</span>, num_layers=<span class=\"number\">2</span>)</span><br><span class=\"line\">encoder.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">X = torch.zeros((<span class=\"number\">4</span>, <span class=\"number\">7</span>), dtype=torch.long)</span><br><span class=\"line\">output, state = encoder(X)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output.shape, state.shape)  <span class=\"comment\"># torch.Size([7, 4, 16]) torch.Size([2, 4, 16])</span></span><br></pre></td></tr></table></figure>\n<p>å½“å®ç°è§£ç å™¨æ—¶ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨ç¼–ç å™¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšçŠ¶æ€æ¥åˆå§‹åŒ–è§£ç å™¨çš„éšçŠ¶æ€ã€‚è¿™å°±è¦æ±‚ä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œå®ç°çš„ç¼–ç å™¨å’Œè§£ç å™¨å…·æœ‰<strong>ç›¸åŒæ•°é‡çš„å±‚å’Œéšè—å•å…ƒ</strong>ã€‚ä¸ºäº†è¿›ä¸€æ­¥åŒ…å«ç»è¿‡ç¼–ç çš„è¾“å…¥åºåˆ—çš„ä¿¡æ¯ï¼Œä¸Šä¸‹æ–‡å˜é‡åœ¨æ‰€æœ‰çš„æ—¶é—´æ­¥ä¸è§£ç å™¨çš„è¾“å…¥è¿›è¡Œæ‹¼æ¥ï¼ˆconcatenateï¼‰ã€‚ä¸ºäº†é¢„æµ‹è¾“å‡ºè¯å…ƒçš„æ¦‚ç‡åˆ†å¸ƒï¼Œåœ¨å¾ªç¯ç¥ç»ç½‘ç»œè§£ç å™¨çš„æœ€åä¸€å±‚ä½¿ç”¨å…¨è¿æ¥å±‚æ¥å˜æ¢éšçŠ¶æ€ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Seq2SeqDecoder</span>(d2l.Decoder):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ç”¨äºåºåˆ—åˆ°åºåˆ—å­¦ä¹ çš„å¾ªç¯ç¥ç»ç½‘ç»œè§£ç å™¨&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, vocab_size, embed_size, num_hiddens, num_layers, dropout=<span class=\"number\">0.</span>, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Seq2SeqDecoder, self).__init__(**kwargs)</span><br><span class=\"line\">        self.embedding = nn.Embedding(vocab_size, embed_size)</span><br><span class=\"line\">        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)</span><br><span class=\"line\">        self.dense = nn.Linear(num_hiddens, vocab_size)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">init_state</span>(<span class=\"params\">self, enc_outputs, *args</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> enc_outputs[<span class=\"number\">1</span>]  <span class=\"comment\"># enc_outputs[1]å³ä¸º[output, state]ä¸­çš„state</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, state</span>):</span><br><span class=\"line\">        X = self.embedding(X).permute(<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">2</span>)  <span class=\"comment\"># X.shape: (num_steps, batch_size, embed_size)</span></span><br><span class=\"line\">        context = state[-<span class=\"number\">1</span>].repeat(X.shape[<span class=\"number\">0</span>], <span class=\"number\">1</span>, <span class=\"number\">1</span>)  <span class=\"comment\"># å¹¿æ’­contextï¼Œä½¿å…¶å…·æœ‰ä¸Xç›¸åŒçš„num_steps</span></span><br><span class=\"line\">        X_and_context = torch.cat((X, context), <span class=\"number\">2</span>)  <span class=\"comment\"># å› æ­¤RNNçš„è¾“å…¥ç»´åº¦ä¸ºembed_size + num_hiddens</span></span><br><span class=\"line\">        output, state = self.rnn(X_and_context, state)</span><br><span class=\"line\">        output = self.dense(output).permute(<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">        <span class=\"comment\"># output.shape: (batch_size, num_steps, vocab_size)</span></span><br><span class=\"line\">        <span class=\"comment\"># state.shape: (num_layers, batch_size, num_hiddens)</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> output, state</span><br></pre></td></tr></table></figure>\n<p>ä¸‹é¢ï¼Œæˆ‘ä»¬ç”¨ä¸å‰é¢æåˆ°çš„ç¼–ç å™¨ä¸­ç›¸åŒçš„è¶…å‚æ•°æ¥å®ä¾‹åŒ–è§£ç å™¨ã€‚å¦‚æˆ‘ä»¬æ‰€è§ï¼Œè§£ç å™¨çš„è¾“å‡ºå½¢çŠ¶å˜ä¸º <code>(æ‰¹é‡å¤§å°, æ—¶é—´æ­¥æ•°, è¯è¡¨å¤§å°)</code>ï¼Œå…¶ä¸­å¼ é‡çš„æœ€åä¸€ä¸ªç»´åº¦å­˜å‚¨é¢„æµ‹çš„è¯å…ƒåˆ†å¸ƒã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">decoder = Seq2SeqDecoder(vocab_size=<span class=\"number\">10</span>, embed_size=<span class=\"number\">8</span>, num_hiddens=<span class=\"number\">16</span>, num_layers=<span class=\"number\">2</span>)</span><br><span class=\"line\">decoder.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">state = decoder.init_state(encoder(X))</span><br><span class=\"line\">output, state = decoder(X, state)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output.shape, state.shape)  <span class=\"comment\"># torch.Size([4, 7, 10]) torch.Size([2, 4, 16])</span></span><br></pre></td></tr></table></figure>\n<p>åœ¨æ¯ä¸ªæ—¶é—´æ­¥ï¼Œè§£ç å™¨é¢„æµ‹äº†è¾“å‡ºè¯å…ƒçš„æ¦‚ç‡åˆ†å¸ƒã€‚ç±»ä¼¼äºè¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨ Softmax æ¥è·å¾—åˆ†å¸ƒï¼Œå¹¶é€šè¿‡è®¡ç®—äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è¿›è¡Œä¼˜åŒ–ã€‚å›æƒ³ä¸€ä¸‹æˆ‘ä»¬å°†ç‰¹å®šçš„å¡«å……è¯å…ƒæ·»åŠ åˆ°åºåˆ—çš„æœ«å°¾ï¼Œå› æ­¤ä¸åŒé•¿åº¦çš„åºåˆ—å¯ä»¥ä»¥ç›¸åŒå½¢çŠ¶çš„å°æ‰¹é‡åŠ è½½ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬åº”è¯¥å°†å¡«å……è¯å…ƒçš„é¢„æµ‹æ’é™¤åœ¨æŸå¤±å‡½æ•°çš„è®¡ç®—ä¹‹å¤–ã€‚</p>\n<p>ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ <code>sequence_mask</code> å‡½æ•°é€šè¿‡<strong>é›¶å€¼åŒ–</strong>å±è”½ä¸ç›¸å…³çš„é¡¹ï¼Œä»¥ä¾¿åé¢ä»»ä½•ä¸ç›¸å…³é¢„æµ‹çš„è®¡ç®—éƒ½æ˜¯ä¸é›¶çš„ä¹˜ç§¯ï¼Œç»“æœéƒ½ç­‰äºé›¶ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸¤ä¸ªåºåˆ—çš„æœ‰æ•ˆé•¿åº¦ï¼ˆä¸åŒ…æ‹¬å¡«å……è¯å…ƒï¼‰åˆ†åˆ«ä¸º1å’Œ2ï¼Œåˆ™ç¬¬ä¸€ä¸ªåºåˆ—çš„ç¬¬ä¸€é¡¹å’Œç¬¬äºŒä¸ªåºåˆ—çš„å‰ä¸¤é¡¹ä¹‹åçš„å‰©ä½™é¡¹å°†è¢«æ¸…é™¤ä¸ºé›¶ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># è§£æ[None, :]å’Œ[:, None]</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.arange(<span class=\"number\">3</span>)[<span class=\"literal\">None</span>, :])  <span class=\"comment\"># tensor([[0, 1, 2]])ï¼Œåœ¨ç¬¬1ç»´å¢åŠ ä¸€ç»´ï¼ŒåŒç†[:, None]åœ¨ç¬¬2ç»´å¢åŠ ä¸€ç»´</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.arange(<span class=\"number\">3</span>)[<span class=\"literal\">None</span>, :] &lt; torch.tensor([<span class=\"number\">1</span>, <span class=\"number\">2</span>])[:, <span class=\"literal\">None</span>])</span><br><span class=\"line\"><span class=\"comment\"># tensor([[ True, False, False],</span></span><br><span class=\"line\"><span class=\"comment\">#         [ True,  True, False]])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sequence_mask</span>(<span class=\"params\">X, valid_len, value=<span class=\"number\">0</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;åœ¨åºåˆ—ä¸­å±è”½ä¸ç›¸å…³çš„é¡¹&quot;&quot;&quot;</span></span><br><span class=\"line\">    maxlen = X.size(<span class=\"number\">1</span>)</span><br><span class=\"line\">    mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[<span class=\"literal\">None</span>, :] &lt; valid_len[:, <span class=\"literal\">None</span>]</span><br><span class=\"line\">    X[~mask] = value</span><br><span class=\"line\">    <span class=\"keyword\">return</span> X</span><br><span class=\"line\"></span><br><span class=\"line\">X = torch.tensor([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(sequence_mask(X, torch.tensor([<span class=\"number\">1</span>, <span class=\"number\">2</span>])))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[1, 0, 0],</span></span><br><span class=\"line\"><span class=\"comment\">#         [4, 5, 0]])</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ‰©å±• Softmax äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥é®è”½ä¸ç›¸å…³çš„é¢„æµ‹ã€‚æœ€åˆï¼Œæ‰€æœ‰é¢„æµ‹è¯å…ƒçš„æ©ç éƒ½è®¾ç½®ä¸º1ã€‚ä¸€æ—¦ç»™å®šäº†æœ‰æ•ˆé•¿åº¦ï¼Œä¸å¡«å……è¯å…ƒå¯¹åº”çš„æ©ç å°†è¢«è®¾ç½®ä¸º0ã€‚æœ€åï¼Œå°†æ‰€æœ‰è¯å…ƒçš„æŸå¤±ä¹˜ä»¥æ©ç ï¼Œä»¥è¿‡æ»¤æ‰æŸå¤±ä¸­å¡«å……è¯å…ƒäº§ç”Ÿçš„ä¸ç›¸å…³é¢„æµ‹ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MaskedSoftmaxCELoss</span>(nn.CrossEntropyLoss):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å¸¦é®è”½çš„softmaxäº¤å‰ç†µæŸå¤±å‡½æ•°&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># pred.shape: (batch_size, num_steps, vocab_size)</span></span><br><span class=\"line\">    <span class=\"comment\"># label.shape: (batch_size, num_steps)</span></span><br><span class=\"line\">    <span class=\"comment\"># valid_len.shape: (batch_size,)</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, pred, label, valid_len</span>):</span><br><span class=\"line\">        weights = torch.ones_like(label)</span><br><span class=\"line\">        weights = sequence_mask(weights, valid_len)</span><br><span class=\"line\">        self.reduction=<span class=\"string\">&#x27;none&#x27;</span></span><br><span class=\"line\">        unweighted_loss = <span class=\"built_in\">super</span>(MaskedSoftmaxCELoss, self).forward(pred.permute(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>), label)</span><br><span class=\"line\">        weighted_loss = (unweighted_loss * weights).mean(dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> weighted_loss</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸‰ä¸ªç›¸åŒçš„åºåˆ—æ¥è¿›è¡Œä»£ç å¥å…¨æ€§æ£€æŸ¥ï¼Œç„¶ååˆ†åˆ«æŒ‡å®šè¿™äº›åºåˆ—çš„æœ‰æ•ˆé•¿åº¦ä¸º4ã€2å’Œ0ã€‚ç»“æœå°±æ˜¯ï¼Œç¬¬ä¸€ä¸ªåºåˆ—çš„æŸå¤±åº”ä¸ºç¬¬äºŒä¸ªåºåˆ—çš„ä¸¤å€ï¼Œè€Œç¬¬ä¸‰ä¸ªåºåˆ—çš„æŸå¤±åº”ä¸ºé›¶ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss = MaskedSoftmaxCELoss()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(loss(torch.ones(<span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">10</span>), torch.ones((<span class=\"number\">3</span>, <span class=\"number\">4</span>), dtype=torch.long), torch.tensor([<span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>])))  <span class=\"comment\"># tensor([2.3026, 1.1513, 0.0000])</span></span><br></pre></td></tr></table></figure>\n<p>åœ¨ä¸‹é¢çš„å¾ªç¯è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç‰¹å®šçš„åºåˆ—å¼€å§‹è¯å…ƒï¼ˆ<code>&lt;bos&gt;</code>ï¼‰å’ŒåŸå§‹çš„è¾“å‡ºåºåˆ—ï¼ˆä¸åŒ…æ‹¬åºåˆ—ç»“æŸè¯å…ƒ <code>&lt;eos&gt;</code>ï¼‰æ‹¼æ¥åœ¨ä¸€èµ·ä½œä¸ºè§£ç å™¨çš„è¾“å…¥ã€‚è¿™è¢«ç§°ä¸º<strong>å¼ºåˆ¶æ•™å­¦</strong>ï¼ˆteacher forcingï¼‰ï¼Œå› ä¸ºåŸå§‹çš„è¾“å‡ºåºåˆ—ï¼ˆè¯å…ƒçš„æ ‡ç­¾ï¼‰è¢«é€å…¥è§£ç å™¨ã€‚æˆ–è€…ï¼Œå°†æ¥è‡ªä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹å¾—åˆ°çš„è¯å…ƒä½œä¸ºè§£ç å™¨çš„å½“å‰è¾“å…¥ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_seq2seq</span>(<span class=\"params\">net, data_iter, lr, num_epochs, tgt_vocab, device</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è®­ç»ƒåºåˆ—åˆ°åºåˆ—æ¨¡å‹&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">xavier_init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">            nn.init.xavier_uniform_(m.weight)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.GRU:</span><br><span class=\"line\">            <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> m._flat_weights_names:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> <span class=\"string\">&quot;weight&quot;</span> <span class=\"keyword\">in</span> param:</span><br><span class=\"line\">                    nn.init.xavier_uniform_(m._parameters[param])</span><br><span class=\"line\"></span><br><span class=\"line\">    net.apply(xavier_init_weights)</span><br><span class=\"line\">    net.to(device)</span><br><span class=\"line\">    optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class=\"line\">    loss_function = MaskedSoftmaxCELoss()</span><br><span class=\"line\"></span><br><span class=\"line\">    net.train()</span><br><span class=\"line\">    writer = SummaryWriter(<span class=\"string\">&#x27;../logs/seq2seq_train_log&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        timer = d2l.Timer()</span><br><span class=\"line\">        num_tokens = <span class=\"number\">0</span>  <span class=\"comment\"># è¯å…ƒæ•°é‡</span></span><br><span class=\"line\">        train_loss = []</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> tqdm(data_iter):</span><br><span class=\"line\">            X, X_valid_len, Y, Y_valid_len = [x.to(device) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> batch]</span><br><span class=\"line\">            bos = torch.tensor([tgt_vocab[<span class=\"string\">&#x27;&lt;bos&gt;&#x27;</span>]] * Y.shape[<span class=\"number\">0</span>], device=device).reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">            dec_input = torch.cat([bos, Y[:, :-<span class=\"number\">1</span>]], <span class=\"number\">1</span>)  <span class=\"comment\"># å¼ºåˆ¶æ•™å­¦</span></span><br><span class=\"line\">            Y_hat, _ = net(X, dec_input, X_valid_len)</span><br><span class=\"line\">            loss = loss_function(Y_hat, Y, Y_valid_len).mean()</span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            loss.backward()  <span class=\"comment\"># æŸå¤±å‡½æ•°çš„æ ‡é‡è¿›è¡Œâ€œåå‘ä¼ æ’­â€</span></span><br><span class=\"line\">            d2l.grad_clipping(net, <span class=\"number\">1</span>)</span><br><span class=\"line\">            optimizer.step()</span><br><span class=\"line\">            train_loss.append(loss)</span><br><span class=\"line\">            num_tokens += Y_valid_len.<span class=\"built_in\">sum</span>()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % <span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            train_loss = <span class=\"built_in\">sum</span>(train_loss) / <span class=\"built_in\">len</span>(train_loss)</span><br><span class=\"line\">            writer.add_scalar(<span class=\"string\">&#x27;train_loss&#x27;</span>, train_loss, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;loss <span class=\"subst\">&#123;train_loss:<span class=\"number\">.3</span>f&#125;</span>, <span class=\"subst\">&#123;num_tokens / timer.stop():<span class=\"number\">.1</span>f&#125;</span> tokens/sec on <span class=\"subst\">&#123;<span class=\"built_in\">str</span>(device)&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    writer.close()</span><br><span class=\"line\"></span><br><span class=\"line\">embed_size, num_hiddens, num_layers, dropout = <span class=\"number\">32</span>, <span class=\"number\">32</span>, <span class=\"number\">2</span>, <span class=\"number\">0.1</span></span><br><span class=\"line\">batch_size, num_steps, lr, num_epochs = <span class=\"number\">64</span>, <span class=\"number\">10</span>, <span class=\"number\">0.005</span>, <span class=\"number\">300</span></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)</span><br><span class=\"line\">encoder = Seq2SeqEncoder(<span class=\"built_in\">len</span>(src_vocab), embed_size, num_hiddens, num_layers, dropout)</span><br><span class=\"line\">decoder = Seq2SeqDecoder(<span class=\"built_in\">len</span>(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)</span><br><span class=\"line\">net = d2l.EncoderDecoder(encoder, decoder)</span><br><span class=\"line\">train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)</span><br></pre></td></tr></table></figure>\n<p>ä¸ºäº†é‡‡ç”¨ä¸€ä¸ªæ¥ç€ä¸€ä¸ªè¯å…ƒçš„æ–¹å¼é¢„æµ‹è¾“å‡ºåºåˆ—ï¼Œæ¯ä¸ªè§£ç å™¨å½“å‰æ—¶é—´æ­¥çš„è¾“å…¥éƒ½å°†æ¥è‡ªäºå‰ä¸€æ—¶é—´æ­¥çš„é¢„æµ‹è¯å…ƒã€‚ä¸è®­ç»ƒç±»ä¼¼ï¼Œåºåˆ—å¼€å§‹è¯å…ƒï¼ˆ<code>&lt;bos&gt;</code>ï¼‰åœ¨åˆå§‹æ—¶é—´æ­¥è¢«è¾“å…¥åˆ°è§£ç å™¨ä¸­ï¼Œå½“è¾“å‡ºåºåˆ—çš„é¢„æµ‹é‡åˆ°åºåˆ—ç»“æŸè¯å…ƒï¼ˆ<code>&lt;eos&gt;</code>ï¼‰æ—¶ï¼Œé¢„æµ‹å°±ç»“æŸäº†ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">predict_seq2seq</span>(<span class=\"params\">net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„é¢„æµ‹&quot;&quot;&quot;</span></span><br><span class=\"line\">    net.<span class=\"built_in\">eval</span>()  <span class=\"comment\"># åœ¨é¢„æµ‹æ—¶å°†netè®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼</span></span><br><span class=\"line\">    src_tokens = src_vocab[src_sentence.lower().split(<span class=\"string\">&#x27; &#x27;</span>)] + [src_vocab[<span class=\"string\">&#x27;&lt;eos&gt;&#x27;</span>]]</span><br><span class=\"line\">    enc_valid_len = torch.tensor([<span class=\"built_in\">len</span>(src_tokens)], device=device)</span><br><span class=\"line\">    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab[<span class=\"string\">&#x27;&lt;pad&gt;&#x27;</span>])</span><br><span class=\"line\">    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=<span class=\"number\">0</span>)  <span class=\"comment\"># æ·»åŠ æ‰¹é‡ç»´åº¦</span></span><br><span class=\"line\">    enc_outputs = net.encoder(enc_X, enc_valid_len)</span><br><span class=\"line\">    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)</span><br><span class=\"line\">    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab[<span class=\"string\">&#x27;&lt;bos&gt;&#x27;</span>]], dtype=torch.long, device=device), dim=<span class=\"number\">0</span>)  <span class=\"comment\"># æ·»åŠ æ‰¹é‡ç»´åº¦</span></span><br><span class=\"line\">    output_seq, attention_weight_seq = [], []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_steps):</span><br><span class=\"line\">        Y, dec_state = net.decoder(dec_X, dec_state)</span><br><span class=\"line\">        dec_X = Y.argmax(dim=<span class=\"number\">2</span>)  <span class=\"comment\"># æˆ‘ä»¬ä½¿ç”¨å…·æœ‰é¢„æµ‹æœ€é«˜å¯èƒ½æ€§çš„è¯å…ƒï¼Œä½œä¸ºè§£ç å™¨åœ¨ä¸‹ä¸€æ—¶é—´æ­¥çš„è¾“å…¥</span></span><br><span class=\"line\">        pred = dec_X.squeeze(dim=<span class=\"number\">0</span>).<span class=\"built_in\">type</span>(torch.int32).item()</span><br><span class=\"line\">        <span class=\"comment\"># ä¿å­˜æ³¨æ„åŠ›æƒé‡ï¼ˆç¨åè®¨è®ºï¼‰</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> save_attention_weights:</span><br><span class=\"line\">            attention_weight_seq.append(net.decoder.attention_weights)</span><br><span class=\"line\">        <span class=\"comment\"># ä¸€æ—¦åºåˆ—ç»“æŸè¯å…ƒè¢«é¢„æµ‹ï¼Œè¾“å‡ºåºåˆ—çš„ç”Ÿæˆå°±å®Œæˆäº†</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> pred == tgt_vocab[<span class=\"string\">&#x27;&lt;eos&gt;&#x27;</span>]:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        output_seq.append(pred)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">&#x27; &#x27;</span>.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸çœŸå®çš„æ ‡ç­¾åºåˆ—è¿›è¡Œæ¯”è¾ƒæ¥è¯„ä¼°é¢„æµ‹åºåˆ—ã€‚è™½ç„¶BLEUï¼ˆbilingual evaluation understudyï¼‰æœ€å…ˆæ˜¯ç”¨äºè¯„ä¼°æœºå™¨ç¿»è¯‘çš„ç»“æœï¼Œä½†ç°åœ¨å®ƒå·²ç»è¢«å¹¿æ³›ç”¨äºæµ‹é‡è®¸å¤šåº”ç”¨çš„è¾“å‡ºåºåˆ—çš„è´¨é‡ã€‚BLEUçš„è¯¦ç»†ä»‹ç»å¯è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-modern/seq2seq.html\">åºåˆ—åˆ°åºåˆ—å­¦ä¹ ï¼ˆseq2seqï¼‰</a>ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bleu</span>(<span class=\"params\">pred_seq, label_seq, k</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è®¡ç®—BLEU&quot;&quot;&quot;</span></span><br><span class=\"line\">    pred_tokens, label_tokens = pred_seq.split(<span class=\"string\">&#x27; &#x27;</span>), label_seq.split(<span class=\"string\">&#x27; &#x27;</span>)</span><br><span class=\"line\">    len_pred, len_label = <span class=\"built_in\">len</span>(pred_tokens), <span class=\"built_in\">len</span>(label_tokens)</span><br><span class=\"line\">    score = math.exp(<span class=\"built_in\">min</span>(<span class=\"number\">0</span>, <span class=\"number\">1</span> - len_label / len_pred))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, k + <span class=\"number\">1</span>):</span><br><span class=\"line\">        num_matches, label_subs = <span class=\"number\">0</span>, collections.defaultdict(<span class=\"built_in\">int</span>)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(len_label - n + <span class=\"number\">1</span>):</span><br><span class=\"line\">            label_subs[<span class=\"string\">&#x27; &#x27;</span>.join(label_tokens[i: i + n])] += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(len_pred - n + <span class=\"number\">1</span>):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> label_subs[<span class=\"string\">&#x27; &#x27;</span>.join(pred_tokens[i: i + n])] &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">                num_matches += <span class=\"number\">1</span></span><br><span class=\"line\">                label_subs[<span class=\"string\">&#x27; &#x27;</span>.join(pred_tokens[i: i + n])] -= <span class=\"number\">1</span></span><br><span class=\"line\">        score *= math.<span class=\"built_in\">pow</span>(num_matches / (len_pred - n + <span class=\"number\">1</span>), math.<span class=\"built_in\">pow</span>(<span class=\"number\">0.5</span>, n))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> score</span><br><span class=\"line\"></span><br><span class=\"line\">engs = [<span class=\"string\">&#x27;go .&#x27;</span>, <span class=\"string\">&quot;i lost .&quot;</span>, <span class=\"string\">&#x27;he\\&#x27;s calm .&#x27;</span>, <span class=\"string\">&#x27;i\\&#x27;m home .&#x27;</span>]</span><br><span class=\"line\">fras = [<span class=\"string\">&#x27;va !&#x27;</span>, <span class=\"string\">&#x27;j\\&#x27;ai perdu .&#x27;</span>, <span class=\"string\">&#x27;il est calme .&#x27;</span>, <span class=\"string\">&#x27;je suis chez moi .&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> eng, fra <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(engs, fras):</span><br><span class=\"line\">    translation, attention_weight_seq = predict_seq2seq(net, eng, src_vocab, tgt_vocab, num_steps, device)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;eng&#125;</span> =&gt; <span class=\"subst\">&#123;translation&#125;</span>, bleu <span class=\"subst\">&#123;bleu(translation, fra, k=<span class=\"number\">2</span>):<span class=\"number\">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># go . =&gt; va !, bleu 1.000</span></span><br><span class=\"line\"><span class=\"comment\"># i lost . =&gt; j&#x27;ai perdu ., bleu 1.000</span></span><br><span class=\"line\"><span class=\"comment\"># he&#x27;s calm . =&gt; il est bon malade pas gagnÃ© pas en gagnÃ© pas, bleu 0.258</span></span><br><span class=\"line\"><span class=\"comment\"># i&#x27;m home . =&gt; je suis fainÃ©ante fainÃ©ante tomber ai ai homme paresseux ?, bleu 0.258</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"8-æŸæœç´¢\">8. æŸæœç´¢</h2>\n<p>æŸæœç´¢ä¸ºé¢„æµ‹è¾“å‡ºåºåˆ—çš„ä¸€ä¸ªç®—æ³•ï¼Œè¯¦ç»†ä»‹ç»å¯è§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-modern/beam-search.html\">æŸæœç´¢</a>ã€‚</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/11559.html",
            "url": "https://asanosaki.github.io/posts/11559.html",
            "title": "åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ç¬”è®°(ææ²)-å¾ªç¯ç¥ç»ç½‘ç»œ",
            "date_published": "2023-04-05T06:04:00.000Z",
            "content_html": "<blockquote>\n<p>ææ²åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆPyTorchï¼‰è¯¾ç¨‹å­¦ä¹ ç¬”è®°ç¬¬å…«ç« ï¼šå¾ªç¯ç¥ç»ç½‘ç»œã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-åºåˆ—æ¨¡å‹\">1. åºåˆ—æ¨¡å‹</h2>\n<p>ç”±äºæ¶‰åŠè¾ƒå¤šæ•°å­¦å…¬å¼ï¼Œåºåˆ—æ¨¡å‹çš„è®²è§£å¯ä»¥è½¬è‡³ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/sequence.html\">åºåˆ—æ¨¡å‹</a>ã€‚</p>\n<p>é¦–å…ˆï¼Œæˆ‘ä»¬ç”Ÿæˆä¸€äº›æ•°æ®ï¼šä½¿ç”¨æ­£å¼¦å‡½æ•°å’Œä¸€äº›å¯åŠ æ€§å™ªå£°æ¥ç”Ÿæˆåºåˆ—æ•°æ®ï¼Œæ—¶é—´æ­¥ä¸º <code>1, 2, ..., 1000</code>ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\">T = <span class=\"number\">1000</span>  <span class=\"comment\"># æ€»å…±äº§ç”Ÿ1000ä¸ªç‚¹</span></span><br><span class=\"line\">time = torch.arange(<span class=\"number\">1</span>, T + <span class=\"number\">1</span>, dtype=torch.float32)</span><br><span class=\"line\">x = torch.sin(<span class=\"number\">0.01</span> * time) + torch.normal(<span class=\"number\">0</span>, <span class=\"number\">0.2</span>, (T,))  <span class=\"comment\"># 0~10å¤§æ¦‚ä¸ºä¸€ä¸ªåŠå‘¨æœŸ(3*PI)ï¼Œå¹¶åŠ å…¥å™ªå£°</span></span><br><span class=\"line\">d2l.plot(time, [x], <span class=\"string\">&#x27;time&#x27;</span>, <span class=\"string\">&#x27;x&#x27;</span>, xlim=[<span class=\"number\">1</span>, <span class=\"number\">1000</span>], figsize=(<span class=\"number\">6</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªåºåˆ—è½¬æ¢ä¸ºæ¨¡å‹çš„ç‰¹å¾-æ ‡ç­¾ï¼ˆfeature-labelï¼‰å¯¹ã€‚åŸºäºåµŒå…¥ç»´åº¦ <code>ğœ</code>ï¼Œæˆ‘ä»¬å°†æ•°æ®æ˜ å°„ä¸ºæ•°æ®å¯¹ <code>ğ‘¦_ğ‘¡ = ğ‘¥_ğ‘¡</code> å’Œ <code>ğ±_ğ‘¡ = [ğ‘¥_&#123;ğ‘¡ - ğœ&#125;, ...,ğ‘¥_&#123;ğ‘¡ - 1&#125;]</code>ï¼Œè¿™æ¯”æˆ‘ä»¬æä¾›çš„æ•°æ®æ ·æœ¬å°‘äº† <code>ğœ</code> ä¸ªï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰è¶³å¤Ÿçš„å†å²è®°å½•æ¥æè¿°å‰ <code>ğœ</code> ä¸ªæ•°æ®æ ·æœ¬ã€‚ä¸€ä¸ªç®€å•çš„è§£å†³åŠæ³•æ˜¯ï¼šå¦‚æœæ‹¥æœ‰è¶³å¤Ÿé•¿çš„åºåˆ—å°±ä¸¢å¼ƒè¿™å‡ é¡¹ï¼›å¦ä¸€ä¸ªæ–¹æ³•æ˜¯ç”¨é›¶å¡«å……åºåˆ—ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨å‰600ä¸ªç‰¹å¾-æ ‡ç­¾å¯¹è¿›è¡Œè®­ç»ƒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tau = <span class=\"number\">4</span></span><br><span class=\"line\">features = torch.zeros((T - tau, tau))  <span class=\"comment\"># ä¸€å…±996ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾é•¿åº¦ä¸º4</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(tau):</span><br><span class=\"line\">    features[:, i] = x[i:T - tau + i]  <span class=\"comment\"># æŒ‰åˆ—å¡«å……</span></span><br><span class=\"line\">labels = x[tau:].reshape((-<span class=\"number\">1</span>, <span class=\"number\">1</span>))  <span class=\"comment\"># labelsçš„å…ƒç´ åœ¨xä¸­çš„ä¸‹æ ‡ä¸º[4, 5, 6, ...]ï¼Œå³0~3é¢„æµ‹4ï¼Œ1~4é¢„æµ‹5</span></span><br><span class=\"line\"><span class=\"comment\"># featuresçš„å…ƒç´ åœ¨xä¸­çš„ä¸‹æ ‡:</span></span><br><span class=\"line\"><span class=\"comment\"># [0, 1, 2, 3]</span></span><br><span class=\"line\"><span class=\"comment\"># [1, 2, 3, 4]</span></span><br><span class=\"line\"><span class=\"comment\"># ...</span></span><br><span class=\"line\"><span class=\"comment\"># [T - tau, T - tau + 1, T - tau + 2, T - tau + 3]</span></span><br><span class=\"line\"></span><br><span class=\"line\">batch_size, n_train = <span class=\"number\">16</span>, <span class=\"number\">600</span></span><br><span class=\"line\"><span class=\"comment\"># åªæœ‰å‰n_trainä¸ªæ ·æœ¬ç”¨äºè®­ç»ƒ</span></span><br><span class=\"line\">train_iter = d2l.load_array((features[:n_train], labels[:n_train]), batch_size, is_train=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç›¸å½“ç®€å•çš„æ¶æ„è®­ç»ƒæ¨¡å‹ï¼šä¸€ä¸ªæ‹¥æœ‰ä¸¤ä¸ªå…¨è¿æ¥å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºï¼ŒReLU æ¿€æ´»å‡½æ•°å’Œå¹³æ–¹æŸå¤±ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.xavier_uniform_(m.weight)</span><br><span class=\"line\"></span><br><span class=\"line\">net = nn.Sequential(nn.Linear(<span class=\"number\">4</span>, <span class=\"number\">10</span>), nn.ReLU(), nn.Linear(<span class=\"number\">10</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">net.apply(init_weights)</span><br><span class=\"line\"></span><br><span class=\"line\">loss_function = nn.MSELoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)  <span class=\"comment\"># æ³¨æ„ï¼šMSELossè®¡ç®—å¹³æ–¹è¯¯å·®æ—¶ä¸å¸¦ç³»æ•°1/2</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨å‡†å¤‡è®­ç»ƒæ¨¡å‹ï¼Œå®ç°ä¸‹é¢çš„è®­ç»ƒä»£ç çš„æ–¹å¼ä¸å‰é¢å‡ ç« ä¸­çš„å¾ªç¯è®­ç»ƒåŸºæœ¬ç›¸åŒã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸ä¼šæ·±å…¥æ¢è®¨å¤ªå¤šç»†èŠ‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_iter, loss_function, num_epochs, lr, device</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;training on&#x27;</span>, device)</span><br><span class=\"line\">    net.to(device)</span><br><span class=\"line\">    loss_function.to(device)</span><br><span class=\"line\">    optimizer = torch.optim.Adam(net.parameters(), lr=lr)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        net.train()</span><br><span class=\"line\">        train_loss = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> tqdm(train_iter):</span><br><span class=\"line\">            X, y = X.to(device), y.to(device)</span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            loss = loss_function(net(X), y)</span><br><span class=\"line\">            loss.mean().backward()</span><br><span class=\"line\">            optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">            train_loss.append(loss.mean())</span><br><span class=\"line\">        train_loss = <span class=\"built_in\">sum</span>(train_loss) / <span class=\"built_in\">len</span>(train_loss)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;[ Train | <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>:03d&#125;</span>/<span class=\"subst\">&#123;num_epochs:03d&#125;</span> ] loss = <span class=\"subst\">&#123;train_loss:<span class=\"number\">.5</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">lr, num_epochs = <span class=\"number\">0.01</span>, <span class=\"number\">5</span></span><br><span class=\"line\"></span><br><span class=\"line\">train(net, train_iter, loss_function, <span class=\"number\">5</span>, <span class=\"number\">0.01</span>, device)</span><br></pre></td></tr></table></figure>\n<p>ç”±äºè®­ç»ƒæŸå¤±å¾ˆå°ï¼Œå› æ­¤æˆ‘ä»¬æœŸæœ›æ¨¡å‹èƒ½æœ‰å¾ˆå¥½çš„å·¥ä½œæ•ˆæœã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™åœ¨å®è·µä¸­æ„å‘³ç€ä»€ä¹ˆã€‚é¦–å…ˆæ˜¯æ£€æŸ¥æ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„èƒ½åŠ›ï¼Œä¹Ÿå°±æ˜¯å•æ­¥é¢„æµ‹ï¼ˆone-step-ahead predictionï¼‰ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">onestep_preds = net(features.to(device))</span><br><span class=\"line\">d2l.plot([time, time[tau:]], [x.detach().numpy(), onestep_preds.cpu().detach().numpy()],</span><br><span class=\"line\">         <span class=\"string\">&#x27;time&#x27;</span>, <span class=\"string\">&#x27;x&#x27;</span>, legend=[<span class=\"string\">&#x27;data&#x27;</span>, <span class=\"string\">&#x27;1-step preds&#x27;</span>], xlim=[<span class=\"number\">1</span>, <span class=\"number\">1000</span>], figsize=(<span class=\"number\">6</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>æ­£å¦‚æˆ‘ä»¬æ‰€æ–™ï¼Œå•æ­¥é¢„æµ‹æ•ˆæœä¸é”™ã€‚å³ä½¿è¿™äº›é¢„æµ‹çš„æ—¶é—´æ­¥è¶…è¿‡äº†604ï¼ˆ<code>n_train + tau</code>ï¼‰ï¼Œå…¶ç»“æœçœ‹èµ·æ¥ä»ç„¶æ˜¯å¯ä¿¡çš„ã€‚ç„¶è€Œæœ‰ä¸€ä¸ªå°é—®é¢˜ï¼šå¦‚æœæ•°æ®è§‚å¯Ÿåºåˆ—çš„æ—¶é—´æ­¥åªåˆ°604ï¼Œæˆ‘ä»¬éœ€è¦ä¸€æ­¥ä¸€æ­¥åœ°å‘å‰è¿ˆè¿›ï¼Œæ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬å¿…é¡»ä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„é¢„æµ‹ï¼ˆè€Œä¸æ˜¯åŸå§‹æ•°æ®ï¼‰æ¥è¿›è¡Œå¤šæ­¥é¢„æµ‹ã€‚è®©æˆ‘ä»¬çœ‹çœ‹æ•ˆæœå¦‚ä½•ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">multistep_preds = torch.zeros(T)</span><br><span class=\"line\">multistep_preds[:n_train + tau] = x[:n_train + tau]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n_train + tau, T):</span><br><span class=\"line\">    multistep_preds[i] = net(multistep_preds[i - tau:i].reshape((<span class=\"number\">1</span>, -<span class=\"number\">1</span>)).to(device))</span><br><span class=\"line\"></span><br><span class=\"line\">d2l.plot([time, time[tau:], time[n_train + tau:]],</span><br><span class=\"line\">         [x.detach().numpy(), onestep_preds.cpu().detach().numpy(),</span><br><span class=\"line\">          multistep_preds[n_train + tau:].cpu().detach().numpy()], <span class=\"string\">&#x27;time&#x27;</span>, <span class=\"string\">&#x27;x&#x27;</span>,</span><br><span class=\"line\">         legend=[<span class=\"string\">&#x27;data&#x27;</span>, <span class=\"string\">&#x27;1-step preds&#x27;</span>, <span class=\"string\">&#x27;multi-step preds&#x27;</span>], xlim=[<span class=\"number\">1</span>, <span class=\"number\">1000</span>], figsize=(<span class=\"number\">6</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>å¦‚ä¸Šé¢çš„ä¾‹å­æ‰€ç¤ºï¼Œç»¿çº¿çš„é¢„æµ‹æ˜¾ç„¶å¹¶ä¸ç†æƒ³ã€‚ç»è¿‡å‡ ä¸ªé¢„æµ‹æ­¥éª¤ä¹‹åï¼Œé¢„æµ‹çš„ç»“æœå¾ˆå¿«å°±ä¼šè¡°å‡åˆ°ä¸€ä¸ªå¸¸æ•°ã€‚ä¸ºä»€ä¹ˆè¿™ä¸ªç®—æ³•æ•ˆæœè¿™ä¹ˆå·®å‘¢ï¼Ÿäº‹å®æ˜¯ç”±äºè¯¯å·®çš„ç´¯ç§¯ï¼šå‡è®¾åœ¨æ­¥éª¤1ä¹‹åï¼Œæˆ‘ä»¬ç§¯ç´¯äº†ä¸€äº›è¯¯å·®ï¼Œäºæ˜¯æ­¥éª¤2çš„è¾“å…¥è¢«æ‰°åŠ¨äº†ï¼Œåé¢çš„é¢„æµ‹è¯¯å·®ä¾æ­¤ç±»æ¨ã€‚å› æ­¤è¯¯å·®å¯èƒ½ä¼šç›¸å½“å¿«åœ°åç¦»çœŸå®çš„è§‚æµ‹ç»“æœã€‚ä¾‹å¦‚ï¼Œæœªæ¥24å°æ—¶çš„å¤©æ°”é¢„æŠ¥å¾€å¾€ç›¸å½“å‡†ç¡®ï¼Œä½†è¶…è¿‡è¿™ä¸€ç‚¹ï¼Œç²¾åº¦å°±ä¼šè¿…é€Ÿä¸‹é™ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« åŠåç»­ç« èŠ‚ä¸­è®¨è®ºå¦‚ä½•æ”¹è¿›è¿™ä¸€ç‚¹ã€‚</p>\n<p>åŸºäº <code>k = 1, 4, 16, 64</code>ï¼Œé€šè¿‡å¯¹æ•´ä¸ªåºåˆ—é¢„æµ‹çš„è®¡ç®—ï¼Œè®©æˆ‘ä»¬æ›´ä»”ç»†åœ°çœ‹ä¸€ä¸‹ <code>k</code> æ­¥é¢„æµ‹çš„å›°éš¾ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">max_steps = <span class=\"number\">64</span></span><br><span class=\"line\">features = torch.zeros((T - tau - max_steps + <span class=\"number\">1</span>, tau + max_steps))</span><br><span class=\"line\"><span class=\"comment\"># åˆ—i(i&lt;tau)æ˜¯æ¥è‡ªxçš„è§‚æµ‹ï¼Œå…¶æ—¶é—´æ­¥ä»(i)åˆ°(i+T-tau-max_steps+1)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(tau):</span><br><span class=\"line\">    features[:, i] = x[i:i + T - tau - max_steps + <span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># åˆ—i(i&gt;=tau)æ˜¯æ¥è‡ª(i-tau+1)æ­¥çš„é¢„æµ‹ï¼Œå…¶æ—¶é—´æ­¥ä»(i)åˆ°(i+T-tau-max_steps+1)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(tau, tau + max_steps):</span><br><span class=\"line\">    features[:, i] = net(features[:, i - tau:i].to(device)).reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">steps = (<span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">16</span>, <span class=\"number\">64</span>)</span><br><span class=\"line\">d2l.plot([time[tau + i - <span class=\"number\">1</span>:T - max_steps + i] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> steps],</span><br><span class=\"line\">         [features[:, tau + i - <span class=\"number\">1</span>].cpu().detach().numpy() <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> steps], <span class=\"string\">&#x27;time&#x27;</span>, <span class=\"string\">&#x27;x&#x27;</span>,</span><br><span class=\"line\">         legend=[<span class=\"string\">f&#x27;<span class=\"subst\">&#123;i&#125;</span>-step preds&#x27;</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> steps], xlim=[<span class=\"number\">5</span>, <span class=\"number\">1000</span>], figsize=(<span class=\"number\">6</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-æ–‡æœ¬é¢„å¤„ç†\">2. æ–‡æœ¬é¢„å¤„ç†</h2>\n<p>å¯¹äºåºåˆ—æ•°æ®å¤„ç†é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚ä¸­è¯„ä¼°äº†æ‰€éœ€çš„ç»Ÿè®¡å·¥å…·å’Œé¢„æµ‹æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚è¿™æ ·çš„æ•°æ®å­˜åœ¨è®¸å¤šç§å½¢å¼ï¼Œæ–‡æœ¬æ˜¯æœ€å¸¸è§ä¾‹å­ä¹‹ä¸€ã€‚ä¾‹å¦‚ï¼Œä¸€ç¯‡æ–‡ç« å¯ä»¥è¢«ç®€å•åœ°çœ‹ä½œä¸€ä¸²å•è¯åºåˆ—ï¼Œç”šè‡³æ˜¯ä¸€ä¸²å­—ç¬¦åºåˆ—ã€‚æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è§£ææ–‡æœ¬çš„å¸¸è§é¢„å¤„ç†æ­¥éª¤ã€‚è¿™äº›æ­¥éª¤é€šå¸¸åŒ…æ‹¬ï¼š</p>\n<ul>\n<li>å°†æ–‡æœ¬ä½œä¸ºå­—ç¬¦ä¸²åŠ è½½åˆ°å†…å­˜ä¸­ã€‚</li>\n<li>å°†å­—ç¬¦ä¸²æ‹†åˆ†ä¸ºè¯å…ƒï¼ˆå¦‚å•è¯å’Œå­—ç¬¦ï¼‰ã€‚</li>\n<li>å»ºç«‹ä¸€ä¸ªè¯è¡¨ï¼Œå°†æ‹†åˆ†çš„è¯å…ƒæ˜ å°„åˆ°æ•°å­—ç´¢å¼•ã€‚</li>\n<li>å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—ç´¢å¼•åºåˆ—ï¼Œæ–¹ä¾¿æ¨¡å‹æ“ä½œã€‚</li>\n</ul>\n<p>é¦–å…ˆï¼Œæˆ‘ä»¬ä» H.G.Well çš„<a href=\"https://www.gutenberg.org/ebooks/35\">æ—¶å…‰æœºå™¨</a>ä¸­åŠ è½½æ–‡æœ¬ã€‚è¿™æ˜¯ä¸€ä¸ªç›¸å½“å°çš„è¯­æ–™åº“ï¼Œåªæœ‰30000å¤šä¸ªå•è¯ï¼Œä½†è¶³å¤Ÿæˆ‘ä»¬å°è¯•ç‰›åˆ€ï¼Œè€Œç°å®ä¸­çš„æ–‡æ¡£é›†åˆå¯èƒ½ä¼šåŒ…å«æ•°åäº¿ä¸ªå•è¯ã€‚ä¸‹é¢çš„å‡½æ•°å°†æ•°æ®é›†è¯»å–åˆ°ç”±å¤šæ¡æ–‡æœ¬è¡Œç»„æˆçš„åˆ—è¡¨ä¸­ï¼Œå…¶ä¸­æ¯æ¡æ–‡æœ¬è¡Œéƒ½æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œå¿½ç•¥äº†æ ‡ç‚¹ç¬¦å·å’Œå­—æ¯å¤§å†™ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> collections</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">d2l.DATA_HUB[<span class=\"string\">&#x27;time_machine&#x27;</span>] = (d2l.DATA_URL + <span class=\"string\">&#x27;timemachine.txt&#x27;</span>, <span class=\"string\">&#x27;090b5e7e70c295757f55df93cb0a180b9691891a&#x27;</span>)</span><br><span class=\"line\">d2l.download(<span class=\"string\">&#x27;time_machine&#x27;</span>)  <span class=\"comment\"># é»˜è®¤è·¯å¾„åœ¨../data</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">read_time_machine</span>():</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å°†æ—¶é—´æœºå™¨æ•°æ®é›†åŠ è½½åˆ°æ–‡æœ¬è¡Œçš„åˆ—è¡¨ä¸­ï¼ŒåŒæ—¶å°†éå¤§å°å†™å­—æ¯å¤–çš„æ‰€æœ‰å­—ç¬¦æ›¿æ¢ä¸ºç©ºæ ¼&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;../data/timemachine.txt&#x27;</span>, <span class=\"string\">&#x27;r&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        lines = f.readlines()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> [re.sub(<span class=\"string\">&#x27;[^A-Za-z]+&#x27;</span>, <span class=\"string\">&#x27; &#x27;</span>, line).strip().lower() <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines]</span><br><span class=\"line\"></span><br><span class=\"line\">lines = read_time_machine()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;æ–‡æœ¬æ€»è¡Œæ•°: <span class=\"subst\">&#123;<span class=\"built_in\">len</span>(lines)&#125;</span>&#x27;</span>)  <span class=\"comment\"># æ–‡æœ¬æ€»è¡Œæ•°: 3221</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(lines[<span class=\"number\">0</span>])  <span class=\"comment\"># the time machine by h g wells</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(lines[<span class=\"number\">10</span>])  <span class=\"comment\"># twinkled and his usually pale face was flushed and animated the</span></span><br></pre></td></tr></table></figure>\n<p>ä¸‹é¢çš„ <code>tokenize</code> å‡½æ•°å°†æ–‡æœ¬è¡Œåˆ—è¡¨ï¼ˆlinesï¼‰ä½œä¸ºè¾“å…¥ï¼Œåˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ–‡æœ¬åºåˆ—ï¼ˆå¦‚ä¸€æ¡æ–‡æœ¬è¡Œï¼‰ã€‚æ¯ä¸ªæ–‡æœ¬åºåˆ—åˆè¢«æ‹†åˆ†æˆä¸€ä¸ªè¯å…ƒåˆ—è¡¨ï¼Œè¯å…ƒï¼ˆtokenï¼‰æ˜¯æ–‡æœ¬çš„åŸºæœ¬å•ä½ã€‚æœ€åï¼Œè¿”å›ä¸€ä¸ªç”±è¯å…ƒåˆ—è¡¨ç»„æˆçš„åˆ—è¡¨ï¼Œå…¶ä¸­çš„æ¯ä¸ªè¯å…ƒéƒ½æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ˆstringï¼‰ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">tokenize</span>(<span class=\"params\">lines, token=<span class=\"string\">&#x27;word&#x27;</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å°†æ–‡æœ¬è¡Œæ‹†åˆ†ä¸ºå•è¯æˆ–å­—ç¬¦è¯å…ƒ&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> token == <span class=\"string\">&#x27;word&#x27;</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [line.split() <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines]</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> token == <span class=\"string\">&#x27;char&#x27;</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [<span class=\"built_in\">list</span>(line) <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines]  <span class=\"comment\"># list(str)èƒ½å°†å­—ç¬¦ä¸²ä¸­çš„æ¯ä¸ªå­—ç¬¦åˆ†éš”å¼€å½¢æˆlist</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;é”™è¯¯ï¼æœªçŸ¥è¯å…ƒç±»å‹:&#x27;</span> + token)</span><br><span class=\"line\"></span><br><span class=\"line\">tokens = tokenize(lines)</span><br><span class=\"line\"><span class=\"comment\"># tokens = tokenize(lines, token=&#x27;char&#x27;)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">10</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(tokens[i])</span><br><span class=\"line\"><span class=\"comment\"># [&#x27;the&#x27;, &#x27;time&#x27;, &#x27;machine&#x27;, &#x27;by&#x27;, &#x27;h&#x27;, &#x27;g&#x27;, &#x27;wells&#x27;]</span></span><br><span class=\"line\"><span class=\"comment\"># []</span></span><br><span class=\"line\"><span class=\"comment\"># []</span></span><br><span class=\"line\"><span class=\"comment\"># []</span></span><br><span class=\"line\"><span class=\"comment\"># []</span></span><br><span class=\"line\"><span class=\"comment\"># [&#x27;i&#x27;]</span></span><br><span class=\"line\"><span class=\"comment\"># []</span></span><br><span class=\"line\"><span class=\"comment\"># []</span></span><br><span class=\"line\"><span class=\"comment\"># [&#x27;the&#x27;, &#x27;time&#x27;, &#x27;traveller&#x27;, &#x27;for&#x27;, &#x27;so&#x27;, &#x27;it&#x27;, &#x27;will&#x27;, &#x27;be&#x27;, &#x27;convenient&#x27;, &#x27;to&#x27;, &#x27;speak&#x27;, &#x27;of&#x27;, &#x27;him&#x27;]</span></span><br><span class=\"line\"><span class=\"comment\"># [&#x27;was&#x27;, &#x27;expounding&#x27;, &#x27;a&#x27;, &#x27;recondite&#x27;, &#x27;matter&#x27;, &#x27;to&#x27;, &#x27;us&#x27;, &#x27;his&#x27;, &#x27;grey&#x27;, &#x27;eyes&#x27;, &#x27;shone&#x27;, &#x27;and&#x27;]</span></span><br></pre></td></tr></table></figure>\n<p>è¯å…ƒçš„ç±»å‹æ˜¯å­—ç¬¦ä¸²ï¼Œè€Œæ¨¡å‹éœ€è¦çš„è¾“å…¥æ˜¯æ•°å­—ï¼Œå› æ­¤è¿™ç§ç±»å‹ä¸æ–¹ä¾¿æ¨¡å‹ä½¿ç”¨ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªå­—å…¸ï¼Œé€šå¸¸ä¹Ÿå«åšè¯è¡¨ï¼ˆvocabularyï¼‰ï¼Œç”¨æ¥å°†å­—ç¬¦ä¸²ç±»å‹çš„è¯å…ƒæ˜ å°„åˆ°ä»0å¼€å§‹çš„æ•°å­—ç´¢å¼•ä¸­ã€‚æˆ‘ä»¬å…ˆå°†è®­ç»ƒé›†ä¸­çš„æ‰€æœ‰æ–‡æ¡£åˆå¹¶åœ¨ä¸€èµ·ï¼Œå¯¹å®ƒä»¬çš„å”¯ä¸€è¯å…ƒè¿›è¡Œç»Ÿè®¡ï¼Œå¾—åˆ°çš„ç»Ÿè®¡ç»“æœç§°ä¹‹ä¸ºè¯­æ–™ï¼ˆcorpusï¼‰ã€‚ç„¶åæ ¹æ®æ¯ä¸ªå”¯ä¸€è¯å…ƒçš„å‡ºç°é¢‘ç‡ï¼Œä¸ºå…¶åˆ†é…ä¸€ä¸ªæ•°å­—ç´¢å¼•ã€‚å¾ˆå°‘å‡ºç°çš„è¯å…ƒé€šå¸¸è¢«ç§»é™¤ï¼Œè¿™å¯ä»¥é™ä½å¤æ‚æ€§ã€‚å¦å¤–ï¼Œè¯­æ–™åº“ä¸­ä¸å­˜åœ¨æˆ–å·²åˆ é™¤çš„ä»»ä½•è¯å…ƒéƒ½å°†æ˜ å°„åˆ°ä¸€ä¸ªç‰¹å®šçš„æœªçŸ¥è¯å…ƒ <code>&lt;unk&gt;</code>ã€‚æˆ‘ä»¬å¯ä»¥é€‰æ‹©å¢åŠ ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºä¿å­˜é‚£äº›è¢«ä¿ç•™çš„è¯å…ƒï¼Œä¾‹å¦‚ï¼šå¡«å……è¯å…ƒï¼ˆ<code>&lt;pad&gt;</code>ï¼‰ã€åºåˆ—å¼€å§‹è¯å…ƒï¼ˆ<code>&lt;bos&gt;</code>ï¼‰ã€åºåˆ—ç»“æŸè¯å…ƒï¼ˆ<code>&lt;eos&gt;</code>ï¼‰ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Vocab</span>:</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;æ–‡æœ¬è¯è¡¨&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, tokens=<span class=\"literal\">None</span>, min_freq=<span class=\"number\">0</span>, reserved_tokens=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> tokens <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            tokens = []</span><br><span class=\"line\">        <span class=\"keyword\">if</span> reserved_tokens <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            reserved_tokens = []</span><br><span class=\"line\">        <span class=\"comment\"># æŒ‰å‡ºç°é¢‘ç‡ä»å¤§åˆ°å°æ’åº</span></span><br><span class=\"line\">        counter = count_corpus(tokens)</span><br><span class=\"line\">        self._token_freqs = <span class=\"built_in\">sorted</span>(counter.items(), key=<span class=\"keyword\">lambda</span> x: x[<span class=\"number\">1</span>], reverse=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        <span class=\"comment\"># æ„å»ºç´¢å¼•åˆ°è¯å…ƒä¸è¯å…ƒåˆ°ç´¢å¼•çš„æ˜ å°„ï¼ŒæœªçŸ¥è¯å…ƒçš„ç´¢å¼•ä¸º0</span></span><br><span class=\"line\">        self.idx_to_token = [<span class=\"string\">&#x27;&lt;unk&gt;&#x27;</span>] + reserved_tokens</span><br><span class=\"line\">        self.token_to_idx = &#123;token: idx <span class=\"keyword\">for</span> idx, token <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(self.idx_to_token)&#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> token, freq <span class=\"keyword\">in</span> self._token_freqs:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> freq &lt; min_freq:  <span class=\"comment\"># å¦‚æœtokenå‡ºç°çš„æ¬¡æ•°å°‘äºmin_freqæ¬¡åˆ™ç›´æ¥ä¸¢å¼ƒ</span></span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> token <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> self.token_to_idx:</span><br><span class=\"line\">                self.idx_to_token.append(token)</span><br><span class=\"line\">                self.token_to_idx[token] = <span class=\"built_in\">len</span>(self.idx_to_token) - <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(self.idx_to_token)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, tokens</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(tokens, (<span class=\"built_in\">list</span>, <span class=\"built_in\">tuple</span>)):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.token_to_idx.get(tokens, self.unk)  <span class=\"comment\"># tokensä¸å­˜åœ¨åˆ™è¿”å›0</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> [self.__getitem__(token) <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> tokens]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">to_tokens</span>(<span class=\"params\">self, indices</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(indices, (<span class=\"built_in\">list</span>, <span class=\"built_in\">tuple</span>)):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.idx_to_token[indices]</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [self.idx_to_token[index] <span class=\"keyword\">for</span> index <span class=\"keyword\">in</span> indices]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @property</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">unk</span>(<span class=\"params\">self</span>):  <span class=\"comment\"># æœªçŸ¥è¯å…ƒçš„ç´¢å¼•ä¸º0</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @property</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">token_freqs</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self._token_freqs</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">count_corpus</span>(<span class=\"params\">tokens</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ç»Ÿè®¡è¯å…ƒçš„é¢‘ç‡&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># è¿™é‡Œçš„tokensæ˜¯1Dåˆ—è¡¨æˆ–2Dåˆ—è¡¨</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(tokens) == <span class=\"number\">0</span> <span class=\"keyword\">or</span> <span class=\"built_in\">isinstance</span>(tokens[<span class=\"number\">0</span>], <span class=\"built_in\">list</span>):</span><br><span class=\"line\">        tokens = [token <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> tokens <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> line]  <span class=\"comment\"># å°†è¯å…ƒåˆ—è¡¨å±•å¹³æˆä¸€ä¸ªåˆ—è¡¨</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> collections.Counter(tokens)</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬é¦–å…ˆä½¿ç”¨æ—¶å…‰æœºå™¨æ•°æ®é›†ä½œä¸ºè¯­æ–™åº“æ¥æ„å»ºè¯è¡¨ï¼Œç„¶åæ‰“å°å‰å‡ ä¸ªé«˜é¢‘è¯å…ƒåŠå…¶ç´¢å¼•ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vocab = Vocab(tokens)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">list</span>(vocab.token_to_idx.items())[:<span class=\"number\">10</span>])  <span class=\"comment\"># æ³¨æ„ä¸åŠ item()çš„è¯åªä¼šå°†keyè½¬æˆlist</span></span><br><span class=\"line\"><span class=\"comment\"># [(&#x27;&lt;unk&gt;&#x27;, 0), (&#x27;the&#x27;, 1), (&#x27;i&#x27;, 2), (&#x27;and&#x27;, 3), (&#x27;of&#x27;, 4), (&#x27;a&#x27;, 5), (&#x27;to&#x27;, 6), (&#x27;was&#x27;, 7), (&#x27;in&#x27;, 8), (&#x27;that&#x27;, 9)]</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¯ä¸€æ¡æ–‡æœ¬è¡Œè½¬æ¢æˆä¸€ä¸ªæ•°å­—ç´¢å¼•åˆ—è¡¨ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;æ–‡æœ¬:&#x27;</span>, tokens[<span class=\"number\">0</span>])  <span class=\"comment\"># æ–‡æœ¬: [&#x27;the&#x27;, &#x27;time&#x27;, &#x27;machine&#x27;, &#x27;by&#x27;, &#x27;h&#x27;, &#x27;g&#x27;, &#x27;wells&#x27;]</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;ç´¢å¼•:&#x27;</span>, vocab[tokens[<span class=\"number\">0</span>]])  <span class=\"comment\"># ç´¢å¼•: [1, 19, 50, 40, 2183, 2184, 400]</span></span><br></pre></td></tr></table></figure>\n<p>åœ¨ä½¿ç”¨ä¸Šè¿°å‡½æ•°æ—¶ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰åŠŸèƒ½æ‰“åŒ…åˆ° <code>load_corpus_time_machine</code> å‡½æ•°ä¸­ï¼Œè¯¥å‡½æ•°è¿”å› <code>corpus</code>ï¼ˆè¯å…ƒç´¢å¼•åˆ—è¡¨ï¼‰å’Œ <code>vocab</code>ï¼ˆæ—¶å…‰æœºå™¨è¯­æ–™åº“çš„è¯è¡¨ï¼‰ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œæ‰€åšçš„æ”¹å˜æ˜¯ï¼š</p>\n<ul>\n<li>ä¸ºäº†ç®€åŒ–åé¢ç« èŠ‚ä¸­çš„è®­ç»ƒï¼Œæˆ‘ä»¬ä½¿ç”¨å­—ç¬¦ï¼ˆè€Œä¸æ˜¯å•è¯ï¼‰å®ç°æ–‡æœ¬è¯å…ƒåŒ–ï¼›</li>\n<li>æ—¶å…‰æœºå™¨æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ–‡æœ¬è¡Œä¸ä¸€å®šæ˜¯ä¸€ä¸ªå¥å­æˆ–ä¸€ä¸ªæ®µè½ï¼Œè¿˜å¯èƒ½æ˜¯ä¸€ä¸ªå•è¯ï¼Œå› æ­¤è¿”å›çš„ <code>corpus</code> ä»…å¤„ç†ä¸ºå•ä¸ªåˆ—è¡¨ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å¤šè¯å…ƒåˆ—è¡¨æ„æˆçš„ä¸€ä¸ªåˆ—è¡¨ã€‚</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_corpus_time_machine</span>(<span class=\"params\">max_tokens=-<span class=\"number\">1</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è¿”å›æ—¶å…‰æœºå™¨æ•°æ®é›†çš„è¯å…ƒç´¢å¼•åˆ—è¡¨å’Œè¯è¡¨&quot;&quot;&quot;</span></span><br><span class=\"line\">    lines = read_time_machine()</span><br><span class=\"line\">    tokens = tokenize(lines, <span class=\"string\">&#x27;char&#x27;</span>)</span><br><span class=\"line\">    vocab = Vocab(tokens)</span><br><span class=\"line\">    <span class=\"comment\"># å› ä¸ºæ—¶å…‰æœºå™¨æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ–‡æœ¬è¡Œä¸ä¸€å®šæ˜¯ä¸€ä¸ªå¥å­æˆ–ä¸€ä¸ªæ®µè½ï¼Œæ‰€ä»¥å°†æ‰€æœ‰æ–‡æœ¬è¡Œå±•å¹³åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­</span></span><br><span class=\"line\">    corpus = [vocab[token] <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> tokens <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> line]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> max_tokens &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        corpus = corpus[:max_tokens]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> corpus, vocab</span><br><span class=\"line\"></span><br><span class=\"line\">corpus, vocab = load_corpus_time_machine()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(corpus), <span class=\"built_in\">len</span>(vocab))  <span class=\"comment\"># 170580 28</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;ç´¢å¼•:&#x27;</span>, corpus[:<span class=\"number\">10</span>])  <span class=\"comment\"># ç´¢å¼•: [3, 9, 2, 1, 3, 5, 13, 2, 1, 13]</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;æ–‡æœ¬:&#x27;</span>, vocab.to_tokens(corpus[:<span class=\"number\">10</span>]))  <span class=\"comment\"># æ–‡æœ¬: [&#x27;t&#x27;, &#x27;h&#x27;, &#x27;e&#x27;, &#x27; &#x27;, &#x27;t&#x27;, &#x27;i&#x27;, &#x27;m&#x27;, &#x27;e&#x27;, &#x27; &#x27;, &#x27;m&#x27;]</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"3-è¯­è¨€æ¨¡å‹å’Œæ•°æ®é›†\">3. è¯­è¨€æ¨¡å‹å’Œæ•°æ®é›†</h2>\n<p>ç”±äºæ¶‰åŠè¾ƒå¤šæ•°å­¦å…¬å¼ï¼Œè¯­è¨€æ¨¡å‹çš„è®²è§£å¯ä»¥è½¬è‡³ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/language-models-and-dataset.html\">è¯­è¨€æ¨¡å‹å’Œæ•°æ®é›†</a>ã€‚</p>\n<p>æ ¹æ®ä¸Šä¸€èŠ‚ä¸­ä»‹ç»çš„æ—¶å…‰æœºå™¨æ•°æ®é›†æ„å»ºè¯è¡¨ï¼Œå¹¶æ‰“å°å‰10ä¸ªæœ€å¸¸ç”¨çš„ï¼ˆé¢‘ç‡æœ€é«˜çš„ï¼‰å•è¯ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">tokens = d2l.tokenize(d2l.read_time_machine())</span><br><span class=\"line\"><span class=\"comment\"># å› ä¸ºæ¯ä¸ªæ–‡æœ¬è¡Œä¸ä¸€å®šæ˜¯ä¸€ä¸ªå¥å­æˆ–ä¸€ä¸ªæ®µè½ï¼Œå› æ­¤æˆ‘ä»¬æŠŠæ‰€æœ‰æ–‡æœ¬è¡Œæ‹¼æ¥åˆ°ä¸€èµ·</span></span><br><span class=\"line\">corpus = [token <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> tokens <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> line]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(corpus[:<span class=\"number\">10</span>])  <span class=\"comment\"># [&#x27;the&#x27;, &#x27;time&#x27;, &#x27;machine&#x27;, &#x27;by&#x27;, &#x27;h&#x27;, &#x27;g&#x27;, &#x27;wells&#x27;, &#x27;i&#x27;, &#x27;the&#x27;, &#x27;time&#x27;]</span></span><br><span class=\"line\">vocab = d2l.Vocab(corpus)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(vocab.token_freqs[:<span class=\"number\">10</span>])  <span class=\"comment\"># [(&#x27;the&#x27;, 2261), (&#x27;i&#x27;, 1267), (&#x27;and&#x27;, 1245), (&#x27;of&#x27;, 1155), ...]</span></span><br></pre></td></tr></table></figure>\n<p>æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œæœ€æµè¡Œçš„è¯çœ‹èµ·æ¥å¾ˆæ— èŠï¼Œè¿™äº›è¯é€šå¸¸è¢«ç§°ä¸ºåœç”¨è¯ï¼ˆstop wordsï¼‰ï¼Œå› æ­¤å¯ä»¥è¢«è¿‡æ»¤æ‰ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒä»¬æœ¬èº«ä»ç„¶æ˜¯æœ‰æ„ä¹‰çš„ï¼Œæˆ‘ä»¬ä»ç„¶ä¼šåœ¨æ¨¡å‹ä¸­ä½¿ç”¨å®ƒä»¬ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸ªæ˜æ˜¾çš„é—®é¢˜æ˜¯è¯é¢‘è¡°å‡çš„é€Ÿåº¦ç›¸å½“åœ°å¿«ã€‚ä¾‹å¦‚ï¼Œæœ€å¸¸ç”¨å•è¯çš„è¯é¢‘å¯¹æ¯”ï¼Œç¬¬10ä¸ªè¿˜ä¸åˆ°ç¬¬1ä¸ªçš„1/5ã€‚ä¸ºäº†æ›´å¥½åœ°ç†è§£ï¼Œæˆ‘ä»¬å¯ä»¥ç”»å‡ºçš„è¯é¢‘å›¾ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">freqs = [freq <span class=\"keyword\">for</span> token, freq <span class=\"keyword\">in</span> vocab.token_freqs]</span><br><span class=\"line\">d2l.plot(freqs, xlabel=<span class=\"string\">&#x27;token: x&#x27;</span>, ylabel=<span class=\"string\">&#x27;frequency: n(x)&#x27;</span>, xscale=<span class=\"string\">&#x27;log&#x27;</span>, yscale=<span class=\"string\">&#x27;log&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>é€šè¿‡è¯é¢‘å›¾æˆ‘ä»¬å¯ä»¥å‘ç°ï¼šè¯é¢‘ä»¥ä¸€ç§æ˜ç¡®çš„æ–¹å¼è¿…é€Ÿè¡°å‡ã€‚å°†å‰å‡ ä¸ªå•è¯ä½œä¸ºä¾‹å¤–æ¶ˆé™¤åï¼Œå‰©ä½™çš„æ‰€æœ‰å•è¯å¤§è‡´éµå¾ªåŒå¯¹æ•°åæ ‡å›¾ä¸Šçš„ä¸€æ¡ç›´çº¿ã€‚è¿™æ„å‘³ç€å•è¯çš„é¢‘ç‡æ»¡è¶³é½æ™®å¤«å®šå¾‹ï¼ˆZipfâ€™s lawï¼‰ã€‚è¿™å‘Šè¯‰æˆ‘ä»¬æƒ³è¦é€šè¿‡è®¡æ•°ç»Ÿè®¡å’Œå¹³æ»‘æ¥å»ºæ¨¡å•è¯æ˜¯ä¸å¯è¡Œçš„ï¼Œå› ä¸ºè¿™æ ·å»ºæ¨¡çš„ç»“æœä¼šå¤§å¤§é«˜ä¼°å°¾éƒ¨å•è¯çš„é¢‘ç‡ï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„ä¸å¸¸ç”¨å•è¯ã€‚é‚£ä¹ˆå…¶ä»–çš„è¯å…ƒç»„åˆï¼Œæ¯”å¦‚äºŒå…ƒè¯­æ³•ã€ä¸‰å…ƒè¯­æ³•ç­‰ç­‰ï¼Œåˆä¼šå¦‚ä½•å‘¢ï¼Ÿæˆ‘ä»¬æ¥çœ‹çœ‹äºŒå…ƒè¯­æ³•çš„é¢‘ç‡æ˜¯å¦ä¸ä¸€å…ƒè¯­æ³•çš„é¢‘ç‡è¡¨ç°å‡ºç›¸åŒçš„è¡Œä¸ºæ–¹å¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bigram_tokens = [pair <span class=\"keyword\">for</span> pair <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(corpus[:-<span class=\"number\">1</span>], corpus[<span class=\"number\">1</span>:])]  <span class=\"comment\"># éå†æ‰€æœ‰è¿ç»­çš„ä¸¤ä¸ªè¯å…ƒ</span></span><br><span class=\"line\">bigram_vocab = d2l.Vocab(bigram_tokens)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(bigram_vocab.token_freqs[:<span class=\"number\">10</span>])  <span class=\"comment\"># [((&#x27;of&#x27;, &#x27;the&#x27;), 309), ((&#x27;in&#x27;, &#x27;the&#x27;), 169), ...]</span></span><br></pre></td></tr></table></figure>\n<p>è¿™é‡Œå€¼å¾—æ³¨æ„ï¼šåœ¨åä¸ªæœ€é¢‘ç¹çš„è¯å¯¹ä¸­ï¼Œæœ‰ä¹ä¸ªæ˜¯ç”±ä¸¤ä¸ªåœç”¨è¯ç»„æˆçš„ï¼Œåªæœ‰ä¸€ä¸ªä¸ <code>the time</code> æœ‰å…³ã€‚æˆ‘ä»¬å†è¿›ä¸€æ­¥çœ‹çœ‹ä¸‰å…ƒè¯­æ³•çš„é¢‘ç‡æ˜¯å¦è¡¨ç°å‡ºç›¸åŒçš„è¡Œä¸ºæ–¹å¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trigram_tokens = [triple <span class=\"keyword\">for</span> triple <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(corpus[:-<span class=\"number\">2</span>], corpus[<span class=\"number\">1</span>:-<span class=\"number\">1</span>], corpus[<span class=\"number\">2</span>:])]  <span class=\"comment\"># éå†æ‰€æœ‰è¿ç»­çš„ä¸‰ä¸ªè¯å…ƒ</span></span><br><span class=\"line\">trigram_vocab = d2l.Vocab(trigram_tokens)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(trigram_vocab.token_freqs[:<span class=\"number\">10</span>])  <span class=\"comment\"># [((&#x27;the&#x27;, &#x27;time&#x27;, &#x27;traveller&#x27;), 59), ((&#x27;the&#x27;, &#x27;time&#x27;, &#x27;machine&#x27;), 30), ...]</span></span><br></pre></td></tr></table></figure>\n<p>æœ€åï¼Œæˆ‘ä»¬ç›´è§‚åœ°å¯¹æ¯”ä¸‰ç§æ¨¡å‹ä¸­çš„è¯å…ƒé¢‘ç‡ï¼šä¸€å…ƒè¯­æ³•ã€äºŒå…ƒè¯­æ³•å’Œä¸‰å…ƒè¯­æ³•ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bigram_freqs = [freq <span class=\"keyword\">for</span> token, freq <span class=\"keyword\">in</span> bigram_vocab.token_freqs]</span><br><span class=\"line\">trigram_freqs = [freq <span class=\"keyword\">for</span> token, freq <span class=\"keyword\">in</span> trigram_vocab.token_freqs]</span><br><span class=\"line\">d2l.plot([freqs, bigram_freqs, trigram_freqs], xlabel=<span class=\"string\">&#x27;token: x&#x27;</span>, ylabel=<span class=\"string\">&#x27;frequency: n(x)&#x27;</span>,</span><br><span class=\"line\">         xscale=<span class=\"string\">&#x27;log&#x27;</span>, yscale=<span class=\"string\">&#x27;log&#x27;</span>, legend=[<span class=\"string\">&#x27;unigram&#x27;</span>, <span class=\"string\">&#x27;bigram&#x27;</span>, <span class=\"string\">&#x27;trigram&#x27;</span>])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>ç”±äºåºåˆ—æ•°æ®æœ¬è´¨ä¸Šæ˜¯<strong>è¿ç»­çš„</strong>ï¼Œå› æ­¤æˆ‘ä»¬åœ¨å¤„ç†æ•°æ®æ—¶éœ€è¦è§£å†³è¿™ä¸ªé—®é¢˜ã€‚åœ¨ç¬¬ä¸€èŠ‚ä¸­æˆ‘ä»¬ä»¥ä¸€ç§ç›¸å½“ç‰¹åˆ«çš„æ–¹å¼åšåˆ°äº†è¿™ä¸€ç‚¹ï¼šå½“åºåˆ—å˜å¾—å¤ªé•¿è€Œä¸èƒ½è¢«æ¨¡å‹ä¸€æ¬¡æ€§å…¨éƒ¨å¤„ç†æ—¶ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›æ‹†åˆ†è¿™æ ·çš„åºåˆ—æ–¹ä¾¿æ¨¡å‹è¯»å–ã€‚</p>\n<p>åœ¨ä»‹ç»è¯¥æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬çœ‹ä¸€ä¸‹æ€»ä½“ç­–ç•¥ã€‚å‡è®¾æˆ‘ä»¬å°†ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œæ¨¡å‹ä¸­çš„ç½‘ç»œä¸€æ¬¡å¤„ç†å…·æœ‰é¢„å®šä¹‰é•¿åº¦ï¼ˆä¾‹å¦‚ ğ‘› ä¸ªæ—¶é—´æ­¥ï¼‰çš„ä¸€ä¸ªå°æ‰¹é‡åºåˆ—ã€‚ç°åœ¨çš„é—®é¢˜æ˜¯å¦‚ä½•éšæœºç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡æ•°æ®çš„ç‰¹å¾å’Œæ ‡ç­¾ä»¥ä¾›è¯»å–ã€‚</p>\n<p>é¦–å…ˆï¼Œç”±äºæ–‡æœ¬åºåˆ—å¯ä»¥æ˜¯ä»»æ„é•¿çš„ï¼Œä¾‹å¦‚æ•´æœ¬ã€Šæ—¶å…‰æœºå™¨ã€‹ï¼ˆThe Time Machineï¼‰ï¼Œäºæ˜¯ä»»æ„é•¿çš„åºåˆ—å¯ä»¥è¢«æˆ‘ä»¬åˆ’åˆ†ä¸ºå…·æœ‰ç›¸åŒæ—¶é—´æ­¥æ•°çš„å­åºåˆ—ã€‚å½“è®­ç»ƒæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œæ—¶ï¼Œè¿™æ ·çš„å°æ‰¹é‡å­åºåˆ—å°†è¢«è¾“å…¥åˆ°æ¨¡å‹ä¸­ã€‚å‡è®¾ç½‘ç»œä¸€æ¬¡åªå¤„ç†å…·æœ‰ ğ‘› ä¸ªæ—¶é—´æ­¥çš„å­åºåˆ—ï¼Œé‚£ä¹ˆå¯ä»¥ä»æŒ‡å®šçš„èµ·å§‹ä½ç½®å¼€å§‹æˆªå–è¿ç»­çš„é•¿åº¦ä¸º ğ‘› çš„å­åºåˆ—ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä»»æ„åç§»é‡æ¥æŒ‡ç¤ºåˆå§‹ä½ç½®ï¼Œæ‰€ä»¥æˆ‘ä»¬æœ‰ç›¸å½“å¤§çš„è‡ªç”±åº¦ã€‚</p>\n<p>å¦‚æœæˆ‘ä»¬åªé€‰æ‹©ä¸€ä¸ªåç§»é‡ï¼Œé‚£ä¹ˆç”¨äºè®­ç»ƒç½‘ç»œçš„ã€æ‰€æœ‰å¯èƒ½çš„å­åºåˆ—çš„è¦†ç›–èŒƒå›´å°†æ˜¯æœ‰é™çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä»<strong>éšæœºåç§»é‡</strong>å¼€å§‹åˆ’åˆ†åºåˆ—ï¼Œä»¥åŒæ—¶è·å¾—è¦†ç›–æ€§ï¼ˆcoverageï¼‰å’Œéšæœºæ€§ï¼ˆrandomnessï¼‰ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬å°†æè¿°å¦‚ä½•å®ç°<strong>éšæœºé‡‡æ ·</strong>ï¼ˆrandom samplingï¼‰å’Œ<strong>é¡ºåºåˆ†åŒº</strong>ï¼ˆsequential partitioningï¼‰ç­–ç•¥ã€‚</p>\n<p>åœ¨éšæœºé‡‡æ ·ä¸­ï¼Œæ¯ä¸ªæ ·æœ¬éƒ½æ˜¯åœ¨åŸå§‹çš„é•¿åºåˆ—ä¸Š<strong>ä»»æ„æ•è·</strong>çš„å­åºåˆ—ã€‚åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œæ¥è‡ªä¸¤ä¸ªç›¸é‚»çš„ã€éšæœºçš„ã€å°æ‰¹é‡ä¸­çš„å­åºåˆ—ä¸ä¸€å®šåœ¨åŸå§‹åºåˆ—ä¸Šç›¸é‚»ã€‚å¯¹äºè¯­è¨€å»ºæ¨¡ï¼Œç›®æ ‡æ˜¯åŸºäºåˆ°ç›®å‰ä¸ºæ­¢æˆ‘ä»¬çœ‹åˆ°çš„è¯å…ƒæ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè¯å…ƒï¼Œå› æ­¤æ ‡ç­¾æ˜¯ç§»ä½äº†ä¸€ä¸ªè¯å…ƒçš„åŸå§‹åºåˆ—ã€‚</p>\n<p>ä¸‹é¢çš„ä»£ç æ¯æ¬¡å¯ä»¥ä»æ•°æ®ä¸­éšæœºç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡ã€‚åœ¨è¿™é‡Œï¼Œå‚æ•° <code>batch_size</code> æŒ‡å®šäº†æ¯ä¸ªå°æ‰¹é‡ä¸­å­åºåˆ—æ ·æœ¬çš„æ•°ç›®ï¼Œå‚æ•° <code>num_steps</code> æ˜¯æ¯ä¸ªå­åºåˆ—ä¸­é¢„å®šä¹‰çš„æ—¶é—´æ­¥æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">seq_data_iter_random</span>(<span class=\"params\">corpus, batch_size, num_steps</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä½¿ç”¨éšæœºæŠ½æ ·ç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡å­åºåˆ—&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># ä»éšæœºåç§»é‡å¼€å§‹å¯¹åºåˆ—è¿›è¡Œåˆ†åŒºï¼ŒéšæœºèŒƒå›´åŒ…æ‹¬num_steps-1</span></span><br><span class=\"line\">    corpus = corpus[random.randint(<span class=\"number\">0</span>, num_steps - <span class=\"number\">1</span>):]  <span class=\"comment\"># æˆªå–éšæœºèµ·å§‹ä½ç½®ä¹‹åçš„éƒ¨åˆ†</span></span><br><span class=\"line\">    <span class=\"comment\"># å‡å»1ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬éœ€è¦è€ƒè™‘æ ‡ç­¾ï¼Œè¦ç•™è‡³å°‘ä¸€ä¸ªæ•°æ®ä½œä¸ºæœ€åä¸€ç»„é¢„æµ‹çš„æ ‡ç­¾</span></span><br><span class=\"line\">    num_subseqs = (<span class=\"built_in\">len</span>(corpus) - <span class=\"number\">1</span>) // num_steps  <span class=\"comment\"># åˆ†åŒºæ•°</span></span><br><span class=\"line\">    <span class=\"comment\"># é•¿åº¦ä¸ºnum_stepsçš„å­åºåˆ—çš„èµ·å§‹ç´¢å¼•</span></span><br><span class=\"line\">    initial_indices = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(<span class=\"number\">0</span>, num_subseqs * num_steps, num_steps))</span><br><span class=\"line\">    <span class=\"comment\"># åœ¨éšæœºæŠ½æ ·çš„è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œæ¥è‡ªä¸¤ä¸ªç›¸é‚»çš„ã€éšæœºçš„ã€å°æ‰¹é‡ä¸­çš„å­åºåˆ—ä¸ä¸€å®šåœ¨åŸå§‹åºåˆ—ä¸Šç›¸é‚»</span></span><br><span class=\"line\">    random.shuffle(initial_indices)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">data</span>(<span class=\"params\">pos</span>):</span><br><span class=\"line\">        <span class=\"comment\"># è¿”å›ä»posä½ç½®å¼€å§‹çš„é•¿åº¦ä¸ºnum_stepsçš„åºåˆ—</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> corpus[pos:pos + num_steps]</span><br><span class=\"line\"></span><br><span class=\"line\">    num_batches = num_subseqs // batch_size</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, batch_size * num_batches, batch_size):</span><br><span class=\"line\">        <span class=\"comment\"># åœ¨è¿™é‡Œï¼Œinitial_indicesåŒ…å«å­åºåˆ—çš„éšæœºèµ·å§‹ç´¢å¼•</span></span><br><span class=\"line\">        initial_indices_per_batch = initial_indices[i:i + batch_size]</span><br><span class=\"line\">        X = [data(j) <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> initial_indices_per_batch]</span><br><span class=\"line\">        Y = [data(j + <span class=\"number\">1</span>) <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> initial_indices_per_batch]</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> torch.tensor(X), torch.tensor(Y)</span><br></pre></td></tr></table></figure>\n<p>ä¸‹é¢æˆ‘ä»¬ç”Ÿæˆä¸€ä¸ªä»0åˆ°34çš„åºåˆ—ã€‚å‡è®¾æ‰¹é‡å¤§å°ä¸º2ï¼Œæ—¶é—´æ­¥æ•°ä¸º5ï¼Œè¿™æ„å‘³ç€å¯ä»¥ç”Ÿæˆ6ä¸ªç‰¹å¾-æ ‡ç­¾å­åºåˆ—å¯¹ã€‚å¦‚æœè®¾ç½®å°æ‰¹é‡å¤§å°ä¸º2ï¼Œæˆ‘ä»¬åªèƒ½å¾—åˆ°3ä¸ªå°æ‰¹é‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">my_seq = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(<span class=\"number\">35</span>))</span><br><span class=\"line\"><span class=\"keyword\">for</span> X, Y <span class=\"keyword\">in</span> seq_data_iter_random(my_seq, batch_size=<span class=\"number\">2</span>, num_steps=<span class=\"number\">5</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;X:&#x27;</span>, X, <span class=\"string\">&#x27;\\nY:&#x27;</span>, Y)</span><br><span class=\"line\"><span class=\"comment\"># X: tensor([[ 7,  8,  9, 10, 11], [17, 18, 19, 20, 21]])</span></span><br><span class=\"line\"><span class=\"comment\"># Y: tensor([[ 8,  9, 10, 11, 12], [18, 19, 20, 21, 22]])</span></span><br><span class=\"line\"><span class=\"comment\"># X: tensor([[22, 23, 24, 25, 26], [27, 28, 29, 30, 31]])</span></span><br><span class=\"line\"><span class=\"comment\"># Y: tensor([[23, 24, 25, 26, 27], [28, 29, 30, 31, 32]])</span></span><br><span class=\"line\"><span class=\"comment\"># X: tensor([[ 2,  3,  4,  5,  6], [12, 13, 14, 15, 16]])</span></span><br><span class=\"line\"><span class=\"comment\"># Y: tensor([[ 3,  4,  5,  6,  7], [13, 14, 15, 16, 17]])</span></span><br></pre></td></tr></table></figure>\n<p>åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œé™¤äº†å¯¹åŸå§‹åºåˆ—å¯ä»¥éšæœºæŠ½æ ·å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä¿è¯ä¸¤ä¸ªç›¸é‚»çš„å°æ‰¹é‡ä¸­çš„å­åºåˆ—åœ¨åŸå§‹åºåˆ—ä¸Šä¹Ÿæ˜¯ç›¸é‚»çš„ã€‚è¿™ç§ç­–ç•¥åœ¨åŸºäºå°æ‰¹é‡çš„è¿­ä»£è¿‡ç¨‹ä¸­ä¿ç•™äº†æ‹†åˆ†çš„å­åºåˆ—çš„é¡ºåºï¼Œå› æ­¤ç§°ä¸ºé¡ºåºåˆ†åŒºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">seq_data_iter_sequential</span>(<span class=\"params\">corpus, batch_size, num_steps</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä½¿ç”¨é¡ºåºåˆ†åŒºç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡å­åºåˆ—&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># ä»éšæœºåç§»é‡å¼€å§‹åˆ’åˆ†åºåˆ—</span></span><br><span class=\"line\">    offset = random.randint(<span class=\"number\">0</span>, num_steps)</span><br><span class=\"line\">    num_tokens = ((<span class=\"built_in\">len</span>(corpus) - offset - <span class=\"number\">1</span>) // batch_size) * batch_size</span><br><span class=\"line\">    Xs = torch.tensor(corpus[offset:offset + num_tokens])</span><br><span class=\"line\">    Ys = torch.tensor(corpus[offset + <span class=\"number\">1</span>:offset + <span class=\"number\">1</span> + num_tokens])</span><br><span class=\"line\">    Xs, Ys = Xs.reshape(batch_size, -<span class=\"number\">1</span>), Ys.reshape(batch_size, -<span class=\"number\">1</span>)</span><br><span class=\"line\">    num_batches = Xs.shape[<span class=\"number\">1</span>] // num_steps  <span class=\"comment\"># batchçš„æ•°é‡</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, num_steps * num_batches, num_steps):</span><br><span class=\"line\">        X = Xs[:, i:i + num_steps]</span><br><span class=\"line\">        Y = Ys[:, i:i + num_steps]</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> X, Y</span><br></pre></td></tr></table></figure>\n<p>åŸºäºç›¸åŒçš„è®¾ç½®ï¼Œé€šè¿‡é¡ºåºåˆ†åŒºè¯»å–æ¯ä¸ªå°æ‰¹é‡çš„å­åºåˆ—çš„ç‰¹å¾ <code>X</code> å’Œæ ‡ç­¾ <code>Y</code>ã€‚é€šè¿‡å°†å®ƒä»¬æ‰“å°å‡ºæ¥å¯ä»¥å‘ç°ï¼šè¿­ä»£æœŸé—´æ¥è‡ªä¸¤ä¸ªç›¸é‚»çš„å°æ‰¹é‡ä¸­çš„å­åºåˆ—åœ¨åŸå§‹åºåˆ—ä¸­ç¡®å®æ˜¯ç›¸é‚»çš„ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> X, Y <span class=\"keyword\">in</span> seq_data_iter_sequential(my_seq, batch_size=<span class=\"number\">2</span>, num_steps=<span class=\"number\">5</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;X:&#x27;</span>, X, <span class=\"string\">&#x27;\\nY:&#x27;</span>, Y)</span><br><span class=\"line\"><span class=\"comment\"># X: tensor([[ 2,  3,  4,  5,  6], [18, 19, 20, 21, 22]])</span></span><br><span class=\"line\"><span class=\"comment\"># Y: tensor([[ 3,  4,  5,  6,  7], [19, 20, 21, 22, 23]])</span></span><br><span class=\"line\"><span class=\"comment\"># X: tensor([[ 7,  8,  9, 10, 11], [23, 24, 25, 26, 27]])</span></span><br><span class=\"line\"><span class=\"comment\"># Y: tensor([[ 8,  9, 10, 11, 12], [24, 25, 26, 27, 28]])</span></span><br><span class=\"line\"><span class=\"comment\"># X: tensor([[12, 13, 14, 15, 16], [28, 29, 30, 31, 32]])</span></span><br><span class=\"line\"><span class=\"comment\"># Y: tensor([[13, 14, 15, 16, 17], [29, 30, 31, 32, 33]])</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä¸Šé¢çš„ä¸¤ä¸ªé‡‡æ ·å‡½æ•°åŒ…è£…åˆ°ä¸€ä¸ªç±»ä¸­ï¼Œä»¥ä¾¿ç¨åå¯ä»¥å°†å…¶ç”¨ä½œæ•°æ®è¿­ä»£å™¨ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">SeqDataLoader</span>:</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;åŠ è½½åºåˆ—æ•°æ®çš„è¿­ä»£å™¨&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, batch_size, num_steps, use_random_iter, max_tokens</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> use_random_iter:</span><br><span class=\"line\">            self.data_iter_fn = d2l.seq_data_iter_random</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.data_iter_fn = d2l.seq_data_iter_sequential</span><br><span class=\"line\">        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)</span><br><span class=\"line\">        self.batch_size, self.num_steps = batch_size, num_steps</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__iter__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)</span><br></pre></td></tr></table></figure>\n<p>æœ€åï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå‡½æ•° <code>load_data_time_machine</code>ï¼Œå®ƒåŒæ—¶è¿”å›æ•°æ®è¿­ä»£å™¨å’Œè¯è¡¨ï¼Œå› æ­¤å¯ä»¥ä¸å…¶ä»–å¸¦æœ‰ <code>load_data</code> å‰ç¼€çš„å‡½æ•°ï¼ˆå¦‚ <code>d2l.load_data_fashion_mnist</code>ï¼‰ç±»ä¼¼åœ°ä½¿ç”¨ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_data_time_machine</span>(<span class=\"params\">batch_size, num_steps, use_random_iter=<span class=\"literal\">False</span>, max_tokens=<span class=\"number\">10000</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è¿”å›æ—¶å…‰æœºå™¨æ•°æ®é›†çš„è¿­ä»£å™¨å’Œè¯è¡¨&quot;&quot;&quot;</span></span><br><span class=\"line\">    data_iter = SeqDataLoader(batch_size, num_steps, use_random_iter, max_tokens)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data_iter, data_iter.vocab</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-å¾ªç¯ç¥ç»ç½‘ç»œ\">4. å¾ªç¯ç¥ç»ç½‘ç»œ</h2>\n<p>ç”±äºæ¶‰åŠè¾ƒå¤šæ•°å­¦å…¬å¼ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œçš„ç†è®ºéƒ¨åˆ†å¯ä»¥è½¬è‡³ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/rnn.html\">å¾ªç¯ç¥ç»ç½‘ç»œ</a>ã€‚</p>\n<h3 id=\"4-1-å¾ªç¯ç¥ç»ç½‘ç»œçš„ä»é›¶å¼€å§‹å®ç°\">4.1 å¾ªç¯ç¥ç»ç½‘ç»œçš„ä»é›¶å¼€å§‹å®ç°</h3>\n<p>æœ¬èŠ‚å°†ä»å¤´å¼€å§‹åŸºäºå¾ªç¯ç¥ç»ç½‘ç»œå®ç°å­—ç¬¦çº§è¯­è¨€æ¨¡å‹ã€‚è¿™æ ·çš„æ¨¡å‹å°†åœ¨ H.G.Wells çš„æ—¶å…‰æœºå™¨æ•°æ®é›†ä¸Šè®­ç»ƒã€‚å’Œå‰é¢ä¸Šä¸€èŠ‚ä¸­ä»‹ç»è¿‡çš„ä¸€æ ·ï¼Œæˆ‘ä»¬å…ˆè¯»å–æ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size, num_steps = <span class=\"number\">32</span>, <span class=\"number\">35</span></span><br><span class=\"line\">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps, max_tokens=<span class=\"number\">10000</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(train_iter.corpus))  <span class=\"comment\"># 10000</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(X.shape, y.shape)  <span class=\"comment\"># torch.Size([32, 35]) torch.Size([32, 35])</span></span><br><span class=\"line\">    <span class=\"keyword\">break</span></span><br></pre></td></tr></table></figure>\n<p>å›æƒ³ä¸€ä¸‹ï¼Œåœ¨ <code>train_iter</code> ä¸­ï¼Œæ¯ä¸ªè¯å…ƒéƒ½è¡¨ç¤ºä¸ºä¸€ä¸ªæ•°å­—ç´¢å¼•ï¼Œå°†è¿™äº›ç´¢å¼•ç›´æ¥è¾“å…¥ç¥ç»ç½‘ç»œå¯èƒ½ä¼šä½¿å­¦ä¹ å˜å¾—å›°éš¾ã€‚æˆ‘ä»¬é€šå¸¸å°†æ¯ä¸ªè¯å…ƒè¡¨ç¤ºä¸ºæ›´å…·è¡¨ç°åŠ›çš„ç‰¹å¾å‘é‡ã€‚æœ€ç®€å•çš„è¡¨ç¤ºç§°ä¸ºç‹¬çƒ­ç¼–ç ï¼ˆone-hot encodingï¼‰ã€‚</p>\n<p>ç®€è¨€ä¹‹ï¼Œå°†æ¯ä¸ªç´¢å¼•æ˜ å°„ä¸ºç›¸äº’ä¸åŒçš„å•ä½å‘é‡ï¼šå‡è®¾è¯è¡¨ä¸­ä¸åŒè¯å…ƒçš„æ•°ç›®ä¸ºNï¼ˆå³ <code>len(vocab)</code>ï¼‰ï¼Œè¯å…ƒç´¢å¼•çš„èŒƒå›´ä¸º0~N-1ã€‚å¦‚æœè¯å…ƒçš„ç´¢å¼•æ˜¯æ•´æ•° <code>i</code>ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªé•¿åº¦ä¸ºNçš„å…¨0å‘é‡ï¼Œå¹¶å°†ç¬¬ <code>i</code> å¤„çš„å…ƒç´ è®¾ç½®ä¸º1ã€‚æ­¤å‘é‡æ˜¯åŸå§‹è¯å…ƒçš„ä¸€ä¸ªç‹¬çƒ­å‘é‡ã€‚ç´¢å¼•ä¸º0å’Œ2çš„ç‹¬çƒ­å‘é‡å¦‚ä¸‹æ‰€ç¤ºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(F.one_hot(torch.tensor([<span class=\"number\">0</span>, <span class=\"number\">2</span>]), <span class=\"built_in\">len</span>(vocab)))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬æ¯æ¬¡é‡‡æ ·çš„å°æ‰¹é‡æ•°æ®å½¢çŠ¶æ˜¯äºŒç»´å¼ é‡ï¼š<code>(æ‰¹é‡å¤§å°, æ—¶é—´æ­¥æ•°)</code>ã€‚<code>one_hot</code> å‡½æ•°å°†è¿™æ ·ä¸€ä¸ªå°æ‰¹é‡æ•°æ®è½¬æ¢æˆä¸‰ç»´å¼ é‡ï¼Œå¼ é‡çš„æœ€åä¸€ä¸ªç»´åº¦ç­‰äºè¯è¡¨å¤§å°ï¼ˆ<code>len(vocab)</code>ï¼‰ã€‚æˆ‘ä»¬ç»å¸¸è½¬æ¢è¾“å…¥çš„ç»´åº¦ï¼Œä»¥ä¾¿è·å¾—å½¢çŠ¶ä¸º <code>(æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)</code> çš„è¾“å‡ºã€‚è¿™å°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ›´æ–¹ä¾¿åœ°é€šè¿‡æœ€å¤–å±‚çš„ç»´åº¦ï¼Œä¸€æ­¥ä¸€æ­¥åœ°æ›´æ–°å°æ‰¹é‡æ•°æ®çš„éšçŠ¶æ€ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = torch.arange(<span class=\"number\">10</span>).reshape((<span class=\"number\">2</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(F.one_hot(X.T, <span class=\"number\">28</span>).shape)  <span class=\"comment\"># torch.Size([5, 2, 28])</span></span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆå§‹åŒ–å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹çš„æ¨¡å‹å‚æ•°ã€‚éšè—å•å…ƒæ•° <code>num_hiddens</code> æ˜¯ä¸€ä¸ªå¯è°ƒçš„è¶…å‚æ•°ã€‚å½“è®­ç»ƒè¯­è¨€æ¨¡å‹æ—¶ï¼Œè¾“å…¥å’Œè¾“å‡ºæ¥è‡ªç›¸åŒçš„è¯è¡¨ï¼ˆè¾“å‡ºå¯ä»¥çœ‹æˆå¤šåˆ†ç±»é—®é¢˜ï¼Œå³è¾“å‡ºè¡¨ç¤ºå¯¹æ¯ä¸ªè¯å…ƒçš„é¢„æµ‹æ¦‚ç‡ï¼‰ã€‚å› æ­¤ï¼Œå®ƒä»¬å…·æœ‰ç›¸åŒçš„ç»´åº¦ï¼Œå³è¯è¡¨çš„å¤§å°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_params</span>(<span class=\"params\">vocab_size, num_hiddens, device</span>):</span><br><span class=\"line\">    num_inputs = num_outputs = vocab_size</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">normal</span>(<span class=\"params\">shape</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.randn(size=shape, device=device) * <span class=\"number\">0.01</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># éšè—å±‚å‚æ•°</span></span><br><span class=\"line\">    W_xh = normal((num_inputs, num_hiddens))</span><br><span class=\"line\">    W_hh = normal((num_hiddens, num_hiddens))</span><br><span class=\"line\">    b_h = torch.zeros(num_hiddens, device=device)</span><br><span class=\"line\">    <span class=\"comment\"># è¾“å‡ºå±‚å‚æ•°</span></span><br><span class=\"line\">    W_hq = normal((num_hiddens, num_outputs))</span><br><span class=\"line\">    b_q = torch.zeros(num_outputs, device=device)</span><br><span class=\"line\">    <span class=\"comment\"># é™„åŠ æ¢¯åº¦</span></span><br><span class=\"line\">    params = [W_xh, W_hh, b_h, W_hq, b_q]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> params:</span><br><span class=\"line\">        param.requires_grad_(<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> params</span><br></pre></td></tr></table></figure>\n<p>ä¸ºäº†å®šä¹‰å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦ä¸€ä¸ª <code>init_rnn_state</code> å‡½æ•°åœ¨åˆå§‹åŒ–æ—¶è¿”å›éšçŠ¶æ€ã€‚è¿™ä¸ªå‡½æ•°çš„è¿”å›æ˜¯ä¸€ä¸ªå¼ é‡ï¼Œå¼ é‡å…¨ç”¨0å¡«å……ï¼Œå½¢çŠ¶ä¸º <code>(æ‰¹é‡å¤§å°, éšè—å•å…ƒæ•°)</code>ã€‚åœ¨åé¢çš„ç« èŠ‚ä¸­æˆ‘ä»¬å°†ä¼šé‡åˆ°éšçŠ¶æ€åŒ…å«å¤šä¸ªå˜é‡çš„æƒ…å†µï¼Œè€Œä½¿ç”¨å…ƒç»„å¯ä»¥æ›´å®¹æ˜“åœ°å¤„ç†äº›ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_rnn_state</span>(<span class=\"params\">batch_size, num_hiddens, device</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (torch.zeros((batch_size, num_hiddens), device=device),)</span><br></pre></td></tr></table></figure>\n<p>ä¸‹é¢çš„ <code>rnn</code> å‡½æ•°å®šä¹‰äº†å¦‚ä½•åœ¨ä¸€ä¸ªæ—¶é—´æ­¥å†…è®¡ç®—éšçŠ¶æ€å’Œè¾“å‡ºã€‚å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹é€šè¿‡ <code>inputs</code> æœ€å¤–å±‚çš„ç»´åº¦å®ç°å¾ªç¯ï¼Œä»¥ä¾¿é€æ—¶é—´æ­¥æ›´æ–°å°æ‰¹é‡æ•°æ®çš„éšçŠ¶æ€Hã€‚æ­¤å¤–ï¼Œè¿™é‡Œä½¿ç”¨ <code>tanh</code> å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå½“å…ƒç´ åœ¨å®æ•°ä¸Šæ»¡è¶³å‡åŒ€åˆ†å¸ƒæ—¶ï¼Œ<code>tanh</code> å‡½æ•°çš„å¹³å‡å€¼ä¸º0ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rnn</span>(<span class=\"params\">inputs, state, params</span>):</span><br><span class=\"line\">    <span class=\"comment\"># inputs.shape: (æ—¶é—´æ­¥æ•°é‡, æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)</span></span><br><span class=\"line\">    W_xh, W_hh, b_h, W_hq, b_q = params</span><br><span class=\"line\">    H, = state</span><br><span class=\"line\">    outputs = []</span><br><span class=\"line\">    <span class=\"comment\"># X.shape: (æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> X <span class=\"keyword\">in</span> inputs:</span><br><span class=\"line\">        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)</span><br><span class=\"line\">        Y = torch.mm(H, W_hq) + b_q</span><br><span class=\"line\">        outputs.append(Y)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.cat(outputs, dim=<span class=\"number\">0</span>), (H,)</span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰äº†æ‰€æœ‰éœ€è¦çš„å‡½æ•°ä¹‹åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç±»æ¥åŒ…è£…è¿™äº›å‡½æ•°ï¼Œå¹¶å­˜å‚¨ä»é›¶å¼€å§‹å®ç°çš„å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹çš„å‚æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">RNNModelScratch</span>:</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä»é›¶å¼€å§‹å®ç°çš„å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, vocab_size, num_hiddens, device, get_params, init_state, forward_fn</span>):</span><br><span class=\"line\">        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens</span><br><span class=\"line\">        self.params = get_params(vocab_size, num_hiddens, device)</span><br><span class=\"line\">        self.init_state, self.forward_fn = init_state, forward_fn</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__call__</span>(<span class=\"params\">self, X, state</span>):</span><br><span class=\"line\">        X = F.one_hot(X.T, self.vocab_size).<span class=\"built_in\">type</span>(torch.float32)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.forward_fn(X, state, self.params)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">begin_state</span>(<span class=\"params\">self, batch_size, device</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.init_state(batch_size, self.num_hiddens, device)</span><br></pre></td></tr></table></figure>\n<p>è®©æˆ‘ä»¬æ£€æŸ¥è¾“å‡ºæ˜¯å¦å…·æœ‰æ­£ç¡®çš„å½¢çŠ¶ã€‚ä¾‹å¦‚ï¼ŒéšçŠ¶æ€çš„ç»´æ•°æ˜¯å¦ä¿æŒä¸å˜ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">num_hiddens = <span class=\"number\">512</span></span><br><span class=\"line\">net = RNNModelScratch(<span class=\"built_in\">len</span>(vocab), num_hiddens, device, get_params, init_rnn_state, rnn)</span><br><span class=\"line\">state = net.begin_state(X.shape[<span class=\"number\">0</span>], device)</span><br><span class=\"line\">Y, new_state = net(X.to(device), state)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(Y.shape, <span class=\"built_in\">len</span>(new_state), new_state[<span class=\"number\">0</span>].shape)  <span class=\"comment\"># torch.Size([10, 28]) 1 torch.Size([2, 512])</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¾“å‡ºå½¢çŠ¶æ˜¯ <code>(æ—¶é—´æ­¥æ•° * æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)</code>ï¼Œè€ŒéšçŠ¶æ€å½¢çŠ¶ä¿æŒä¸å˜ï¼Œå³ <code>(æ‰¹é‡å¤§å°, éšè—å•å…ƒæ•°)</code>ã€‚</p>\n<p>è®©æˆ‘ä»¬é¦–å…ˆå®šä¹‰é¢„æµ‹å‡½æ•°æ¥ç”Ÿæˆ <code>prefix</code> ä¹‹åçš„æ–°å­—ç¬¦ï¼Œå…¶ä¸­çš„ <code>prefix</code> æ˜¯ä¸€ä¸ªç”¨æˆ·æä¾›çš„åŒ…å«å¤šä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²ã€‚åœ¨å¾ªç¯éå† <code>prefix</code> ä¸­çš„å¼€å§‹å­—ç¬¦æ—¶ï¼Œæˆ‘ä»¬ä¸æ–­åœ°å°†éšçŠ¶æ€ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œä½†æ˜¯ä¸ç”Ÿæˆä»»ä½•è¾“å‡ºã€‚è¿™è¢«ç§°ä¸ºé¢„çƒ­ï¼ˆwarm-upï¼‰æœŸï¼Œå› ä¸ºåœ¨æ­¤æœŸé—´æ¨¡å‹ä¼šè‡ªæˆ‘æ›´æ–°ï¼ˆä¾‹å¦‚ï¼Œæ›´æ–°éšçŠ¶æ€ï¼‰ï¼Œä½†ä¸ä¼šè¿›è¡Œé¢„æµ‹ã€‚é¢„çƒ­æœŸç»“æŸåï¼ŒéšçŠ¶æ€çš„å€¼é€šå¸¸æ¯”åˆšå¼€å§‹çš„åˆå§‹å€¼æ›´é€‚åˆé¢„æµ‹ï¼Œä»è€Œé¢„æµ‹å­—ç¬¦å¹¶è¾“å‡ºå®ƒä»¬ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">predict</span>(<span class=\"params\">prefix, num_preds, net, vocab, device</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;åœ¨prefixåé¢ç”Ÿæˆæ–°å­—ç¬¦&quot;&quot;&quot;</span></span><br><span class=\"line\">    state = net.begin_state(batch_size=<span class=\"number\">1</span>, device=device)</span><br><span class=\"line\">    outputs = [vocab[prefix[<span class=\"number\">0</span>]]]</span><br><span class=\"line\">    get_input = <span class=\"keyword\">lambda</span>: torch.tensor([outputs[-<span class=\"number\">1</span>]], device=device).reshape((<span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> prefix[<span class=\"number\">1</span>:]:  <span class=\"comment\"># é¢„çƒ­æœŸ</span></span><br><span class=\"line\">        _, state = net(get_input(), state)</span><br><span class=\"line\">        outputs.append(vocab[y])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_preds):  <span class=\"comment\"># é¢„æµ‹num_predsæ­¥</span></span><br><span class=\"line\">        y, state = net(get_input(), state)</span><br><span class=\"line\">        outputs.append(<span class=\"built_in\">int</span>(y.argmax(dim=<span class=\"number\">1</span>).reshape(<span class=\"number\">1</span>)))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">&#x27;&#x27;</span>.join([vocab.idx_to_token[i] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> outputs])</span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æˆ‘ä»¬å¯ä»¥æµ‹è¯• <code>predict</code> å‡½æ•°ã€‚æˆ‘ä»¬å°†å‰ç¼€æŒ‡å®šä¸º <code>time traveller</code>ï¼Œå¹¶åŸºäºè¿™ä¸ªå‰ç¼€ç”Ÿæˆ10ä¸ªåç»­å­—ç¬¦ã€‚é‰´äºæˆ‘ä»¬è¿˜æ²¡æœ‰è®­ç»ƒç½‘ç»œï¼Œå®ƒä¼šç”Ÿæˆè’è°¬çš„é¢„æµ‹ç»“æœï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(predict(<span class=\"string\">&#x27;time traveller &#x27;</span>, <span class=\"number\">10</span>, net, vocab, device))  <span class=\"comment\"># time traveller gxgtlsryyy</span></span><br></pre></td></tr></table></figure>\n<p>æ¢¯åº¦è£å‰ªçš„ç†è®ºå¯è½¬è‡³ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/rnn-scratch.html\">å¾ªç¯ç¥ç»ç½‘ç»œçš„ä»é›¶å¼€å§‹å®ç°</a>ã€‚</p>\n<p>ä¸‹é¢æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è£å‰ªæ¨¡å‹çš„æ¢¯åº¦ï¼Œæ¨¡å‹æ˜¯ä»é›¶å¼€å§‹å®ç°çš„æ¨¡å‹æˆ–ç”±é«˜çº§ API æ„å»ºçš„æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨æ­¤è®¡ç®—äº†æ‰€æœ‰æ¨¡å‹å‚æ•°çš„æ¢¯åº¦çš„èŒƒæ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">grad_clipping</span>(<span class=\"params\">net, theta</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è£å‰ªæ¢¯åº¦&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, nn.Module):</span><br><span class=\"line\">        params = [p <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> net.parameters() <span class=\"keyword\">if</span> p.requires_grad]</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        params = net.params</span><br><span class=\"line\">    norm = torch.sqrt(<span class=\"built_in\">sum</span>(torch.<span class=\"built_in\">sum</span>((p.grad ** <span class=\"number\">2</span>)) <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> params))</span><br><span class=\"line\">    <span class=\"keyword\">if</span> norm &gt; theta:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> params:</span><br><span class=\"line\">            param.grad[:] *= theta / norm</span><br></pre></td></tr></table></figure>\n<p>åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°åœ¨ä¸€ä¸ªè¿­ä»£å‘¨æœŸå†…è®­ç»ƒæ¨¡å‹ã€‚å®ƒä¸æˆ‘ä»¬è®­ç»ƒ Softmax æ¨¡å‹çš„æ–¹å¼æœ‰ä¸‰ä¸ªä¸åŒä¹‹å¤„ï¼š</p>\n<ul>\n<li>åºåˆ—æ•°æ®çš„ä¸åŒé‡‡æ ·æ–¹æ³•ï¼ˆéšæœºé‡‡æ ·å’Œé¡ºåºåˆ†åŒºï¼‰å°†å¯¼è‡´éšçŠ¶æ€åˆå§‹åŒ–çš„å·®å¼‚ã€‚</li>\n<li>æˆ‘ä»¬åœ¨æ›´æ–°æ¨¡å‹å‚æ•°ä¹‹å‰è£å‰ªæ¢¯åº¦ã€‚è¿™æ ·çš„æ“ä½œçš„ç›®çš„æ˜¯ï¼Œå³ä½¿è®­ç»ƒè¿‡ç¨‹ä¸­æŸä¸ªç‚¹ä¸Šå‘ç”Ÿäº†æ¢¯åº¦çˆ†ç‚¸ï¼Œä¹Ÿèƒ½ä¿è¯æ¨¡å‹ä¸ä¼šå‘æ•£ã€‚</li>\n<li>æˆ‘ä»¬ç”¨å›°æƒ‘åº¦æ¥è¯„ä»·æ¨¡å‹ã€‚è¿™æ ·çš„åº¦é‡ç¡®ä¿äº†ä¸åŒé•¿åº¦çš„åºåˆ—å…·æœ‰å¯æ¯”æ€§ã€‚</li>\n</ul>\n<p>å…·ä½“æ¥è¯´ï¼Œå½“ä½¿ç”¨é¡ºåºåˆ†åŒºæ—¶ï¼Œæˆ‘ä»¬åªåœ¨æ¯ä¸ªè¿­ä»£å‘¨æœŸçš„å¼€å§‹ä½ç½®åˆå§‹åŒ–éšçŠ¶æ€ã€‚ç”±äºä¸‹ä¸€ä¸ªå°æ‰¹é‡æ•°æ®ä¸­çš„ç¬¬ <code>i</code> ä¸ªå­åºåˆ—æ ·æœ¬ä¸å½“å‰ç¬¬ <code>i</code> ä¸ªå­åºåˆ—æ ·æœ¬ç›¸é‚»ï¼Œå› æ­¤å½“å‰å°æ‰¹é‡æ•°æ®æœ€åä¸€ä¸ªæ ·æœ¬çš„éšçŠ¶æ€ï¼Œå°†ç”¨äºåˆå§‹åŒ–ä¸‹ä¸€ä¸ªå°æ‰¹é‡æ•°æ®ç¬¬ä¸€ä¸ªæ ·æœ¬çš„éšçŠ¶æ€ã€‚è¿™æ ·ï¼Œå­˜å‚¨åœ¨éšçŠ¶æ€ä¸­çš„åºåˆ—çš„å†å²ä¿¡æ¯å¯ä»¥åœ¨ä¸€ä¸ªè¿­ä»£å‘¨æœŸå†…æµç»ç›¸é‚»çš„å­åºåˆ—ã€‚ç„¶è€Œï¼Œåœ¨ä»»ä½•ä¸€ç‚¹éšçŠ¶æ€çš„è®¡ç®—ï¼Œéƒ½ä¾èµ–äºåŒä¸€è¿­ä»£å‘¨æœŸä¸­å‰é¢æ‰€æœ‰çš„å°æ‰¹é‡æ•°æ®ï¼Œè¿™ä½¿å¾—æ¢¯åº¦è®¡ç®—å˜å¾—å¤æ‚ã€‚ä¸ºäº†é™ä½è®¡ç®—é‡ï¼Œåœ¨å¤„ç†ä»»ä½•ä¸€ä¸ªå°æ‰¹é‡æ•°æ®ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆ<strong>åˆ†ç¦»æ¢¯åº¦</strong>ï¼Œä½¿å¾—éšçŠ¶æ€çš„æ¢¯åº¦è®¡ç®—æ€»æ˜¯é™åˆ¶åœ¨ä¸€ä¸ªå°æ‰¹é‡æ•°æ®çš„æ—¶é—´æ­¥å†…ã€‚</p>\n<p>å½“ä½¿ç”¨éšæœºæŠ½æ ·æ—¶ï¼Œå› ä¸ºæ¯ä¸ªæ ·æœ¬éƒ½æ˜¯åœ¨ä¸€ä¸ªéšæœºä½ç½®æŠ½æ ·çš„ï¼Œå› æ­¤éœ€è¦<strong>ä¸ºæ¯ä¸ªè¿­ä»£å‘¨æœŸé‡æ–°åˆå§‹åŒ–éšçŠ¶æ€</strong>ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_epoch</span>(<span class=\"params\">net, train_iter, loss_function, optimizer, device, use_random_iter</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è®­ç»ƒç½‘ç»œä¸€ä¸ªè¿­ä»£å‘¨æœŸï¼ˆå®šä¹‰è§ç¬¬8ç« ï¼‰&quot;&quot;&quot;</span></span><br><span class=\"line\">    state = <span class=\"literal\">None</span></span><br><span class=\"line\">    train_loss = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, Y <span class=\"keyword\">in</span> tqdm(train_iter):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> state <span class=\"keyword\">is</span> <span class=\"literal\">None</span> <span class=\"keyword\">or</span> use_random_iter:</span><br><span class=\"line\">            <span class=\"comment\"># åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æˆ–ä½¿ç”¨éšæœºæŠ½æ ·æ—¶åˆå§‹åŒ–state</span></span><br><span class=\"line\">            state = net.begin_state(batch_size=X.shape[<span class=\"number\">0</span>], device=device)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, nn.Module) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(state, <span class=\"built_in\">tuple</span>):</span><br><span class=\"line\">                <span class=\"comment\"># stateå¯¹äºnn.GRUæ˜¯ä¸ªå¼ é‡</span></span><br><span class=\"line\">                state.detach_()</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"comment\"># stateå¯¹äºnn.LSTMæˆ–å¯¹äºæˆ‘ä»¬ä»é›¶å¼€å§‹å®ç°çš„æ¨¡å‹æ˜¯ä¸ªå…ƒç»„</span></span><br><span class=\"line\">                <span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> state:</span><br><span class=\"line\">                    s.detach_()</span><br><span class=\"line\">        y = Y.T.reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\">        X, y = X.to(device), y.to(device)</span><br><span class=\"line\">        y_hat, state = net(X, state)</span><br><span class=\"line\">        loss = loss_function(y_hat, y.long()).mean()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(optimizer, torch.optim.Optimizer):</span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            loss.backward()</span><br><span class=\"line\">            grad_clipping(net, <span class=\"number\">1</span>)</span><br><span class=\"line\">            optimizer.step()</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            loss.backward()</span><br><span class=\"line\">            grad_clipping(net, <span class=\"number\">1</span>)</span><br><span class=\"line\">            optimizer(batch_size=<span class=\"number\">1</span>)</span><br><span class=\"line\">        train_loss.append(loss)  <span class=\"comment\"># å› ä¸ºå·²ç»è°ƒç”¨äº†meanå‡½æ•°</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> math.exp(<span class=\"built_in\">sum</span>(train_loss) / <span class=\"built_in\">len</span>(train_loss))  <span class=\"comment\"># è¿”å›å›°æƒ‘åº¦</span></span><br></pre></td></tr></table></figure>\n<p>å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹çš„è®­ç»ƒå‡½æ•°æ—¢æ”¯æŒä»é›¶å¼€å§‹å®ç°ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨é«˜çº§ API æ¥å®ç°ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_iter, vocab, lr, num_epochs, device, use_random_iter=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è®­ç»ƒæ¨¡å‹ï¼ˆå®šä¹‰è§ç¬¬8ç« ï¼‰&quot;&quot;&quot;</span></span><br><span class=\"line\">    loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">    <span class=\"comment\"># åˆå§‹åŒ–</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, nn.Module):</span><br><span class=\"line\">        optimizer = torch.optim.SGD(net.parameters(), lr)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        optimizer = <span class=\"keyword\">lambda</span> batch_size: d2l.sgd(net.params, lr, batch_size)</span><br><span class=\"line\">    pred = <span class=\"keyword\">lambda</span> prefix: predict(prefix, <span class=\"number\">50</span>, net, vocab, device)</span><br><span class=\"line\">    <span class=\"comment\"># è®­ç»ƒå’Œé¢„æµ‹</span></span><br><span class=\"line\">    writer = SummaryWriter(<span class=\"string\">&#x27;../logs/RNN_scratch_train_log&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        ppl = train_epoch(net, train_iter, loss_function, optimizer, device, use_random_iter)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % <span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;time traveller&#x27;</span>))</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;Perplexity: <span class=\"subst\">&#123;ppl:<span class=\"number\">.1</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">            writer.add_scalar(<span class=\"string\">&#x27;train_loss&#x27;</span>, ppl, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;time traveller&#x27;</span>))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;traveller&#x27;</span>))</span><br><span class=\"line\">    writer.close()</span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨ï¼Œæˆ‘ä»¬è®­ç»ƒå¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚å› ä¸ºæˆ‘ä»¬åœ¨æ•°æ®é›†ä¸­åªä½¿ç”¨äº†10000ä¸ªè¯å…ƒï¼Œæ‰€ä»¥æ¨¡å‹éœ€è¦æ›´å¤šçš„è¿­ä»£å‘¨æœŸæ¥æ›´å¥½åœ°æ”¶æ•›ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_epochs, lr = <span class=\"number\">500</span>, <span class=\"number\">1</span></span><br><span class=\"line\">train(net, train_iter, vocab, lr, num_epochs, device)</span><br><span class=\"line\"><span class=\"comment\"># Perplexity: 1.0</span></span><br><span class=\"line\"><span class=\"comment\"># time travelleryou can show black is white by argument said filby</span></span><br><span class=\"line\"><span class=\"comment\"># travelleryou can show black is white by argument said filby</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-2-å¾ªç¯ç¥ç»ç½‘ç»œçš„ç®€æ´å®ç°\">4.2 å¾ªç¯ç¥ç»ç½‘ç»œçš„ç®€æ´å®ç°</h3>\n<p>è™½ç„¶ä»é›¶å¼€å§‹å®ç°å¾ªç¯ç¥ç»ç½‘ç»œå¯¹äº†è§£ç½‘ç»œçš„å®ç°æ–¹å¼å…·æœ‰æŒ‡å¯¼æ„ä¹‰ï¼Œä½†å¹¶ä¸æ–¹ä¾¿ã€‚æœ¬èŠ‚å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¡†æ¶çš„é«˜çº§ API æä¾›çš„å‡½æ•°æ›´æœ‰æ•ˆåœ°å®ç°ç›¸åŒçš„è¯­è¨€æ¨¡å‹ã€‚æˆ‘ä»¬ä»ç„¶ä»è¯»å–æ—¶å…‰æœºå™¨æ•°æ®é›†å¼€å§‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size, num_steps = <span class=\"number\">32</span>, <span class=\"number\">35</span></span><br><span class=\"line\">train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br></pre></td></tr></table></figure>\n<p>é«˜çº§ API æä¾›äº†å¾ªç¯ç¥ç»ç½‘ç»œçš„å®ç°ã€‚æˆ‘ä»¬æ„é€ ä¸€ä¸ªå…·æœ‰256ä¸ªéšè—å•å…ƒçš„å•éšè—å±‚çš„å¾ªç¯ç¥ç»ç½‘ç»œå±‚ <code>rnn_layer</code>ã€‚äº‹å®ä¸Šï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰è®¨è®ºå¤šå±‚å¾ªç¯ç¥ç»ç½‘ç»œçš„æ„ä¹‰ï¼ˆè¿™å°†åœ¨æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œä¸­ä»‹ç»ï¼‰ã€‚ç°åœ¨ä»…éœ€è¦å°†å¤šå±‚ç†è§£ä¸ºä¸€å±‚å¾ªç¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºè¢«ç”¨ä½œä¸‹ä¸€å±‚å¾ªç¯ç¥ç»ç½‘ç»œçš„è¾“å…¥å°±è¶³å¤Ÿäº†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_hiddens = <span class=\"number\">256</span></span><br><span class=\"line\">rnn_layer = nn.RNN(<span class=\"built_in\">len</span>(vocab), num_hiddens)</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬ä½¿ç”¨å¼ é‡æ¥åˆå§‹åŒ–éšçŠ¶æ€ï¼Œå®ƒçš„å½¢çŠ¶æ˜¯ <code>(éšè—å±‚æ•°, æ‰¹é‡å¤§å°, éšè—å•å…ƒæ•°)</code>ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">state = torch.zeros((<span class=\"number\">1</span>, batch_size, num_hiddens))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(state.shape)  <span class=\"comment\"># torch.Size([1, 32, 256])</span></span><br></pre></td></tr></table></figure>\n<p>é€šè¿‡ä¸€ä¸ªéšçŠ¶æ€å’Œä¸€ä¸ªè¾“å…¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨æ›´æ–°åçš„éšçŠ¶æ€è®¡ç®—è¾“å‡ºã€‚éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼Œ<code>rnn_layer</code> çš„è¾“å‡ºï¼ˆ<code>Y</code>ï¼‰ä¸æ¶‰åŠè¾“å‡ºå±‚çš„è®¡ç®—ï¼šå®ƒæ˜¯æŒ‡<strong>æ¯ä¸ªæ—¶é—´æ­¥çš„éšçŠ¶æ€</strong>ï¼Œè¿™äº›éšçŠ¶æ€å¯ä»¥ç”¨ä½œåç»­è¾“å‡ºå±‚çš„è¾“å…¥ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = torch.rand(size=(num_steps, batch_size, <span class=\"built_in\">len</span>(vocab)))</span><br><span class=\"line\">Y, state_new = rnn_layer(X, state)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(Y.shape, state_new.shape)  <span class=\"comment\"># torch.Size([35, 32, 256]) torch.Size([1, 32, 256])</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬ä¸ºä¸€ä¸ªå®Œæ•´çš„å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹å®šä¹‰äº†ä¸€ä¸ª <code>RNNModel</code> ç±»ã€‚æ³¨æ„ï¼Œ<code>rnn_layer</code> åªåŒ…å«éšè—çš„å¾ªç¯å±‚ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„è¾“å‡ºå±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">RNNModel</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, rnn_layer, vocab_size, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(RNNModel, self).__init__(**kwargs)</span><br><span class=\"line\">        self.rnn = rnn_layer</span><br><span class=\"line\">        self.vocab_size = vocab_size</span><br><span class=\"line\">        self.num_hiddens = self.rnn.hidden_size</span><br><span class=\"line\">        <span class=\"comment\"># å¦‚æœRNNæ˜¯åŒå‘çš„ï¼ˆä¹‹åå°†ä»‹ç»ï¼‰ï¼Œnum_directionsåº”è¯¥æ˜¯2ï¼Œå¦åˆ™åº”è¯¥æ˜¯1</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.rnn.bidirectional:</span><br><span class=\"line\">            self.num_directions = <span class=\"number\">1</span></span><br><span class=\"line\">            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.num_directions = <span class=\"number\">2</span></span><br><span class=\"line\">            self.linear = nn.Linear(self.num_hiddens * <span class=\"number\">2</span>, self.vocab_size)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, inputs, state</span>):</span><br><span class=\"line\">        X = F.one_hot(inputs.T.long(), self.vocab_size)</span><br><span class=\"line\">        X = X.to(torch.float32)</span><br><span class=\"line\">        Y, state = self.rnn(X, state)</span><br><span class=\"line\">        <span class=\"comment\"># å…¨è¿æ¥å±‚é¦–å…ˆå°†Yçš„å½¢çŠ¶æ”¹ä¸ºï¼š(æ—¶é—´æ­¥æ•° * æ‰¹é‡å¤§å°, éšè—å•å…ƒæ•°)</span></span><br><span class=\"line\">        <span class=\"comment\"># å®ƒçš„è¾“å‡ºå½¢çŠ¶æ˜¯ï¼š(æ—¶é—´æ­¥æ•° * æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)</span></span><br><span class=\"line\">        output = self.linear(Y.reshape((-<span class=\"number\">1</span>, Y.shape[-<span class=\"number\">1</span>])))  <span class=\"comment\"># (35 * 32, 256) -&gt; (35 * 32, 28)</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> output, state</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">begin_state</span>(<span class=\"params\">self, device, batch_size=<span class=\"number\">1</span></span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(self.rnn, nn.LSTM):</span><br><span class=\"line\">            <span class=\"comment\"># nn.GRUä»¥å¼ é‡ä½œä¸ºéšçŠ¶æ€</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># nn.LSTMä»¥å…ƒç»„ä½œä¸ºéšçŠ¶æ€</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> (torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device),</span><br><span class=\"line\">                    torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device))</span><br></pre></td></tr></table></figure>\n<p>åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬åŸºäºä¸€ä¸ªå…·æœ‰éšæœºæƒé‡çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œ<code>d2l.predict_ch8</code> å‡½æ•°ä¸ä¸Šä¸€èŠ‚ä¸­çš„ <code>predict</code> å‡½æ•°ç›¸åŒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">net = RNNModel(rnn_layer, vocab_size=<span class=\"built_in\">len</span>(vocab))</span><br><span class=\"line\">net = net.to(device)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(d2l.predict_ch8(<span class=\"string\">&#x27;time traveller&#x27;</span>, <span class=\"number\">10</span>, net, vocab, device))  <span class=\"comment\"># time travellerxhhhhhhhhh</span></span><br></pre></td></tr></table></figure>\n<p>å¾ˆæ˜æ˜¾ï¼Œè¿™ç§æ¨¡å‹æ ¹æœ¬ä¸èƒ½è¾“å‡ºå¥½çš„ç»“æœã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸Šä¸€èŠ‚ä¸­å®šä¹‰çš„è¶…å‚æ•°è®­ç»ƒæ¨¡å‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_epoch</span>(<span class=\"params\">net, train_iter, loss_function, optimizer, device, use_random_iter</span>):</span><br><span class=\"line\">    state = <span class=\"literal\">None</span></span><br><span class=\"line\">    train_loss = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, Y <span class=\"keyword\">in</span> tqdm(train_iter):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> state <span class=\"keyword\">is</span> <span class=\"literal\">None</span> <span class=\"keyword\">or</span> use_random_iter:</span><br><span class=\"line\">            state = net.begin_state(batch_size=X.shape[<span class=\"number\">0</span>], device=device)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, nn.Module) <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(state, <span class=\"built_in\">tuple</span>):</span><br><span class=\"line\">                state.detach_()</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> state:</span><br><span class=\"line\">                    s.detach_()</span><br><span class=\"line\">        y = Y.T.reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\">        X, y = X.to(device), y.to(device)</span><br><span class=\"line\">        loss_function.to(device)</span><br><span class=\"line\">        y_hat, state = net(X, state)</span><br><span class=\"line\">        loss = loss_function(y_hat, y.long()).mean()</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        d2l.grad_clipping(net, <span class=\"number\">1</span>)  <span class=\"comment\"># ä¸ä¸Šä¸€èŠ‚ä¸­çš„grad_clippingå‡½æ•°ç›¸åŒ</span></span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">        train_loss.append(loss)  <span class=\"comment\"># å› ä¸ºå·²ç»è°ƒç”¨äº†meanå‡½æ•°</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> math.exp(<span class=\"built_in\">sum</span>(train_loss) / <span class=\"built_in\">len</span>(train_loss))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_iter, vocab, lr, num_epochs, device, use_random_iter=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\">    loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">    optimizer = torch.optim.SGD(net.parameters(), lr)</span><br><span class=\"line\">    pred = <span class=\"keyword\">lambda</span> prefix: d2l.predict_ch8(prefix, <span class=\"number\">50</span>, net, vocab, device)</span><br><span class=\"line\"></span><br><span class=\"line\">    writer = SummaryWriter(<span class=\"string\">&#x27;../logs/RNN_scratch_train_log&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        ppl = train_epoch(net, train_iter, loss_function, optimizer, device, use_random_iter)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % <span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;time traveller&#x27;</span>))</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;Perplexity: <span class=\"subst\">&#123;ppl:<span class=\"number\">.1</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">            writer.add_scalar(<span class=\"string\">&#x27;train_loss&#x27;</span>, ppl, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;time traveller&#x27;</span>))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pred(<span class=\"string\">&#x27;traveller&#x27;</span>))</span><br><span class=\"line\">    writer.close()</span><br><span class=\"line\"></span><br><span class=\"line\">num_epochs, lr = <span class=\"number\">500</span>, <span class=\"number\">1</span></span><br><span class=\"line\">train(net, train_iter, vocab, lr, num_epochs, device)</span><br><span class=\"line\"><span class=\"comment\"># Perplexity: 1.3</span></span><br><span class=\"line\"><span class=\"comment\"># time traveller for so ig will aboca thoursugli gpseknop how stac</span></span><br><span class=\"line\"><span class=\"comment\"># travelleryou can space of the simestiok satt or al and wisc</span></span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/24840.html",
            "url": "https://asanosaki.github.io/posts/24840.html",
            "title": "åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ç¬”è®°(ææ²)-è®¡ç®—æœºè§†è§‰",
            "date_published": "2023-03-10T02:24:00.000Z",
            "content_html": "<blockquote>\n<p>ææ²åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆPyTorchï¼‰è¯¾ç¨‹å­¦ä¹ ç¬”è®°ç¬¬ä¸ƒç« ï¼šè®¡ç®—æœºè§†è§‰ã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-å›¾åƒå¢å¹¿\">1. å›¾åƒå¢å¹¿</h2>\n<p>å›¾åƒå¢å¹¿åœ¨å¯¹è®­ç»ƒå›¾åƒè¿›è¡Œä¸€ç³»åˆ—çš„éšæœºå˜åŒ–ä¹‹åï¼Œç”Ÿæˆç›¸ä¼¼ä½†ä¸åŒçš„è®­ç»ƒæ ·æœ¬ï¼Œä»è€Œæ‰©å¤§äº†è®­ç»ƒé›†çš„è§„æ¨¡ã€‚æ­¤å¤–ï¼Œåº”ç”¨å›¾åƒå¢å¹¿çš„åŸå› æ˜¯ï¼Œéšæœºæ”¹å˜è®­ç»ƒæ ·æœ¬å¯ä»¥å‡å°‘æ¨¡å‹å¯¹æŸäº›å±æ€§çš„ä¾èµ–ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥ä¸åŒçš„æ–¹å¼è£å‰ªå›¾åƒï¼Œä½¿æ„Ÿå…´è¶£çš„å¯¹è±¡å‡ºç°åœ¨ä¸åŒçš„ä½ç½®ï¼Œå‡å°‘æ¨¡å‹å¯¹äºå¯¹è±¡å‡ºç°ä½ç½®çš„ä¾èµ–ã€‚æˆ‘ä»¬è¿˜å¯ä»¥è°ƒæ•´äº®åº¦ã€é¢œè‰²ç­‰å› ç´ æ¥é™ä½æ¨¡å‹å¯¹é¢œè‰²çš„æ•æ„Ÿåº¦ã€‚</p>\n<p>ä¸‹é¢çš„ä»£ç æœ‰50%çš„å‡ ç‡ä½¿å›¾åƒå‘å·¦æˆ–å‘å³ç¿»è½¬ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trans = torchvision.transforms.RandomHorizontalFlip()</span><br></pre></td></tr></table></figure>\n<p>æœ‰50%çš„å‡ ç‡å‘ä¸Šæˆ–å‘ä¸‹ç¿»è½¬ï¼Œæ³¨æ„ï¼Œä¸Šä¸‹ç¿»è½¬å›¾åƒä¸å¦‚å·¦å³å›¾åƒç¿»è½¬é‚£æ ·å¸¸ç”¨ï¼Œéœ€è¦æ ¹æ®æ•°æ®é›†çš„ç‰¹å¾è€ƒè™‘æ˜¯å¦å¯ä»¥å°†å›¾åƒä¸Šä¸‹ç¿»è½¬ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trans = torchvision.transforms.RandomVerticalFlip()</span><br></pre></td></tr></table></figure>\n<p>éšæœºè£å‰ªä¸€ä¸ªé¢ç§¯ä¸ºåŸå§‹é¢ç§¯10%åˆ°100%çš„åŒºåŸŸï¼Œè¯¥åŒºåŸŸçš„å®½é«˜æ¯”ä»0.5~2ä¹‹é—´éšæœºå–å€¼ã€‚ç„¶åï¼ŒåŒºåŸŸçš„å®½åº¦å’Œé«˜åº¦éƒ½è¢«ç¼©æ”¾åˆ°200åƒç´ ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trans = torchvision.transforms.RandomResizedCrop((<span class=\"number\">200</span>, <span class=\"number\">200</span>), scale=(<span class=\"number\">0.1</span>, <span class=\"number\">1</span>), ratio=(<span class=\"number\">0.5</span>, <span class=\"number\">2</span>))</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥æ”¹å˜å›¾åƒé¢œè‰²çš„å››ä¸ªæ–¹é¢ï¼šäº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦å’Œè‰²è°ƒã€‚åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬éšæœºæ›´æ”¹å›¾åƒçš„äº®åº¦ï¼Œéšæœºå€¼ä¸ºåŸå§‹å›¾åƒçš„50%(1 - 0.5)åˆ°150%(1 + 0.5)ä¹‹é—´ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trans = torchvision.transforms.ColorJitter(brightness=<span class=\"number\">0.5</span>, contrast=<span class=\"number\">0</span>, saturation=<span class=\"number\">0</span>, hue=<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<p>åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å°†ç»“åˆå¤šç§å›¾åƒå¢å¹¿æ–¹æ³•ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ä¸€ä¸ª <code>Compose</code> å®ä¾‹æ¥ç»¼åˆä¸Šé¢å®šä¹‰çš„ä¸åŒçš„å›¾åƒå¢å¹¿æ–¹æ³•ï¼Œå¹¶å°†å®ƒä»¬åº”ç”¨åˆ°æ¯ä¸ªå›¾åƒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trans = transforms.Compose([</span><br><span class=\"line\">    transforms.RandomHorizontalFlip(p=<span class=\"number\">0.5</span>),  <span class=\"comment\"># 50%çš„æ¦‚ç‡ä½¿å›¾ç‰‡æ°´å¹³ç¿»è½¬</span></span><br><span class=\"line\">    transforms.ColorJitter(brightness=<span class=\"number\">0.5</span>, contrast=<span class=\"number\">0.5</span>, saturation=<span class=\"number\">0.5</span>, hue=<span class=\"number\">0.5</span>),</span><br><span class=\"line\">    transforms.ToTensor()])</span><br></pre></td></tr></table></figure>\n<p>å›¾åƒå¢å¹¿å¯ä»¥ç›´æ¥ä½œç”¨åœ¨å›¾åƒæ•°æ®ä¸Šï¼Œä¹Ÿå¯ä»¥åœ¨ä½¿ç”¨ <code>torchvision.datasets</code> å¯¼å…¥æ•°æ®é›†çš„æ—¶å€™é€šè¿‡ <code>transform</code> å‚æ•°æŒ‡å®šï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = trans(X)</span><br><span class=\"line\"></span><br><span class=\"line\">cifar_train = torchvision.datasets.CIFAR10(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">True</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-å¾®è°ƒ\">2. å¾®è°ƒ</h2>\n<p>å¾®è°ƒï¼ˆfine-tuningï¼‰æ˜¯è¿ç§»å­¦ä¹ ï¼ˆtransfer learningï¼‰ä¸­çš„å¸¸è§æŠ€å·§ï¼Œå¾®è°ƒåŒ…æ‹¬ä»¥ä¸‹å››ä¸ªæ­¥éª¤ï¼š</p>\n<ul>\n<li>åœ¨æºæ•°æ®é›†ï¼ˆä¾‹å¦‚ ImageNet æ•°æ®é›†ï¼‰ä¸Šé¢„è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå³æºæ¨¡å‹ã€‚</li>\n<li>åˆ›å»ºä¸€ä¸ªæ–°çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå³ç›®æ ‡æ¨¡å‹ã€‚è¿™å°†å¤åˆ¶æºæ¨¡å‹ä¸Šçš„æ‰€æœ‰æ¨¡å‹è®¾è®¡åŠå…¶å‚æ•°ï¼ˆè¾“å‡ºå±‚é™¤å¤–ï¼‰ã€‚æˆ‘ä»¬å‡å®šè¿™äº›æ¨¡å‹å‚æ•°åŒ…å«ä»æºæ•°æ®é›†ä¸­å­¦åˆ°çš„çŸ¥è¯†ï¼Œè¿™äº›çŸ¥è¯†ä¹Ÿå°†é€‚ç”¨äºç›®æ ‡æ•°æ®é›†ã€‚æˆ‘ä»¬è¿˜å‡è®¾æºæ¨¡å‹çš„è¾“å‡ºå±‚ä¸æºæ•°æ®é›†çš„æ ‡ç­¾å¯†åˆ‡ç›¸å…³ï¼›å› æ­¤ä¸åœ¨ç›®æ ‡æ¨¡å‹ä¸­ä½¿ç”¨è¯¥å±‚ã€‚</li>\n<li>å‘ç›®æ ‡æ¨¡å‹æ·»åŠ è¾“å‡ºå±‚ï¼Œå…¶è¾“å‡ºæ•°æ˜¯ç›®æ ‡æ•°æ®é›†ä¸­çš„ç±»åˆ«æ•°ã€‚ç„¶åéšæœºåˆå§‹åŒ–è¯¥å±‚çš„æ¨¡å‹å‚æ•°ã€‚</li>\n<li>åœ¨ç›®æ ‡æ•°æ®é›†ï¼ˆå¦‚æ¤…å­æ•°æ®é›†ï¼‰ä¸Šè®­ç»ƒç›®æ ‡æ¨¡å‹ã€‚è¾“å‡ºå±‚å°†ä»å¤´å¼€å§‹è¿›è¡Œè®­ç»ƒï¼Œè€Œæ‰€æœ‰å…¶ä»–å±‚çš„å‚æ•°å°†æ ¹æ®æºæ¨¡å‹çš„å‚æ•°è¿›è¡Œå¾®è°ƒã€‚</li>\n</ul>\n<p>å½“ç›®æ ‡æ•°æ®é›†æ¯”æºæ•°æ®é›†å°å¾—å¤šæ—¶ï¼Œå¾®è°ƒæœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>\n<p>æˆ‘ä»¬å°†åœ¨ä¸€ä¸ª CIFAR10 æ•°æ®é›†ä¸Šå¾®è°ƒ ResNet-18 æ¨¡å‹ã€‚è¯¥æ¨¡å‹å·²åœ¨ ImageNet æ•°æ®é›†ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> models</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ---------- Data ----------</span></span><br><span class=\"line\">train_trans = transforms.Compose([</span><br><span class=\"line\">    transforms.RandomResizedCrop(<span class=\"number\">224</span>),</span><br><span class=\"line\">    transforms.RandomHorizontalFlip(),</span><br><span class=\"line\">    transforms.ToTensor(),</span><br><span class=\"line\">    <span class=\"comment\"># ä½¿ç”¨ImageNetçš„RGBé€šé“çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä»¥æ ‡å‡†åŒ–æ¯ä¸ªé€šé“</span></span><br><span class=\"line\">    transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>],</span><br><span class=\"line\">                         [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>])])</span><br><span class=\"line\"></span><br><span class=\"line\">test_trans = transforms.Compose([</span><br><span class=\"line\">    transforms.Resize([<span class=\"number\">256</span>, <span class=\"number\">256</span>]),</span><br><span class=\"line\">    transforms.CenterCrop(<span class=\"number\">224</span>),</span><br><span class=\"line\">    transforms.ToTensor(),</span><br><span class=\"line\">    transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>],</span><br><span class=\"line\">                         [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>])])</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">128</span></span><br><span class=\"line\">cifar_train = torchvision.datasets.CIFAR10(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">True</span>, transform=train_trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">cifar_test = torchvision.datasets.CIFAR10(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">False</span>, transform=test_trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">train_iter = data.DataLoader(cifar_train, batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\">test_iter = data.DataLoader(cifar_test, batch_size, shuffle=<span class=\"literal\">False</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ---------- ResNet-18 ----------</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">resnet_model</span>(<span class=\"params\">num_classes, use_pretrained=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">    net = models.resnet18(pretrained=use_pretrained)</span><br><span class=\"line\">    net.fc = nn.Linear(net.fc.in_features, num_classes)</span><br><span class=\"line\">    nn.init.xavier_uniform_(net.fc.weight)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> net</span><br><span class=\"line\"></span><br><span class=\"line\">net = resnet_model(<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ---------- Train ----------</span></span><br><span class=\"line\"><span class=\"comment\"># å¦‚æœparam_group=Trueï¼Œè¾“å‡ºå±‚ä¸­çš„æ¨¡å‹å‚æ•°å°†ä½¿ç”¨åå€çš„å­¦ä¹ ç‡</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_iter, test_iter, num_epochs, lr, device, wd, param_group=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;training on&#x27;</span>, device)</span><br><span class=\"line\">    net.to(device)</span><br><span class=\"line\">    loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">    loss_function.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> param_group:</span><br><span class=\"line\">        params_1x = [param <span class=\"keyword\">for</span> name, param <span class=\"keyword\">in</span> net.named_parameters() <span class=\"keyword\">if</span> name <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> [<span class=\"string\">&quot;fc.weight&quot;</span>, <span class=\"string\">&quot;fc.bias&quot;</span>]]</span><br><span class=\"line\">        optimizer = torch.optim.SGD([&#123;<span class=\"string\">&#x27;params&#x27;</span>: params_1x&#125;,</span><br><span class=\"line\">                                     &#123;<span class=\"string\">&#x27;params&#x27;</span>: net.fc.parameters(), <span class=\"string\">&#x27;lr&#x27;</span>: lr * <span class=\"number\">10</span>&#125;], lr=lr, weight_decay=wd)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd)</span><br><span class=\"line\"></span><br><span class=\"line\">    writer = SummaryWriter(<span class=\"string\">&#x27;../logs/FineTune_CIFAR10_train_log&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    best_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        net.train()</span><br><span class=\"line\">        train_loss = []</span><br><span class=\"line\">        train_acc = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> img, label <span class=\"keyword\">in</span> tqdm(train_iter):</span><br><span class=\"line\">            img, label = img.to(device), label.to(device)</span><br><span class=\"line\">            label_hat = net(img)</span><br><span class=\"line\"></span><br><span class=\"line\">            loss = loss_function(label_hat, label)</span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            loss.backward()</span><br><span class=\"line\">            optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">            label_hat = label_hat.argmax(axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">            acc = (label_hat.<span class=\"built_in\">type</span>(label.dtype) == label).<span class=\"built_in\">float</span>().mean()</span><br><span class=\"line\">            train_loss.append(loss.item())</span><br><span class=\"line\">            train_acc.append(acc)</span><br><span class=\"line\"></span><br><span class=\"line\">        train_loss = <span class=\"built_in\">sum</span>(train_loss) / <span class=\"built_in\">len</span>(train_loss)</span><br><span class=\"line\">        train_acc = <span class=\"built_in\">sum</span>(train_acc) / <span class=\"built_in\">len</span>(train_acc)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;[ Train | <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>:03d&#125;</span>/<span class=\"subst\">&#123;num_epochs:03d&#125;</span> ] loss = <span class=\"subst\">&#123;train_loss:<span class=\"number\">.5</span>f&#125;</span>, acc = <span class=\"subst\">&#123;train_acc:<span class=\"number\">.5</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        net.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">        valid_loss = []</span><br><span class=\"line\">        valid_acc = []</span><br><span class=\"line\">        <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">            <span class=\"keyword\">for</span> img, label <span class=\"keyword\">in</span> tqdm(test_iter):</span><br><span class=\"line\">                img, label = img.to(device), label.to(device)</span><br><span class=\"line\">                label_hat = net(img)</span><br><span class=\"line\">                loss = loss_function(label_hat, label)</span><br><span class=\"line\">                label_hat = label_hat.argmax(axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">                acc = (label_hat.<span class=\"built_in\">type</span>(label.dtype) == label).<span class=\"built_in\">float</span>().mean()</span><br><span class=\"line\">                valid_loss.append(loss.item())</span><br><span class=\"line\">                valid_acc.append(acc)</span><br><span class=\"line\"></span><br><span class=\"line\">        valid_loss = <span class=\"built_in\">sum</span>(valid_loss) / <span class=\"built_in\">len</span>(valid_loss)</span><br><span class=\"line\">        valid_acc = <span class=\"built_in\">sum</span>(valid_acc) / <span class=\"built_in\">len</span>(valid_acc)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;[ Valid | <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>:03d&#125;</span>/<span class=\"subst\">&#123;num_epochs:03d&#125;</span> ] loss = <span class=\"subst\">&#123;valid_loss:<span class=\"number\">.5</span>f&#125;</span>, acc = <span class=\"subst\">&#123;valid_acc:<span class=\"number\">.5</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        writer.add_scalar(<span class=\"string\">&#x27;train_loss&#x27;</span>, train_loss, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\">        writer.add_scalar(<span class=\"string\">&#x27;train_acc&#x27;</span>, train_acc, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\">        writer.add_scalar(<span class=\"string\">&#x27;valid_loss&#x27;</span>, valid_loss, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\">        writer.add_scalar(<span class=\"string\">&#x27;valid_acc&#x27;</span>, valid_acc, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> valid_acc &gt; best_acc:</span><br><span class=\"line\">            best_acc = valid_acc</span><br><span class=\"line\">            torch.save(net.state_dict(), <span class=\"string\">&#x27;../save/FineTune_CIFAR10_train.params&#x27;</span>)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;saving model with acc &#123;:.3f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(best_acc))</span><br><span class=\"line\"></span><br><span class=\"line\">    writer.close()</span><br><span class=\"line\"></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">lr, wd, num_epochs = <span class=\"number\">0.0005</span>, <span class=\"number\">0.001</span>, <span class=\"number\">50</span></span><br><span class=\"line\"></span><br><span class=\"line\">train(net, train_iter, test_iter, num_epochs, lr, device, wd, param_group=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-ç›®æ ‡æ£€æµ‹å’Œè¾¹ç•Œæ¡†\">3. ç›®æ ‡æ£€æµ‹å’Œè¾¹ç•Œæ¡†</h2>\n<p>åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å‡è®¾å›¾åƒä¸­åªæœ‰ä¸€ä¸ªä¸»è¦ç‰©ä½“å¯¹è±¡ï¼Œæˆ‘ä»¬åªå…³æ³¨å¦‚ä½•è¯†åˆ«å…¶ç±»åˆ«ã€‚ç„¶è€Œï¼Œå¾ˆå¤šæ—¶å€™å›¾åƒé‡Œæœ‰å¤šä¸ªæˆ‘ä»¬æ„Ÿå…´è¶£çš„ç›®æ ‡ï¼Œæˆ‘ä»¬ä¸ä»…æƒ³çŸ¥é“å®ƒä»¬çš„ç±»åˆ«ï¼Œè¿˜æƒ³å¾—åˆ°å®ƒä»¬åœ¨å›¾åƒä¸­çš„<strong>å…·ä½“ä½ç½®</strong>ã€‚åœ¨è®¡ç®—æœºè§†è§‰é‡Œï¼Œæˆ‘ä»¬å°†è¿™ç±»ä»»åŠ¡ç§°ä¸º<strong>ç›®æ ‡æ£€æµ‹</strong>ï¼ˆobject detectionï¼‰æˆ–<strong>ç›®æ ‡è¯†åˆ«</strong>ï¼ˆobject recognitionï¼‰ã€‚</p>\n<p>ä¸‹é¢åŠ è½½æœ¬èŠ‚å°†ä½¿ç”¨çš„ç¤ºä¾‹å›¾åƒã€‚å›¾åƒå·¦è¾¹æ˜¯ä¸€åªç‹—ï¼Œå³è¾¹æ˜¯ä¸€åªçŒ«ã€‚å®ƒä»¬æ˜¯è¿™å¼ å›¾åƒé‡Œçš„ä¸¤ä¸ªä¸»è¦ç›®æ ‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">plt.rcParams[<span class=\"string\">&#x27;font.sans-serif&#x27;</span>] = [<span class=\"string\">&#x27;SimHei&#x27;</span>]</span><br><span class=\"line\">plt.rcParams[<span class=\"string\">&#x27;axes.unicode_minus&#x27;</span>] = <span class=\"literal\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(dpi=<span class=\"number\">100</span>, figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">img = plt.imread(<span class=\"string\">&#x27;../images/catdog.jpg&#x27;</span>)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>åœ¨ç›®æ ‡æ£€æµ‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨è¾¹ç•Œæ¡†ï¼ˆbounding boxï¼‰æ¥æè¿°å¯¹è±¡çš„ç©ºé—´ä½ç½®ã€‚è¾¹ç•Œæ¡†æ˜¯çŸ©å½¢çš„ï¼Œç”±çŸ©å½¢å·¦ä¸Šè§’çš„ä»¥åŠå³ä¸‹è§’çš„ <code>x</code> å’Œ <code>y</code> åæ ‡å†³å®šã€‚å¦ä¸€ç§å¸¸ç”¨çš„è¾¹ç•Œæ¡†è¡¨ç¤ºæ–¹æ³•æ˜¯è¾¹ç•Œæ¡†ä¸­å¿ƒçš„ <code>(x, y)</code> è½´åæ ‡ä»¥åŠæ¡†çš„å®½åº¦å’Œé«˜åº¦ã€‚</p>\n<p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®šä¹‰åœ¨è¿™ä¸¤ç§è¡¨ç¤ºæ³•ä¹‹é—´è¿›è¡Œè½¬æ¢çš„å‡½æ•°ï¼š<code>box_corner_to_center</code> ä»ä¸¤è§’è¡¨ç¤ºæ³•è½¬æ¢ä¸ºä¸­å¿ƒå®½åº¦è¡¨ç¤ºæ³•ï¼Œè€Œ <code>box_center_to_corner</code> åä¹‹äº¦ç„¶ã€‚è¾“å…¥å‚æ•° <code>boxes</code> å¯ä»¥æ˜¯é•¿åº¦ä¸º4çš„å¼ é‡ï¼Œä¹Ÿå¯ä»¥æ˜¯å½¢çŠ¶ä¸º <code>(N, 4)</code> çš„äºŒç»´å¼ é‡ï¼Œå…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†çš„æ•°é‡ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">box_corner_to_center</span>(<span class=\"params\">boxes</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä»ï¼ˆå·¦ä¸Šï¼Œå³ä¸‹ï¼‰è½¬æ¢åˆ°ï¼ˆä¸­é—´ï¼Œå®½åº¦ï¼Œé«˜åº¦ï¼‰&quot;&quot;&quot;</span></span><br><span class=\"line\">    x1, y1, x2, y2 = boxes[:, <span class=\"number\">0</span>], boxes[:, <span class=\"number\">1</span>], boxes[:, <span class=\"number\">2</span>], boxes[:, <span class=\"number\">3</span>]</span><br><span class=\"line\">    cx = (x1 + x2) / <span class=\"number\">2</span></span><br><span class=\"line\">    cy = (y1 + y2) / <span class=\"number\">2</span></span><br><span class=\"line\">    w = x2 - x1</span><br><span class=\"line\">    h = y2 - y1</span><br><span class=\"line\">    boxes = torch.stack((cx, cy, w, h), dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> boxes</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">box_center_to_corner</span>(<span class=\"params\">boxes</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä»ï¼ˆä¸­é—´ï¼Œå®½åº¦ï¼Œé«˜åº¦ï¼‰è½¬æ¢åˆ°ï¼ˆå·¦ä¸Šï¼Œå³ä¸‹ï¼‰&quot;&quot;&quot;</span></span><br><span class=\"line\">    cx, cy, w, h = boxes[:, <span class=\"number\">0</span>], boxes[:, <span class=\"number\">1</span>], boxes[:, <span class=\"number\">2</span>], boxes[:, <span class=\"number\">3</span>]</span><br><span class=\"line\">    x1 = cx - <span class=\"number\">0.5</span> * w</span><br><span class=\"line\">    y1 = cy - <span class=\"number\">0.5</span> * h</span><br><span class=\"line\">    x2 = cx + <span class=\"number\">0.5</span> * w</span><br><span class=\"line\">    y2 = cy + <span class=\"number\">0.5</span> * h</span><br><span class=\"line\">    boxes = torch.stack((x1, y1, x2, y2), dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> boxes</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å°†æ ¹æ®åæ ‡ä¿¡æ¯å®šä¹‰å›¾åƒä¸­ç‹—å’ŒçŒ«çš„è¾¹ç•Œæ¡†ã€‚å›¾åƒä¸­åæ ‡çš„åŸç‚¹æ˜¯å›¾åƒçš„å·¦ä¸Šè§’ï¼Œå‘å³çš„æ–¹å‘ä¸º <code>x</code> è½´çš„æ­£æ–¹å‘ï¼Œå‘ä¸‹çš„æ–¹å‘ä¸º <code>y</code> è½´çš„æ­£æ–¹å‘ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># bboxæ˜¯è¾¹ç•Œæ¡†çš„è‹±æ–‡ç¼©å†™</span></span><br><span class=\"line\">dog_bbox, cat_bbox = [<span class=\"number\">60.0</span>, <span class=\"number\">45.0</span>, <span class=\"number\">378.0</span>, <span class=\"number\">516.0</span>], [<span class=\"number\">400.0</span>, <span class=\"number\">112.0</span>, <span class=\"number\">655.0</span>, <span class=\"number\">493.0</span>]</span><br><span class=\"line\">boxes = torch.tensor((dog_bbox, cat_bbox))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(box_center_to_corner(box_corner_to_center(boxes)) == boxes)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[True, True, True, True],</span></span><br><span class=\"line\"><span class=\"comment\">#         [True, True, True, True]])</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥å°†è¾¹ç•Œæ¡†åœ¨å›¾ä¸­ç”»å‡ºï¼Œä»¥æ£€æŸ¥å…¶æ˜¯å¦å‡†ç¡®ã€‚ç”»ä¹‹å‰ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•° <code>bbox_to_rect</code>ã€‚å®ƒå°†è¾¹ç•Œæ¡†è¡¨ç¤ºæˆ <code>matplotlib</code> çš„è¾¹ç•Œæ¡†æ ¼å¼ï¼Œåœ¨å›¾åƒä¸Šæ·»åŠ è¾¹ç•Œæ¡†ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸¤ä¸ªç‰©ä½“çš„ä¸»è¦è½®å»“åŸºæœ¬ä¸Šåœ¨ä¸¤ä¸ªæ¡†å†…ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bbox_to_rect</span>(<span class=\"params\">bbox, color</span>):</span><br><span class=\"line\">    <span class=\"comment\"># å°†è¾¹ç•Œæ¡†(å·¦ä¸Šx, å·¦ä¸Šy, å³ä¸‹x, å³ä¸‹y)æ ¼å¼è½¬æ¢æˆmatplotlibæ ¼å¼ï¼š(xy=(å·¦ä¸Šx, å·¦ä¸Šy), width=å®½, height=é«˜)</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> plt.Rectangle(xy=(bbox[<span class=\"number\">0</span>], bbox[<span class=\"number\">1</span>]), width=bbox[<span class=\"number\">2</span>]-bbox[<span class=\"number\">0</span>], height=bbox[<span class=\"number\">3</span>]-bbox[<span class=\"number\">1</span>],</span><br><span class=\"line\">                         fill=<span class=\"literal\">False</span>, edgecolor=color, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">fig = plt.imshow(img)</span><br><span class=\"line\">fig.axes.add_patch(bbox_to_rect(dog_bbox, <span class=\"string\">&#x27;blue&#x27;</span>))</span><br><span class=\"line\">fig.axes.add_patch(bbox_to_rect(cat_bbox, <span class=\"string\">&#x27;red&#x27;</span>))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-ç›®æ ‡æ£€æµ‹æ•°æ®é›†\">4. ç›®æ ‡æ£€æµ‹æ•°æ®é›†</h2>\n<p>ç›®æ ‡æ£€æµ‹é¢†åŸŸæ²¡æœ‰åƒ MNIST å’Œ Fashion-MNIST é‚£æ ·çš„å°æ•°æ®é›†ã€‚ä¸ºäº†å¿«é€Ÿæµ‹è¯•ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œæˆ‘ä»¬æ”¶é›†å¹¶æ ‡è®°äº†ä¸€ä¸ªå°å‹æ•°æ®é›†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ‹æ‘„äº†ä¸€ç»„é¦™è•‰çš„ç…§ç‰‡ï¼Œå¹¶ç”Ÿæˆäº†1000å¼ ä¸åŒè§’åº¦å’Œå¤§å°çš„é¦™è•‰å›¾åƒã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨ä¸€äº›èƒŒæ™¯å›¾ç‰‡çš„éšæœºä½ç½®ä¸Šæ”¾ä¸€å¼ é¦™è•‰çš„å›¾åƒã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨å›¾ç‰‡ä¸Šä¸ºè¿™äº›é¦™è•‰æ ‡è®°äº†è¾¹ç•Œæ¡†ã€‚</p>\n<p>åŒ…å«æ‰€æœ‰å›¾åƒå’Œ CSV æ ‡ç­¾æ–‡ä»¶çš„é¦™è•‰æ£€æµ‹æ•°æ®é›†å¯ä»¥ç›´æ¥ä»äº’è”ç½‘ä¸‹è½½ï¼Œé€šè¿‡ <code>read_data_bananas</code> å‡½æ•°ï¼Œæˆ‘ä»¬è¯»å–é¦™è•‰æ£€æµ‹æ•°æ®é›†çš„å›¾åƒå’Œæ ‡ç­¾ã€‚è¯¥æ•°æ®é›†çš„ CSV æ–‡ä»¶å†…å«ç›®æ ‡ç±»åˆ«æ ‡ç­¾å’Œä½äºå·¦ä¸Šè§’å’Œå³ä¸‹è§’çš„çœŸå®è¾¹ç•Œæ¡†åæ ‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">plt.rcParams[<span class=\"string\">&#x27;font.sans-serif&#x27;</span>] = [<span class=\"string\">&#x27;SimHei&#x27;</span>]</span><br><span class=\"line\">plt.rcParams[<span class=\"string\">&#x27;axes.unicode_minus&#x27;</span>] = <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader</span><br><span class=\"line\"></span><br><span class=\"line\">d2l.DATA_HUB[<span class=\"string\">&#x27;banana-detection&#x27;</span>] = (d2l.DATA_URL + <span class=\"string\">&#x27;banana-detection.zip&#x27;</span>, <span class=\"string\">&#x27;5de26c8fce5ccdea9f91267273464dc968d20d72&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">read_data_bananas</span>(<span class=\"params\">is_train=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è¯»å–é¦™è•‰æ£€æµ‹æ•°æ®é›†ä¸­çš„å›¾åƒå’Œæ ‡ç­¾&quot;&quot;&quot;</span></span><br><span class=\"line\">    data_dir = d2l.download_extract(<span class=\"string\">&#x27;banana-detection&#x27;</span>)  <span class=\"comment\"># è·¯å¾„ä¸º../data</span></span><br><span class=\"line\">    csv_fname = os.path.join(data_dir, <span class=\"string\">&#x27;bananas_train&#x27;</span> <span class=\"keyword\">if</span> is_train <span class=\"keyword\">else</span> <span class=\"string\">&#x27;bananas_val&#x27;</span>, <span class=\"string\">&#x27;label.csv&#x27;</span>)</span><br><span class=\"line\">    csv_data = pd.read_csv(csv_fname)</span><br><span class=\"line\">    csv_data = csv_data.set_index(<span class=\"string\">&#x27;img_name&#x27;</span>)</span><br><span class=\"line\">    images, targets = [], []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> img_name, target <span class=\"keyword\">in</span> csv_data.iterrows():</span><br><span class=\"line\">        images.append(torchvision.io.read_image(os.path.join(data_dir, <span class=\"string\">&#x27;bananas_train&#x27;</span> <span class=\"keyword\">if</span> is_train <span class=\"keyword\">else</span> <span class=\"string\">&#x27;bananas_val&#x27;</span>, <span class=\"string\">&#x27;images&#x27;</span>, <span class=\"string\">f&#x27;<span class=\"subst\">&#123;img_name&#125;</span>&#x27;</span>)))</span><br><span class=\"line\">        <span class=\"comment\"># è¿™é‡Œçš„targetä¸ºï¼š(ç±»åˆ«, å·¦ä¸Šè§’x, å·¦ä¸Šè§’y, å³ä¸‹è§’x, å³ä¸‹è§’y)ï¼Œå…¶ä¸­æ‰€æœ‰å›¾åƒéƒ½å…·æœ‰ç›¸åŒçš„é¦™è•‰ç±»ï¼ˆç´¢å¼•ä¸º0ï¼‰</span></span><br><span class=\"line\">        targets.append(<span class=\"built_in\">list</span>(target))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> images, torch.tensor(targets).unsqueeze(<span class=\"number\">1</span>) / <span class=\"number\">256</span></span><br></pre></td></tr></table></figure>\n<p>ä»¥ä¸‹ <code>BananasDataset</code> ç±»åˆ«å°†å…è®¸æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰ <code>Dataset</code> å®ä¾‹æ¥åŠ è½½é¦™è•‰æ£€æµ‹æ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">BananasDataset</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä¸€ä¸ªç”¨äºåŠ è½½é¦™è•‰æ£€æµ‹æ•°æ®é›†çš„è‡ªå®šä¹‰æ•°æ®é›†&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, is_train</span>):</span><br><span class=\"line\">        self.features, self.labels = read_data_bananas(is_train)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;read &#x27;</span> + <span class=\"built_in\">str</span>(<span class=\"built_in\">len</span>(self.features)) + (<span class=\"string\">f&#x27; training examples&#x27;</span> <span class=\"keyword\">if</span> is_train <span class=\"keyword\">else</span> <span class=\"string\">f&#x27; validation examples&#x27;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, idx</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (self.features[idx].<span class=\"built_in\">float</span>(), self.labels[idx])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(self.features)</span><br></pre></td></tr></table></figure>\n<p>æœ€åï¼Œæˆ‘ä»¬å®šä¹‰ <code>load_data_bananas</code> å‡½æ•°ï¼Œæ¥ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿”å›ä¸¤ä¸ªæ•°æ®åŠ è½½å™¨å®ä¾‹ã€‚å¯¹äºæµ‹è¯•é›†ï¼Œæ— é¡»æŒ‰éšæœºé¡ºåºè¯»å–å®ƒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_data_bananas</span>(<span class=\"params\">batch_size</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;åŠ è½½é¦™è•‰æ£€æµ‹æ•°æ®é›†&quot;&quot;&quot;</span></span><br><span class=\"line\">    train_iter = DataLoader(BananasDataset(is_train=<span class=\"literal\">True</span>), batch_size, shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    val_iter = DataLoader(BananasDataset(is_train=<span class=\"literal\">False</span>), batch_size)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_iter, val_iter</span><br></pre></td></tr></table></figure>\n<p>è®©æˆ‘ä»¬è¯»å–ä¸€ä¸ªå°æ‰¹é‡ï¼Œå¹¶æ‰“å°å…¶ä¸­çš„å›¾åƒå’Œæ ‡ç­¾çš„å½¢çŠ¶ã€‚å›¾åƒçš„å°æ‰¹é‡çš„å½¢çŠ¶ä¸ºï¼š<code>(æ‰¹é‡å¤§å°, é€šé“æ•°, é«˜åº¦, å®½åº¦)</code>ï¼Œå®ƒä¸æˆ‘ä»¬ä¹‹å‰å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­çš„ç›¸åŒã€‚æ ‡ç­¾çš„å°æ‰¹é‡çš„å½¢çŠ¶ä¸ºï¼š<code>(æ‰¹é‡å¤§å°, M, 5)</code>ï¼Œå…¶ä¸­ M æ˜¯æ•°æ®é›†çš„ä»»ä½•å›¾åƒä¸­è¾¹ç•Œæ¡†å¯èƒ½å‡ºç°çš„æœ€å¤§æ•°é‡ã€‚</p>\n<p>å°æ‰¹é‡è®¡ç®—è™½ç„¶é«˜æ•ˆï¼Œä½†å®ƒè¦æ±‚æ¯å¼ å›¾åƒå«æœ‰ç›¸åŒæ•°é‡çš„è¾¹ç•Œæ¡†ï¼Œä»¥ä¾¿æ”¾åœ¨åŒä¸€ä¸ªæ‰¹é‡ä¸­ã€‚é€šå¸¸æ¥è¯´ï¼Œå›¾åƒå¯èƒ½æ‹¥æœ‰ä¸åŒæ•°é‡ä¸ªè¾¹ç•Œæ¡†ï¼›å› æ­¤ï¼Œåœ¨è¾¾åˆ° M ä¹‹å‰ï¼Œè¾¹ç•Œæ¡†å°‘äº M çš„å›¾åƒå°†è¢«éæ³•è¾¹ç•Œæ¡†å¡«å……ã€‚è¿™æ ·ï¼Œæ¯ä¸ªè¾¹ç•Œæ¡†çš„æ ‡ç­¾å°†è¢«é•¿åº¦ä¸º5çš„æ•°ç»„è¡¨ç¤ºã€‚æ•°ç»„ä¸­çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯è¾¹ç•Œæ¡†ä¸­å¯¹è±¡çš„ç±»åˆ«ï¼Œå…¶ä¸­-1è¡¨ç¤ºç”¨äºå¡«å……çš„éæ³•è¾¹ç•Œæ¡†ã€‚æ•°ç»„çš„å…¶ä½™å››ä¸ªå…ƒç´ æ˜¯è¾¹ç•Œæ¡†å·¦ä¸Šè§’å’Œå³ä¸‹è§’çš„ <code>(x, y)</code> åæ ‡å€¼ï¼ˆå€¼åŸŸåœ¨0~1ä¹‹é—´ï¼‰ã€‚å¯¹äºé¦™è•‰æ•°æ®é›†è€Œè¨€ï¼Œç”±äºæ¯å¼ å›¾åƒä¸Šåªæœ‰ä¸€ä¸ªè¾¹ç•Œæ¡†ï¼Œå› æ­¤ <code>M = 1</code>ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">batch_size, edge_size = <span class=\"number\">32</span>, <span class=\"number\">256</span></span><br><span class=\"line\">train_iter, val_iter = load_data_bananas(batch_size)</span><br><span class=\"line\">features, labels = <span class=\"built_in\">next</span>(<span class=\"built_in\">iter</span>(train_iter))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(features.shape, labels.shape)  <span class=\"comment\"># torch.Size([32, 3, 256, 256]) torch.Size([32, 1, 5])</span></span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥è®©æˆ‘ä»¬å±•ç¤º10å¹…å¸¦æœ‰çœŸå®è¾¹ç•Œæ¡†çš„å›¾åƒã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨æ‰€æœ‰è¿™äº›å›¾åƒä¸­é¦™è•‰çš„æ—‹è½¬è§’åº¦ã€å¤§å°å’Œä½ç½®éƒ½æœ‰æ‰€ä¸åŒã€‚å½“ç„¶ï¼Œè¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„äººå·¥æ•°æ®é›†ï¼Œå®è·µä¸­çœŸå®ä¸–ç•Œçš„æ•°æ®é›†é€šå¸¸è¦å¤æ‚å¾—å¤šï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># d2l.show_images()å‡½æ•°çš„å®ç°</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">show_images</span>(<span class=\"params\">imgs, num_rows, num_cols, titles=<span class=\"literal\">None</span>, scale=<span class=\"number\">1.5</span></span>):</span><br><span class=\"line\">    figsize = (num_cols * scale, num_rows * scale)</span><br><span class=\"line\">    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)</span><br><span class=\"line\">    axes = axes.flatten()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, (ax, img) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(<span class=\"built_in\">zip</span>(axes, imgs)):</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            img = img.numpy()</span><br><span class=\"line\">        <span class=\"keyword\">except</span>:</span><br><span class=\"line\">            <span class=\"keyword\">pass</span></span><br><span class=\"line\">        ax.imshow(img)</span><br><span class=\"line\">        ax.axes.get_xaxis().set_visible(<span class=\"literal\">False</span>)</span><br><span class=\"line\">        ax.axes.get_yaxis().set_visible(<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> titles:</span><br><span class=\"line\">            ax.set_title(titles[i])</span><br><span class=\"line\">    <span class=\"keyword\">return</span> axes</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bbox_to_rect</span>(<span class=\"params\">bbox, color</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> plt.Rectangle(xy=(bbox[<span class=\"number\">0</span>], bbox[<span class=\"number\">1</span>]), width=bbox[<span class=\"number\">2</span>]-bbox[<span class=\"number\">0</span>], height=bbox[<span class=\"number\">3</span>]-bbox[<span class=\"number\">1</span>],</span><br><span class=\"line\">                         fill=<span class=\"literal\">False</span>, edgecolor=color, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">imgs = (features[<span class=\"number\">0</span>:<span class=\"number\">10</span>].permute(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>)) / <span class=\"number\">255</span></span><br><span class=\"line\">axes = show_images(imgs, <span class=\"number\">2</span>, <span class=\"number\">5</span>, scale=<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> ax, label <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(axes, labels[<span class=\"number\">0</span>:<span class=\"number\">10</span>]):</span><br><span class=\"line\">    ax.add_patch(bbox_to_rect(label[<span class=\"number\">0</span>][<span class=\"number\">1</span>:<span class=\"number\">5</span>] * edge_size, color=<span class=\"string\">&#x27;white&#x27;</span>))</span><br><span class=\"line\">    <span class=\"comment\"># d2l.show_bboxes(ax, [label[0][1:5] * edge_size], colors=[&#x27;w&#x27;])  # åŠŸèƒ½ä¸ä¸Šä¸€è¡Œç›¸åŒ</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h2 id=\"5-é”šæ¡†\">5. é”šæ¡†</h2>\n<p>ç”±äºæœ¬èŠ‚éš¾åº¦è¾ƒå¤§ï¼Œå› æ­¤è¯¦ç»†åˆ†æè§ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_computer-vision/anchor.html\">D2L-è®¡ç®—æœºè§†è§‰-é”šæ¡†</a>ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">torch.set_printoptions(<span class=\"number\">2</span>)  <span class=\"comment\"># ç²¾ç®€è¾“å‡ºç²¾åº¦</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">multibox_prior</span>(<span class=\"params\">data, sizes, ratios</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ç”Ÿæˆä»¥æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒå…·æœ‰ä¸åŒå½¢çŠ¶çš„é”šæ¡†&quot;&quot;&quot;</span></span><br><span class=\"line\">    in_height, in_width = data.shape[-<span class=\"number\">2</span>:]</span><br><span class=\"line\">    device, num_sizes, num_ratios = data.device, <span class=\"built_in\">len</span>(sizes), <span class=\"built_in\">len</span>(ratios)</span><br><span class=\"line\">    boxes_per_pixel = (num_sizes + num_ratios - <span class=\"number\">1</span>)</span><br><span class=\"line\">    size_tensor = torch.tensor(sizes, device=device)</span><br><span class=\"line\">    ratio_tensor = torch.tensor(ratios, device=device)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># ä¸ºäº†å°†é”šç‚¹ç§»åŠ¨åˆ°åƒç´ çš„ä¸­å¿ƒï¼Œéœ€è¦è®¾ç½®åç§»é‡ã€‚</span></span><br><span class=\"line\">    <span class=\"comment\"># å› ä¸ºä¸€ä¸ªåƒç´ çš„é«˜ä¸º1ä¸”å®½ä¸º1ï¼Œæˆ‘ä»¬é€‰æ‹©åç§»æˆ‘ä»¬çš„ä¸­å¿ƒ0.5</span></span><br><span class=\"line\">    offset_h, offset_w = <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span></span><br><span class=\"line\">    steps_h = <span class=\"number\">1.0</span> / in_height  <span class=\"comment\"># åœ¨yè½´ä¸Šç¼©æ”¾æ­¥é•¿</span></span><br><span class=\"line\">    steps_w = <span class=\"number\">1.0</span> / in_width  <span class=\"comment\"># åœ¨xè½´ä¸Šç¼©æ”¾æ­¥é•¿</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># ç”Ÿæˆé”šæ¡†çš„æ‰€æœ‰ä¸­å¿ƒç‚¹</span></span><br><span class=\"line\">    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h</span><br><span class=\"line\">    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w</span><br><span class=\"line\">    shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing=<span class=\"string\">&#x27;ij&#x27;</span>)</span><br><span class=\"line\">    shift_y, shift_x = shift_y.reshape(-<span class=\"number\">1</span>), shift_x.reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(center_h.shape)  <span class=\"comment\"># torch.Size([561])</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(shift_y.shape)  <span class=\"comment\"># torch.Size([408408])</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># ç”Ÿæˆâ€œboxes_per_pixelâ€ä¸ªé«˜å’Œå®½ï¼Œä¹‹åç”¨äºåˆ›å»ºé”šæ¡†çš„å››è§’åæ ‡(xmin, xmax, ymin, ymax)</span></span><br><span class=\"line\">    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[<span class=\"number\">0</span>]),</span><br><span class=\"line\">                   sizes[<span class=\"number\">0</span>] * torch.sqrt(ratio_tensor[<span class=\"number\">1</span>:]))) * in_height / in_width  <span class=\"comment\"># å¤„ç†çŸ©å½¢è¾“å…¥</span></span><br><span class=\"line\">    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[<span class=\"number\">0</span>]),</span><br><span class=\"line\">                   sizes[<span class=\"number\">0</span>] / torch.sqrt(ratio_tensor[<span class=\"number\">1</span>:])))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(w.shape)  <span class=\"comment\"># torch.Size([5])</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># é™¤ä»¥2æ¥è·å¾—åŠé«˜å’ŒåŠå®½ä½œä¸ºä¸­å¿ƒç‚¹åˆ°å·¦ä¸Šå’Œå³ä¸‹çš„åç§»é‡ï¼Œrepeat(a, b)è¡¨ç¤ºåœ¨è¡Œä¸Šå¤åˆ¶aå€ï¼Œåœ¨åˆ—ä¸Šå¤åˆ¶bå€</span></span><br><span class=\"line\">    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(in_height * in_width, <span class=\"number\">1</span>) / <span class=\"number\">2</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(anchor_manipulations.shape)  <span class=\"comment\"># torch.Size([2042040, 4])</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># æ¯ä¸ªä¸­å¿ƒç‚¹éƒ½å°†æœ‰â€œboxes_per_pixelâ€ä¸ªé”šæ¡†ï¼Œæ‰€ä»¥ç”Ÿæˆå«æ‰€æœ‰é”šæ¡†ä¸­å¿ƒçš„ç½‘æ ¼ï¼Œé‡å¤äº†â€œboxes_per_pixelâ€æ¬¡</span></span><br><span class=\"line\">    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y], dim=<span class=\"number\">1</span>).repeat_interleave(boxes_per_pixel, dim=<span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(out_grid.shape)  <span class=\"comment\"># torch.Size([2042040, 4])</span></span><br><span class=\"line\">    output = out_grid + anchor_manipulations</span><br><span class=\"line\">    <span class=\"keyword\">return</span> output.unsqueeze(<span class=\"number\">0</span>)  <span class=\"comment\"># å¢åŠ batchç»´åº¦</span></span><br><span class=\"line\"></span><br><span class=\"line\">img = plt.imread(<span class=\"string\">&#x27;../images/catdog.jpg&#x27;</span>)</span><br><span class=\"line\">h, w = img.shape[:<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(h, w)  <span class=\"comment\"># 561 728</span></span><br><span class=\"line\">X = torch.rand(size=(<span class=\"number\">1</span>, <span class=\"number\">3</span>, h, w))</span><br><span class=\"line\">Y = multibox_prior(X, sizes=[<span class=\"number\">0.75</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.25</span>], ratios=[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0.5</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(Y.shape)  <span class=\"comment\"># torch.Size([1, 2042040, 4])</span></span><br><span class=\"line\"></span><br><span class=\"line\">boxes = Y.reshape(h, w, <span class=\"number\">5</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(boxes[<span class=\"number\">250</span>, <span class=\"number\">250</span>, <span class=\"number\">0</span>, :])  <span class=\"comment\"># tensor([0.06, 0.07, 0.63, 0.82])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">show_bboxes</span>(<span class=\"params\">axes, bboxes, labels=<span class=\"literal\">None</span>, colors=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;æ˜¾ç¤ºæ‰€æœ‰è¾¹ç•Œæ¡†&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">_make_list</span>(<span class=\"params\">obj, default_values=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> obj <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            obj = default_values</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> <span class=\"keyword\">not</span> <span class=\"built_in\">isinstance</span>(obj, (<span class=\"built_in\">list</span>, <span class=\"built_in\">tuple</span>)):</span><br><span class=\"line\">            obj = [obj]</span><br><span class=\"line\">        <span class=\"keyword\">return</span> obj</span><br><span class=\"line\"></span><br><span class=\"line\">    labels = _make_list(labels)</span><br><span class=\"line\">    colors = _make_list(colors, [<span class=\"string\">&#x27;b&#x27;</span>, <span class=\"string\">&#x27;g&#x27;</span>, <span class=\"string\">&#x27;r&#x27;</span>, <span class=\"string\">&#x27;m&#x27;</span>, <span class=\"string\">&#x27;c&#x27;</span>])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, bbox <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(bboxes):</span><br><span class=\"line\">        color = colors[i % <span class=\"built_in\">len</span>(colors)]</span><br><span class=\"line\">        rect = d2l.bbox_to_rect(bbox.detach().numpy(), color)</span><br><span class=\"line\">        axes.add_patch(rect)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> labels <span class=\"keyword\">and</span> <span class=\"built_in\">len</span>(labels) &gt; i:</span><br><span class=\"line\">            text_color = <span class=\"string\">&#x27;k&#x27;</span> <span class=\"keyword\">if</span> color == <span class=\"string\">&#x27;w&#x27;</span> <span class=\"keyword\">else</span> <span class=\"string\">&#x27;w&#x27;</span></span><br><span class=\"line\">            axes.text(rect.xy[<span class=\"number\">0</span>], rect.xy[<span class=\"number\">1</span>], labels[i], va=<span class=\"string\">&#x27;center&#x27;</span>, ha=<span class=\"string\">&#x27;center&#x27;</span>,</span><br><span class=\"line\">                      fontsize=<span class=\"number\">9</span>, color=text_color, bbox=<span class=\"built_in\">dict</span>(facecolor=color, lw=<span class=\"number\">0</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(dpi=<span class=\"number\">100</span>)</span><br><span class=\"line\">bbox_scale = torch.tensor((w, h, w, h))  <span class=\"comment\"># ç”¨äºå°†åæ ‡å€¼ä»0~1å¤åŸä¸º0~w(h)</span></span><br><span class=\"line\"><span class=\"comment\"># fig = plt.imshow(img)</span></span><br><span class=\"line\"><span class=\"comment\"># show_bboxes(fig.axes, boxes[250, 250, :, :] * bbox_scale,</span></span><br><span class=\"line\"><span class=\"comment\">#             [&#x27;s=0.75, r=1&#x27;, &#x27;s=0.5, r=1&#x27;, &#x27;s=0.25, r=1&#x27;, &#x27;s=0.75, r=2&#x27;, &#x27;s=0.75, r=0.5&#x27;])</span></span><br><span class=\"line\"><span class=\"comment\"># plt.show()</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">box_iou</span>(<span class=\"params\">boxes1, boxes2</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è®¡ç®—ä¸¤ä¸ªé”šæ¡†æˆ–è¾¹ç•Œæ¡†åˆ—è¡¨ä¸­æˆå¯¹çš„äº¤å¹¶æ¯”&quot;&quot;&quot;</span></span><br><span class=\"line\">    box_area = <span class=\"keyword\">lambda</span> boxes: ((boxes[:, <span class=\"number\">2</span>] - boxes[:, <span class=\"number\">0</span>]) * (boxes[:, <span class=\"number\">3</span>] - boxes[:, <span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"comment\"># boxes1.shape: (boxes1çš„æ•°é‡, 4)</span></span><br><span class=\"line\">    <span class=\"comment\"># boxes2.shape: (boxes2çš„æ•°é‡, 4)</span></span><br><span class=\"line\">    <span class=\"comment\"># areas1.shape: (boxes1çš„æ•°é‡,)</span></span><br><span class=\"line\">    <span class=\"comment\"># areas2.shape: (boxes2çš„æ•°é‡,)</span></span><br><span class=\"line\">    areas1 = box_area(boxes1)</span><br><span class=\"line\">    areas2 = box_area(boxes2)</span><br><span class=\"line\">    <span class=\"comment\"># inter_upperlefts.shape, inter_lowerrights.shape, inters.shape: (boxes1çš„æ•°é‡, boxes2çš„æ•°é‡, 2)</span></span><br><span class=\"line\">    inter_upperlefts = torch.<span class=\"built_in\">max</span>(boxes1[:, <span class=\"literal\">None</span>, :<span class=\"number\">2</span>], boxes2[:, :<span class=\"number\">2</span>])</span><br><span class=\"line\">    inter_lowerrights = torch.<span class=\"built_in\">min</span>(boxes1[:, <span class=\"literal\">None</span>, <span class=\"number\">2</span>:], boxes2[:, <span class=\"number\">2</span>:])</span><br><span class=\"line\">    inters = (inter_lowerrights - inter_upperlefts).clamp(<span class=\"built_in\">min</span>=<span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"comment\"># inter_areas.shape, union_areas.shape: (boxes1çš„æ•°é‡, boxes2çš„æ•°é‡)</span></span><br><span class=\"line\">    inter_areas = inters[:, :, <span class=\"number\">0</span>] * inters[:, :, <span class=\"number\">1</span>]</span><br><span class=\"line\">    union_areas = areas1[:, <span class=\"literal\">None</span>] + areas2 - inter_areas</span><br><span class=\"line\">    <span class=\"keyword\">return</span> inter_areas / union_areas</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">assign_anchor_to_bbox</span>(<span class=\"params\">ground_truth, anchors, device, iou_threshold=<span class=\"number\">0.5</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å°†æœ€æ¥è¿‘çš„çœŸå®è¾¹ç•Œæ¡†åˆ†é…ç»™é”šæ¡†&quot;&quot;&quot;</span></span><br><span class=\"line\">    num_anchors, num_gt_boxes = anchors.shape[<span class=\"number\">0</span>], ground_truth.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    <span class=\"comment\"># ä½äºç¬¬iè¡Œå’Œç¬¬jåˆ—çš„å…ƒç´ x_ijæ˜¯é”šæ¡†iå’ŒçœŸå®è¾¹ç•Œæ¡†jçš„IoU</span></span><br><span class=\"line\">    jaccard = box_iou(anchors, ground_truth)</span><br><span class=\"line\">    <span class=\"comment\"># å¯¹äºæ¯ä¸ªé”šæ¡†ï¼Œåˆ†é…çš„çœŸå®è¾¹ç•Œæ¡†çš„å¼ é‡</span></span><br><span class=\"line\">    anchors_bbox_map = torch.full((num_anchors,), -<span class=\"number\">1</span>, dtype=torch.long, device=device)</span><br><span class=\"line\">    <span class=\"comment\"># æ ¹æ®é˜ˆå€¼ï¼Œå†³å®šæ˜¯å¦åˆ†é…çœŸå®è¾¹ç•Œæ¡†</span></span><br><span class=\"line\">    max_ious, indices = torch.<span class=\"built_in\">max</span>(jaccard, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">    anc_i = torch.nonzero(max_ious &gt;= iou_threshold).reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\">    box_j = indices[max_ious &gt;= iou_threshold]</span><br><span class=\"line\">    anchors_bbox_map[anc_i] = box_j</span><br><span class=\"line\">    col_discard = torch.full((num_anchors,), -<span class=\"number\">1</span>)</span><br><span class=\"line\">    row_discard = torch.full((num_gt_boxes,), -<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_gt_boxes):</span><br><span class=\"line\">        max_idx = torch.argmax(jaccard)</span><br><span class=\"line\">        box_idx = (max_idx % num_gt_boxes).long()</span><br><span class=\"line\">        anc_idx = (max_idx / num_gt_boxes).long()</span><br><span class=\"line\">        anchors_bbox_map[anc_idx] = box_idx</span><br><span class=\"line\">        jaccard[:, box_idx] = col_discard</span><br><span class=\"line\">        jaccard[anc_idx, :] = row_discard</span><br><span class=\"line\">    <span class=\"keyword\">return</span> anchors_bbox_map</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">offset_boxes</span>(<span class=\"params\">anchors, assigned_bb, eps=<span class=\"number\">1e-6</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å¯¹é”šæ¡†åç§»é‡çš„è½¬æ¢&quot;&quot;&quot;</span></span><br><span class=\"line\">    c_anc = d2l.box_corner_to_center(anchors)</span><br><span class=\"line\">    c_assigned_bb = d2l.box_corner_to_center(assigned_bb)</span><br><span class=\"line\">    offset_xy = <span class=\"number\">10</span> * (c_assigned_bb[:, :<span class=\"number\">2</span>] - c_anc[:, :<span class=\"number\">2</span>]) / c_anc[:, <span class=\"number\">2</span>:]</span><br><span class=\"line\">    offset_wh = <span class=\"number\">5</span> * torch.log(eps + c_assigned_bb[:, <span class=\"number\">2</span>:] / c_anc[:, <span class=\"number\">2</span>:])</span><br><span class=\"line\">    offset = torch.cat([offset_xy, offset_wh], dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> offset</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">multibox_target</span>(<span class=\"params\">anchors, labels</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä½¿ç”¨çœŸå®è¾¹ç•Œæ¡†æ ‡è®°é”šæ¡†&quot;&quot;&quot;</span></span><br><span class=\"line\">    batch_size, anchors = labels.shape[<span class=\"number\">0</span>], anchors.squeeze(<span class=\"number\">0</span>)</span><br><span class=\"line\">    batch_offset, batch_mask, batch_class_labels = [], [], []</span><br><span class=\"line\">    device, num_anchors = anchors.device, anchors.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(batch_size):</span><br><span class=\"line\">        label = labels[i, :, :]</span><br><span class=\"line\">        anchors_bbox_map = assign_anchor_to_bbox(label[:, <span class=\"number\">1</span>:], anchors, device)</span><br><span class=\"line\">        bbox_mask = ((anchors_bbox_map &gt;= <span class=\"number\">0</span>).<span class=\"built_in\">float</span>().unsqueeze(-<span class=\"number\">1</span>)).repeat(<span class=\"number\">1</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">        <span class=\"comment\"># å°†ç±»æ ‡ç­¾å’Œåˆ†é…çš„è¾¹ç•Œæ¡†åæ ‡åˆå§‹åŒ–ä¸ºé›¶</span></span><br><span class=\"line\">        class_labels = torch.zeros(num_anchors, dtype=torch.long, device=device)</span><br><span class=\"line\">        assigned_bb = torch.zeros((num_anchors, <span class=\"number\">4</span>), dtype=torch.float32, device=device)</span><br><span class=\"line\">        <span class=\"comment\"># ä½¿ç”¨çœŸå®è¾¹ç•Œæ¡†æ¥æ ‡è®°é”šæ¡†çš„ç±»åˆ«</span></span><br><span class=\"line\">        <span class=\"comment\"># å¦‚æœä¸€ä¸ªé”šæ¡†æ²¡æœ‰è¢«åˆ†é…ï¼Œæ ‡è®°å…¶ä¸ºèƒŒæ™¯ï¼ˆå€¼ä¸ºé›¶ï¼‰</span></span><br><span class=\"line\">        indices_true = torch.nonzero(anchors_bbox_map &gt;= <span class=\"number\">0</span>)</span><br><span class=\"line\">        bb_idx = anchors_bbox_map[indices_true]</span><br><span class=\"line\">        class_labels[indices_true] = label[bb_idx, <span class=\"number\">0</span>].long() + <span class=\"number\">1</span></span><br><span class=\"line\">        assigned_bb[indices_true] = label[bb_idx, <span class=\"number\">1</span>:]</span><br><span class=\"line\">        <span class=\"comment\"># åç§»é‡è½¬æ¢</span></span><br><span class=\"line\">        offset = offset_boxes(anchors, assigned_bb) * bbox_mask</span><br><span class=\"line\">        batch_offset.append(offset.reshape(-<span class=\"number\">1</span>))</span><br><span class=\"line\">        batch_mask.append(bbox_mask.reshape(-<span class=\"number\">1</span>))</span><br><span class=\"line\">        batch_class_labels.append(class_labels)</span><br><span class=\"line\">    bbox_offset = torch.stack(batch_offset)</span><br><span class=\"line\">    bbox_mask = torch.stack(batch_mask)</span><br><span class=\"line\">    class_labels = torch.stack(batch_class_labels)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (bbox_offset, bbox_mask, class_labels)</span><br><span class=\"line\"></span><br><span class=\"line\">ground_truth = torch.tensor([[<span class=\"number\">0</span>, <span class=\"number\">0.1</span>, <span class=\"number\">0.08</span>, <span class=\"number\">0.52</span>, <span class=\"number\">0.92</span>],</span><br><span class=\"line\">                             [<span class=\"number\">1</span>, <span class=\"number\">0.55</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.9</span>, <span class=\"number\">0.88</span>]])</span><br><span class=\"line\">anchors = torch.tensor([[<span class=\"number\">0</span>, <span class=\"number\">0.1</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.3</span>], [<span class=\"number\">0.15</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.4</span>, <span class=\"number\">0.4</span>],</span><br><span class=\"line\">                        [<span class=\"number\">0.63</span>, <span class=\"number\">0.05</span>, <span class=\"number\">0.88</span>, <span class=\"number\">0.98</span>], [<span class=\"number\">0.66</span>, <span class=\"number\">0.45</span>, <span class=\"number\">0.8</span>, <span class=\"number\">0.8</span>],</span><br><span class=\"line\">                        [<span class=\"number\">0.57</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.92</span>, <span class=\"number\">0.9</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># fig = plt.imshow(img)</span></span><br><span class=\"line\"><span class=\"comment\"># show_bboxes(fig.axes, ground_truth[:, 1:] * bbox_scale, [&#x27;dog&#x27;, &#x27;cat&#x27;], &#x27;k&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\"># show_bboxes(fig.axes, anchors * bbox_scale, [&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;])</span></span><br><span class=\"line\"><span class=\"comment\"># plt.show()</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è¿”å›çš„ç»“æœä¸­æœ‰ä¸‰ä¸ªå…ƒç´ ï¼Œéƒ½æ˜¯å¼ é‡æ ¼å¼ã€‚ç¬¬ä¸€ä¸ªå…ƒç´ åŒ…å«äº†ä¸ºæ¯ä¸ªé”šæ¡†æ ‡è®°çš„å››ä¸ªåç§»å€¼ã€‚æ³¨æ„è´Ÿç±»é”šæ¡†çš„åç§»é‡è¢«æ ‡è®°ä¸ºé›¶</span></span><br><span class=\"line\"><span class=\"comment\"># ç¬¬äºŒä¸ªå…ƒç´ æ˜¯æ©ç ï¼ˆmaskï¼‰å˜é‡ï¼Œå½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ï¼Œé”šæ¡†æ•°çš„å››å€ï¼‰</span></span><br><span class=\"line\"><span class=\"comment\"># ç¬¬ä¸‰ä¸ªå…ƒç´ åŒ…å«æ ‡è®°çš„è¾“å…¥é”šæ¡†çš„ç±»åˆ«</span></span><br><span class=\"line\">labels = multibox_target(anchors.unsqueeze(<span class=\"number\">0</span>), ground_truth.unsqueeze(<span class=\"number\">0</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(labels[<span class=\"number\">2</span>])  <span class=\"comment\"># tensor([[0, 1, 2, 0, 2]])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">offset_inverse</span>(<span class=\"params\">anchors, offset_preds</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;æ ¹æ®å¸¦æœ‰é¢„æµ‹åç§»é‡çš„é”šæ¡†æ¥é¢„æµ‹è¾¹ç•Œæ¡†&quot;&quot;&quot;</span></span><br><span class=\"line\">    anc = d2l.box_corner_to_center(anchors)</span><br><span class=\"line\">    pred_bbox_xy = (offset_preds[:, :<span class=\"number\">2</span>] * anc[:, <span class=\"number\">2</span>:] / <span class=\"number\">10</span>) + anc[:, :<span class=\"number\">2</span>]</span><br><span class=\"line\">    pred_bbox_wh = torch.exp(offset_preds[:, <span class=\"number\">2</span>:] / <span class=\"number\">5</span>) * anc[:, <span class=\"number\">2</span>:]</span><br><span class=\"line\">    pred_bbox = torch.cat((pred_bbox_xy, pred_bbox_wh), dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">    predicted_bbox = d2l.box_center_to_corner(pred_bbox)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> predicted_bbox</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">nms</span>(<span class=\"params\">boxes, scores, iou_threshold</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å¯¹é¢„æµ‹è¾¹ç•Œæ¡†çš„ç½®ä¿¡åº¦è¿›è¡Œæ’åº&quot;&quot;&quot;</span></span><br><span class=\"line\">    B = torch.argsort(scores, dim=-<span class=\"number\">1</span>, descending=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    keep = []  <span class=\"comment\"># ä¿ç•™é¢„æµ‹è¾¹ç•Œæ¡†çš„æŒ‡æ ‡</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> B.numel() &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        i = B[<span class=\"number\">0</span>]</span><br><span class=\"line\">        keep.append(i)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> B.numel() == <span class=\"number\">1</span>: <span class=\"keyword\">break</span></span><br><span class=\"line\">        iou = box_iou(boxes[i, :].reshape(-<span class=\"number\">1</span>, <span class=\"number\">4</span>), boxes[B[<span class=\"number\">1</span>:], :].reshape(-<span class=\"number\">1</span>, <span class=\"number\">4</span>)).reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\">        inds = torch.nonzero(torch.as_tensor(iou &lt;= iou_threshold, dtype=torch.float32)).reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\">        B = B[inds + <span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.tensor(keep, device=boxes.device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">multibox_detection</span>(<span class=\"params\">cls_probs, offset_preds, anchors, nms_threshold=<span class=\"number\">0.5</span>, pos_threshold=<span class=\"number\">0.009999999</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶æ¥é¢„æµ‹è¾¹ç•Œæ¡†&quot;&quot;&quot;</span></span><br><span class=\"line\">    device, batch_size = cls_probs.device, cls_probs.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    anchors = anchors.squeeze(<span class=\"number\">0</span>)</span><br><span class=\"line\">    num_classes, num_anchors = cls_probs.shape[<span class=\"number\">1</span>], cls_probs.shape[<span class=\"number\">2</span>]</span><br><span class=\"line\">    out = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(batch_size):</span><br><span class=\"line\">        cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape(-<span class=\"number\">1</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">        conf, class_id = torch.<span class=\"built_in\">max</span>(cls_prob[<span class=\"number\">1</span>:], <span class=\"number\">0</span>)</span><br><span class=\"line\">        predicted_bb = offset_inverse(anchors, offset_pred)</span><br><span class=\"line\">        keep = nms(predicted_bb, conf, nms_threshold)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># æ‰¾åˆ°æ‰€æœ‰çš„non_keepç´¢å¼•ï¼Œå¹¶å°†ç±»è®¾ç½®ä¸ºèƒŒæ™¯</span></span><br><span class=\"line\">        all_idx = torch.arange(num_anchors, dtype=torch.long, device=device)</span><br><span class=\"line\">        combined = torch.cat((keep, all_idx))</span><br><span class=\"line\">        uniques, counts = combined.unique(return_counts=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        non_keep = uniques[counts == <span class=\"number\">1</span>]</span><br><span class=\"line\">        all_id_sorted = torch.cat((keep, non_keep))</span><br><span class=\"line\">        class_id[non_keep] = -<span class=\"number\">1</span></span><br><span class=\"line\">        class_id = class_id[all_id_sorted]</span><br><span class=\"line\">        conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted]</span><br><span class=\"line\">        <span class=\"comment\"># pos_thresholdæ˜¯ä¸€ä¸ªç”¨äºéèƒŒæ™¯é¢„æµ‹çš„é˜ˆå€¼</span></span><br><span class=\"line\">        below_min_idx = (conf &lt; pos_threshold)</span><br><span class=\"line\">        class_id[below_min_idx] = -<span class=\"number\">1</span></span><br><span class=\"line\">        conf[below_min_idx] = <span class=\"number\">1</span> - conf[below_min_idx]</span><br><span class=\"line\">        pred_info = torch.cat((class_id.unsqueeze(<span class=\"number\">1</span>), conf.unsqueeze(<span class=\"number\">1</span>), predicted_bb), dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        out.append(pred_info)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.stack(out)</span><br><span class=\"line\"></span><br><span class=\"line\">anchors = torch.tensor([[<span class=\"number\">0.1</span>, <span class=\"number\">0.08</span>, <span class=\"number\">0.52</span>, <span class=\"number\">0.92</span>], [<span class=\"number\">0.08</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.56</span>, <span class=\"number\">0.95</span>],</span><br><span class=\"line\">                        [<span class=\"number\">0.15</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.62</span>, <span class=\"number\">0.91</span>], [<span class=\"number\">0.55</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.9</span>, <span class=\"number\">0.88</span>]])</span><br><span class=\"line\">offset_preds = torch.tensor([<span class=\"number\">0</span>] * anchors.numel())</span><br><span class=\"line\">cls_probs = torch.tensor([[<span class=\"number\">0</span>] * <span class=\"number\">4</span>,  <span class=\"comment\"># èƒŒæ™¯çš„é¢„æµ‹æ¦‚ç‡</span></span><br><span class=\"line\">                          [<span class=\"number\">0.9</span>, <span class=\"number\">0.8</span>, <span class=\"number\">0.7</span>, <span class=\"number\">0.1</span>],  <span class=\"comment\"># ç‹—çš„é¢„æµ‹æ¦‚ç‡</span></span><br><span class=\"line\">                          [<span class=\"number\">0.1</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.9</span>]])  <span class=\"comment\"># çŒ«çš„é¢„æµ‹æ¦‚ç‡</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># fig = plt.imshow(img)</span></span><br><span class=\"line\"><span class=\"comment\"># show_bboxes(fig.axes, anchors * bbox_scale, [&#x27;dog=0.9&#x27;, &#x27;dog=0.8&#x27;, &#x27;dog=0.7&#x27;, &#x27;cat=0.9&#x27;])</span></span><br><span class=\"line\"><span class=\"comment\"># plt.show()</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è¿”å›ç»“æœçš„å½¢çŠ¶æ˜¯ï¼ˆæ‰¹é‡å¤§å°ï¼Œé”šæ¡†çš„æ•°é‡ï¼Œ6ï¼‰</span></span><br><span class=\"line\"><span class=\"comment\"># ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯é¢„æµ‹çš„ç±»ç´¢å¼•ï¼Œä»0å¼€å§‹ï¼ˆ0ä»£è¡¨ç‹—ï¼Œ1ä»£è¡¨çŒ«ï¼‰ï¼Œå€¼-1è¡¨ç¤ºèƒŒæ™¯æˆ–åœ¨éæå¤§å€¼æŠ‘åˆ¶ä¸­è¢«ç§»é™¤äº†</span></span><br><span class=\"line\"><span class=\"comment\"># ç¬¬äºŒä¸ªå…ƒç´ æ˜¯é¢„æµ‹çš„è¾¹ç•Œæ¡†çš„ç½®ä¿¡åº¦</span></span><br><span class=\"line\"><span class=\"comment\"># å…¶ä½™å››ä¸ªå…ƒç´ åˆ†åˆ«æ˜¯é¢„æµ‹è¾¹ç•Œæ¡†å·¦ä¸Šè§’å’Œå³ä¸‹è§’çš„åæ ‡ï¼ˆèŒƒå›´ä»‹äº0~1ä¹‹é—´ï¼‰</span></span><br><span class=\"line\">output = multibox_detection(cls_probs.unsqueeze(<span class=\"number\">0</span>),</span><br><span class=\"line\">                            offset_preds.unsqueeze(<span class=\"number\">0</span>),</span><br><span class=\"line\">                            anchors.unsqueeze(<span class=\"number\">0</span>),</span><br><span class=\"line\">                            nms_threshold=<span class=\"number\">0.5</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[ 0.00,  0.90,  0.10,  0.08,  0.52,  0.92],</span></span><br><span class=\"line\"><span class=\"comment\">#          [ 1.00,  0.90,  0.55,  0.20,  0.90,  0.88],</span></span><br><span class=\"line\"><span class=\"comment\">#          [-1.00,  0.80,  0.08,  0.20,  0.56,  0.95],</span></span><br><span class=\"line\"><span class=\"comment\">#          [-1.00,  0.70,  0.15,  0.30,  0.62,  0.91]]])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># åˆ é™¤-1ç±»åˆ«ï¼ˆèƒŒæ™¯ï¼‰çš„é¢„æµ‹è¾¹ç•Œæ¡†åï¼Œæˆ‘ä»¬å¯ä»¥è¾“å‡ºç”±éæå¤§å€¼æŠ‘åˆ¶ä¿å­˜çš„æœ€ç»ˆé¢„æµ‹è¾¹ç•Œæ¡†</span></span><br><span class=\"line\">fig = plt.imshow(img)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> output[<span class=\"number\">0</span>].detach().numpy():</span><br><span class=\"line\">    <span class=\"keyword\">if</span> i[<span class=\"number\">0</span>] == -<span class=\"number\">1</span>:</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\">    label = (<span class=\"string\">&#x27;dog=&#x27;</span>, <span class=\"string\">&#x27;cat=&#x27;</span>)[<span class=\"built_in\">int</span>(i[<span class=\"number\">0</span>])] + <span class=\"built_in\">str</span>(i[<span class=\"number\">1</span>])</span><br><span class=\"line\">    show_bboxes(fig.axes, [torch.tensor(i[<span class=\"number\">2</span>:]) * bbox_scale], label)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<h2 id=\"6-å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹\">6. å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹</h2>\n<p>åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»¥è¾“å…¥å›¾åƒçš„æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒï¼Œç”Ÿæˆäº†å¤šä¸ªé”šæ¡†ã€‚åŸºæœ¬è€Œè¨€ï¼Œè¿™äº›é”šæ¡†ä»£è¡¨äº†å›¾åƒä¸åŒåŒºåŸŸçš„æ ·æœ¬ã€‚ç„¶è€Œï¼Œå¦‚æœä¸ºæ¯ä¸ªåƒç´ éƒ½ç”Ÿæˆçš„é”šæ¡†ï¼Œæˆ‘ä»¬æœ€ç»ˆå¯èƒ½ä¼šå¾—åˆ°å¤ªå¤šéœ€è¦è®¡ç®—çš„é”šæ¡†ã€‚æƒ³è±¡ä¸€ä¸ª561*728çš„è¾“å…¥å›¾åƒï¼Œå¦‚æœä»¥æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒç”Ÿæˆäº”ä¸ªå½¢çŠ¶ä¸åŒçš„é”šæ¡†ï¼Œå°±éœ€è¦åœ¨å›¾åƒä¸Šæ ‡è®°å’Œé¢„æµ‹è¶…è¿‡200ä¸‡ä¸ªé”šæ¡†ï¼ˆ561*728*5ï¼‰ã€‚</p>\n<h3 id=\"6-1-å¤šå°ºåº¦é”šæ¡†\">6.1 å¤šå°ºåº¦é”šæ¡†</h3>\n<p>å‡å°‘å›¾åƒä¸Šçš„é”šæ¡†æ•°é‡å¹¶ä¸å›°éš¾ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¾“å…¥å›¾åƒä¸­å‡åŒ€é‡‡æ ·ä¸€å°éƒ¨åˆ†åƒç´ ï¼Œå¹¶ä»¥å®ƒä»¬ä¸ºä¸­å¿ƒç”Ÿæˆé”šæ¡†ã€‚æ­¤å¤–ï¼Œåœ¨ä¸åŒå°ºåº¦ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆä¸åŒæ•°é‡å’Œä¸åŒå¤§å°çš„é”šæ¡†ã€‚ç›´è§‚åœ°è¯´ï¼Œæ¯”èµ·è¾ƒå¤§çš„ç›®æ ‡ï¼Œè¾ƒå°çš„ç›®æ ‡åœ¨å›¾åƒä¸Šå‡ºç°çš„å¯èƒ½æ€§æ›´å¤šæ ·ã€‚ä¾‹å¦‚ï¼Œ1*1ã€1*2å’Œ2*2çš„ç›®æ ‡å¯ä»¥åˆ†åˆ«ä»¥4ã€2å’Œ1ç§å¯èƒ½çš„æ–¹å¼å‡ºç°åœ¨2*2çš„å›¾åƒä¸Šã€‚å› æ­¤ï¼Œå½“ä½¿ç”¨è¾ƒå°çš„é”šæ¡†æ£€æµ‹è¾ƒå°çš„ç‰©ä½“æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡æ ·æ›´å¤šçš„åŒºåŸŸï¼Œè€Œå¯¹äºè¾ƒå¤§çš„ç‰©ä½“ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡æ ·è¾ƒå°‘çš„åŒºåŸŸã€‚</p>\n<p>ä¸ºäº†æ¼”ç¤ºå¦‚ä½•åœ¨å¤šä¸ªå°ºåº¦ä¸‹ç”Ÿæˆé”šæ¡†ï¼Œè®©æˆ‘ä»¬å…ˆè¯»å–ä¸€å¼ å›¾åƒã€‚å®ƒçš„é«˜åº¦å’Œå®½åº¦åˆ†åˆ«ä¸º561å’Œ728åƒç´ ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">img = plt.imread(<span class=\"string\">&#x27;../images/catdog.jpg&#x27;</span>)</span><br><span class=\"line\">h, w = img.shape[:<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(h, w)  <span class=\"comment\"># 561 728</span></span><br></pre></td></tr></table></figure>\n<p><code>display_anchors</code> å‡½æ•°å®šä¹‰å¦‚ä¸‹ã€‚æˆ‘ä»¬åœ¨<strong>ç‰¹å¾å›¾</strong>ï¼ˆfmapï¼‰ä¸Šç”Ÿæˆé”šæ¡†ï¼ˆanchorsï¼‰ï¼Œæ¯ä¸ªå•ä½ï¼ˆåƒç´ ï¼‰ä½œä¸ºé”šæ¡†çš„ä¸­å¿ƒã€‚ç”±äºé”šæ¡†ä¸­çš„ <code>(x, y)</code> è½´åæ ‡å€¼ï¼ˆanchorsï¼‰å·²ç»è¢«é™¤ä»¥ç‰¹å¾å›¾ï¼ˆfmapï¼‰çš„å®½åº¦å’Œé«˜åº¦ï¼Œå› æ­¤è¿™äº›å€¼ä»‹äº0å’Œ1ä¹‹é—´ï¼Œè¡¨ç¤ºç‰¹å¾å›¾ä¸­é”šæ¡†çš„ç›¸å¯¹ä½ç½®ã€‚</p>\n<p>ç”±äºé”šæ¡†ï¼ˆanchorsï¼‰çš„ä¸­å¿ƒåˆ†å¸ƒäºç‰¹å¾å›¾ï¼ˆfmapï¼‰ä¸Šçš„æ‰€æœ‰å•ä½ï¼Œå› æ­¤è¿™äº›ä¸­å¿ƒå¿…é¡»æ ¹æ®å…¶ç›¸å¯¹ç©ºé—´ä½ç½®åœ¨ä»»ä½•è¾“å…¥å›¾åƒä¸Šå‡åŒ€åˆ†å¸ƒã€‚æ›´å…·ä½“åœ°è¯´ï¼Œç»™å®šç‰¹å¾å›¾çš„å®½åº¦å’Œé«˜åº¦ <code>fmap_w</code> å’Œ <code>fmap_h</code>ï¼Œä»¥ä¸‹å‡½æ•°å°†å‡åŒ€åœ°å¯¹ä»»ä½•è¾“å…¥å›¾åƒä¸­ <code>fmap_h</code> è¡Œå’Œ <code>fmap_w</code> åˆ—ä¸­çš„åƒç´ è¿›è¡Œé‡‡æ ·ã€‚ä»¥è¿™äº›å‡åŒ€é‡‡æ ·çš„åƒç´ ä¸ºä¸­å¿ƒï¼Œå°†ä¼šç”Ÿæˆå¤§å°ä¸º <code>s</code>ï¼ˆå‡è®¾åˆ—è¡¨ <code>s</code> çš„é•¿åº¦ä¸º1ï¼‰ä¸”å®½é«˜æ¯”ï¼ˆratiosï¼‰ä¸åŒçš„é”šæ¡†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">display_anchors</span>(<span class=\"params\">fmap_w, fmap_h, s</span>):</span><br><span class=\"line\">    plt.figure(dpi=<span class=\"number\">100</span>)</span><br><span class=\"line\">    <span class=\"comment\"># å‰ä¸¤ä¸ªç»´åº¦ä¸Šçš„å€¼ä¸å½±å“è¾“å‡º</span></span><br><span class=\"line\">    fmap = torch.zeros((<span class=\"number\">1</span>, <span class=\"number\">10</span>, fmap_h, fmap_w))</span><br><span class=\"line\">    anchors = d2l.multibox_prior(fmap, sizes=s, ratios=[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0.5</span>])</span><br><span class=\"line\">    bbox_scale = torch.tensor((w, h, w, h))</span><br><span class=\"line\">    d2l.show_bboxes(plt.imshow(img).axes, anchors[<span class=\"number\">0</span>] * bbox_scale)</span><br><span class=\"line\">    plt.show()</span><br></pre></td></tr></table></figure>\n<p>é¦–å…ˆï¼Œè®©æˆ‘ä»¬è€ƒè™‘æ¢æµ‹å°ç›®æ ‡ã€‚ä¸ºäº†åœ¨æ˜¾ç¤ºæ—¶æ›´å®¹æ˜“åˆ†è¾¨ï¼Œåœ¨è¿™é‡Œå…·æœ‰ä¸åŒä¸­å¿ƒçš„é”šæ¡†ä¸ä¼šé‡å ï¼šé”šæ¡†çš„å°ºåº¦è®¾ç½®ä¸º0.15ï¼Œç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦è®¾ç½®ä¸º4ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå›¾åƒä¸Š4è¡Œå’Œ4åˆ—çš„é”šæ¡†çš„ä¸­å¿ƒæ˜¯å‡åŒ€åˆ†å¸ƒçš„ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">display_anchors(fmap_w=<span class=\"number\">4</span>, fmap_h=<span class=\"number\">4</span>, s=[<span class=\"number\">0.15</span>])</span><br></pre></td></tr></table></figure>\n<p>ç„¶åï¼Œæˆ‘ä»¬å°†ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦å‡å°ä¸€åŠï¼Œç„¶åä½¿ç”¨è¾ƒå¤§çš„é”šæ¡†æ¥æ£€æµ‹è¾ƒå¤§çš„ç›®æ ‡ã€‚å½“å°ºåº¦è®¾ç½®ä¸º0.4æ—¶ï¼Œä¸€äº›é”šæ¡†å°†å½¼æ­¤é‡å ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">display_anchors(fmap_w=<span class=\"number\">2</span>, fmap_h=<span class=\"number\">2</span>, s=[<span class=\"number\">0.4</span>])</span><br></pre></td></tr></table></figure>\n<p>æœ€åï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å°†ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦å‡å°ä¸€åŠï¼Œç„¶åå°†é”šæ¡†çš„å°ºåº¦å¢åŠ åˆ°0.8ã€‚æ­¤æ—¶ï¼Œé”šæ¡†çš„ä¸­å¿ƒå³æ˜¯å›¾åƒçš„ä¸­å¿ƒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">display_anchors(fmap_w=<span class=\"number\">1</span>, fmap_h=<span class=\"number\">1</span>, s=[<span class=\"number\">0.8</span>])</span><br></pre></td></tr></table></figure>\n<h3 id=\"6-2-å¤šå°ºåº¦æ£€æµ‹\">6.2 å¤šå°ºåº¦æ£€æµ‹</h3>\n<p>æ—¢ç„¶æˆ‘ä»¬å·²ç»ç”Ÿæˆäº†å¤šå°ºåº¦çš„é”šæ¡†ï¼Œæˆ‘ä»¬å°±å°†ä½¿ç”¨å®ƒä»¬æ¥æ£€æµ‹ä¸åŒå°ºåº¦ä¸‹å„ç§å¤§å°çš„ç›®æ ‡ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬ä»‹ç»ä¸€ç§åŸºäº CNN çš„å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹æ–¹æ³•ï¼Œå°†åœ¨ç¬¬8èŠ‚ï¼ˆSSDï¼‰ä¸­å®ç°ã€‚</p>\n<p>åœ¨æŸç§è§„æ¨¡ä¸Šï¼Œå‡è®¾æˆ‘ä»¬æœ‰ <code>c</code> å¼ å½¢çŠ¶ä¸º <code>h * w</code> çš„ç‰¹å¾å›¾ã€‚ä½¿ç”¨ä¸Šä¸€å°èŠ‚ä¸­çš„æ–¹æ³•ï¼Œæˆ‘ä»¬ç”Ÿæˆäº† <code>hw</code> ç»„é”šæ¡†ï¼Œå…¶ä¸­æ¯ç»„éƒ½æœ‰ <code>a</code> ä¸ªä¸­å¿ƒç›¸åŒçš„é”šæ¡†ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸Šä¸€å°èŠ‚å®éªŒçš„ç¬¬ä¸€ä¸ªå°ºåº¦ä¸Šï¼Œç»™å®š10ä¸ªï¼ˆé€šé“æ•°é‡ï¼‰<code>4 * 4</code> çš„ç‰¹å¾å›¾ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†16ç»„é”šæ¡†ï¼Œæ¯ç»„åŒ…å«3ä¸ªä¸­å¿ƒç›¸åŒçš„é”šæ¡†ã€‚æ¥ä¸‹æ¥ï¼Œæ¯ä¸ªé”šæ¡†éƒ½æ ¹æ®çœŸå®å€¼è¾¹ç•Œæ¡†æ¥æ ‡è®°äº†ç±»å’Œåç§»é‡ã€‚åœ¨å½“å‰å°ºåº¦ä¸‹ï¼Œç›®æ ‡æ£€æµ‹æ¨¡å‹éœ€è¦é¢„æµ‹è¾“å…¥å›¾åƒä¸Š <code>hw</code> ç»„é”šæ¡†ç±»åˆ«å’Œåç§»é‡ï¼Œå…¶ä¸­ä¸åŒç»„é”šæ¡†å…·æœ‰ä¸åŒçš„ä¸­å¿ƒã€‚</p>\n<p>å‡è®¾æ­¤å¤„çš„ <code>c</code> å¼ ç‰¹å¾å›¾æ˜¯ CNN åŸºäºè¾“å…¥å›¾åƒçš„æ­£å‘ä¼ æ’­ç®—æ³•è·å¾—çš„ä¸­é—´è¾“å‡ºã€‚æ—¢ç„¶æ¯å¼ ç‰¹å¾å›¾ä¸Šéƒ½æœ‰ <code>hw</code> ä¸ªä¸åŒçš„ç©ºé—´ä½ç½®ï¼Œé‚£ä¹ˆç›¸åŒç©ºé—´ä½ç½®å¯ä»¥çœ‹ä½œå«æœ‰ <code>c</code> ä¸ªå•å…ƒã€‚æ ¹æ®æ„Ÿå—é‡çš„å®šä¹‰ï¼Œç‰¹å¾å›¾åœ¨ç›¸åŒç©ºé—´ä½ç½®çš„ <code>c</code> ä¸ªå•å…ƒåœ¨è¾“å…¥å›¾åƒä¸Šçš„æ„Ÿå—é‡ç›¸åŒï¼šå®ƒä»¬è¡¨å¾äº†åŒä¸€æ„Ÿå—é‡å†…çš„è¾“å…¥å›¾åƒä¿¡æ¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°†ç‰¹å¾å›¾åœ¨åŒä¸€ç©ºé—´ä½ç½®çš„ <code>c</code> ä¸ªå•å…ƒå˜æ¢ä¸ºä½¿ç”¨æ­¤ç©ºé—´ä½ç½®ç”Ÿæˆçš„ <code>a</code> ä¸ªé”šæ¡†ç±»åˆ«å’Œåç§»é‡ã€‚æœ¬è´¨ä¸Šï¼Œæˆ‘ä»¬ç”¨è¾“å…¥å›¾åƒåœ¨æŸä¸ªæ„Ÿå—é‡åŒºåŸŸå†…çš„ä¿¡æ¯ï¼Œæ¥é¢„æµ‹è¾“å…¥å›¾åƒä¸Šä¸è¯¥åŒºåŸŸä½ç½®ç›¸è¿‘çš„é”šæ¡†ç±»åˆ«å’Œåç§»é‡ã€‚</p>\n<p>å½“ä¸åŒå±‚çš„ç‰¹å¾å›¾åœ¨è¾“å…¥å›¾åƒä¸Šåˆ†åˆ«æ‹¥æœ‰ä¸åŒå¤§å°çš„æ„Ÿå—é‡æ—¶ï¼Œå®ƒä»¬å¯ä»¥ç”¨äºæ£€æµ‹ä¸åŒå¤§å°çš„ç›®æ ‡ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è®¾è®¡ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå…¶ä¸­é è¿‘è¾“å‡ºå±‚çš„ç‰¹å¾å›¾å•å…ƒå…·æœ‰æ›´å®½çš„æ„Ÿå—é‡ï¼Œè¿™æ ·å®ƒä»¬å°±å¯ä»¥ä»è¾“å…¥å›¾åƒä¸­æ£€æµ‹åˆ°è¾ƒå¤§çš„ç›®æ ‡ã€‚</p>\n<p>ç®€è¨€ä¹‹ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨æ·±å±‚ç¥ç»ç½‘ç»œåœ¨å¤šä¸ªå±‚æ¬¡ä¸Šå¯¹å›¾åƒè¿›è¡Œåˆ†å±‚è¡¨ç¤ºï¼Œä»è€Œå®ç°å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹ã€‚åœ¨ç¬¬8èŠ‚æˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ªå…·ä½“çš„ä¾‹å­æ¥è¯´æ˜å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚</p>\n<h2 id=\"7-åŒºåŸŸå·ç§¯ç¥ç»ç½‘ç»œï¼ˆR-CNNï¼‰ç³»åˆ—\">7. åŒºåŸŸå·ç§¯ç¥ç»ç½‘ç»œï¼ˆR-CNNï¼‰ç³»åˆ—</h2>\n<h3 id=\"7-1-R-CNN\">7.1 R-CNN</h3>\n<p>R-CNN é¦–å…ˆä»è¾“å…¥å›¾åƒä¸­é€‰å–è‹¥å¹²ï¼ˆä¾‹å¦‚2000ä¸ªï¼‰æè®®åŒºåŸŸï¼ˆå¦‚é”šæ¡†ä¹Ÿæ˜¯ä¸€ç§é€‰å–æ–¹æ³•ï¼‰ï¼Œå¹¶æ ‡æ³¨å®ƒä»¬çš„ç±»åˆ«å’Œè¾¹ç•Œæ¡†ï¼ˆå¦‚åç§»é‡ï¼‰ã€‚ç„¶åï¼Œç”¨å·ç§¯ç¥ç»ç½‘ç»œå¯¹æ¯ä¸ªæè®®åŒºåŸŸè¿›è¡Œå‰å‘ä¼ æ’­ä»¥æŠ½å–å…¶ç‰¹å¾ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç”¨æ¯ä¸ªæè®®åŒºåŸŸçš„ç‰¹å¾æ¥é¢„æµ‹ç±»åˆ«å’Œè¾¹ç•Œæ¡†ã€‚å…·ä½“æ¥è¯´ï¼ŒR-CNN åŒ…æ‹¬ä»¥ä¸‹å››ä¸ªæ­¥éª¤ï¼š</p>\n<ol>\n<li>å¯¹è¾“å…¥å›¾åƒä½¿ç”¨é€‰æ‹©æ€§æœç´¢æ¥é€‰å–å¤šä¸ªé«˜è´¨é‡çš„æè®®åŒºåŸŸã€‚è¿™äº›æè®®åŒºåŸŸé€šå¸¸æ˜¯åœ¨å¤šä¸ªå°ºåº¦ä¸‹é€‰å–çš„ï¼Œå¹¶å…·æœ‰ä¸åŒçš„å½¢çŠ¶å’Œå¤§å°ã€‚æ¯ä¸ªæè®®åŒºåŸŸéƒ½å°†è¢«æ ‡æ³¨ç±»åˆ«å’ŒçœŸå®è¾¹ç•Œæ¡†ï¼›</li>\n<li>é€‰æ‹©ä¸€ä¸ªé¢„è®­ç»ƒçš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œå¹¶å°†å…¶åœ¨è¾“å‡ºå±‚ä¹‹å‰æˆªæ–­ã€‚å°†æ¯ä¸ªæè®®åŒºåŸŸå˜å½¢ä¸ºç½‘ç»œéœ€è¦çš„è¾“å…¥å°ºå¯¸ï¼Œå¹¶é€šè¿‡å‰å‘ä¼ æ’­è¾“å‡ºæŠ½å–çš„æè®®åŒºåŸŸç‰¹å¾ï¼›</li>\n<li>å°†æ¯ä¸ªæè®®åŒºåŸŸçš„ç‰¹å¾è¿åŒå…¶æ ‡æ³¨çš„ç±»åˆ«ä½œä¸ºä¸€ä¸ªæ ·æœ¬ã€‚è®­ç»ƒå¤šä¸ªæ”¯æŒå‘é‡æœºå¯¹ç›®æ ‡åˆ†ç±»ï¼Œå…¶ä¸­æ¯ä¸ªæ”¯æŒå‘é‡æœºç”¨æ¥åˆ¤æ–­æ ·æœ¬æ˜¯å¦å±äºæŸä¸€ä¸ªç±»åˆ«ï¼›</li>\n<li>å°†æ¯ä¸ªæè®®åŒºåŸŸçš„ç‰¹å¾è¿åŒå…¶æ ‡æ³¨çš„è¾¹ç•Œæ¡†ä½œä¸ºä¸€ä¸ªæ ·æœ¬ï¼Œè®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹æ¥é¢„æµ‹çœŸå®è¾¹ç•Œæ¡†ã€‚</li>\n</ol>\n<p>å°½ç®¡ R-CNN æ¨¡å‹é€šè¿‡é¢„è®­ç»ƒçš„å·ç§¯ç¥ç»ç½‘ç»œæœ‰æ•ˆåœ°æŠ½å–äº†å›¾åƒç‰¹å¾ï¼Œä½†å®ƒçš„é€Ÿåº¦å¾ˆæ…¢ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½ä»ä¸€å¼ å›¾åƒä¸­é€‰å‡ºä¸Šåƒä¸ªæè®®åŒºåŸŸï¼Œè¿™éœ€è¦ä¸Šåƒæ¬¡çš„å·ç§¯ç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­æ¥æ‰§è¡Œç›®æ ‡æ£€æµ‹ã€‚è¿™ç§åºå¤§çš„è®¡ç®—é‡ä½¿å¾— R-CNN åœ¨ç°å®ä¸–ç•Œä¸­éš¾ä»¥è¢«å¹¿æ³›åº”ç”¨ã€‚</p>\n<h3 id=\"7-2-Fast-R-CNN\">7.2 Fast R-CNN</h3>\n<p>R-CNN çš„ä¸»è¦æ€§èƒ½ç“¶é¢ˆåœ¨äºï¼Œå¯¹æ¯ä¸ªæè®®åŒºåŸŸï¼Œå·ç§¯ç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­æ˜¯ç‹¬ç«‹çš„ï¼Œè€Œæ²¡æœ‰å…±äº«è®¡ç®—ã€‚ç”±äºè¿™äº›åŒºåŸŸé€šå¸¸æœ‰é‡å ï¼Œç‹¬ç«‹çš„ç‰¹å¾æŠ½å–ä¼šå¯¼è‡´é‡å¤çš„è®¡ç®—ã€‚Fast R-CNN å¯¹ R-CNN çš„ä¸»è¦æ”¹è¿›ä¹‹ä¸€ï¼Œæ˜¯ä»…åœ¨<strong>æ•´å¼ å›¾åƒ</strong>ä¸Šæ‰§è¡Œå·ç§¯ç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­ã€‚Fast R-CNN çš„ä¸»è¦è®¡ç®—å¦‚ä¸‹ï¼š</p>\n<ol>\n<li>ä¸ R-CNN ç›¸æ¯”ï¼ŒFast R-CNN ç”¨æ¥æå–ç‰¹å¾çš„å…¥å·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å…¥æ˜¯æ•´ä¸ªå›¾åƒï¼Œè€Œä¸æ˜¯å„ä¸ªæè®®åŒºåŸŸã€‚æ­¤å¤–ï¼Œè¿™ä¸ªç½‘ç»œé€šå¸¸ä¼šå‚ä¸è®­ç»ƒã€‚è®¾è¾“å…¥ä¸ºä¸€å¼ å›¾åƒï¼Œå°†å·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºçš„å½¢çŠ¶è®°ä¸º <code>1 * c * h1 * w1</code>ï¼›</li>\n<li>å‡è®¾é€‰æ‹©æ€§æœç´¢ç”Ÿæˆäº† <code>n</code> ä¸ªæè®®åŒºåŸŸã€‚è¿™äº›å½¢çŠ¶å„å¼‚çš„æè®®åŒºåŸŸåœ¨å·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºä¸Šåˆ†åˆ«æ ‡å‡ºäº†å½¢çŠ¶å„å¼‚çš„å…´è¶£åŒºåŸŸã€‚ç„¶åï¼Œè¿™äº›æ„Ÿå…´è¶£çš„åŒºåŸŸéœ€è¦è¿›ä¸€æ­¥æŠ½å–å‡º<strong>å½¢çŠ¶ç›¸åŒ</strong>çš„ç‰¹å¾ï¼ˆæ¯”å¦‚æŒ‡å®šé«˜åº¦ <code>h2</code> å’Œå®½åº¦ <code>w2</code>ï¼‰ï¼Œä»¥ä¾¿äºè¿ç»“åè¾“å‡ºã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼ŒFast R-CNN å¼•å…¥äº†<strong>å…´è¶£åŒºåŸŸæ±‡èšå±‚</strong>ï¼ˆRoI poolingï¼‰ï¼šå°†å·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºå’Œæè®®åŒºåŸŸä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºè¿ç»“åçš„å„ä¸ªæè®®åŒºåŸŸæŠ½å–çš„ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º <code>n * c * h2 * w2</code>ï¼›</li>\n<li>é€šè¿‡å…¨è¿æ¥å±‚å°†è¾“å‡ºå½¢çŠ¶å˜æ¢ä¸º <code>n * d</code>ï¼Œå…¶ä¸­è¶…å‚æ•° <code>d</code> å–å†³äºæ¨¡å‹è®¾è®¡ï¼›</li>\n<li>é¢„æµ‹ <code>n</code> ä¸ªæè®®åŒºåŸŸä¸­æ¯ä¸ªåŒºåŸŸçš„ç±»åˆ«å’Œè¾¹ç•Œæ¡†ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œåœ¨é¢„æµ‹ç±»åˆ«å’Œè¾¹ç•Œæ¡†æ—¶ï¼Œå°†å…¨è¿æ¥å±‚çš„è¾“å‡ºåˆ†åˆ«è½¬æ¢ä¸ºå½¢çŠ¶ä¸º <code>n * q</code>ï¼ˆ<code>q</code> æ˜¯ç±»åˆ«çš„æ•°é‡ï¼‰çš„è¾“å‡ºå’Œå½¢çŠ¶ä¸º <code>n * 4</code> çš„è¾“å‡ºã€‚å…¶ä¸­é¢„æµ‹ç±»åˆ«æ—¶ä½¿ç”¨ Softmax å›å½’ã€‚</li>\n</ol>\n<p>ä¸‹é¢ï¼Œæˆ‘ä»¬æ¼”ç¤ºäº†å…´è¶£åŒºåŸŸæ±‡èšå±‚çš„è®¡ç®—æ–¹æ³•ã€‚å‡è®¾å·ç§¯ç¥ç»ç½‘ç»œæŠ½å–çš„ç‰¹å¾ <code>X</code> çš„é«˜åº¦å’Œå®½åº¦éƒ½æ˜¯4ï¼Œä¸”åªæœ‰å•é€šé“ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"></span><br><span class=\"line\">X = torch.arange(<span class=\"number\">16.</span>).reshape(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(X)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[[ 0.,  1.,  2.,  3.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [ 4.,  5.,  6.,  7.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [ 8.,  9., 10., 11.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [12., 13., 14., 15.]]]])</span></span><br></pre></td></tr></table></figure>\n<p>è®©æˆ‘ä»¬è¿›ä¸€æ­¥å‡è®¾è¾“å…¥å›¾åƒçš„é«˜åº¦å’Œå®½åº¦éƒ½æ˜¯40åƒç´ ï¼Œä¸”é€‰æ‹©æ€§æœç´¢åœ¨æ­¤å›¾åƒä¸Šç”Ÿæˆäº†ä¸¤ä¸ªæè®®åŒºåŸŸã€‚æ¯ä¸ªåŒºåŸŸç”±5ä¸ªå…ƒç´ è¡¨ç¤ºï¼šåŒºåŸŸç›®æ ‡ç±»åˆ«ã€å·¦ä¸Šè§’å’Œå³ä¸‹è§’çš„ <code>(x, y)</code> åæ ‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rois = torch.Tensor([[<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">20</span>, <span class=\"number\">20</span>], [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">10</span>, <span class=\"number\">30</span>, <span class=\"number\">30</span>]])</span><br></pre></td></tr></table></figure>\n<p>ç”±äº <code>X</code> çš„é«˜å’Œå®½æ˜¯è¾“å…¥å›¾åƒé«˜å’Œå®½çš„1/10ï¼Œå› æ­¤ï¼Œä¸¤ä¸ªæè®®åŒºåŸŸçš„åæ ‡å…ˆæŒ‰ <code>spatial_scale</code> ä¹˜ä»¥0.1ã€‚ç„¶åï¼Œåœ¨ <code>X</code> ä¸Šåˆ†åˆ«æ ‡å‡ºè¿™ä¸¤ä¸ªå…´è¶£åŒºåŸŸ <code>X[:, :, 0:3, 0:3]</code> å’Œ <code>X[:, :, 1:4, 0:4]</code>ã€‚æœ€åï¼Œåœ¨ <code>2 * 2</code> çš„å…´è¶£åŒºåŸŸæ±‡èšå±‚ä¸­ï¼Œæ¯ä¸ªå…´è¶£åŒºåŸŸè¢«åˆ’åˆ†ä¸ºå­çª—å£ç½‘æ ¼ï¼Œå¹¶è¿›ä¸€æ­¥æŠ½å–ç›¸åŒå½¢çŠ¶ <code>2 * 2</code> çš„ç‰¹å¾ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(torchvision.ops.roi_pool(X, rois, output_size=(<span class=\"number\">2</span>, <span class=\"number\">2</span>), spatial_scale=<span class=\"number\">0.1</span>))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[[ 5.,  6.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [ 9., 10.]]],</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#         [[[ 9., 11.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [13., 15.]]]])</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"7-3-Faster-R-CNN\">7.3 Faster R-CNN</h3>\n<p>ä¸ºäº†è¾ƒç²¾ç¡®åœ°æ£€æµ‹ç›®æ ‡ç»“æœï¼ŒFast R-CNN æ¨¡å‹é€šå¸¸éœ€è¦åœ¨é€‰æ‹©æ€§æœç´¢ä¸­ç”Ÿæˆå¤§é‡çš„æè®®åŒºåŸŸã€‚Faster R-CNN æå‡ºå°†é€‰æ‹©æ€§æœç´¢æ›¿æ¢ä¸º<strong>åŒºåŸŸæè®®ç½‘ç»œ</strong>ï¼ˆregion proposal networkï¼‰ï¼Œä»è€Œå‡å°‘æè®®åŒºåŸŸçš„ç”Ÿæˆæ•°é‡ï¼Œå¹¶ä¿è¯ç›®æ ‡æ£€æµ‹çš„ç²¾åº¦ã€‚å…·ä½“æ¥è¯´ï¼ŒåŒºåŸŸæè®®ç½‘ç»œçš„è®¡ç®—æ­¥éª¤å¦‚ä¸‹ï¼š</p>\n<ol>\n<li>ä½¿ç”¨å¡«å……ä¸º1çš„ <code>3 * 3</code> çš„å·ç§¯å±‚å˜æ¢å·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºï¼Œå¹¶å°†è¾“å‡ºé€šé“æ•°è®°ä¸º <code>c</code>ã€‚è¿™æ ·ï¼Œå·ç§¯ç¥ç»ç½‘ç»œä¸ºå›¾åƒæŠ½å–çš„ç‰¹å¾å›¾ä¸­çš„æ¯ä¸ªå•å…ƒå‡å¾—åˆ°ä¸€ä¸ªé•¿åº¦ä¸º <code>c</code> çš„æ–°ç‰¹å¾ï¼›</li>\n<li>ä»¥ç‰¹å¾å›¾çš„æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒï¼Œç”Ÿæˆå¤šä¸ªä¸åŒå¤§å°å’Œå®½é«˜æ¯”çš„é”šæ¡†å¹¶æ ‡æ³¨å®ƒä»¬ï¼›</li>\n<li>ä½¿ç”¨é”šæ¡†ä¸­å¿ƒå•å…ƒé•¿åº¦ä¸º <code>c</code> çš„ç‰¹å¾ï¼Œåˆ†åˆ«é¢„æµ‹è¯¥é”šæ¡†çš„äºŒå…ƒç±»åˆ«ï¼ˆå«ç›®æ ‡è¿˜æ˜¯èƒŒæ™¯ï¼‰å’Œè¾¹ç•Œæ¡†ï¼›</li>\n<li>ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶ï¼Œä»é¢„æµ‹ç±»åˆ«ä¸ºç›®æ ‡çš„é¢„æµ‹è¾¹ç•Œæ¡†ä¸­ç§»é™¤ç›¸ä¼¼çš„ç»“æœã€‚æœ€ç»ˆè¾“å‡ºçš„é¢„æµ‹è¾¹ç•Œæ¡†å³æ˜¯å…´è¶£åŒºåŸŸæ±‡èšå±‚æ‰€éœ€çš„æè®®åŒºåŸŸã€‚</li>\n</ol>\n<p>å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒåŒºåŸŸæè®®ç½‘ç»œä½œä¸º Faster R-CNN æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œæ˜¯å’Œæ•´ä¸ªæ¨¡å‹ä¸€èµ·è®­ç»ƒå¾—åˆ°çš„ã€‚æ¢å¥è¯è¯´ï¼ŒFaster R-CNN çš„ç›®æ ‡å‡½æ•°ä¸ä»…åŒ…æ‹¬ç›®æ ‡æ£€æµ‹ä¸­çš„ç±»åˆ«å’Œè¾¹ç•Œæ¡†é¢„æµ‹ï¼Œè¿˜åŒ…æ‹¬åŒºåŸŸæè®®ç½‘ç»œä¸­é”šæ¡†çš„äºŒå…ƒç±»åˆ«å’Œè¾¹ç•Œæ¡†é¢„æµ‹ã€‚ä½œä¸ºç«¯åˆ°ç«¯è®­ç»ƒçš„ç»“æœï¼ŒåŒºåŸŸæè®®ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ åˆ°å¦‚ä½•ç”Ÿæˆé«˜è´¨é‡çš„æè®®åŒºåŸŸï¼Œä»è€Œåœ¨å‡å°‘äº†ä»æ•°æ®ä¸­å­¦ä¹ çš„æè®®åŒºåŸŸçš„æ•°é‡çš„æƒ…å†µä¸‹ï¼Œä»ä¿æŒç›®æ ‡æ£€æµ‹çš„ç²¾åº¦ã€‚</p>\n<h3 id=\"7-4-Mask-R-CNN\">7.4 Mask R-CNN</h3>\n<p>å¦‚æœåœ¨è®­ç»ƒé›†ä¸­è¿˜æ ‡æ³¨äº†æ¯ä¸ªç›®æ ‡åœ¨å›¾åƒä¸Šçš„<strong>åƒç´ çº§ä½ç½®</strong>ï¼Œé‚£ä¹ˆ Mask R-CNN èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨è¿™äº›è¯¦å°½çš„æ ‡æ³¨ä¿¡æ¯è¿›ä¸€æ­¥æå‡ç›®æ ‡æ£€æµ‹çš„ç²¾åº¦ã€‚</p>\n<p>Mask R-CNN æ˜¯åŸºäº Faster R-CNN ä¿®æ”¹è€Œæ¥çš„ã€‚å…·ä½“æ¥è¯´ï¼ŒMask R-CNN å°†å…´è¶£åŒºåŸŸæ±‡èšå±‚æ›¿æ¢ä¸ºäº†å…´è¶£åŒºåŸŸå¯¹é½å±‚ï¼ˆRoI Alignï¼‰ï¼Œä½¿ç”¨åŒçº¿æ€§æ’å€¼ï¼ˆbilinear interpolationï¼‰æ¥ä¿ç•™ç‰¹å¾å›¾ä¸Šçš„ç©ºé—´ä¿¡æ¯ï¼Œä»è€Œæ›´é€‚äºåƒç´ çº§é¢„æµ‹ã€‚å…´è¶£åŒºåŸŸå¯¹é½å±‚çš„è¾“å‡ºåŒ…å«äº†æ‰€æœ‰ä¸å…´è¶£åŒºåŸŸçš„å½¢çŠ¶ç›¸åŒçš„ç‰¹å¾å›¾ã€‚å®ƒä»¬ä¸ä»…è¢«ç”¨äºé¢„æµ‹æ¯ä¸ªå…´è¶£åŒºåŸŸçš„ç±»åˆ«å’Œè¾¹ç•Œæ¡†ï¼Œè¿˜é€šè¿‡é¢å¤–çš„å…¨å·ç§¯ç½‘ç»œé¢„æµ‹ç›®æ ‡çš„åƒç´ çº§ä½ç½®ã€‚æœ¬ç« çš„åç»­ç« èŠ‚å°†æ›´è¯¦ç»†åœ°ä»‹ç»å¦‚ä½•ä½¿ç”¨å…¨å·ç§¯ç½‘ç»œé¢„æµ‹å›¾åƒä¸­åƒç´ çº§çš„è¯­ä¹‰ã€‚</p>\n<h2 id=\"8-å•å‘å¤šæ¡†æ£€æµ‹ï¼ˆSSDï¼‰\">8. å•å‘å¤šæ¡†æ£€æµ‹ï¼ˆSSDï¼‰</h2>\n<p>SSD æ¨¡å‹ä¸»è¦ç”±åŸºç¡€ç½‘ç»œç»„æˆï¼Œå…¶åæ˜¯å‡ ä¸ªå¤šå°ºåº¦ç‰¹å¾å—ã€‚åŸºæœ¬ç½‘ç»œç”¨äºä»è¾“å…¥å›¾åƒä¸­æå–ç‰¹å¾ï¼Œå› æ­¤å®ƒå¯ä»¥ä½¿ç”¨æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œã€‚å•å‘å¤šæ¡†æ£€æµ‹è®ºæ–‡ä¸­é€‰ç”¨äº†åœ¨åˆ†ç±»å±‚ä¹‹å‰æˆªæ–­çš„ VGGï¼Œç°åœ¨ä¹Ÿå¸¸ç”¨ ResNet æ›¿ä»£ã€‚æˆ‘ä»¬å¯ä»¥è®¾è®¡åŸºç¡€ç½‘ç»œï¼Œä½¿å®ƒè¾“å‡ºçš„é«˜å’Œå®½è¾ƒå¤§ã€‚è¿™æ ·ä¸€æ¥ï¼ŒåŸºäºè¯¥ç‰¹å¾å›¾ç”Ÿæˆçš„é”šæ¡†æ•°é‡è¾ƒå¤šï¼Œå¯ä»¥ç”¨æ¥æ£€æµ‹å°ºå¯¸è¾ƒå°çš„ç›®æ ‡ã€‚æ¥ä¸‹æ¥çš„æ¯ä¸ªå¤šå°ºåº¦ç‰¹å¾å—å°†ä¸Šä¸€å±‚æä¾›çš„ç‰¹å¾å›¾çš„é«˜å’Œå®½ç¼©å°ï¼ˆå¦‚å‡åŠï¼‰ï¼Œå¹¶ä½¿ç‰¹å¾å›¾ä¸­æ¯ä¸ªå•å…ƒåœ¨è¾“å…¥å›¾åƒä¸Šçš„æ„Ÿå—é‡å˜å¾—æ›´å¹¿é˜”ã€‚</p>\n<p>å›æƒ³ä¸€ä¸‹åœ¨ç¬¬6èŠ‚ä¸­ï¼Œé€šè¿‡æ·±åº¦ç¥ç»ç½‘ç»œåˆ†å±‚è¡¨ç¤ºå›¾åƒçš„å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹çš„è®¾è®¡ã€‚ç”±äºæ¥è¿‘é¡¶éƒ¨çš„å¤šå°ºåº¦ç‰¹å¾å›¾è¾ƒå°ï¼Œä½†å…·æœ‰è¾ƒå¤§çš„æ„Ÿå—é‡ï¼Œå®ƒä»¬é€‚åˆæ£€æµ‹è¾ƒå°‘ä½†è¾ƒå¤§çš„ç‰©ä½“ã€‚ç®€è€Œè¨€ä¹‹ï¼Œé€šè¿‡å¤šå°ºåº¦ç‰¹å¾å—ï¼Œå•å‘å¤šæ¡†æ£€æµ‹ç”Ÿæˆä¸åŒå¤§å°çš„é”šæ¡†ï¼Œå¹¶é€šè¿‡é¢„æµ‹è¾¹ç•Œæ¡†çš„ç±»åˆ«å’Œåç§»é‡æ¥æ£€æµ‹å¤§å°ä¸åŒçš„ç›®æ ‡ï¼Œå› æ­¤è¿™æ˜¯ä¸€ä¸ªå¤šå°ºåº¦ç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚</p>\n<h3 id=\"8-1-ç±»åˆ«é¢„æµ‹å±‚ä¸è¾¹ç•Œæ¡†é¢„æµ‹å±‚\">8.1 ç±»åˆ«é¢„æµ‹å±‚ä¸è¾¹ç•Œæ¡†é¢„æµ‹å±‚</h3>\n<p>è®¾ç›®æ ‡ç±»åˆ«çš„æ•°é‡ä¸º <code>q</code>ã€‚è¿™æ ·ä¸€æ¥ï¼Œé”šæ¡†æœ‰ <code>q + 1</code> ä¸ªç±»åˆ«ï¼Œå…¶ä¸­ç¬¬0ç±»æ˜¯èƒŒæ™¯ã€‚åœ¨æŸä¸ªå°ºåº¦ä¸‹ï¼Œè®¾ç‰¹å¾å›¾çš„é«˜å’Œå®½åˆ†åˆ«ä¸º <code>h</code> å’Œ <code>w</code>ã€‚å¦‚æœä»¥å…¶ä¸­æ¯ä¸ªå•å…ƒä¸ºä¸­å¿ƒç”Ÿæˆ <code>a</code> ä¸ªé”šæ¡†ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦å¯¹ <code>hwa</code> ä¸ªé”šæ¡†è¿›è¡Œåˆ†ç±»ã€‚å¦‚æœä½¿ç”¨å…¨è¿æ¥å±‚ä½œä¸ºè¾“å‡ºï¼Œå¾ˆå®¹æ˜“å¯¼è‡´æ¨¡å‹å‚æ•°è¿‡å¤šã€‚å›å¿† NiN ä¸€èŠ‚ä»‹ç»çš„ä½¿ç”¨å·ç§¯å±‚çš„é€šé“æ¥è¾“å‡ºç±»åˆ«é¢„æµ‹çš„æ–¹æ³•ï¼Œå•å‘å¤šæ¡†æ£€æµ‹é‡‡ç”¨åŒæ ·çš„æ–¹æ³•æ¥é™ä½æ¨¡å‹å¤æ‚åº¦ã€‚</p>\n<p>å…·ä½“æ¥è¯´ï¼Œç±»åˆ«é¢„æµ‹å±‚ä½¿ç”¨ä¸€ä¸ªä¿æŒè¾“å…¥é«˜å’Œå®½çš„å·ç§¯å±‚ã€‚è¿™æ ·ä¸€æ¥ï¼Œè¾“å‡ºå’Œè¾“å…¥åœ¨ç‰¹å¾å›¾å®½å’Œé«˜ä¸Šçš„ç©ºé—´åæ ‡ä¸€ä¸€å¯¹åº”ã€‚è€ƒè™‘è¾“å‡ºå’Œè¾“å…¥åŒä¸€ç©ºé—´åæ ‡ <code>(x, y)</code>ï¼šè¾“å‡ºç‰¹å¾å›¾ä¸Š <code>(x, y)</code> åæ ‡çš„é€šé“é‡ŒåŒ…å«äº†ä»¥è¾“å…¥ç‰¹å¾å›¾ <code>(x, y)</code> åæ ‡ä¸ºä¸­å¿ƒç”Ÿæˆçš„æ‰€æœ‰é”šæ¡†çš„ç±»åˆ«é¢„æµ‹ã€‚å› æ­¤è¾“å‡ºé€šé“æ•°ä¸º <code>a * (q + 1)</code>ã€‚</p>\n<p>ç±»åˆ«é¢„æµ‹å±‚çš„å®šä¹‰å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># num_inputsä¸ºè¾“å…¥é€šé“æ•°ï¼Œ(num_classes + 1)è¡¨ç¤ºè¿˜æœ‰ä¸€ä¸ªèƒŒæ™¯ç±»ï¼Œå› ä¸ºéœ€è¦é¢„æµ‹æ¯ä¸ªé”šæ¡†æ˜¯å“ªä¸ªç±»å› æ­¤è¾“å‡ºé€šé“è¦ä¹˜ä»¥num_anchors</span></span><br><span class=\"line\"><span class=\"comment\"># å³å¯¹äºè¾“å…¥çš„æ¯ä¸€ä¸ªåƒç´ ï¼Œå®ƒçš„è¾“å‡ºé€šé“æ•°å°±æ˜¯ä»¥è¯¥åƒç´ ä¸ºä¸­å¿ƒçš„num_anchorsä¸ªé”šæ¡†çš„é¢„æµ‹å€¼</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cls_predictor</span>(<span class=\"params\">num_inputs, num_anchors, num_classes</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Conv2d(num_inputs, num_anchors * (num_classes + <span class=\"number\">1</span>), kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<p>è¾¹ç•Œæ¡†é¢„æµ‹å±‚çš„è®¾è®¡ä¸ç±»åˆ«é¢„æµ‹å±‚çš„è®¾è®¡ç±»ä¼¼ã€‚å”¯ä¸€ä¸åŒçš„æ˜¯ï¼Œè¿™é‡Œéœ€è¦ä¸ºæ¯ä¸ªé”šæ¡†é¢„æµ‹4ä¸ªåç§»é‡ï¼Œè€Œä¸æ˜¯ <code>q + 1</code> ä¸ªç±»åˆ«ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># é¢„æµ‹é”šæ¡†å’ŒçœŸå®è¾¹ç•Œæ¡†çš„offsetï¼Œå¯¹æ¯ä¸€ä¸ªé”šæ¡†æœ‰4ä¸ªé¢„æµ‹å€¼</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bbox_predictor</span>(<span class=\"params\">num_inputs, num_anchors</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Conv2d(num_inputs, num_anchors * <span class=\"number\">4</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"8-2-è¿ç»“å¤šå°ºåº¦çš„é¢„æµ‹\">8.2 è¿ç»“å¤šå°ºåº¦çš„é¢„æµ‹</h3>\n<p>å•å‘å¤šæ¡†æ£€æµ‹ä½¿ç”¨å¤šå°ºåº¦ç‰¹å¾å›¾æ¥ç”Ÿæˆé”šæ¡†å¹¶é¢„æµ‹å…¶ç±»åˆ«å’Œåç§»é‡ã€‚åœ¨ä¸åŒçš„å°ºåº¦ä¸‹ï¼Œç‰¹å¾å›¾çš„å½¢çŠ¶æˆ–ä»¥åŒä¸€å•å…ƒä¸ºä¸­å¿ƒçš„é”šæ¡†çš„æ•°é‡å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚å› æ­¤ï¼Œä¸åŒå°ºåº¦ä¸‹é¢„æµ‹è¾“å‡ºçš„å½¢çŠ¶å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚</p>\n<p>åœ¨ä»¥ä¸‹ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä¸ºåŒä¸€ä¸ªå°æ‰¹é‡æ„å»ºä¸¤ä¸ªä¸åŒæ¯”ä¾‹ï¼ˆ<code>Y1</code> å’Œ <code>Y2</code>ï¼‰çš„ç‰¹å¾å›¾ï¼Œå…¶ä¸­ <code>Y2</code> çš„é«˜åº¦å’Œå®½åº¦æ˜¯ <code>Y1</code> çš„ä¸€åŠã€‚ä»¥ç±»åˆ«é¢„æµ‹ä¸ºä¾‹ï¼Œå‡è®¾ <code>Y1</code> å’Œ <code>Y2</code> çš„æ¯ä¸ªå•å…ƒåˆ†åˆ«ç”Ÿæˆäº†5ä¸ªå’Œ3ä¸ªé”šæ¡†ã€‚è¿›ä¸€æ­¥å‡è®¾ç›®æ ‡ç±»åˆ«çš„æ•°é‡ä¸º10ï¼Œå¯¹äºç‰¹å¾å›¾ <code>Y1</code> å’Œ <code>Y2</code>ï¼Œç±»åˆ«é¢„æµ‹è¾“å‡ºä¸­çš„é€šé“æ•°åˆ†åˆ«ä¸º <code>5 * (10 + 1) = 55</code> å’Œ <code>3 * (10 + 1) = 33</code>ï¼Œå…¶ä¸­ä»»ä¸€è¾“å‡ºçš„å½¢çŠ¶æ˜¯ <code>(æ‰¹é‡å¤§å°, é€šé“æ•°, é«˜åº¦, å®½åº¦)</code>ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">x, block</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> block(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Y1ä¸ºå¯¹è¾“å…¥çš„400(20*20)ä¸ªåƒç´ éƒ½ä¼šåš55(5*(10+1))ä¸ªé¢„æµ‹</span></span><br><span class=\"line\"><span class=\"comment\"># å› æ­¤åœ¨ä¸åŒå°ºåº¦ä¸‹çš„é¢„æµ‹é™¤äº†batchç»´ä¹‹å¤–å¦å¤–ä¸‰ä¸ªç»´åº¦éƒ½ä¼šå‘ç”Ÿå˜åŒ–</span></span><br><span class=\"line\">Y1 = forward(torch.zeros((<span class=\"number\">2</span>, <span class=\"number\">8</span>, <span class=\"number\">20</span>, <span class=\"number\">20</span>)), cls_predictor(<span class=\"number\">8</span>, <span class=\"number\">5</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">Y2 = forward(torch.zeros((<span class=\"number\">2</span>, <span class=\"number\">16</span>, <span class=\"number\">10</span>, <span class=\"number\">10</span>)), cls_predictor(<span class=\"number\">16</span>, <span class=\"number\">3</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(Y1.shape, Y2.shape)  <span class=\"comment\"># torch.Size([2, 55, 20, 20]) torch.Size([2, 33, 10, 10])</span></span><br></pre></td></tr></table></figure>\n<p>é™¤äº†æ‰¹é‡å¤§å°è¿™ä¸€ç»´åº¦å¤–ï¼Œå…¶ä»–ä¸‰ä¸ªç»´åº¦éƒ½å…·æœ‰ä¸åŒçš„å°ºå¯¸ã€‚ä¸ºäº†å°†è¿™ä¸¤ä¸ªé¢„æµ‹è¾“å‡ºé“¾æ¥èµ·æ¥ä»¥æé«˜è®¡ç®—æ•ˆç‡ï¼Œæˆ‘ä»¬å°†æŠŠè¿™äº›å¼ é‡è½¬æ¢ä¸ºæ›´ä¸€è‡´çš„æ ¼å¼ã€‚</p>\n<p>é€šé“ç»´åŒ…å«ä¸­å¿ƒç›¸åŒçš„é”šæ¡†çš„é¢„æµ‹ç»“æœã€‚æˆ‘ä»¬é¦–å…ˆå°†é€šé“ç»´ç§»åˆ°æœ€åä¸€ç»´ã€‚å› ä¸ºä¸åŒå°ºåº¦ä¸‹æ‰¹é‡å¤§å°ä»ä¿æŒä¸å˜ï¼Œæˆ‘ä»¬å¯ä»¥å°†é¢„æµ‹ç»“æœè½¬æˆäºŒç»´çš„ <code>(æ‰¹é‡å¤§å°, é«˜ * å®½ * é€šé“æ•°)</code> çš„æ ¼å¼ï¼Œä»¥æ–¹ä¾¿ä¹‹ååœ¨ç»´åº¦1ä¸Šçš„è¿ç»“ã€‚è¿™æ ·ä¸€æ¥ï¼Œå°½ç®¡ <code>Y1</code> å’Œ <code>Y2</code> åœ¨é€šé“æ•°ã€é«˜åº¦å’Œå®½åº¦æ–¹é¢å…·æœ‰ä¸åŒçš„å¤§å°ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥åœ¨åŒä¸€ä¸ªå°æ‰¹é‡çš„ä¸¤ä¸ªä¸åŒå°ºåº¦ä¸Šè¿æ¥è¿™ä¸¤ä¸ªé¢„æµ‹è¾“å‡ºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># start_dim=1è¡¨ç¤ºå°†åé¢ä¸‰ä¸ªç»´åº¦å±•å¹³æˆä¸€ç»´</span></span><br><span class=\"line\"><span class=\"comment\"># æŠŠé€šé“æ”¾æœ€åè¡¨ç¤ºå¯¹äºæ¯ä¸ªåƒç´ çš„é¢„æµ‹æ˜¯è¿ç»­å€¼ï¼Œå¦åˆ™å±•å¹³åæ¯ä¸ªåƒç´ çš„é¢„æµ‹å°±ä¸æ˜¯è¿ç»­çš„</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">flatten_pred</span>(<span class=\"params\">pred</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.flatten(pred.permute(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>), start_dim=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">concat_preds</span>(<span class=\"params\">preds</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.cat([flatten_pred(p) <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> preds], dim=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(concat_preds([Y1, Y2]).shape)  <span class=\"comment\"># torch.Size([2, 25300])</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"8-3-é«˜å’Œå®½å‡åŠå—\">8.3 é«˜å’Œå®½å‡åŠå—</h3>\n<p>é«˜å’Œå®½å‡åŠå—å°†è¾“å…¥ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦å‡åŠï¼Œä¼šæ‰©å¤§æ¯ä¸ªå•å…ƒåœ¨å…¶è¾“å‡ºç‰¹å¾å›¾ä¸­çš„æ„Ÿå—é‡ï¼Œè¯¥æ¨¡å—æ­¤å‰å·²åœ¨ VGG ä¸­ä½¿ç”¨è¿‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># é«˜å®½å‡åŠå—ï¼Œè¯¥æ¨¡å—å°†è¾“å…¥ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦å‡åŠ</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">down_sample_blk</span>(<span class=\"params\">in_channels, out_channels</span>):</span><br><span class=\"line\">    blk = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">2</span>):</span><br><span class=\"line\">        blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>))</span><br><span class=\"line\">        blk.append(nn.BatchNorm2d(out_channels))</span><br><span class=\"line\">        blk.append(nn.ReLU())</span><br><span class=\"line\">        in_channels = out_channels</span><br><span class=\"line\">    blk.append(nn.MaxPool2d(<span class=\"number\">2</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(*blk)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(forward(torch.zeros((<span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">20</span>, <span class=\"number\">20</span>)), down_sample_blk(<span class=\"number\">3</span>, <span class=\"number\">10</span>)).shape)  <span class=\"comment\"># torch.Size([2, 10, 10, 10])</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"8-4-åŸºæœ¬ç½‘ç»œå—\">8.4 åŸºæœ¬ç½‘ç»œå—</h3>\n<p>åŸºæœ¬ç½‘ç»œå—ç”¨äºä»è¾“å…¥å›¾åƒä¸­æŠ½å–ç‰¹å¾ã€‚ä¸ºäº†è®¡ç®—ç®€æ´ï¼Œæˆ‘ä»¬æ„é€ äº†ä¸€ä¸ªå°çš„åŸºç¡€ç½‘ç»œï¼Œè¯¥ç½‘ç»œä¸²è”3ä¸ªé«˜å’Œå®½å‡åŠå—ï¼Œå¹¶é€æ­¥å°†é€šé“æ•°ç¿»å€ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">base_net</span>():</span><br><span class=\"line\">    blk = []</span><br><span class=\"line\">    num_filters = [<span class=\"number\">3</span>, <span class=\"number\">16</span>, <span class=\"number\">32</span>, <span class=\"number\">64</span>]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(num_filters) - <span class=\"number\">1</span>):</span><br><span class=\"line\">        blk.append(down_sample_blk(num_filters[i], num_filters[i + <span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(*blk)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(forward(torch.zeros((<span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>)), base_net()).shape)  <span class=\"comment\"># torch.Size([2, 64, 32, 32])</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"8-5-å®Œæ•´çš„æ¨¡å‹\">8.5 å®Œæ•´çš„æ¨¡å‹</h3>\n<p>å®Œæ•´çš„å•å‘å¤šæ¡†æ£€æµ‹æ¨¡å‹ç”±<strong>äº”ä¸ªæ¨¡å—</strong>ç»„æˆï¼Œæ¯ä¸ªå—ç”Ÿæˆçš„ç‰¹å¾å›¾æ—¢ç”¨äºç”Ÿæˆé”šæ¡†ï¼Œåˆç”¨äºé¢„æµ‹è¿™äº›é”šæ¡†çš„ç±»åˆ«å’Œåç§»é‡ã€‚åœ¨è¿™äº”ä¸ªæ¨¡å—ä¸­ï¼Œç¬¬ä¸€ä¸ªæ˜¯<strong>åŸºæœ¬ç½‘ç»œå—</strong>ï¼Œç¬¬äºŒä¸ªåˆ°ç¬¬å››ä¸ªæ˜¯<strong>é«˜å’Œå®½å‡åŠå—</strong>ï¼Œæœ€åä¸€ä¸ªæ¨¡å—ä½¿ç”¨<strong>å…¨å±€æœ€å¤§æ± åŒ–å±‚</strong>å°†é«˜åº¦å’Œå®½åº¦éƒ½é™åˆ°1ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œç¬¬äºŒåˆ°ç¬¬äº”ä¸ªåŒºå—éƒ½æ˜¯ SSD ä¸­çš„<strong>å¤šå°ºåº¦ç‰¹å¾å—</strong>ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_blk</span>(<span class=\"params\">i</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> i == <span class=\"number\">0</span>:</span><br><span class=\"line\">        blk = base_net()</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> i == <span class=\"number\">1</span>:</span><br><span class=\"line\">        blk = down_sample_blk(<span class=\"number\">64</span>, <span class=\"number\">128</span>)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> i == <span class=\"number\">4</span>:</span><br><span class=\"line\">        blk = nn.AdaptiveMaxPool2d((<span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        blk = down_sample_blk(<span class=\"number\">128</span>, <span class=\"number\">128</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> blk</span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æˆ‘ä»¬ä¸ºæ¯ä¸ªå—å®šä¹‰å‰å‘ä¼ æ’­ã€‚ä¸å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸åŒï¼Œæ­¤å¤„çš„è¾“å‡ºåŒ…æ‹¬ï¼šCNN ç‰¹å¾å›¾ <code>Y</code>ã€åœ¨å½“å‰å°ºåº¦ä¸‹æ ¹æ® <code>Y</code> ç”Ÿæˆçš„é”šæ¡†ã€é¢„æµ‹çš„è¿™äº›é”šæ¡†çš„ç±»åˆ«å’Œåç§»é‡ï¼ˆåŸºäº <code>Y</code>ï¼‰ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ä¸ºæ¯ä¸ªå—å®šä¹‰å‰å‘ä¼ æ’­ï¼Œæ­¤å¤„çš„cls_predictorå’Œbbox_predictorä¸ºå·²ç»æ„é€ å¥½çš„å·ç§¯å±‚</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">blk_forward</span>(<span class=\"params\">X, blk, size, ratio, cls_predictor, bbox_predictor</span>):</span><br><span class=\"line\">    Y = blk(X)  <span class=\"comment\"># feature map</span></span><br><span class=\"line\">    anchors = d2l.multibox_prior(Y, sizes=size, ratios=ratio)</span><br><span class=\"line\">    cls_preds = cls_predictor(Y)</span><br><span class=\"line\">    bbox_preds = bbox_predictor(Y)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (Y, anchors, cls_preds, bbox_preds)</span><br></pre></td></tr></table></figure>\n<p>è¶…å‚æ•°çš„è®¾ç½®è¿‡ç¨‹å¯ä»¥çœ‹ï¼š<a href=\"https://zh-v2.d2l.ai/chapter_computer-vision/ssd.html\">å•å‘å¤šæ¡†æ£€æµ‹ï¼ˆSSDï¼‰</a>ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sizes = [[<span class=\"number\">0.2</span>, <span class=\"number\">0.272</span>], [<span class=\"number\">0.37</span>, <span class=\"number\">0.447</span>], [<span class=\"number\">0.54</span>, <span class=\"number\">0.619</span>], [<span class=\"number\">0.71</span>, <span class=\"number\">0.79</span>], [<span class=\"number\">0.88</span>, <span class=\"number\">0.961</span>]]</span><br><span class=\"line\">ratios = [[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0.5</span>]] * <span class=\"number\">5</span></span><br><span class=\"line\">num_anchors = <span class=\"built_in\">len</span>(sizes[<span class=\"number\">0</span>]) + <span class=\"built_in\">len</span>(ratios[<span class=\"number\">0</span>]) - <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨ï¼Œæˆ‘ä»¬å°±å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼å®šä¹‰å®Œæ•´çš„æ¨¡å‹ <code>TinySSD</code> äº†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">TinySSD</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, num_classes, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(TinySSD, self).__init__(**kwargs)</span><br><span class=\"line\">        self.num_classes = num_classes</span><br><span class=\"line\">        idx_to_in_channels = [<span class=\"number\">64</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">5</span>):</span><br><span class=\"line\">            <span class=\"comment\"># å³èµ‹å€¼è¯­å¥self.blk_i=get_blk(i)</span></span><br><span class=\"line\">            <span class=\"built_in\">setattr</span>(self, <span class=\"string\">f&#x27;blk_<span class=\"subst\">&#123;i&#125;</span>&#x27;</span>, get_blk(i))</span><br><span class=\"line\">            <span class=\"built_in\">setattr</span>(self, <span class=\"string\">f&#x27;cls_<span class=\"subst\">&#123;i&#125;</span>&#x27;</span>, cls_predictor(idx_to_in_channels[i], num_anchors, num_classes))</span><br><span class=\"line\">            <span class=\"built_in\">setattr</span>(self, <span class=\"string\">f&#x27;bbox_<span class=\"subst\">&#123;i&#125;</span>&#x27;</span>, bbox_predictor(idx_to_in_channels[i], num_anchors))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        anchors, cls_preds, bbox_preds = [<span class=\"literal\">None</span>] * <span class=\"number\">5</span>, [<span class=\"literal\">None</span>] * <span class=\"number\">5</span>, [<span class=\"literal\">None</span>] * <span class=\"number\">5</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">5</span>):</span><br><span class=\"line\">            <span class=\"comment\"># getattr(self, &#x27;blk_%d&#x27;%i)å³è®¿é—®self.blk_i</span></span><br><span class=\"line\">            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(</span><br><span class=\"line\">                X, <span class=\"built_in\">getattr</span>(self, <span class=\"string\">f&#x27;blk_<span class=\"subst\">&#123;i&#125;</span>&#x27;</span>), sizes[i], ratios[i],</span><br><span class=\"line\">                <span class=\"built_in\">getattr</span>(self, <span class=\"string\">f&#x27;cls_<span class=\"subst\">&#123;i&#125;</span>&#x27;</span>), <span class=\"built_in\">getattr</span>(self, <span class=\"string\">f&#x27;bbox_<span class=\"subst\">&#123;i&#125;</span>&#x27;</span>))</span><br><span class=\"line\">            <span class=\"comment\"># print(f&#x27;anchors[&#123;i&#125;], cls_preds[&#123;i&#125;], bbox_preds[&#123;i&#125;]:&#x27;, anchors[i].shape, cls_preds[i].shape, bbox_preds[i].shape)</span></span><br><span class=\"line\">        anchors = torch.cat(anchors, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        cls_preds = concat_preds(cls_preds)</span><br><span class=\"line\">        cls_preds = cls_preds.reshape(cls_preds.shape[<span class=\"number\">0</span>], -<span class=\"number\">1</span>, self.num_classes + <span class=\"number\">1</span>)</span><br><span class=\"line\">        bbox_preds = concat_preds(bbox_preds)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> anchors, cls_preds, bbox_preds</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># f_map: (32, 3, 256, 256)-&gt;(32, 64, 32, 32)-&gt;(32, 128, 16, 16)-&gt;(32, 128, 8, 8)-&gt;(32, 128, 4, 4)-&gt;(32, 128, 1, 1)</span></span><br><span class=\"line\"><span class=\"comment\"># anchors[0], cls_preds[0], bbox_preds[0]: torch.Size([1, 4096, 4]) torch.Size([32, 8, 32, 32]) torch.Size([32, 16, 32, 32])</span></span><br><span class=\"line\"><span class=\"comment\"># anchors[1], cls_preds[1], bbox_preds[1]: torch.Size([1, 1024, 4]) torch.Size([32, 8, 16, 16]) torch.Size([32, 16, 16, 16])</span></span><br><span class=\"line\"><span class=\"comment\"># anchors[2], cls_preds[2], bbox_preds[2]: torch.Size([1, 256, 4]) torch.Size([32, 8, 8, 8]) torch.Size([32, 16, 8, 8])</span></span><br><span class=\"line\"><span class=\"comment\"># anchors[3], cls_preds[3], bbox_preds[3]: torch.Size([1, 64, 4]) torch.Size([32, 8, 4, 4]) torch.Size([32, 16, 4, 4])</span></span><br><span class=\"line\"><span class=\"comment\"># anchors[4], cls_preds[4], bbox_preds[4]: torch.Size([1, 4, 4]) torch.Size([32, 8, 1, 1]) torch.Size([32, 16, 1, 1])</span></span><br><span class=\"line\">net = TinySSD(num_classes=<span class=\"number\">1</span>)</span><br><span class=\"line\">X = torch.zeros((<span class=\"number\">32</span>, <span class=\"number\">3</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>))</span><br><span class=\"line\">anchors, cls_preds, bbox_preds = net(X)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;output anchors:&#x27;</span>, anchors.shape)  <span class=\"comment\"># output anchors: torch.Size([1, 5444, 4])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;output class preds:&#x27;</span>, cls_preds.shape)  <span class=\"comment\"># output class preds: torch.Size([32, 5444, 2])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;output bbox preds:&#x27;</span>, bbox_preds.shape)  <span class=\"comment\"># output bbox preds: torch.Size([32, 21776])</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"8-6-è®­ç»ƒæ¨¡å‹\">8.6 è®­ç»ƒæ¨¡å‹</h3>\n<p>é¦–å…ˆè¯»å–æ•°æ®é›†å’Œè®¾ç½®è¶…å‚æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">lr, num_epochs, batch_size = <span class=\"number\">0.2</span>, <span class=\"number\">20</span>, <span class=\"number\">32</span></span><br><span class=\"line\">train_iter, valid_iter = d2l.load_data_bananas(batch_size)</span><br></pre></td></tr></table></figure>\n<p>ç„¶åå®šä¹‰æŸå¤±å‡½æ•°å’Œè¯„ä»·å‡½æ•°ï¼Œç›®æ ‡æ£€æµ‹æœ‰ä¸¤ç§ç±»å‹çš„æŸå¤±ã€‚ç¬¬ä¸€ç§æœ‰å…³<strong>é”šæ¡†ç±»åˆ«</strong>çš„æŸå¤±ï¼šæˆ‘ä»¬å¯ä»¥ç®€å•åœ°å¤ç”¨ä¹‹å‰å›¾åƒåˆ†ç±»é—®é¢˜é‡Œä¸€ç›´ä½¿ç”¨çš„äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è®¡ç®—ï¼›ç¬¬äºŒç§æœ‰å…³<strong>æ­£ç±»é”šæ¡†åç§»é‡</strong>çš„æŸå¤±ï¼šé¢„æµ‹åç§»é‡æ˜¯ä¸€ä¸ªå›å½’é—®é¢˜ã€‚ä½†æ˜¯ï¼Œå¯¹äºè¿™ä¸ªå›å½’é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œä¸ä½¿ç”¨å¹³æ–¹æŸå¤±ï¼Œè€Œæ˜¯ä½¿ç”¨ L1 èŒƒæ•°æŸå¤±ï¼Œå³é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹å·®çš„ç»å¯¹å€¼ã€‚æ©ç å˜é‡ <code>bbox_masks</code> ä»¤è´Ÿç±»é”šæ¡†å’Œå¡«å……é”šæ¡†ä¸å‚ä¸æŸå¤±çš„è®¡ç®—ã€‚æœ€åï¼Œæˆ‘ä»¬å°†é”šæ¡†ç±»åˆ«å’Œåç§»é‡çš„æŸå¤±ç›¸åŠ ï¼Œä»¥è·å¾—æ¨¡å‹çš„æœ€ç»ˆæŸå¤±å‡½æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cls_loss = nn.CrossEntropyLoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\">bbox_loss = nn.L1Loss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">calc_loss</span>(<span class=\"params\">cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks</span>):</span><br><span class=\"line\">    batch_size, num_classes = cls_preds.shape[<span class=\"number\">0</span>], cls_preds.shape[<span class=\"number\">2</span>]</span><br><span class=\"line\">    cls = cls_loss(cls_preds.reshape(-<span class=\"number\">1</span>, num_classes), cls_labels.reshape(-<span class=\"number\">1</span>)).reshape(batch_size, -<span class=\"number\">1</span>).mean(dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">    bbox = bbox_loss(bbox_preds * bbox_masks, bbox_labels * bbox_masks).mean(dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> cls + bbox</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥æ²¿ç”¨å‡†ç¡®ç‡è¯„ä»·åˆ†ç±»ç»“æœã€‚ç”±äºåç§»é‡ä½¿ç”¨äº† L1 èŒƒæ•°æŸå¤±ï¼Œæˆ‘ä»¬ä½¿ç”¨å¹³å‡ç»å¯¹è¯¯å·®æ¥ï¼ˆMAEï¼‰è¯„ä»·è¾¹ç•Œæ¡†çš„é¢„æµ‹ç»“æœã€‚è¿™äº›é¢„æµ‹ç»“æœæ˜¯ä»ç”Ÿæˆçš„é”šæ¡†åŠå…¶é¢„æµ‹åç§»é‡ä¸­è·å¾—çš„ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cls_eval</span>(<span class=\"params\">cls_preds, cls_labels</span>):</span><br><span class=\"line\">    <span class=\"comment\"># ç”±äºç±»åˆ«é¢„æµ‹ç»“æœæ”¾åœ¨æœ€åä¸€ç»´ï¼Œargmaxéœ€è¦æŒ‡å®šæœ€åä¸€ç»´</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">float</span>((cls_preds.argmax(dim=-<span class=\"number\">1</span>).<span class=\"built_in\">type</span>(cls_labels.dtype) == cls_labels).<span class=\"built_in\">sum</span>())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">bbox_eval</span>(<span class=\"params\">bbox_preds, bbox_labels, bbox_masks</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">float</span>((torch.<span class=\"built_in\">abs</span>((bbox_labels - bbox_preds) * bbox_masks)).<span class=\"built_in\">sum</span>())</span><br></pre></td></tr></table></figure>\n<p>æœ€åæ˜¯è®­ç»ƒæ¨¡å‹ï¼Œåœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦åœ¨æ¨¡å‹çš„å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ç”Ÿæˆå¤šå°ºåº¦é”šæ¡† <code>anchors</code>ï¼Œå¹¶é¢„æµ‹å…¶ç±»åˆ« <code>cls_preds</code> å’Œåç§»é‡ <code>bbox_preds</code>ã€‚ç„¶åï¼Œæˆ‘ä»¬æ ¹æ®æ ‡ç­¾ä¿¡æ¯ <code>label</code> ä¸ºç”Ÿæˆçš„é”šæ¡†æ ‡è®°ç±»åˆ« <code>cls_labels</code> å’Œåç§»é‡ <code>bbox_labels</code>ã€‚æœ€åï¼Œæˆ‘ä»¬æ ¹æ®ç±»åˆ«å’Œåç§»é‡çš„é¢„æµ‹å’Œæ ‡æ³¨å€¼è®¡ç®—æŸå¤±å‡½æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_iter, valid_iter, num_epochs, lr, device</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear <span class=\"keyword\">or</span> <span class=\"built_in\">type</span>(m) == nn.Conv2d:</span><br><span class=\"line\">            nn.init.xavier_uniform_(m.weight)</span><br><span class=\"line\">    net.apply(init_weights)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;training on&#x27;</span>, device)</span><br><span class=\"line\">    net.to(device)</span><br><span class=\"line\">    optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=<span class=\"number\">5e-4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    writer = SummaryWriter(<span class=\"string\">&#x27;../logs/SSD_train_log&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    best_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        net.train()</span><br><span class=\"line\">        train_loss, train_acc, train_bbox_err = [], [], []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> feature, label <span class=\"keyword\">in</span> tqdm(train_iter):</span><br><span class=\"line\">            feature, label = feature.to(device), label.to(device)</span><br><span class=\"line\">            <span class=\"comment\"># ç”Ÿæˆå¤šå°ºåº¦çš„é”šæ¡†ï¼Œä¸ºæ¯ä¸ªé”šæ¡†é¢„æµ‹ç±»åˆ«å’Œåç§»é‡</span></span><br><span class=\"line\">            anchors, cls_preds, bbox_preds = net(feature)</span><br><span class=\"line\">            <span class=\"comment\"># ä¸ºæ¯ä¸ªé”šæ¡†æ ‡æ³¨ç±»åˆ«å’Œåç§»é‡</span></span><br><span class=\"line\">            bbox_labels, bbox_masks, cls_labels = d2l.multibox_target(anchors, label)</span><br><span class=\"line\">            <span class=\"comment\"># æ ¹æ®ç±»åˆ«å’Œåç§»é‡çš„é¢„æµ‹å’Œæ ‡æ³¨å€¼è®¡ç®—æŸå¤±å‡½æ•°</span></span><br><span class=\"line\">            loss = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks)</span><br><span class=\"line\"></span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            loss.mean().backward()</span><br><span class=\"line\">            optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">            acc = cls_eval(cls_preds, cls_labels) / cls_labels.numel()</span><br><span class=\"line\">            bbox_mae = bbox_eval(bbox_preds, bbox_labels, bbox_masks) / bbox_labels.numel()</span><br><span class=\"line\"></span><br><span class=\"line\">            train_loss.append(loss.mean())</span><br><span class=\"line\">            train_acc.append(acc)</span><br><span class=\"line\">            train_bbox_err.append(bbox_mae)</span><br><span class=\"line\"></span><br><span class=\"line\">        train_loss = <span class=\"built_in\">sum</span>(train_loss) / <span class=\"built_in\">len</span>(train_loss)</span><br><span class=\"line\">        train_acc = <span class=\"built_in\">sum</span>(train_acc) / <span class=\"built_in\">len</span>(train_acc)</span><br><span class=\"line\">        train_bbox_err = <span class=\"built_in\">sum</span>(train_bbox_err) / <span class=\"built_in\">len</span>(train_bbox_err)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;[ Train | <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>:03d&#125;</span>/<span class=\"subst\">&#123;num_epochs:03d&#125;</span> ] loss = <span class=\"subst\">&#123;train_loss:<span class=\"number\">.5</span>f&#125;</span>, acc = <span class=\"subst\">&#123;train_acc:<span class=\"number\">.5</span>f&#125;</span>, bbox_err = <span class=\"subst\">&#123;train_bbox_err:<span class=\"number\">.5</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        net.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">        valid_loss, valid_acc, valid_bbox_err = [], [], []</span><br><span class=\"line\">        <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">            <span class=\"keyword\">for</span> feature, label <span class=\"keyword\">in</span> tqdm(valid_iter):</span><br><span class=\"line\">                feature, label = feature.to(device), label.to(device)</span><br><span class=\"line\">                anchors, cls_preds, bbox_preds = net(feature)</span><br><span class=\"line\">                bbox_labels, bbox_masks, cls_labels = d2l.multibox_target(anchors, label)</span><br><span class=\"line\"></span><br><span class=\"line\">                loss = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks)</span><br><span class=\"line\">                acc = cls_eval(cls_preds, cls_labels) / cls_labels.numel()</span><br><span class=\"line\">                bbox_mae = bbox_eval(bbox_preds, bbox_labels, bbox_masks) / bbox_labels.numel()</span><br><span class=\"line\"></span><br><span class=\"line\">                valid_loss.append(loss.mean())</span><br><span class=\"line\">                valid_acc.append(acc)</span><br><span class=\"line\">                valid_bbox_err.append(bbox_mae)</span><br><span class=\"line\"></span><br><span class=\"line\">        valid_loss = <span class=\"built_in\">sum</span>(valid_loss) / <span class=\"built_in\">len</span>(valid_loss)</span><br><span class=\"line\">        valid_acc = <span class=\"built_in\">sum</span>(valid_acc) / <span class=\"built_in\">len</span>(valid_acc)</span><br><span class=\"line\">        valid_bbox_err = <span class=\"built_in\">sum</span>(valid_bbox_err) / <span class=\"built_in\">len</span>(valid_bbox_err)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;[ Valid | <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>:03d&#125;</span>/<span class=\"subst\">&#123;num_epochs:03d&#125;</span> ] loss = <span class=\"subst\">&#123;valid_loss:<span class=\"number\">.5</span>f&#125;</span>, acc = <span class=\"subst\">&#123;valid_acc:<span class=\"number\">.5</span>f&#125;</span>, bbox_err = <span class=\"subst\">&#123;valid_bbox_err:<span class=\"number\">.5</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        writer.add_scalars(<span class=\"string\">&#x27;train&#x27;</span>, &#123;<span class=\"string\">&#x27;loss&#x27;</span>: train_loss,</span><br><span class=\"line\">                                     <span class=\"string\">&#x27;acc&#x27;</span>: train_acc,</span><br><span class=\"line\">                                     <span class=\"string\">&#x27;bbox_err&#x27;</span>: train_bbox_err&#125;, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\">        writer.add_scalars(<span class=\"string\">&#x27;valid&#x27;</span>, &#123;<span class=\"string\">&#x27;loss&#x27;</span>: valid_loss,</span><br><span class=\"line\">                                     <span class=\"string\">&#x27;acc&#x27;</span>: valid_acc,</span><br><span class=\"line\">                                     <span class=\"string\">&#x27;bbox_err&#x27;</span>: valid_bbox_err&#125;, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> valid_acc &gt; best_acc:</span><br><span class=\"line\">            best_acc = valid_acc</span><br><span class=\"line\">            torch.save(net.state_dict(), <span class=\"string\">&#x27;../save/SSD_train.params&#x27;</span>)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;saving model with acc &#123;:.3f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(best_acc))</span><br><span class=\"line\"></span><br><span class=\"line\">    writer.close()</span><br><span class=\"line\"></span><br><span class=\"line\">train(net, train_iter, valid_iter, num_epochs, lr, device)</span><br></pre></td></tr></table></figure>\n<h3 id=\"8-7-é¢„æµ‹ç›®æ ‡\">8.7 é¢„æµ‹ç›®æ ‡</h3>\n<p>åœ¨é¢„æµ‹é˜¶æ®µï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½æŠŠå›¾åƒé‡Œé¢æ‰€æœ‰æˆ‘ä»¬æ„Ÿå…´è¶£çš„ç›®æ ‡æ£€æµ‹å‡ºæ¥ã€‚åœ¨ä¸‹é¢ï¼Œæˆ‘ä»¬è¯»å–å¹¶è°ƒæ•´æµ‹è¯•å›¾åƒçš„å¤§å°ï¼Œç„¶åå°†å…¶è½¬æˆå·ç§¯å±‚éœ€è¦çš„å››ç»´æ ¼å¼ã€‚ä½¿ç”¨ <code>multibox_detection</code> å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®é”šæ¡†åŠå…¶é¢„æµ‹åç§»é‡å¾—åˆ°é¢„æµ‹è¾¹ç•Œæ¡†ï¼Œç„¶åé€šè¿‡éæå¤§å€¼æŠ‘åˆ¶æ¥ç§»é™¤ç›¸ä¼¼çš„é¢„æµ‹è¾¹ç•Œæ¡†ã€‚æœ€åï¼Œæˆ‘ä»¬ç­›é€‰æ‰€æœ‰ç½®ä¿¡åº¦ä¸ä½äº0.9çš„è¾¹ç•Œæ¡†ï¼Œåšä¸ºæœ€ç»ˆè¾“å‡ºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = torchvision.io.read_image(<span class=\"string\">&#x27;../images/banana.jpg&#x27;</span>).unsqueeze(<span class=\"number\">0</span>).<span class=\"built_in\">float</span>()  <span class=\"comment\"># å°†å…¶è½¬æˆå·ç§¯å±‚éœ€è¦çš„å››ç»´æ ¼å¼</span></span><br><span class=\"line\">img = X.squeeze(<span class=\"number\">0</span>).permute(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>).long()  <span class=\"comment\"># (h, w, c)</span></span><br><span class=\"line\">net.to(device)</span><br><span class=\"line\">net.load_state_dict(torch.load(<span class=\"string\">&#x27;../save/SSD_train.params&#x27;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">predict</span>(<span class=\"params\">x, net, device</span>):</span><br><span class=\"line\">    net.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">    anchors, cls_preds, bbox_preds = net(X.to(device))</span><br><span class=\"line\">    cls_probs = F.softmax(cls_preds, dim=<span class=\"number\">2</span>).permute(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">    output = d2l.multibox_detection(cls_probs, bbox_preds, anchors)</span><br><span class=\"line\">    idx = [i <span class=\"keyword\">for</span> i, row <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(output[<span class=\"number\">0</span>]) <span class=\"keyword\">if</span> row[<span class=\"number\">0</span>] != -<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> output[<span class=\"number\">0</span>, idx]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">display</span>(<span class=\"params\">img, output, threshold</span>):</span><br><span class=\"line\">    plt.figure(dpi=<span class=\"number\">100</span>)</span><br><span class=\"line\">    fig = plt.imshow(img)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> output:</span><br><span class=\"line\">        score = <span class=\"built_in\">float</span>(row[<span class=\"number\">1</span>])</span><br><span class=\"line\">        <span class=\"keyword\">if</span> score &lt; threshold:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span></span><br><span class=\"line\">        h, w = img.shape[<span class=\"number\">0</span>:<span class=\"number\">2</span>]</span><br><span class=\"line\">        bbox = [row[<span class=\"number\">2</span>:<span class=\"number\">6</span>] * torch.tensor((w, h, w, h), device=row.device)]</span><br><span class=\"line\">        d2l.show_bboxes(fig.axes, bbox, <span class=\"string\">&#x27;%.2f&#x27;</span> % score, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">output = predict(X, net, device)</span><br><span class=\"line\">display(img, output.cpu(), threshold=<span class=\"number\">0.9</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"9-è¯­ä¹‰åˆ†å‰²å’Œæ•°æ®é›†\">9. è¯­ä¹‰åˆ†å‰²å’Œæ•°æ®é›†</h2>\n<p>åœ¨å‰å‡ èŠ‚ä¸­è®¨è®ºçš„ç›®æ ‡æ£€æµ‹é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬ä¸€ç›´ä½¿ç”¨æ–¹å½¢è¾¹ç•Œæ¡†æ¥æ ‡æ³¨å’Œé¢„æµ‹å›¾åƒä¸­çš„ç›®æ ‡ã€‚æœ¬èŠ‚å°†æ¢è®¨<strong>è¯­ä¹‰åˆ†å‰²</strong>ï¼ˆsemantic segmentationï¼‰é—®é¢˜ï¼Œå®ƒé‡ç‚¹å…³æ³¨äºå¦‚ä½•å°†å›¾åƒåˆ†å‰²æˆå±äºä¸åŒè¯­ä¹‰ç±»åˆ«çš„åŒºåŸŸã€‚ä¸ç›®æ ‡æ£€æµ‹ä¸åŒï¼Œè¯­ä¹‰åˆ†å‰²å¯ä»¥è¯†åˆ«å¹¶ç†è§£å›¾åƒä¸­<strong>æ¯ä¸€ä¸ªåƒç´ </strong>çš„å†…å®¹ï¼šå…¶è¯­ä¹‰åŒºåŸŸçš„æ ‡æ³¨å’Œé¢„æµ‹æ˜¯åƒç´ çº§çš„ã€‚ä¸ç›®æ ‡æ£€æµ‹ç›¸æ¯”ï¼Œè¯­ä¹‰åˆ†å‰²æ ‡æ³¨çš„åƒç´ çº§çš„è¾¹æ¡†æ˜¾ç„¶æ›´åŠ ç²¾ç»†ã€‚</p>\n<h3 id=\"9-1-å›¾åƒåˆ†å‰²å’Œå®ä¾‹åˆ†å‰²\">9.1 å›¾åƒåˆ†å‰²å’Œå®ä¾‹åˆ†å‰²</h3>\n<p>è®¡ç®—æœºè§†è§‰é¢†åŸŸè¿˜æœ‰2ä¸ªä¸è¯­ä¹‰åˆ†å‰²ç›¸ä¼¼çš„é‡è¦é—®é¢˜ï¼Œå³<strong>å›¾åƒåˆ†å‰²</strong>ï¼ˆimage segmentationï¼‰å’Œ<strong>å®ä¾‹åˆ†å‰²</strong>ï¼ˆinstance segmentationï¼‰ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå°†å®ƒä»¬åŒè¯­ä¹‰åˆ†å‰²ç®€å•åŒºåˆ†ä¸€ä¸‹ï¼š</p>\n<ul>\n<li>å›¾åƒåˆ†å‰²å°†å›¾åƒåˆ’åˆ†ä¸ºè‹¥å¹²ç»„æˆåŒºåŸŸï¼Œè¿™ç±»é—®é¢˜çš„æ–¹æ³•é€šå¸¸åˆ©ç”¨å›¾åƒä¸­åƒç´ ä¹‹é—´çš„ç›¸å…³æ€§ã€‚å®ƒåœ¨è®­ç»ƒæ—¶ä¸éœ€è¦æœ‰å…³å›¾åƒåƒç´ çš„æ ‡ç­¾ä¿¡æ¯ï¼Œåœ¨é¢„æµ‹æ—¶ä¹Ÿæ— æ³•ä¿è¯åˆ†å‰²å‡ºçš„åŒºåŸŸå…·æœ‰æˆ‘ä»¬å¸Œæœ›å¾—åˆ°çš„è¯­ä¹‰ã€‚ä»¥å›¾åƒ <code>catdog.jpg</code> ä½œä¸ºè¾“å…¥ï¼Œå›¾åƒåˆ†å‰²å¯èƒ½ä¼šå°†ç‹—åˆ†ä¸ºä¸¤ä¸ªåŒºåŸŸï¼šä¸€ä¸ªè¦†ç›–ä»¥é»‘è‰²ä¸ºä¸»çš„å˜´å’Œçœ¼ç›ï¼Œå¦ä¸€ä¸ªè¦†ç›–ä»¥é»„è‰²ä¸ºä¸»çš„å…¶ä½™éƒ¨åˆ†èº«ä½“ã€‚</li>\n<li>å®ä¾‹åˆ†å‰²ä¹Ÿå«åŒæ—¶æ£€æµ‹å¹¶åˆ†å‰²ï¼ˆsimultaneous detection and segmentationï¼‰ï¼Œå®ƒç ”ç©¶å¦‚ä½•è¯†åˆ«å›¾åƒä¸­å„ä¸ªç›®æ ‡å®ä¾‹çš„åƒç´ çº§åŒºåŸŸã€‚ä¸è¯­ä¹‰åˆ†å‰²ä¸åŒï¼Œå®ä¾‹åˆ†å‰²ä¸ä»…éœ€è¦åŒºåˆ†è¯­ä¹‰ï¼Œè¿˜è¦<strong>åŒºåˆ†ä¸åŒçš„ç›®æ ‡å®ä¾‹</strong>ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå›¾åƒä¸­æœ‰ä¸¤æ¡ç‹—ï¼Œåˆ™å®ä¾‹åˆ†å‰²éœ€è¦åŒºåˆ†åƒç´ å±äºçš„ä¸¤æ¡ç‹—ä¸­çš„å“ªä¸€æ¡ã€‚</li>\n</ul>\n<h3 id=\"9-2-Pascal-VOC2012-è¯­ä¹‰åˆ†å‰²æ•°æ®é›†\">9.2 Pascal VOC2012 è¯­ä¹‰åˆ†å‰²æ•°æ®é›†</h3>\n<p>æœ€é‡è¦çš„è¯­ä¹‰åˆ†å‰²æ•°æ®é›†ä¹‹ä¸€æ˜¯ Pascal VOC2012ï¼Œä¸‹é¢æˆ‘ä»¬æ·±å…¥äº†è§£ä¸€ä¸‹è¿™ä¸ªæ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">d2l.DATA_HUB[<span class=\"string\">&#x27;voc2012&#x27;</span>] = (d2l.DATA_URL + <span class=\"string\">&#x27;VOCtrainval_11-May-2012.tar&#x27;</span>, <span class=\"string\">&#x27;4e443f8a2eca6b1dac8a6c57641b67dd40621a49&#x27;</span>)</span><br><span class=\"line\">voc_dir = d2l.download_extract(<span class=\"string\">&#x27;voc2012&#x27;</span>, <span class=\"string\">&#x27;VOCdevkit/VOC2012&#x27;</span>)  <span class=\"comment\"># æå–å‡ºçš„æ•°æ®é›†ä½äº../data/VOCdevkit/VOC2012</span></span><br></pre></td></tr></table></figure>\n<p>è¿›å…¥è·¯å¾„ <code>../data/VOCdevkit/VOC2012</code> ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ•°æ®é›†çš„ä¸åŒç»„ä»¶ã€‚<code>ImageSets/Segmentation</code> è·¯å¾„åŒ…å«ç”¨äºè®­ç»ƒå’Œæµ‹è¯•æ ·æœ¬çš„æ–‡æœ¬æ–‡ä»¶ï¼Œè€Œ <code>JPEGImages</code> å’Œ <code>SegmentationClass</code> è·¯å¾„åˆ†åˆ«å­˜å‚¨ç€æ¯ä¸ªç¤ºä¾‹çš„è¾“å…¥å›¾åƒå’Œæ ‡ç­¾ã€‚æ­¤å¤„çš„æ ‡ç­¾ä¹Ÿé‡‡ç”¨å›¾åƒæ ¼å¼ï¼Œå…¶å°ºå¯¸å’Œå®ƒæ‰€æ ‡æ³¨çš„è¾“å…¥å›¾åƒçš„å°ºå¯¸ç›¸åŒã€‚æ­¤å¤–ï¼Œæ ‡ç­¾ä¸­é¢œè‰²ç›¸åŒçš„åƒç´ å±äºåŒä¸€ä¸ªè¯­ä¹‰ç±»åˆ«ã€‚ä¸‹é¢å°† <code>read_voc_images</code> å‡½æ•°å®šä¹‰ä¸ºå°†æ‰€æœ‰è¾“å…¥çš„å›¾åƒå’Œæ ‡ç­¾è¯»å…¥å†…å­˜ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">read_voc_images</span>(<span class=\"params\">voc_dir, is_train=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è¯»å–æ‰€æœ‰VOCå›¾åƒå¹¶æ ‡æ³¨&quot;&quot;&quot;</span></span><br><span class=\"line\">    txt_fname = os.path.join(voc_dir, <span class=\"string\">&#x27;ImageSets&#x27;</span>, <span class=\"string\">&#x27;Segmentation&#x27;</span>, <span class=\"string\">&#x27;train.txt&#x27;</span> <span class=\"keyword\">if</span> is_train <span class=\"keyword\">else</span> <span class=\"string\">&#x27;val.txt&#x27;</span>)</span><br><span class=\"line\">    mode = torchvision.io.image.ImageReadMode.RGB</span><br><span class=\"line\">    <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(txt_fname, <span class=\"string\">&#x27;r&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        images = f.read().split()</span><br><span class=\"line\">    features, labels = [], []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, fname <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(images):</span><br><span class=\"line\">        features.append(torchvision.io.read_image(os.path.join(voc_dir, <span class=\"string\">&#x27;JPEGImages&#x27;</span>, <span class=\"string\">f&#x27;<span class=\"subst\">&#123;fname&#125;</span>.jpg&#x27;</span>)))</span><br><span class=\"line\">        labels.append(torchvision.io.read_image(os.path.join(voc_dir, <span class=\"string\">&#x27;SegmentationClass&#x27;</span> , <span class=\"string\">f&#x27;<span class=\"subst\">&#123;fname&#125;</span>.png&#x27;</span>), mode))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> features, labels</span><br><span class=\"line\"></span><br><span class=\"line\">train_features, train_labels = read_voc_images(voc_dir, <span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(train_features))  <span class=\"comment\"># 1464</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(train_features[<span class=\"number\">0</span>].shape, train_labels[<span class=\"number\">0</span>].shape)  <span class=\"comment\"># torch.Size([3, 281, 500]) torch.Size([3, 281, 500])</span></span><br></pre></td></tr></table></figure>\n<p>ä¸‹é¢æˆ‘ä»¬ç»˜åˆ¶å‰5ä¸ªè¾“å…¥å›¾åƒåŠå…¶æ ‡ç­¾ã€‚åœ¨æ ‡ç­¾å›¾åƒä¸­ï¼Œç™½è‰²å’Œé»‘è‰²åˆ†åˆ«è¡¨ç¤ºè¾¹æ¡†å’ŒèƒŒæ™¯ï¼Œè€Œå…¶ä»–é¢œè‰²åˆ™å¯¹åº”ä¸åŒçš„ç±»åˆ«ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">imgs = train_features[<span class=\"number\">0</span>:<span class=\"number\">5</span>] + train_labels[<span class=\"number\">0</span>:<span class=\"number\">5</span>]</span><br><span class=\"line\">imgs = [img.permute(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>) <span class=\"keyword\">for</span> img <span class=\"keyword\">in</span> imgs]  <span class=\"comment\"># å°†é€šé“æ”¾åˆ°æœ€åä¸€ç»´</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(imgs), imgs[<span class=\"number\">0</span>].shape)  <span class=\"comment\"># 10 torch.Size([281, 500, 3])</span></span><br><span class=\"line\">d2l.show_images(imgs, <span class=\"number\">2</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ—ä¸¾ RGB é¢œè‰²å€¼å’Œç±»åï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">VOC_COLORMAP = [[<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">128</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">128</span>, <span class=\"number\">0</span>], [<span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">128</span>], [<span class=\"number\">128</span>, <span class=\"number\">0</span>, <span class=\"number\">128</span>],</span><br><span class=\"line\">                [<span class=\"number\">0</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>], [<span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>], [<span class=\"number\">64</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">192</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">64</span>, <span class=\"number\">128</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">                [<span class=\"number\">192</span>, <span class=\"number\">128</span>, <span class=\"number\">0</span>], [<span class=\"number\">64</span>, <span class=\"number\">0</span>, <span class=\"number\">128</span>], [<span class=\"number\">192</span>, <span class=\"number\">0</span>, <span class=\"number\">128</span>], [<span class=\"number\">64</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>], [<span class=\"number\">192</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>],</span><br><span class=\"line\">                [<span class=\"number\">0</span>, <span class=\"number\">64</span>, <span class=\"number\">0</span>], [<span class=\"number\">128</span>, <span class=\"number\">64</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">192</span>, <span class=\"number\">0</span>], [<span class=\"number\">128</span>, <span class=\"number\">192</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">64</span>, <span class=\"number\">128</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\">VOC_CLASSES = [<span class=\"string\">&#x27;background&#x27;</span>, <span class=\"string\">&#x27;aeroplane&#x27;</span>, <span class=\"string\">&#x27;bicycle&#x27;</span>, <span class=\"string\">&#x27;bird&#x27;</span>, <span class=\"string\">&#x27;boat&#x27;</span>, <span class=\"string\">&#x27;bottle&#x27;</span>, <span class=\"string\">&#x27;bus&#x27;</span>,</span><br><span class=\"line\">               <span class=\"string\">&#x27;car&#x27;</span>, <span class=\"string\">&#x27;cat&#x27;</span>, <span class=\"string\">&#x27;chair&#x27;</span>, <span class=\"string\">&#x27;cow&#x27;</span>, <span class=\"string\">&#x27;diningtable&#x27;</span>, <span class=\"string\">&#x27;dog&#x27;</span>, <span class=\"string\">&#x27;horse&#x27;</span>, <span class=\"string\">&#x27;motorbike&#x27;</span>,</span><br><span class=\"line\">               <span class=\"string\">&#x27;person&#x27;</span>, <span class=\"string\">&#x27;potted plant&#x27;</span>, <span class=\"string\">&#x27;sheep&#x27;</span>, <span class=\"string\">&#x27;sofa&#x27;</span>, <span class=\"string\">&#x27;train&#x27;</span>, <span class=\"string\">&#x27;tv/monitor&#x27;</span>]</span><br></pre></td></tr></table></figure>\n<p>é€šè¿‡ä¸Šé¢å®šä¹‰çš„ä¸¤ä¸ªå¸¸é‡ï¼Œæˆ‘ä»¬å¯ä»¥æ–¹ä¾¿åœ°æŸ¥æ‰¾æ ‡ç­¾ä¸­æ¯ä¸ªåƒç´ çš„ç±»ç´¢å¼•ã€‚æˆ‘ä»¬å®šä¹‰äº† <code>voc_colormap2label</code> å‡½æ•°æ¥æ„å»ºä»ä¸Šè¿° RGB é¢œè‰²å€¼åˆ°ç±»åˆ«ç´¢å¼•çš„æ˜ å°„ï¼Œè€Œ <code>voc_label_indices</code> å‡½æ•°å°† RGB å€¼æ˜ å°„åˆ°åœ¨ Pascal VOC2012 æ•°æ®é›†ä¸­çš„ç±»åˆ«ç´¢å¼•ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">voc_colormap2label</span>():</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;æ„å»ºä»RGBåˆ°VOCç±»åˆ«ç´¢å¼•çš„æ˜ å°„&quot;&quot;&quot;</span></span><br><span class=\"line\">    colormap2label = torch.zeros(<span class=\"number\">256</span> ** <span class=\"number\">3</span>, dtype=torch.long)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, colormap <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(VOC_COLORMAP):</span><br><span class=\"line\">        colormap2label[(colormap[<span class=\"number\">0</span>] * <span class=\"number\">256</span> + colormap[<span class=\"number\">1</span>]) * <span class=\"number\">256</span> + colormap[<span class=\"number\">2</span>]] = i  <span class=\"comment\"># å“ˆå¸Œæ˜ å°„</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> colormap2label</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">voc_label_indices</span>(<span class=\"params\">colormap, colormap2label</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å°†VOCæ ‡ç­¾ä¸­çš„RGBå€¼æ˜ å°„åˆ°å®ƒä»¬çš„ç±»åˆ«ç´¢å¼•&quot;&quot;&quot;</span></span><br><span class=\"line\">    colormap = colormap.permute(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>).numpy().astype(<span class=\"string\">&#x27;int32&#x27;</span>)</span><br><span class=\"line\">    idx = ((colormap[:, :, <span class=\"number\">0</span>] * <span class=\"number\">256</span> + colormap[:, :, <span class=\"number\">1</span>]) * <span class=\"number\">256</span> + colormap[:, :, <span class=\"number\">2</span>])</span><br><span class=\"line\">    <span class=\"keyword\">return</span> colormap2label[idx]</span><br></pre></td></tr></table></figure>\n<p>ä¾‹å¦‚ï¼Œåœ¨ç¬¬ä¸€å¼ æ ·æœ¬å›¾åƒä¸­ï¼Œé£æœºå¤´éƒ¨åŒºåŸŸçš„ç±»åˆ«ç´¢å¼•ä¸º1ï¼Œè€ŒèƒŒæ™¯ç´¢å¼•ä¸º0ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">colormap2label = voc_colormap2label()</span><br><span class=\"line\">y = voc_label_indices(train_labels[<span class=\"number\">0</span>], colormap2label)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y[<span class=\"number\">105</span>:<span class=\"number\">115</span>, <span class=\"number\">130</span>:<span class=\"number\">140</span>], VOC_CLASSES[<span class=\"number\">1</span>])</span><br><span class=\"line\"><span class=\"comment\"># tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]) aeroplane</span></span><br></pre></td></tr></table></figure>\n<p>ä¹‹å‰çš„å®éªŒæˆ‘ä»¬é€šè¿‡å†ç¼©æ”¾å›¾åƒä½¿å…¶ç¬¦åˆæ¨¡å‹çš„è¾“å…¥å½¢çŠ¶ã€‚ç„¶è€Œåœ¨è¯­ä¹‰åˆ†å‰²ä¸­ï¼Œè¿™æ ·åšéœ€è¦å°†é¢„æµ‹çš„åƒç´ ç±»åˆ«é‡æ–°æ˜ å°„å›åŸå§‹å°ºå¯¸çš„è¾“å…¥å›¾åƒã€‚è¿™æ ·çš„æ˜ å°„å¯èƒ½ä¸å¤Ÿç²¾ç¡®ï¼Œå°¤å…¶åœ¨ä¸åŒè¯­ä¹‰çš„åˆ†å‰²åŒºåŸŸã€‚ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†å›¾åƒ<strong>è£å‰ªä¸ºå›ºå®šå°ºå¯¸</strong>ï¼Œè€Œä¸æ˜¯å†ç¼©æ”¾ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨å›¾åƒå¢å¹¿ä¸­çš„éšæœºè£å‰ªï¼Œè£å‰ªè¾“å…¥å›¾åƒå’Œæ ‡ç­¾çš„ç›¸åŒåŒºåŸŸï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">voc_rand_crop</span>(<span class=\"params\">feature, label, height, width</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;éšæœºè£å‰ªç‰¹å¾å’Œæ ‡ç­¾å›¾åƒ&quot;&quot;&quot;</span></span><br><span class=\"line\">    rect = torchvision.transforms.RandomCrop.get_params(feature, (height, width))</span><br><span class=\"line\">    feature = torchvision.transforms.functional.crop(feature, *rect)</span><br><span class=\"line\">    label = torchvision.transforms.functional.crop(label, *rect)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> feature, label</span><br><span class=\"line\"></span><br><span class=\"line\">imgs = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">5</span>):</span><br><span class=\"line\">    imgs += voc_rand_crop(train_features[<span class=\"number\">0</span>], train_labels[<span class=\"number\">0</span>], <span class=\"number\">200</span>, <span class=\"number\">300</span>)</span><br><span class=\"line\">imgs = [img.permute(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>) <span class=\"keyword\">for</span> img <span class=\"keyword\">in</span> imgs]</span><br><span class=\"line\">d2l.show_images(imgs[::<span class=\"number\">2</span>] + imgs[<span class=\"number\">1</span>::<span class=\"number\">2</span>], <span class=\"number\">2</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬é€šè¿‡ç»§æ‰¿é«˜çº§ API æä¾›çš„ <code>Dataset</code> ç±»ï¼Œè‡ªå®šä¹‰äº†ä¸€ä¸ªè¯­ä¹‰åˆ†å‰²æ•°æ®é›†ç±» <code>VOCSegDataset</code>ã€‚é€šè¿‡å®ç° <code>__getitem__</code> å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ä»»æ„è®¿é—®æ•°æ®é›†ä¸­ç´¢å¼•ä¸º <code>idx</code> çš„è¾“å…¥å›¾åƒåŠå…¶æ¯ä¸ªåƒç´ çš„ç±»åˆ«ç´¢å¼•ã€‚ç”±äºæ•°æ®é›†ä¸­æœ‰äº›å›¾åƒçš„å°ºå¯¸å¯èƒ½å°äºéšæœºè£å‰ªæ‰€æŒ‡å®šçš„è¾“å‡ºå°ºå¯¸ï¼Œè¿™äº›æ ·æœ¬å¯ä»¥é€šè¿‡è‡ªå®šä¹‰çš„ <code>filter</code> å‡½æ•°ç§»é™¤æ‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å®šä¹‰äº† <code>normalize_image</code> å‡½æ•°ï¼Œä»è€Œå¯¹è¾“å…¥å›¾åƒçš„ RGB ä¸‰ä¸ªé€šé“çš„å€¼åˆ†åˆ«åšæ ‡å‡†åŒ–ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">VOCSegDataset</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä¸€ä¸ªç”¨äºåŠ è½½VOCæ•°æ®é›†çš„è‡ªå®šä¹‰æ•°æ®é›†&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, is_train, crop_size, voc_dir</span>):</span><br><span class=\"line\">        self.transform = torchvision.transforms.Normalize(mean=[<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], std=[<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>])</span><br><span class=\"line\">        self.crop_size = crop_size</span><br><span class=\"line\">        features, labels = read_voc_images(voc_dir, is_train=is_train)</span><br><span class=\"line\">        self.features = [self.normalize_image(feature) <span class=\"keyword\">for</span> feature <span class=\"keyword\">in</span> self.<span class=\"built_in\">filter</span>(features)]</span><br><span class=\"line\">        self.labels = self.<span class=\"built_in\">filter</span>(labels)</span><br><span class=\"line\">        self.colormap2label = voc_colormap2label()</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;read &#x27;</span> + <span class=\"built_in\">str</span>(<span class=\"built_in\">len</span>(self.features)) + <span class=\"string\">&#x27; examples&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">normalize_image</span>(<span class=\"params\">self, img</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.transform(img.<span class=\"built_in\">float</span>() / <span class=\"number\">255</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># è¿‡æ»¤æ‰æ¯”è£åˆ‡å¤§å°è¿˜å°çš„å›¾åƒ</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">filter</span>(<span class=\"params\">self, imgs</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [img <span class=\"keyword\">for</span> img <span class=\"keyword\">in</span> imgs <span class=\"keyword\">if</span> (img.shape[<span class=\"number\">1</span>] &gt;= self.crop_size[<span class=\"number\">0</span>] <span class=\"keyword\">and</span></span><br><span class=\"line\">                                        img.shape[<span class=\"number\">2</span>] &gt;= self.crop_size[<span class=\"number\">1</span>])]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, idx</span>):</span><br><span class=\"line\">        feature, label = voc_rand_crop(self.features[idx], self.labels[idx], *self.crop_size)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (feature, voc_label_indices(label, self.colormap2label))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(self.features)</span><br><span class=\"line\"></span><br><span class=\"line\">crop_size = (<span class=\"number\">320</span>, <span class=\"number\">480</span>)</span><br><span class=\"line\">voc_train, voc_valid = VOCSegDataset(<span class=\"literal\">True</span>, crop_size, voc_dir), VOCSegDataset(<span class=\"literal\">False</span>, crop_size, voc_dir)</span><br></pre></td></tr></table></figure>\n<p>æœ€åï¼Œæˆ‘ä»¬å®šä¹‰ä»¥ä¸‹ <code>load_data_voc</code> å‡½æ•°æ¥ä¸‹è½½å¹¶è¯»å– Pascal VOC2012 è¯­ä¹‰åˆ†å‰²æ•°æ®é›†ã€‚å®ƒè¿”å›è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ•°æ®è¿­ä»£å™¨ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_data_voc</span>(<span class=\"params\">batch_size</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;åŠ è½½VOCè¯­ä¹‰åˆ†å‰²æ•°æ®é›†&quot;&quot;&quot;</span></span><br><span class=\"line\">    train_iter = DataLoader(voc_train, batch_size, shuffle=<span class=\"literal\">True</span>, drop_last=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\">    valid_iter = DataLoader(voc_valid, batch_size, drop_last=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_iter, valid_iter</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">64</span></span><br><span class=\"line\">train_iter, valid_iter = load_data_voc(batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> features, labels <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(features.shape)  <span class=\"comment\"># torch.Size([64, 3, 320, 480])</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(labels.shape)  <span class=\"comment\"># torch.Size([64, 320, 480])</span></span><br><span class=\"line\">    <span class=\"keyword\">break</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"10-è½¬ç½®å·ç§¯\">10. è½¬ç½®å·ç§¯</h2>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/21165.html",
            "url": "https://asanosaki.github.io/posts/21165.html",
            "title": "åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ç¬”è®°(ææ²)-ç°ä»£å·ç§¯ç¥ç»ç½‘ç»œ",
            "date_published": "2023-03-03T01:57:00.000Z",
            "content_html": "<blockquote>\n<p>ææ²åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆPyTorchï¼‰è¯¾ç¨‹å­¦ä¹ ç¬”è®°ç¬¬å…­ç« ï¼šç°ä»£å·ç§¯ç¥ç»ç½‘ç»œã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆAlexNetï¼‰\">1. æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆAlexNetï¼‰</h2>\n<p>AlexNet å’Œ LeNet çš„è®¾è®¡ç†å¿µéå¸¸ç›¸ä¼¼ï¼Œä½†ä¹Ÿå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼š</p>\n<ul>\n<li>AlexNet æ¯”ç›¸å¯¹è¾ƒå°çš„ LeNet5 è¦æ·±å¾—å¤šã€‚AlexNet ç”±å…«å±‚ç»„æˆï¼šäº”ä¸ªå·ç§¯å±‚ã€ä¸¤ä¸ªå…¨è¿æ¥éšè—å±‚å’Œä¸€ä¸ªå…¨è¿æ¥è¾“å‡ºå±‚ã€‚</li>\n<li>AlexNet ä½¿ç”¨ ReLU è€Œä¸æ˜¯ Sigmoid ä½œä¸ºå…¶æ¿€æ´»å‡½æ•°ã€‚</li>\n</ul>\n<p>æ­¤å¤–ï¼ŒAlexNet å°† Sigmoid æ¿€æ´»å‡½æ•°æ”¹ä¸ºæ›´ç®€å•çš„ ReLU æ¿€æ´»å‡½æ•°ã€‚ä¸€æ–¹é¢ï¼ŒReLU æ¿€æ´»å‡½æ•°çš„è®¡ç®—æ›´ç®€å•ï¼Œå®ƒä¸éœ€è¦å¦‚ Sigmoid æ¿€æ´»å‡½æ•°é‚£èˆ¬å¤æ‚çš„æ±‚å¹‚è¿ç®—ã€‚å¦ä¸€æ–¹é¢ï¼Œå½“ä½¿ç”¨ä¸åŒçš„å‚æ•°åˆå§‹åŒ–æ–¹æ³•æ—¶ï¼ŒReLU æ¿€æ´»å‡½æ•°ä½¿è®­ç»ƒæ¨¡å‹æ›´åŠ å®¹æ˜“ã€‚å½“ Sigmoid æ¿€æ´»å‡½æ•°çš„è¾“å‡ºéå¸¸æ¥è¿‘äº0æˆ–1æ—¶ï¼Œè¿™äº›åŒºåŸŸçš„æ¢¯åº¦å‡ ä¹ä¸º0ï¼Œå› æ­¤åå‘ä¼ æ’­æ— æ³•ç»§ç»­æ›´æ–°ä¸€äº›æ¨¡å‹å‚æ•°ã€‚ç›¸åï¼ŒReLU æ¿€æ´»å‡½æ•°åœ¨æ­£åŒºé—´çš„æ¢¯åº¦æ€»æ˜¯1ã€‚å› æ­¤ï¼Œå¦‚æœæ¨¡å‹å‚æ•°æ²¡æœ‰æ­£ç¡®åˆå§‹åŒ–ï¼ŒSigmoid å‡½æ•°å¯èƒ½åœ¨æ­£åŒºé—´å†…å¾—åˆ°å‡ ä¹ä¸º0çš„æ¢¯åº¦ï¼Œä»è€Œä½¿æ¨¡å‹æ— æ³•å¾—åˆ°æœ‰æ•ˆçš„è®­ç»ƒã€‚</p>\n<p>å°½ç®¡åŸæ–‡ä¸­ AlexNet æ˜¯åœ¨ ImageNet ä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼Œä½†æœ¬æ–‡åœ¨è¿™é‡Œä½¿ç”¨çš„æ˜¯ Fashion-MNIST æ•°æ®é›†ã€‚å› ä¸ºå³ä½¿åœ¨ç°ä»£ GPU ä¸Šï¼Œè®­ç»ƒ ImageNet æ¨¡å‹ï¼ŒåŒæ—¶ä½¿å…¶æ”¶æ•›å¯èƒ½éœ€è¦æ•°å°æ—¶æˆ–æ•°å¤©çš„æ—¶é—´ã€‚å°† AlexNet ç›´æ¥åº”ç”¨äº Fashion-MNIST çš„ä¸€ä¸ªé—®é¢˜æ˜¯ Fashion-MNIST å›¾åƒçš„åˆ†è¾¨ç‡ï¼ˆ28Ã—28åƒç´ ï¼‰ä½äº ImageNet å›¾åƒã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†å®ƒä»¬å¢åŠ åˆ°224Ã—224åƒç´ ï¼ˆé€šå¸¸æ¥è®²è¿™ä¸æ˜¯ä¸€ä¸ªæ˜æ™ºçš„åšæ³•ï¼Œä½†åœ¨è¿™é‡Œè¿™æ ·åšæ˜¯ä¸ºäº†æœ‰æ•ˆä½¿ç”¨ AlexNet æ¶æ„ï¼‰ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> util.functions <span class=\"keyword\">import</span> train_classifier</span><br><span class=\"line\"></span><br><span class=\"line\">net = nn.Sequential(</span><br><span class=\"line\">    <span class=\"comment\"># è¿™é‡Œä½¿ç”¨11*11çš„æ›´å¤§çª—å£æ¥æ•æ‰å¯¹è±¡ï¼ŒåŒæ—¶æ­¥å¹…ä¸º4ï¼Œä»¥å‡å°‘è¾“å‡ºçš„é«˜åº¦å’Œå®½åº¦ï¼Œæ­¤å¤–è¾“å‡ºé€šé“çš„æ•°ç›®è¿œå¤§äºLeNet</span></span><br><span class=\"line\">    nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">96</span>, kernel_size=<span class=\"number\">11</span>, stride=<span class=\"number\">4</span>, padding=<span class=\"number\">1</span>), nn.ReLU(),  <span class=\"comment\"># (96, 54, 54)</span></span><br><span class=\"line\">    nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>),  <span class=\"comment\"># (96, 26, 26)</span></span><br><span class=\"line\">    <span class=\"comment\"># å‡å°å·ç§¯çª—å£ï¼Œä½¿ç”¨å¡«å……ä¸º2æ¥ä½¿å¾—è¾“å…¥ä¸è¾“å‡ºçš„é«˜å’Œå®½ä¸€è‡´ï¼Œä¸”å¢å¤§è¾“å‡ºé€šé“æ•°</span></span><br><span class=\"line\">    nn.Conv2d(<span class=\"number\">96</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">5</span>, padding=<span class=\"number\">2</span>), nn.ReLU(),  <span class=\"comment\"># (256, 26, 26)</span></span><br><span class=\"line\">    nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>),  <span class=\"comment\"># (256, 12, 12)</span></span><br><span class=\"line\">    <span class=\"comment\"># ä½¿ç”¨ä¸‰ä¸ªè¿ç»­çš„å·ç§¯å±‚å’Œè¾ƒå°çš„å·ç§¯çª—å£ï¼Œé™¤äº†æœ€åçš„å·ç§¯å±‚ï¼Œè¾“å‡ºé€šé“çš„æ•°é‡è¿›ä¸€æ­¥å¢åŠ </span></span><br><span class=\"line\">    <span class=\"comment\"># åœ¨å‰ä¸¤ä¸ªå·ç§¯å±‚ä¹‹åï¼Œæ±‡èšå±‚ä¸ç”¨äºå‡å°‘è¾“å…¥çš„é«˜åº¦å’Œå®½åº¦</span></span><br><span class=\"line\">    nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>), nn.ReLU(),  <span class=\"comment\"># (384, 12, 12)</span></span><br><span class=\"line\">    nn.Conv2d(<span class=\"number\">384</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>), nn.ReLU(),  <span class=\"comment\"># (384, 12, 12)</span></span><br><span class=\"line\">    nn.Conv2d(<span class=\"number\">384</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>), nn.ReLU(),  <span class=\"comment\"># (256, 12, 12)</span></span><br><span class=\"line\">    nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>),  <span class=\"comment\"># (256, 5, 5)</span></span><br><span class=\"line\">    nn.Flatten(),</span><br><span class=\"line\">    <span class=\"comment\"># è¿™é‡Œå…¨è¿æ¥å±‚çš„è¾“å‡ºæ•°é‡æ˜¯LeNetä¸­çš„å¥½å‡ å€ï¼Œå› æ­¤ä½¿ç”¨Dropoutå±‚æ¥å‡è½»è¿‡æ‹Ÿåˆ</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">6400</span>, <span class=\"number\">4096</span>), nn.ReLU(),</span><br><span class=\"line\">    nn.Dropout(p=<span class=\"number\">0.5</span>),</span><br><span class=\"line\">    nn.Linear(<span class=\"number\">4096</span>, <span class=\"number\">4096</span>), nn.ReLU(),</span><br><span class=\"line\">    nn.Dropout(p=<span class=\"number\">0.5</span>),</span><br><span class=\"line\">    <span class=\"comment\"># æœ€åæ˜¯è¾“å‡ºå±‚ï¼Œç”±äºè¿™é‡Œä½¿ç”¨Fashion-MNISTï¼Œæ‰€ä»¥ç”¨ç±»åˆ«æ•°ä¸º10ï¼Œè€Œéè®ºæ–‡ä¸­çš„1000</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">4096</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">128</span></span><br><span class=\"line\">trans = transforms.Compose([transforms.Resize((<span class=\"number\">224</span>, <span class=\"number\">224</span>)), transforms.ToTensor()])</span><br><span class=\"line\">mnist_train = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">True</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">mnist_test = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">False</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">train_iter = data.DataLoader(mnist_train, batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\">test_iter = data.DataLoader(mnist_test, batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">lr, num_epochs = <span class=\"number\">0.01</span>, <span class=\"number\">50</span></span><br><span class=\"line\"></span><br><span class=\"line\">train_classifier(net, train_iter, test_iter, num_epochs, lr, device, <span class=\"string\">&#x27;../logs/AlexNet_train_log&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-ä½¿ç”¨å—çš„ç½‘ç»œï¼ˆVGGï¼‰\">2. ä½¿ç”¨å—çš„ç½‘ç»œï¼ˆVGGï¼‰</h2>\n<p>è™½ç„¶ AlexNet è¯æ˜æ·±å±‚ç¥ç»ç½‘ç»œå“æœ‰æˆæ•ˆï¼Œä½†å®ƒæ²¡æœ‰æä¾›ä¸€ä¸ªé€šç”¨çš„æ¨¡æ¿æ¥æŒ‡å¯¼åç»­çš„ç ”ç©¶äººå‘˜è®¾è®¡æ–°çš„ç½‘ç»œã€‚</p>\n<p>ç»å…¸å·ç§¯ç¥ç»ç½‘ç»œçš„åŸºæœ¬ç»„æˆéƒ¨åˆ†æ˜¯ä¸‹é¢çš„è¿™ä¸ªåºåˆ—ï¼š</p>\n<ul>\n<li>å¸¦å¡«å……ä»¥ä¿æŒåˆ†è¾¨ç‡çš„å·ç§¯å±‚ã€‚</li>\n<li>éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œå¦‚ ReLUã€‚</li>\n<li>æ±‡èšå±‚ï¼Œå¦‚æœ€å¤§æ±‡èšå±‚ã€‚</li>\n</ul>\n<p>è€Œä¸€ä¸ª VGG å—ä¸ä¹‹ç±»ä¼¼ï¼Œç”±ä¸€ç³»åˆ—å·ç§¯å±‚ç»„æˆï¼Œåé¢å†åŠ ä¸Šç”¨äºç©ºé—´ä¸‹é‡‡æ ·çš„æœ€å¤§æ±‡èšå±‚ã€‚</p>\n<p>VGG ä½¿ç”¨<strong>å¯é‡å¤ä½¿ç”¨</strong>çš„å·ç§¯å—æ¥æ„å»ºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼Œä¸åŒçš„å·ç§¯å—ä¸ªæ•°å’Œè¶…å‚æ•°å¯ä»¥å¾—åˆ°ä¸åŒå¤æ‚åº¦çš„å˜ç§ã€‚</p>\n<p>ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªåä¸º <code>vgg_block</code> çš„å‡½æ•°æ¥å®ç°ä¸€ä¸ª VGG å—ï¼Œè¯¥å‡½æ•°æœ‰ä¸‰ä¸ªå‚æ•°ï¼Œåˆ†åˆ«å¯¹åº”äºå·ç§¯å±‚çš„æ•°é‡ <code>num_convs</code>ã€è¾“å…¥é€šé“çš„æ•°é‡ <code>in_channels</code> å’Œè¾“å‡ºé€šé“çš„æ•°é‡ <code>out_channels</code>ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">vgg_block</span>(<span class=\"params\">num_convs, in_channels, out_channels</span>):</span><br><span class=\"line\">    layers = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_convs):</span><br><span class=\"line\">        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>))</span><br><span class=\"line\">        layers.append(nn.ReLU())</span><br><span class=\"line\">        in_channels = out_channels</span><br><span class=\"line\">    layers.append(nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>\n<p>åŸå§‹ VGG ç½‘ç»œæœ‰5ä¸ªå·ç§¯å—ï¼Œå…¶ä¸­å‰ä¸¤ä¸ªå—å„æœ‰ä¸€ä¸ªå·ç§¯å±‚ï¼Œåä¸‰ä¸ªå—å„åŒ…å«ä¸¤ä¸ªå·ç§¯å±‚ã€‚ç¬¬ä¸€ä¸ªæ¨¡å—æœ‰64ä¸ªè¾“å‡ºé€šé“ï¼Œæ¯ä¸ªåç»­æ¨¡å—å°†è¾“å‡ºé€šé“æ•°é‡ç¿»å€ï¼Œç›´åˆ°è¾¾åˆ°512ã€‚ç”±äºè¯¥ç½‘ç»œä½¿ç”¨8ä¸ªå·ç§¯å±‚å’Œ3ä¸ªå…¨è¿æ¥å±‚ï¼Œå› æ­¤å®ƒé€šå¸¸è¢«ç§°ä¸º VGG-11ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">vgg</span>(<span class=\"params\">conv_arch</span>):</span><br><span class=\"line\">    conv_blks = []</span><br><span class=\"line\">    in_channels = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"comment\"># å·ç§¯å±‚éƒ¨åˆ†</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (num_convs, out_channels) <span class=\"keyword\">in</span> conv_arch:</span><br><span class=\"line\">        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))</span><br><span class=\"line\">        in_channels = out_channels</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(</span><br><span class=\"line\">        *conv_blks, nn.Flatten(),</span><br><span class=\"line\">        <span class=\"comment\"># å…¨è¿æ¥å±‚éƒ¨åˆ†</span></span><br><span class=\"line\">        nn.Linear(out_channels * <span class=\"number\">7</span> * <span class=\"number\">7</span>, <span class=\"number\">4096</span>), nn.ReLU(), nn.Dropout(<span class=\"number\">0.5</span>),</span><br><span class=\"line\">        nn.Linear(<span class=\"number\">4096</span>, <span class=\"number\">4096</span>), nn.ReLU(), nn.Dropout(<span class=\"number\">0.5</span>),</span><br><span class=\"line\">        nn.Linear(<span class=\"number\">4096</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">conv_arch = ((<span class=\"number\">1</span>, <span class=\"number\">64</span>), (<span class=\"number\">1</span>, <span class=\"number\">128</span>), (<span class=\"number\">2</span>, <span class=\"number\">256</span>), (<span class=\"number\">2</span>, <span class=\"number\">512</span>), (<span class=\"number\">2</span>, <span class=\"number\">512</span>))</span><br><span class=\"line\">net = vgg(conv_arch)</span><br></pre></td></tr></table></figure>\n<p>ç”±äº VGG-11 æ¯” AlexNet è®¡ç®—é‡æ›´å¤§ï¼Œå› æ­¤æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªé€šé“æ•°è¾ƒå°‘çš„ç½‘ç»œï¼Œè¶³å¤Ÿç”¨äºè®­ç»ƒ Fashion-MNIST æ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conv_arch = ((<span class=\"number\">1</span>, <span class=\"number\">16</span>), (<span class=\"number\">1</span>, <span class=\"number\">32</span>), (<span class=\"number\">2</span>, <span class=\"number\">64</span>), (<span class=\"number\">2</span>, <span class=\"number\">128</span>), (<span class=\"number\">2</span>, <span class=\"number\">128</span>))</span><br><span class=\"line\">net = vgg(conv_arch)</span><br></pre></td></tr></table></figure>\n<p>æœ€åæˆ‘ä»¬è¯»å–æ•°æ®é›†å¹¶è¿›è¡Œè®­ç»ƒï¼Œè¶…å‚æ•°è®¾ç½®ï¼š<code>lr, num_epochs = 0.02, 15</code>ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸ç¬¬ä¸€èŠ‚å†…å®¹ä¸€æ ·ï¼Œå› æ­¤ä¸å†æ”¾å‡ºä»£ç ã€‚</p>\n<p>PSï¼šå¦‚æœæ˜¾å­˜ä¸å¤Ÿå¯ä»¥å‡å° <code>batch_size</code>ï¼Œä»128æ”¹ä¸º64æˆ–32ã€‚</p>\n<h2 id=\"3-ç½‘ç»œä¸­çš„ç½‘ç»œï¼ˆNiNï¼‰\">3. ç½‘ç»œä¸­çš„ç½‘ç»œï¼ˆNiNï¼‰</h2>\n<p>å›æƒ³ä¸€ä¸‹ï¼Œå·ç§¯å±‚çš„è¾“å…¥å’Œè¾“å‡ºç”±å››ç»´å¼ é‡ç»„æˆï¼Œå¼ é‡çš„æ¯ä¸ªè½´åˆ†åˆ«å¯¹åº”æ ·æœ¬ã€é€šé“ã€é«˜åº¦å’Œå®½åº¦ã€‚å¦å¤–ï¼Œå…¨è¿æ¥å±‚çš„è¾“å…¥å’Œè¾“å‡ºé€šå¸¸æ˜¯åˆ†åˆ«å¯¹åº”äºæ ·æœ¬å’Œç‰¹å¾çš„äºŒç»´å¼ é‡ã€‚NiN çš„æƒ³æ³•æ˜¯<strong>åœ¨æ¯ä¸ªåƒç´ ä½ç½®ï¼ˆé’ˆå¯¹æ¯ä¸ªé«˜åº¦å’Œå®½åº¦ï¼‰åº”ç”¨ä¸€ä¸ªå…¨è¿æ¥å±‚</strong>ã€‚å¦‚æœæˆ‘ä»¬å°†æƒé‡è¿æ¥åˆ°æ¯ä¸ªç©ºé—´ä½ç½®ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶è§†ä¸º1Ã—1å·ç§¯å±‚ï¼ˆå¦‚ç¬¬äº”ç« ç¬¬å››èŠ‚ PS ä¸­æ‰€è¿°ï¼‰ï¼Œæˆ–ä½œä¸ºåœ¨æ¯ä¸ªåƒç´ ä½ç½®ä¸Šç‹¬ç«‹ä½œç”¨çš„å…¨è¿æ¥å±‚ã€‚ä»å¦ä¸€ä¸ªè§’åº¦çœ‹ï¼Œå³å°†ç©ºé—´ç»´åº¦ä¸­çš„æ¯ä¸ªåƒç´ è§†ä¸ºå•ä¸ªæ ·æœ¬ï¼Œå°†é€šé“ç»´åº¦è§†ä¸ºä¸åŒç‰¹å¾ï¼ˆfeatureï¼‰ã€‚</p>\n<p>NiN å—ä»¥ä¸€ä¸ªæ™®é€šå·ç§¯å±‚å¼€å§‹ï¼Œåé¢æ˜¯ä¸¤ä¸ª1Ã—1çš„å·ç§¯å±‚ã€‚è¿™ä¸¤ä¸ª1Ã—1å·ç§¯å±‚å……å½“å¸¦æœ‰ ReLU æ¿€æ´»å‡½æ•°çš„é€åƒç´ å…¨è¿æ¥å±‚ï¼Œå¯¹æ¯ä¸ªåƒç´ å¢åŠ äº†éçº¿æ€§ç‰¹æ€§ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">nin_block</span>(<span class=\"params\">in_channels, out_channels, kernel_size, strides, padding</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(</span><br><span class=\"line\">        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(),</span><br><span class=\"line\">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class=\"number\">1</span>), nn.ReLU(),</span><br><span class=\"line\">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class=\"number\">1</span>), nn.ReLU())</span><br></pre></td></tr></table></figure>\n<p>NiN å’Œ AlexNet ä¹‹é—´çš„ä¸€ä¸ªæ˜¾è‘—åŒºåˆ«æ˜¯ NiN å®Œå…¨å–æ¶ˆäº†å…¨è¿æ¥å±‚ã€‚ç›¸åï¼ŒNiN ä½¿ç”¨ä¸€ä¸ª NiN å—ï¼Œå…¶è¾“å‡ºé€šé“æ•°ç­‰äºæ ‡ç­¾ç±»åˆ«çš„æ•°é‡ã€‚æœ€åæ”¾ä¸€ä¸ªå…¨å±€å¹³å‡æ±‡èšå±‚ï¼ˆglobal average pooling layerï¼‰ï¼Œç”Ÿæˆä¸€ä¸ªå¯¹æ•°å‡ ç‡ï¼ˆlogitsï¼‰ã€‚NiN è®¾è®¡çš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯ï¼Œå®ƒæ˜¾è‘—å‡å°‘äº†æ¨¡å‹æ‰€éœ€å‚æ•°çš„æ•°é‡ã€‚ç„¶è€Œï¼Œåœ¨å®è·µä¸­ï¼Œè¿™ç§è®¾è®¡æœ‰æ—¶ä¼šå¢åŠ è®­ç»ƒæ¨¡å‹çš„æ—¶é—´ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net = nn.Sequential(</span><br><span class=\"line\">    nin_block(<span class=\"number\">1</span>, <span class=\"number\">96</span>, kernel_size=<span class=\"number\">11</span>, strides=<span class=\"number\">4</span>, padding=<span class=\"number\">0</span>),</span><br><span class=\"line\">    nn.MaxPool2d(<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>),</span><br><span class=\"line\">    nin_block(<span class=\"number\">96</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">5</span>, strides=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),</span><br><span class=\"line\">    nn.MaxPool2d(<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>),</span><br><span class=\"line\">    nin_block(<span class=\"number\">256</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, strides=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),</span><br><span class=\"line\">    nn.MaxPool2d(<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>),</span><br><span class=\"line\">    nn.Dropout(<span class=\"number\">0.5</span>),</span><br><span class=\"line\">    nin_block(<span class=\"number\">384</span>, <span class=\"number\">10</span>, kernel_size=<span class=\"number\">3</span>, strides=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),  <span class=\"comment\"># æ ‡ç­¾ç±»åˆ«æ•°æ˜¯10</span></span><br><span class=\"line\">    nn.AdaptiveAvgPool2d((<span class=\"number\">1</span>, <span class=\"number\">1</span>)),  <span class=\"comment\"># å°†å››ç»´çš„è¾“å‡ºè½¬æˆäºŒç»´çš„è¾“å‡ºï¼Œå…¶å½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°,10)</span></span><br><span class=\"line\">    nn.Flatten())</span><br></pre></td></tr></table></figure>\n<p>æœ€åæˆ‘ä»¬è¯»å–æ•°æ®é›†å¹¶è¿›è¡Œè®­ç»ƒï¼Œè¶…å‚æ•°è®¾ç½®ï¼š<code>lr, num_epochs = 0.1, 15</code>ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸ç¬¬ä¸€èŠ‚å†…å®¹ä¸€æ ·ï¼Œå› æ­¤ä¸å†æ”¾å‡ºä»£ç ã€‚</p>\n<h2 id=\"4-å«å¹¶è¡Œè¿ç»“çš„ç½‘ç»œï¼ˆGoogLeNetï¼‰\">4. å«å¹¶è¡Œè¿ç»“çš„ç½‘ç»œï¼ˆGoogLeNetï¼‰</h2>\n<p>åœ¨ GoogLeNet ä¸­ï¼ŒåŸºæœ¬çš„å·ç§¯å—è¢«ç§°ä¸º Inception å—ï¼ˆInception blockï¼‰ã€‚Inception å—ç”±å››æ¡å¹¶è¡Œè·¯å¾„ç»„æˆã€‚å‰ä¸‰æ¡è·¯å¾„ä½¿ç”¨çª—å£å¤§å°ä¸º1Ã—1ã€3Ã—3å’Œ5Ã—5çš„å·ç§¯å±‚ï¼Œä»ä¸åŒç©ºé—´å¤§å°ä¸­æå–ä¿¡æ¯ã€‚ä¸­é—´çš„ä¸¤æ¡è·¯å¾„åœ¨è¾“å…¥ä¸Šæ‰§è¡Œ1Ã—1å·ç§¯ï¼Œä»¥å‡å°‘é€šé“æ•°ï¼Œä»è€Œé™ä½æ¨¡å‹çš„å¤æ‚æ€§ã€‚ç¬¬å››æ¡è·¯å¾„ä½¿ç”¨3Ã—3æœ€å¤§æ±‡èšå±‚ï¼Œç„¶åä½¿ç”¨1Ã—1å·ç§¯å±‚æ¥æ”¹å˜é€šé“æ•°ã€‚è¿™å››æ¡è·¯å¾„éƒ½ä½¿ç”¨åˆé€‚çš„å¡«å……æ¥ä½¿<strong>è¾“å…¥ä¸è¾“å‡ºçš„é«˜å’Œå®½ä¸€è‡´</strong>ï¼Œæœ€åæˆ‘ä»¬å°†æ¯æ¡çº¿è·¯çš„è¾“å‡ºåœ¨<strong>é€šé“ç»´åº¦</strong>ä¸Šè¿ç»“ï¼Œå¹¶æ„æˆ Inception å—çš„è¾“å‡ºã€‚åœ¨ Inception å—ä¸­ï¼Œé€šå¸¸è°ƒæ•´çš„è¶…å‚æ•°æ˜¯æ¯å±‚è¾“å‡ºé€šé“æ•°ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Inception</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"comment\"># c1-c4æ˜¯æ¯æ¡è·¯å¾„çš„è¾“å‡ºé€šé“æ•°</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_channels, c1, c2, c3, c4, **kwargs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Inception, self).__init__(**kwargs)</span><br><span class=\"line\">        <span class=\"comment\"># çº¿è·¯1ï¼Œå•1x1å·ç§¯å±‚</span></span><br><span class=\"line\">        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># çº¿è·¯2ï¼Œ1x1å·ç§¯å±‚åæ¥3x3å·ç§¯å±‚</span></span><br><span class=\"line\">        self.p2_1 = nn.Conv2d(in_channels, c2[<span class=\"number\">0</span>], kernel_size=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.p2_2 = nn.Conv2d(c2[<span class=\"number\">0</span>], c2[<span class=\"number\">1</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># çº¿è·¯3ï¼Œ1x1å·ç§¯å±‚åæ¥5x5å·ç§¯å±‚</span></span><br><span class=\"line\">        self.p3_1 = nn.Conv2d(in_channels, c3[<span class=\"number\">0</span>], kernel_size=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.p3_2 = nn.Conv2d(c3[<span class=\"number\">0</span>], c3[<span class=\"number\">1</span>], kernel_size=<span class=\"number\">5</span>, padding=<span class=\"number\">2</span>)</span><br><span class=\"line\">        <span class=\"comment\"># çº¿è·¯4ï¼Œ3x3æœ€å¤§æ±‡èšå±‚åæ¥1x1å·ç§¯å±‚</span></span><br><span class=\"line\">        self.p4_1 = nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        p1 = F.relu(self.p1_1(x))</span><br><span class=\"line\">        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))</span><br><span class=\"line\">        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))</span><br><span class=\"line\">        p4 = F.relu(self.p4_2(self.p4_1(x)))</span><br><span class=\"line\">        <span class=\"comment\"># åœ¨é€šé“ç»´åº¦ï¼ˆç¬¬ä¸€ç»´ï¼‰ä¸Šè¿ç»“è¾“å‡º</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.cat((p1, p2, p3, p4), dim=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<p>GoogLeNet ä¸€å…±ä½¿ç”¨9ä¸ª Inception å—å’Œå…¨å±€å¹³å‡æ±‡èšå±‚çš„å †å æ¥ç”Ÿæˆå…¶ä¼°è®¡å€¼ã€‚Inception å—ä¹‹é—´çš„æœ€å¤§æ±‡èšå±‚å¯é™ä½ç»´åº¦ã€‚ç¬¬ä¸€ä¸ªæ¨¡å—ç±»ä¼¼äº AlexNet å’Œ LeNetï¼ŒInception å—çš„ç»„åˆä» VGG ç»§æ‰¿ï¼Œå…¨å±€å¹³å‡æ±‡èšå±‚é¿å…äº†åœ¨æœ€åä½¿ç”¨å…¨è¿æ¥å±‚ã€‚</p>\n<p>ç°åœ¨ï¼Œæˆ‘ä»¬é€ä¸€å®ç° GoogLeNet çš„æ¯ä¸ªæ¨¡å—ã€‚ç¬¬ä¸€ä¸ªæ¨¡å—ä½¿ç”¨64ä¸ªé€šé“ã€7Ã—7å·ç§¯å±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">b1 = nn.Sequential(nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">7</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">3</span>),</span><br><span class=\"line\">                   nn.ReLU(),</span><br><span class=\"line\">                   nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p>ç¬¬äºŒä¸ªæ¨¡å—ä½¿ç”¨ä¸¤ä¸ªå·ç§¯å±‚ï¼šç¬¬ä¸€ä¸ªå·ç§¯å±‚æ˜¯64ä¸ªé€šé“ã€1Ã—1å·ç§¯å±‚ï¼›ç¬¬äºŒä¸ªå·ç§¯å±‚ä½¿ç”¨å°†é€šé“æ•°é‡å¢åŠ ä¸‰å€çš„3Ã—3å·ç§¯å±‚ã€‚è¿™å¯¹åº”äº Inception å—ä¸­çš„ç¬¬äºŒæ¡è·¯å¾„ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">b2 = nn.Sequential(nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>),</span><br><span class=\"line\">                   nn.ReLU(),</span><br><span class=\"line\">                   nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">192</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>),</span><br><span class=\"line\">                   nn.ReLU(),</span><br><span class=\"line\">                   nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p>ç¬¬ä¸‰ä¸ªæ¨¡å—ä¸²è”ä¸¤ä¸ªå®Œæ•´çš„ Inception å—ã€‚ç¬¬ä¸€ä¸ª Inception å—çš„è¾“å‡ºé€šé“æ•°ä¸º <code>64 + 128 + 32 + 32 = 256</code>ï¼Œå››ä¸ªè·¯å¾„ä¹‹é—´çš„è¾“å‡ºé€šé“æ•°é‡æ¯”ä¸º <code>2 : 4 : 1 : 1</code>ï¼Œç¬¬äºŒä¸ªå’Œç¬¬ä¸‰ä¸ªè·¯å¾„é¦–å…ˆå°†è¾“å…¥é€šé“çš„æ•°é‡åˆ†åˆ«å‡å°‘åˆ°96å’Œ16ï¼Œç„¶åè¿æ¥ç¬¬äºŒä¸ªå·ç§¯å±‚ã€‚ç¬¬äºŒä¸ª Inception å—çš„è¾“å‡ºé€šé“æ•°å¢åŠ åˆ° <code>128 + 192 + 96 + 64 = 480</code>ï¼Œå››ä¸ªè·¯å¾„ä¹‹é—´çš„è¾“å‡ºé€šé“æ•°é‡æ¯”ä¸º <code>4 : 6 : 3 : 2</code>ï¼Œç¬¬äºŒæ¡å’Œç¬¬ä¸‰æ¡è·¯å¾„é¦–å…ˆå°†è¾“å…¥é€šé“çš„æ•°é‡åˆ†åˆ«å‡å°‘åˆ°128å’Œ32ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">b3 = nn.Sequential(Inception(<span class=\"number\">192</span>, <span class=\"number\">64</span>, (<span class=\"number\">96</span>, <span class=\"number\">128</span>), (<span class=\"number\">16</span>, <span class=\"number\">32</span>), <span class=\"number\">32</span>),</span><br><span class=\"line\">                   Inception(<span class=\"number\">256</span>, <span class=\"number\">128</span>, (<span class=\"number\">128</span>, <span class=\"number\">192</span>), (<span class=\"number\">32</span>, <span class=\"number\">96</span>), <span class=\"number\">64</span>),</span><br><span class=\"line\">                   nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p>ç¬¬å››æ¨¡å—æ›´åŠ å¤æ‚ï¼Œå®ƒä¸²è”äº†5ä¸ª Inception å—ï¼Œå…¶è¾“å‡ºé€šé“æ•°åˆ†åˆ«æ˜¯ <code>192 + 208 + 48 + 64 = 512</code>ã€<code>160 + 224 + 64 + 64 = 512</code>ã€<code>128 + 256 + 64 + 64 = 512</code>ã€<code>112 + 288 + 64 + 64 = 528</code> å’Œ <code>256 + 320 + 128 + 128 = 832</code>ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">b4 = nn.Sequential(Inception(<span class=\"number\">480</span>, <span class=\"number\">192</span>, (<span class=\"number\">96</span>, <span class=\"number\">208</span>), (<span class=\"number\">16</span>, <span class=\"number\">48</span>), <span class=\"number\">64</span>),</span><br><span class=\"line\">                   Inception(<span class=\"number\">512</span>, <span class=\"number\">160</span>, (<span class=\"number\">112</span>, <span class=\"number\">224</span>), (<span class=\"number\">24</span>, <span class=\"number\">64</span>), <span class=\"number\">64</span>),</span><br><span class=\"line\">                   Inception(<span class=\"number\">512</span>, <span class=\"number\">128</span>, (<span class=\"number\">128</span>, <span class=\"number\">256</span>), (<span class=\"number\">24</span>, <span class=\"number\">64</span>), <span class=\"number\">64</span>),</span><br><span class=\"line\">                   Inception(<span class=\"number\">512</span>, <span class=\"number\">112</span>, (<span class=\"number\">144</span>, <span class=\"number\">288</span>), (<span class=\"number\">32</span>, <span class=\"number\">64</span>), <span class=\"number\">64</span>),</span><br><span class=\"line\">                   Inception(<span class=\"number\">528</span>, <span class=\"number\">256</span>, (<span class=\"number\">160</span>, <span class=\"number\">320</span>), (<span class=\"number\">32</span>, <span class=\"number\">128</span>), <span class=\"number\">128</span>),</span><br><span class=\"line\">                   nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p>ç¬¬äº”æ¨¡å—åŒ…å«è¾“å‡ºé€šé“æ•°ä¸º <code>256 + 320 + 128 + 128 = 832</code> å’Œ <code>384 + 384 + 128 + 128 = 1024</code> çš„ä¸¤ä¸ª Inception å—ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç¬¬äº”æ¨¡å—çš„åé¢ç´§è·Ÿè¾“å‡ºå±‚ï¼Œè¯¥æ¨¡å—åŒ NiN ä¸€æ ·ä½¿ç”¨å…¨å±€å¹³å‡æ±‡èšå±‚ï¼Œå°†æ¯ä¸ªé€šé“çš„é«˜å’Œå®½å˜æˆ1ã€‚æœ€åæˆ‘ä»¬å°†è¾“å‡ºå˜æˆäºŒç»´æ•°ç»„ï¼Œå†æ¥ä¸Šä¸€ä¸ªè¾“å‡ºä¸ªæ•°ä¸ºæ ‡ç­¾ç±»åˆ«æ•°çš„å…¨è¿æ¥å±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">b5 = nn.Sequential(Inception(<span class=\"number\">832</span>, <span class=\"number\">256</span>, (<span class=\"number\">160</span>, <span class=\"number\">320</span>), (<span class=\"number\">32</span>, <span class=\"number\">128</span>), <span class=\"number\">128</span>),</span><br><span class=\"line\">                   Inception(<span class=\"number\">832</span>, <span class=\"number\">384</span>, (<span class=\"number\">192</span>, <span class=\"number\">384</span>), (<span class=\"number\">48</span>, <span class=\"number\">128</span>), <span class=\"number\">128</span>),</span><br><span class=\"line\">                   nn.AdaptiveAvgPool2d((<span class=\"number\">1</span>, <span class=\"number\">1</span>)),</span><br><span class=\"line\">                   nn.Flatten())</span><br><span class=\"line\"></span><br><span class=\"line\">net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(<span class=\"number\">1024</span>, <span class=\"number\">10</span>))</span><br></pre></td></tr></table></figure>\n<p>æœ€åæˆ‘ä»¬è¯»å–æ•°æ®é›†å¹¶è¿›è¡Œè®­ç»ƒï¼Œè¶…å‚æ•°è®¾ç½®ï¼š<code>lr, num_epochs = 0.1, 15</code>ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸ç¬¬ä¸€èŠ‚å†…å®¹ä¸€æ ·ï¼Œå› æ­¤ä¸å†æ”¾å‡ºä»£ç ã€‚</p>\n<h2 id=\"5-æ‰¹é‡è§„èŒƒåŒ–ï¼ˆBNï¼‰\">5. æ‰¹é‡è§„èŒƒåŒ–ï¼ˆBNï¼‰</h2>\n<p>æ‰¹é‡è§„èŒƒåŒ–ï¼ˆBatch Normalizationï¼‰æ˜¯ä¸€ç§æµè¡Œä¸”æœ‰æ•ˆçš„æŠ€æœ¯ï¼Œå¯æŒç»­åŠ é€Ÿæ·±å±‚ç½‘ç»œçš„æ”¶æ•›é€Ÿåº¦ã€‚</p>\n<p>ä½¿ç”¨çœŸå®æ•°æ®æ—¶ï¼Œæˆ‘ä»¬çš„ç¬¬ä¸€æ­¥æ˜¯æ ‡å‡†åŒ–è¾“å…¥ç‰¹å¾ï¼Œä½¿å…¶å¹³å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ã€‚ç›´è§‚åœ°è¯´ï¼Œè¿™ç§æ ‡å‡†åŒ–å¯ä»¥å¾ˆå¥½åœ°ä¸æˆ‘ä»¬çš„ä¼˜åŒ–å™¨é…åˆä½¿ç”¨ï¼Œå› ä¸ºå®ƒå¯ä»¥å°†å‚æ•°çš„é‡çº§è¿›è¡Œç»Ÿä¸€ã€‚</p>\n<p>ç¬¬äºŒï¼Œå¯¹äºå…¸å‹çš„å¤šå±‚æ„ŸçŸ¥æœºæˆ–å·ç§¯ç¥ç»ç½‘ç»œã€‚å½“æˆ‘ä»¬è®­ç»ƒæ—¶ï¼Œä¸­é—´å±‚ä¸­çš„å˜é‡ï¼ˆä¾‹å¦‚ï¼Œå¤šå±‚æ„ŸçŸ¥æœºä¸­çš„ä»¿å°„å˜æ¢è¾“å‡ºï¼‰å¯èƒ½å…·æœ‰æ›´å¹¿çš„å˜åŒ–èŒƒå›´ï¼šä¸è®ºæ˜¯æ²¿ç€ä»è¾“å…¥åˆ°è¾“å‡ºçš„å±‚ï¼Œè·¨åŒä¸€å±‚ä¸­çš„å•å…ƒï¼Œæˆ–æ˜¯éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæ¨¡å‹å‚æ•°éšç€è®­ç»ƒæ›´æ–°çš„å˜å¹»è«æµ‹ã€‚æ‰¹é‡è§„èŒƒåŒ–çš„å‘æ˜è€…éæ­£å¼åœ°å‡è®¾ï¼Œè¿™äº›å˜é‡åˆ†å¸ƒä¸­çš„è¿™ç§åç§»å¯èƒ½ä¼šé˜»ç¢ç½‘ç»œçš„æ”¶æ•›ã€‚ç›´è§‚åœ°è¯´ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šçŒœæƒ³ï¼Œå¦‚æœä¸€ä¸ªå±‚çš„å¯å˜å€¼æ˜¯å¦ä¸€å±‚çš„100å€ï¼Œè¿™å¯èƒ½éœ€è¦å¯¹å­¦ä¹ ç‡è¿›è¡Œè¡¥å¿è°ƒæ•´ã€‚</p>\n<p>ç¬¬ä¸‰ï¼Œæ›´æ·±å±‚çš„ç½‘ç»œå¾ˆå¤æ‚ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆã€‚è¿™æ„å‘³ç€æ­£åˆ™åŒ–å˜å¾—æ›´åŠ é‡è¦ã€‚</p>\n<p>æ‰¹é‡è§„èŒƒåŒ–åº”ç”¨äºå•ä¸ªå¯é€‰å±‚ï¼ˆä¹Ÿå¯ä»¥åº”ç”¨åˆ°æ‰€æœ‰å±‚ï¼‰ï¼Œå…¶åŸç†å¦‚ä¸‹ï¼šåœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè§„èŒƒåŒ–è¾“å…¥ï¼Œå³é€šè¿‡<strong>å‡å»å…¶å‡å€¼å¹¶é™¤ä»¥å…¶æ ‡å‡†å·®</strong>ï¼Œå…¶ä¸­ä¸¤è€…å‡åŸºäºå½“å‰å°æ‰¹é‡å¤„ç†ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åº”ç”¨<strong>æ¯”ä¾‹ç³»æ•°å’Œæ¯”ä¾‹åç§»</strong>ã€‚æ­£æ˜¯ç”±äºè¿™ä¸ªåŸºäºæ‰¹é‡ç»Ÿè®¡çš„æ ‡å‡†åŒ–ï¼Œæ‰æœ‰äº†æ‰¹é‡è§„èŒƒåŒ–çš„åç§°ã€‚</p>\n<p>è¯·æ³¨æ„ï¼Œå¦‚æœæˆ‘ä»¬å°è¯•ä½¿ç”¨å¤§å°ä¸º1çš„å°æ‰¹é‡åº”ç”¨æ‰¹é‡è§„èŒƒåŒ–ï¼Œæˆ‘ä»¬å°†æ— æ³•å­¦åˆ°ä»»ä½•ä¸œè¥¿ã€‚è¿™æ˜¯å› ä¸ºåœ¨å‡å»å‡å€¼ä¹‹åï¼Œæ¯ä¸ªéšè—å•å…ƒå°†ä¸º0ã€‚æ‰€ä»¥ï¼Œåªæœ‰ä½¿ç”¨è¶³å¤Ÿå¤§çš„å°æ‰¹é‡ï¼Œæ‰¹é‡è§„èŒƒåŒ–è¿™ç§æ–¹æ³•æ‰æ˜¯æœ‰æ•ˆä¸”ç¨³å®šçš„ã€‚è¯·æ³¨æ„ï¼Œåœ¨åº”ç”¨æ‰¹é‡è§„èŒƒåŒ–æ—¶ï¼Œæ‰¹é‡å¤§å°çš„é€‰æ‹©å¯èƒ½æ¯”æ²¡æœ‰æ‰¹é‡è§„èŒƒåŒ–æ—¶æ›´é‡è¦ã€‚</p>\n<p>é€šå¸¸ï¼Œæˆ‘ä»¬å°†æ‰¹é‡è§„èŒƒåŒ–å±‚ç½®äºå…¨è¿æ¥å±‚ä¸­çš„ä»¿å°„å˜æ¢å’Œæ¿€æ´»å‡½æ•°ä¹‹é—´ã€‚åŒæ ·ï¼Œå¯¹äºå·ç§¯å±‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å·ç§¯å±‚ä¹‹åå’Œéçº¿æ€§æ¿€æ´»å‡½æ•°ä¹‹å‰åº”ç”¨æ‰¹é‡è§„èŒƒåŒ–ã€‚</p>\n<p>ä¸‹é¢ï¼Œæˆ‘ä»¬ä»å¤´å¼€å§‹å®ç°ä¸€ä¸ªå…·æœ‰å¼ é‡çš„æ‰¹é‡è§„èŒƒåŒ–å±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">batch_norm</span>(<span class=\"params\">X, gamma, beta, moving_mean, moving_var, eps, momentum</span>):</span><br><span class=\"line\">    <span class=\"comment\"># é€šè¿‡is_grad_enabledæ¥åˆ¤æ–­å½“å‰æ¨¡å¼æ˜¯è®­ç»ƒæ¨¡å¼è¿˜æ˜¯é¢„æµ‹æ¨¡å¼</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> torch.is_grad_enabled():</span><br><span class=\"line\">        <span class=\"comment\"># å¦‚æœæ˜¯åœ¨é¢„æµ‹æ¨¡å¼ä¸‹ï¼Œç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ç§»åŠ¨å¹³å‡æ‰€å¾—çš„å‡å€¼å’Œæ–¹å·®</span></span><br><span class=\"line\">        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"comment\"># å‡è®¾åªè€ƒè™‘å…¨è¿æ¥å’ŒäºŒç»´å·ç§¯</span></span><br><span class=\"line\">        <span class=\"keyword\">assert</span> <span class=\"built_in\">len</span>(X.shape) <span class=\"keyword\">in</span> (<span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(X.shape) == <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"comment\"># ä½¿ç”¨å…¨è¿æ¥å±‚çš„æƒ…å†µï¼Œè®¡ç®—ç‰¹å¾ç»´ä¸Šçš„å‡å€¼å’Œæ–¹å·®</span></span><br><span class=\"line\">            mean = X.mean(dim=<span class=\"number\">0</span>)</span><br><span class=\"line\">            var = ((X - mean) ** <span class=\"number\">2</span>).mean(dim=<span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># ä½¿ç”¨äºŒç»´å·ç§¯å±‚çš„æƒ…å†µï¼Œè®¡ç®—é€šé“ç»´ä¸Šï¼ˆaxis=1ï¼‰çš„å‡å€¼å’Œæ–¹å·®ã€‚</span></span><br><span class=\"line\">            <span class=\"comment\"># è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¿æŒXçš„å½¢çŠ¶ä»¥ä¾¿åé¢å¯ä»¥åšå¹¿æ’­è¿ç®—</span></span><br><span class=\"line\">            mean = X.mean(dim=(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>), keepdim=<span class=\"literal\">True</span>)</span><br><span class=\"line\">            var = ((X - mean) ** <span class=\"number\">2</span>).mean(dim=(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>), keepdim=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        <span class=\"comment\"># è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œç”¨å½“å‰çš„å‡å€¼å’Œæ–¹å·®åšæ ‡å‡†åŒ–</span></span><br><span class=\"line\">        X_hat = (X - mean) / torch.sqrt(var + eps)</span><br><span class=\"line\">        <span class=\"comment\"># æ›´æ–°ç§»åŠ¨å¹³å‡çš„å‡å€¼å’Œæ–¹å·®</span></span><br><span class=\"line\">        moving_mean = momentum * moving_mean + (<span class=\"number\">1.0</span> - momentum) * mean</span><br><span class=\"line\">        moving_var = momentum * moving_var + (<span class=\"number\">1.0</span> - momentum) * var</span><br><span class=\"line\">    Y = gamma * X_hat + beta  <span class=\"comment\"># ç¼©æ”¾å’Œç§»ä½</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> Y, moving_mean.data, moving_var.data</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬ç°åœ¨å¯ä»¥åˆ›å»ºä¸€ä¸ªæ­£ç¡®çš„ BatchNorm å±‚ã€‚è¿™ä¸ªå±‚å°†ä¿æŒé€‚å½“çš„å‚æ•°ï¼šæ‹‰ä¼¸ <code>gamma</code> å’Œåç§» <code>beta</code>ï¼Œè¿™ä¸¤ä¸ªå‚æ•°å°†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´æ–°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„å±‚å°†ä¿å­˜å‡å€¼å’Œæ–¹å·®çš„ç§»åŠ¨å¹³å‡å€¼ï¼Œä»¥ä¾¿åœ¨æ¨¡å‹é¢„æµ‹æœŸé—´éšåä½¿ç”¨ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">BatchNorm</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"comment\"># num_featuresï¼šå…¨è¿æ¥å±‚çš„è¾“å‡ºæ•°é‡æˆ–å·ç§¯å±‚çš„è¾“å‡ºé€šé“æ•°</span></span><br><span class=\"line\">    <span class=\"comment\"># num_dimsï¼š2è¡¨ç¤ºå…¨è¿æ¥å±‚ï¼Œ4è¡¨ç¤ºå·ç§¯å±‚</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, num_features, num_dims</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> num_dims == <span class=\"number\">2</span>:</span><br><span class=\"line\">            shape = (<span class=\"number\">1</span>, num_features)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            shape = (<span class=\"number\">1</span>, num_features, <span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># å‚ä¸æ±‚æ¢¯åº¦å’Œè¿­ä»£çš„æ‹‰ä¼¸å’Œåç§»å‚æ•°ï¼Œåˆ†åˆ«åˆå§‹åŒ–æˆ1å’Œ0</span></span><br><span class=\"line\">        self.gamma = nn.Parameter(torch.ones(shape))</span><br><span class=\"line\">        self.beta = nn.Parameter(torch.zeros(shape))</span><br><span class=\"line\">        <span class=\"comment\"># éæ¨¡å‹å‚æ•°çš„å˜é‡åˆå§‹åŒ–ä¸º0å’Œ1</span></span><br><span class=\"line\">        self.moving_mean = torch.zeros(shape)</span><br><span class=\"line\">        self.moving_var = torch.ones(shape)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        <span class=\"comment\"># å¦‚æœXä¸åœ¨å†…å­˜ä¸Šï¼Œå°†moving_meanå’Œmoving_varï¼Œå¤åˆ¶åˆ°Xæ‰€åœ¨æ˜¾å­˜ä¸Š</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.moving_mean.device != X.device:</span><br><span class=\"line\">            self.moving_mean = self.moving_mean.to(X.device)</span><br><span class=\"line\">            self.moving_var = self.moving_var.to(X.device)</span><br><span class=\"line\">        <span class=\"comment\"># ä¿å­˜æ›´æ–°è¿‡çš„moving_meanå’Œmoving_var</span></span><br><span class=\"line\">        Y, self.moving_mean, self.moving_var = batch_norm(X, self.gamma,</span><br><span class=\"line\">            self.beta, self.moving_mean, self.moving_var, eps=<span class=\"number\">1e-5</span>, momentum=<span class=\"number\">0.9</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Y</span><br></pre></td></tr></table></figure>\n<p>ä¸ºäº†æ›´å¥½ç†è§£å¦‚ä½•åº”ç”¨ BatchNormï¼Œä¸‹é¢æˆ‘ä»¬å°†å…¶åº”ç”¨äº LeNet æ¨¡å‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net = nn.Sequential(</span><br><span class=\"line\">    nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">6</span>, kernel_size=<span class=\"number\">5</span>, padding=<span class=\"number\">2</span>), BatchNorm(<span class=\"number\">6</span>, num_dims=<span class=\"number\">4</span>), nn.Sigmoid(),</span><br><span class=\"line\">    nn.AvgPool2d(kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>),</span><br><span class=\"line\">    nn.Conv2d(<span class=\"number\">6</span>, <span class=\"number\">16</span>, kernel_size=<span class=\"number\">5</span>), BatchNorm(<span class=\"number\">16</span>, num_dims=<span class=\"number\">4</span>), nn.Sigmoid(),</span><br><span class=\"line\">    nn.AvgPool2d(kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>), nn.Flatten(),</span><br><span class=\"line\">    nn.Linear(<span class=\"number\">16</span> * <span class=\"number\">5</span> * <span class=\"number\">5</span>, <span class=\"number\">120</span>), BatchNorm(<span class=\"number\">120</span>, num_dims=<span class=\"number\">2</span>), nn.Sigmoid(),</span><br><span class=\"line\">    nn.Linear(<span class=\"number\">120</span>, <span class=\"number\">84</span>), BatchNorm(<span class=\"number\">84</span>, num_dims=<span class=\"number\">2</span>), nn.Sigmoid(),</span><br><span class=\"line\">    nn.Linear(<span class=\"number\">84</span>, <span class=\"number\">10</span>))</span><br></pre></td></tr></table></figure>\n<p>æœ€åæˆ‘ä»¬è¯»å–æ•°æ®é›†å¹¶è¿›è¡Œè®­ç»ƒï¼Œè¶…å‚æ•°è®¾ç½®ï¼š<code>lr, num_epochs = 1, 15</code>ï¼Œç”±äºç½‘ç»œæ¨¡å‹ç±»ä¼¼ LeNetï¼Œå› æ­¤æ— éœ€å¯¹è¾“å…¥å›¾åƒè¿›è¡Œ Resize æ“ä½œï¼Œè®­ç»ƒè¿‡ç¨‹ä¸ç¬¬ä¸€èŠ‚å†…å®¹ä¸€æ ·ï¼Œå› æ­¤ä¸å†æ”¾å‡ºä»£ç ã€‚</p>\n<h2 id=\"6-æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰\">6. æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰</h2>\n<p>åªæœ‰å½“è¾ƒå¤æ‚çš„å‡½æ•°ç±»åŒ…å«è¾ƒå°çš„å‡½æ•°ç±»æ—¶ï¼Œæˆ‘ä»¬æ‰èƒ½ç¡®ä¿æé«˜å®ƒä»¬çš„æ€§èƒ½ã€‚å¯¹äºæ·±åº¦ç¥ç»ç½‘ç»œï¼Œå¦‚æœæˆ‘ä»¬èƒ½å°†æ–°æ·»åŠ çš„å±‚è®­ç»ƒæˆæ’ç­‰æ˜ å°„ï¼ˆidentity functionï¼‰ï¼š<code>f(x) = x</code>ï¼Œæ–°æ¨¡å‹å’ŒåŸæ¨¡å‹å°†åŒæ ·æœ‰æ•ˆã€‚åŒæ—¶ï¼Œç”±äºæ–°æ¨¡å‹å¯èƒ½å¾—å‡ºæ›´ä¼˜çš„è§£æ¥æ‹Ÿåˆè®­ç»ƒæ•°æ®é›†ï¼Œå› æ­¤æ·»åŠ å±‚ä¼¼ä¹æ›´å®¹æ˜“é™ä½è®­ç»ƒè¯¯å·®ã€‚</p>\n<p>æ®‹å·®ç½‘ç»œçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šæ¯ä¸ªé™„åŠ å±‚éƒ½åº”è¯¥æ›´å®¹æ˜“åœ°<strong>åŒ…å«åŸå§‹å‡½æ•°</strong>ä½œä¸ºå…¶å…ƒç´ ä¹‹ä¸€ã€‚</p>\n<p>ResNet æ²¿ç”¨äº† VGG å®Œæ•´çš„å·ç§¯å±‚è®¾è®¡ã€‚æ®‹å·®å—é‡Œé¦–å…ˆæœ‰2ä¸ªæœ‰ç›¸åŒè¾“å‡ºé€šé“æ•°çš„å·ç§¯å±‚ã€‚æ¯ä¸ªå·ç§¯å±‚åæ¥ä¸€ä¸ªæ‰¹é‡è§„èŒƒåŒ–å±‚å’Œ ReLU æ¿€æ´»å‡½æ•°ã€‚ç„¶åæˆ‘ä»¬é€šè¿‡è·¨å±‚æ•°æ®é€šè·¯ï¼Œè·³è¿‡è¿™2ä¸ªå·ç§¯è¿ç®—ï¼Œå°†è¾“å…¥ç›´æ¥åŠ åœ¨æœ€åçš„ ReLU æ¿€æ´»å‡½æ•°å‰ã€‚è¿™æ ·çš„è®¾è®¡è¦æ±‚2ä¸ªå·ç§¯å±‚çš„è¾“å‡ºä¸è¾“å…¥å½¢çŠ¶ä¸€æ ·ï¼Œä»è€Œä½¿å®ƒä»¬å¯ä»¥ç›¸åŠ ã€‚å¦‚æœæƒ³æ”¹å˜é€šé“æ•°ï¼Œå°±éœ€è¦å¼•å…¥ä¸€ä¸ªé¢å¤–çš„1Ã—1å·ç§¯å±‚æ¥å°†è¾“å…¥å˜æ¢æˆéœ€è¦çš„å½¢çŠ¶åå†åšç›¸åŠ è¿ç®—ã€‚æ®‹å·®å—çš„å®ç°å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Residual</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, input_channels, num_channels, use_1x1conv=<span class=\"literal\">False</span>, strides=<span class=\"number\">1</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=strides)</span><br><span class=\"line\">        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> use_1x1conv:</span><br><span class=\"line\">            self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=<span class=\"number\">1</span>, stride=strides)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.conv3 = <span class=\"literal\">None</span></span><br><span class=\"line\">        self.bn1 = nn.BatchNorm2d(num_channels)</span><br><span class=\"line\">        self.bn2 = nn.BatchNorm2d(num_channels)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        Y = F.relu(self.bn1(self.conv1(X)))</span><br><span class=\"line\">        Y = self.bn2(self.conv2(Y))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.conv3:</span><br><span class=\"line\">            X = self.conv3(X)</span><br><span class=\"line\">        Y += X</span><br><span class=\"line\">        <span class=\"keyword\">return</span> F.relu(Y)</span><br></pre></td></tr></table></figure>\n<p>æ­¤ä»£ç ç”Ÿæˆä¸¤ç§ç±»å‹çš„ç½‘ç»œï¼šä¸€ç§æ˜¯å½“ <code>use_1x1conv = False</code> æ—¶ï¼Œåº”ç”¨ ReLU éçº¿æ€§å‡½æ•°ä¹‹å‰ï¼Œå°†è¾“å…¥æ·»åŠ åˆ°è¾“å‡ºã€‚å¦ä¸€ç§æ˜¯å½“ <code>use_1x1conv = True</code> æ—¶ï¼Œæ·»åŠ é€šè¿‡1Ã—1å·ç§¯è°ƒæ•´é€šé“å’Œåˆ†è¾¨ç‡ã€‚</p>\n<p>ResNet çš„å‰ä¸¤å±‚è·Ÿä¹‹å‰ä»‹ç»çš„ GoogLeNet ä¸­çš„ä¸€æ ·ï¼šåœ¨è¾“å‡ºé€šé“æ•°ä¸º64ã€æ­¥å¹…ä¸º2çš„7Ã—7å·ç§¯å±‚åï¼Œæ¥æ­¥å¹…ä¸º2çš„3Ã—3æœ€å¤§æ±‡èšå±‚ã€‚ä¸åŒä¹‹å¤„åœ¨äº ResNet æ¯ä¸ªå·ç§¯å±‚åå¢åŠ äº†æ‰¹é‡è§„èŒƒåŒ–å±‚ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">b1 = nn.Sequential(nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">7</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">3</span>),</span><br><span class=\"line\">                   nn.BatchNorm2d(<span class=\"number\">64</span>), nn.ReLU(),</span><br><span class=\"line\">                   nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p>GoogLeNet åœ¨åé¢æ¥äº†4ä¸ªç”± Inception å—ç»„æˆçš„æ¨¡å—ã€‚ResNet åˆ™ä½¿ç”¨4ä¸ªç”±æ®‹å·®å—ç»„æˆçš„æ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—ä½¿ç”¨è‹¥å¹²ä¸ªåŒæ ·è¾“å‡ºé€šé“æ•°çš„æ®‹å·®å—ã€‚ç¬¬ä¸€ä¸ªæ¨¡å—çš„é€šé“æ•°åŒè¾“å…¥é€šé“æ•°ä¸€è‡´ã€‚ç”±äºä¹‹å‰å·²ç»ä½¿ç”¨äº†æ­¥å¹…ä¸º2çš„æœ€å¤§æ±‡èšå±‚ï¼Œæ‰€ä»¥æ— é¡»å‡å°é«˜å’Œå®½ã€‚ä¹‹åçš„æ¯ä¸ªæ¨¡å—åœ¨ç¬¬ä¸€ä¸ªæ®‹å·®å—é‡Œå°†ä¸Šä¸€ä¸ªæ¨¡å—çš„é€šé“æ•°ç¿»å€ï¼Œå¹¶å°†é«˜å’Œå®½å‡åŠã€‚</p>\n<p>ä¸‹é¢æˆ‘ä»¬æ¥å®ç°è¿™ä¸ªæ¨¡å—ã€‚æ³¨æ„ï¼Œæˆ‘ä»¬å¯¹ç¬¬ä¸€ä¸ªæ¨¡å—åšäº†ç‰¹åˆ«å¤„ç†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">resnet_block</span>(<span class=\"params\">input_channels, num_channels, num_residuals, first_block=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\">    blk = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_residuals):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> i == <span class=\"number\">0</span> <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> first_block:</span><br><span class=\"line\">            blk.append(Residual(input_channels, num_channels, use_1x1conv=<span class=\"literal\">True</span>, strides=<span class=\"number\">2</span>))</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            blk.append(Residual(num_channels, num_channels))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> blk</span><br></pre></td></tr></table></figure>\n<p>æ¥ç€åœ¨ ResNet åŠ å…¥æ‰€æœ‰æ®‹å·®å—ï¼Œè¿™é‡Œæ¯ä¸ªæ¨¡å—ä½¿ç”¨2ä¸ªæ®‹å·®å—ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">b2 = nn.Sequential(*resnet_block(<span class=\"number\">64</span>, <span class=\"number\">64</span>, <span class=\"number\">2</span>, first_block=<span class=\"literal\">True</span>))</span><br><span class=\"line\">b3 = nn.Sequential(*resnet_block(<span class=\"number\">64</span>, <span class=\"number\">128</span>, <span class=\"number\">2</span>))</span><br><span class=\"line\">b4 = nn.Sequential(*resnet_block(<span class=\"number\">128</span>, <span class=\"number\">256</span>, <span class=\"number\">2</span>))</span><br><span class=\"line\">b5 = nn.Sequential(*resnet_block(<span class=\"number\">256</span>, <span class=\"number\">512</span>, <span class=\"number\">2</span>))</span><br></pre></td></tr></table></figure>\n<p>æœ€åï¼Œä¸ GoogLeNet ä¸€æ ·ï¼Œåœ¨ ResNet ä¸­åŠ å…¥å…¨å±€å¹³å‡æ±‡èšå±‚ï¼Œä»¥åŠå…¨è¿æ¥å±‚è¾“å‡ºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net = nn.Sequential(b1, b2, b3, b4, b5,</span><br><span class=\"line\">                    nn.AdaptiveAvgPool2d((<span class=\"number\">1</span>, <span class=\"number\">1</span>)),</span><br><span class=\"line\">                    nn.Flatten(), nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">10</span>))</span><br></pre></td></tr></table></figure>\n<p>æ¯ä¸ªæ¨¡å—æœ‰4ä¸ªå·ç§¯å±‚ï¼ˆä¸åŒ…æ‹¬æ’ç­‰æ˜ å°„çš„å·ç§¯å±‚ï¼‰ã€‚åŠ ä¸Šç¬¬ä¸€ä¸ª7Ã—7å·ç§¯å±‚å’Œæœ€åä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œå…±æœ‰18å±‚ã€‚å› æ­¤ï¼Œè¿™ç§æ¨¡å‹é€šå¸¸è¢«ç§°ä¸º ResNet-18ã€‚é€šè¿‡é…ç½®ä¸åŒçš„é€šé“æ•°å’Œæ¨¡å—é‡Œçš„æ®‹å·®å—æ•°å¯ä»¥å¾—åˆ°ä¸åŒçš„ ResNet æ¨¡å‹ï¼Œä¾‹å¦‚æ›´æ·±çš„å«152å±‚çš„ ResNet-152ã€‚</p>\n<p>æœ€åæˆ‘ä»¬è¯»å–æ•°æ®é›†å¹¶è¿›è¡Œè®­ç»ƒï¼Œè¶…å‚æ•°è®¾ç½®ï¼š<code>lr, num_epochs = 0.02, 15</code>ï¼Œç”±äº ResNet æ€§èƒ½å¾ˆå¼ºï¼Œå¯¹äº FashionMNIST æ•°æ®é›†å¾ˆå®¹æ˜“å°±è¿‡æ‹Ÿåˆäº†ï¼Œå› æ­¤å¯ä»¥å°†è¾“å…¥å›¾åƒ Resize ä¸º <code>(96, 96)</code>ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸ç¬¬ä¸€èŠ‚å†…å®¹ä¸€æ ·ï¼Œå› æ­¤ä¸å†æ”¾å‡ºä»£ç ã€‚</p>\n<p>ResNet å…¶å®ƒç‰ˆæœ¬çš„æ¨¡å‹ç»“æ„å¯ä»¥å‚è€ƒï¼š</p>\n<ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/54289848\">ResNet åŠå…¶å˜ç§çš„ç»“æ„æ¢³ç†ã€æœ‰æ•ˆæ€§åˆ†æä¸ä»£ç è§£è¯»</a>ã€‚</li>\n<li><a href=\"https://www.jianshu.com/p/085f4c8256f1\">ResNet18ã€50ç½‘ç»œç»“æ„ä»¥åŠ PyTorch å®ç°ä»£ç </a>ã€‚</li>\n<li><a href=\"https://blog.csdn.net/New_WR/article/details/121777644\">ResNet50ç½‘ç»œç»“æ„æ­å»ºï¼ˆPyTorchï¼‰</a>ã€‚</li>\n</ul>\n<h2 id=\"7-ç¨ å¯†è¿æ¥ç½‘ç»œï¼ˆDenseNetï¼‰\">7. ç¨ å¯†è¿æ¥ç½‘ç»œï¼ˆDenseNetï¼‰</h2>\n<p>ResNet å’Œ DenseNet çš„å…³é”®åŒºåˆ«åœ¨äºï¼ŒDenseNet è¾“å‡ºæ˜¯è¿æ¥ï¼ˆç”¨ <code>[.]</code> è¡¨ç¤ºï¼‰è€Œä¸æ˜¯å¦‚ ResNet çš„ç®€å•ç›¸åŠ ã€‚</p>\n<p>ç¨ å¯†ç½‘ç»œä¸»è¦ç”±2éƒ¨åˆ†æ„æˆï¼šç¨ å¯†å—ï¼ˆdense blockï¼‰å’Œè¿‡æ¸¡å±‚ï¼ˆtransition layerï¼‰ã€‚å‰è€…å®šä¹‰å¦‚ä½•è¿æ¥è¾“å…¥å’Œè¾“å‡ºï¼Œè€Œåè€…åˆ™æ§åˆ¶é€šé“æ•°é‡ï¼Œä½¿å…¶ä¸ä¼šå¤ªå¤æ‚ã€‚</p>\n<p>DenseNet ä½¿ç”¨äº† ResNet æ”¹è‰¯ç‰ˆçš„â€œæ‰¹é‡è§„èŒƒåŒ–ã€æ¿€æ´»å’Œå·ç§¯â€æ¶æ„ã€‚æˆ‘ä»¬é¦–å…ˆå®ç°ä¸€ä¸‹è¿™ä¸ªæ¶æ„ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">conv_block</span>(<span class=\"params\">input_channels, num_channels</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(</span><br><span class=\"line\">        nn.BatchNorm2d(input_channels), nn.ReLU(),</span><br><span class=\"line\">        nn.Conv2d(input_channels, num_channels, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p>ä¸€ä¸ªç¨ å¯†å—ç”±å¤šä¸ªå·ç§¯å—ç»„æˆï¼Œæ¯ä¸ªå·ç§¯å—ä½¿ç”¨ç›¸åŒæ•°é‡çš„è¾“å‡ºé€šé“ã€‚ç„¶è€Œï¼Œåœ¨å‰å‘ä¼ æ’­ä¸­ï¼Œæˆ‘ä»¬å°†æ¯ä¸ªå·ç§¯å—çš„è¾“å…¥å’Œè¾“å‡ºåœ¨é€šé“ç»´ä¸Šè¿ç»“ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">DenseBlock</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, num_convs, input_channels, num_channels</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(DenseBlock, self).__init__()</span><br><span class=\"line\">        layer = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_convs):</span><br><span class=\"line\">            layer.append(conv_block(num_channels * i + input_channels, num_channels))</span><br><span class=\"line\">        self.net = nn.Sequential(*layer)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> blk <span class=\"keyword\">in</span> self.net:</span><br><span class=\"line\">            Y = blk(X)</span><br><span class=\"line\">            <span class=\"comment\"># è¿æ¥é€šé“ç»´åº¦ä¸Šæ¯ä¸ªå—çš„è¾“å…¥å’Œè¾“å‡º</span></span><br><span class=\"line\">            X = torch.cat((X, Y), dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> X</span><br></pre></td></tr></table></figure>\n<p>ä¾‹å¦‚æˆ‘ä»¬æ„å»ºä¸€ä¸ª <code>DenseBlock(2, 3, 10)</code>ï¼Œé‚£ä¹ˆä¸¤å±‚å·ç§¯å±‚åˆ†åˆ«ä¸º <code>conv_block(3, 10)</code>ã€<code>conv_block(13, 10)</code>ã€‚ç¬¬ä¸€å±‚å·ç§¯è¾“å‡ºçš„é€šé“ç»´æ˜¯10ï¼Œä¸è¾“å…¥ <code>X</code> åœ¨é€šé“ç»´ä¸Šè¿ç»“åé€šé“ç»´æ˜¯13ï¼Œå› æ­¤ç¬¬äºŒå±‚å·ç§¯è¾“å…¥çš„é€šé“ç»´æ˜¯13ï¼Œç¬¬äºŒå±‚å·ç§¯è¾“å‡ºçš„é€šé“ç»´æ˜¯10ï¼Œä¸è¾“å…¥ <code>X</code> åœ¨é€šé“ç»´ä¸Šè¿ç»“åé€šé“ç»´æ˜¯23ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">blk = DenseBlock(<span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">X = torch.randn(<span class=\"number\">4</span>, <span class=\"number\">3</span>, <span class=\"number\">8</span>, <span class=\"number\">8</span>)</span><br><span class=\"line\">Y = blk(X)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(Y.shape)  <span class=\"comment\"># torch.Size([4, 23, 8, 8])</span></span><br></pre></td></tr></table></figure>\n<p>ç”±äºæ¯ä¸ªç¨ å¯†å—éƒ½ä¼šå¸¦æ¥é€šé“æ•°çš„å¢åŠ ï¼Œä½¿ç”¨è¿‡å¤šåˆ™ä¼šè¿‡äºå¤æ‚åŒ–æ¨¡å‹ã€‚è€Œè¿‡æ¸¡å±‚å¯ä»¥ç”¨æ¥æ§åˆ¶æ¨¡å‹å¤æ‚åº¦ã€‚å®ƒé€šè¿‡1Ã—1å·ç§¯å±‚æ¥<strong>å‡å°é€šé“æ•°</strong>ï¼Œå¹¶ä½¿ç”¨æ­¥å¹…ä¸º2çš„å¹³å‡æ±‡èšå±‚å‡åŠé«˜å’Œå®½ï¼Œä»è€Œè¿›ä¸€æ­¥é™ä½æ¨¡å‹å¤æ‚åº¦ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">transition_block</span>(<span class=\"params\">input_channels, num_channels</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(</span><br><span class=\"line\">        nn.BatchNorm2d(input_channels), nn.ReLU(),</span><br><span class=\"line\">        nn.Conv2d(input_channels, num_channels, kernel_size=<span class=\"number\">1</span>),</span><br><span class=\"line\">        nn.AvgPool2d(kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>))</span><br></pre></td></tr></table></figure>\n<p>å¯¹ä¸Šä¸€ä¸ªä¾‹å­ä¸­ç¨ å¯†å—çš„è¾“å‡ºä½¿ç”¨é€šé“æ•°ä¸º10çš„è¿‡æ¸¡å±‚ã€‚æ­¤æ—¶è¾“å‡ºçš„é€šé“æ•°å‡ä¸º10ï¼Œé«˜å’Œå®½å‡å‡åŠï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">blk = transition_block(<span class=\"number\">23</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(blk(Y).shape)  <span class=\"comment\"># torch.Size([4, 10, 4, 4])</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬æ¥æ„é€  DenseNet æ¨¡å‹ã€‚DenseNet é¦–å…ˆä½¿ç”¨åŒ ResNet ä¸€æ ·çš„å•å·ç§¯å±‚å’Œæœ€å¤§æ±‡èšå±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">b1 = nn.Sequential(</span><br><span class=\"line\">    nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">7</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">3</span>),</span><br><span class=\"line\">    nn.BatchNorm2d(<span class=\"number\">64</span>), nn.ReLU(),</span><br><span class=\"line\">    nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥ï¼Œç±»ä¼¼äº ResNet ä½¿ç”¨çš„4ä¸ªæ®‹å·®å—ï¼ŒDenseNet ä½¿ç”¨çš„æ˜¯4ä¸ªç¨ å¯†å—ã€‚ä¸ ResNet ç±»ä¼¼ï¼Œæˆ‘ä»¬å¯ä»¥è®¾ç½®æ¯ä¸ªç¨ å¯†å—ä½¿ç”¨å¤šå°‘ä¸ªå·ç§¯å±‚ã€‚è¿™é‡Œæˆ‘ä»¬è®¾æˆ4ï¼Œä»è€Œä¸ä¹‹å‰çš„ ResNet-18 ä¿æŒä¸€è‡´ã€‚ç¨ å¯†å—é‡Œçš„å·ç§¯å±‚é€šé“æ•°ï¼ˆå³å¢é•¿ç‡ï¼‰è®¾ä¸º32ï¼Œæ‰€ä»¥æ¯ä¸ªç¨ å¯†å—å°†å¢åŠ 128ä¸ªé€šé“ã€‚</p>\n<p>åœ¨æ¯ä¸ªæ¨¡å—ä¹‹é—´ï¼ŒResNet é€šè¿‡æ­¥å¹…ä¸º2çš„æ®‹å·®å—å‡å°é«˜å’Œå®½ï¼ŒDenseNet åˆ™ä½¿ç”¨è¿‡æ¸¡å±‚æ¥å‡åŠé«˜å’Œå®½ï¼Œå¹¶å‡åŠé€šé“æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># num_channelsä¸ºå½“å‰çš„é€šé“æ•°</span></span><br><span class=\"line\">num_channels, growth_rate = <span class=\"number\">64</span>, <span class=\"number\">32</span></span><br><span class=\"line\">num_convs_in_dense_blocks = [<span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span>]</span><br><span class=\"line\">blks = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, num_convs <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(num_convs_in_dense_blocks):</span><br><span class=\"line\">    blks.append(DenseBlock(num_convs, num_channels, growth_rate))</span><br><span class=\"line\">    <span class=\"comment\"># ä¸Šä¸€ä¸ªç¨ å¯†å—çš„è¾“å‡ºé€šé“æ•°</span></span><br><span class=\"line\">    num_channels += num_convs * growth_rate</span><br><span class=\"line\">    <span class=\"comment\"># åœ¨ç¨ å¯†å—ä¹‹é—´æ·»åŠ ä¸€ä¸ªè½¬æ¢å±‚ï¼Œä½¿é€šé“æ•°é‡å‡åŠ</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> i != <span class=\"built_in\">len</span>(num_convs_in_dense_blocks) - <span class=\"number\">1</span>:</span><br><span class=\"line\">        blks.append(transition_block(num_channels, num_channels // <span class=\"number\">2</span>))</span><br><span class=\"line\">        num_channels = num_channels // <span class=\"number\">2</span></span><br></pre></td></tr></table></figure>\n<p>ä¸ ResNet ç±»ä¼¼ï¼Œæœ€åæ¥ä¸Šå…¨å±€æ±‡èšå±‚å’Œå…¨è¿æ¥å±‚æ¥è¾“å‡ºç»“æœï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net = nn.Sequential(</span><br><span class=\"line\">    b1, *blks,</span><br><span class=\"line\">    nn.BatchNorm2d(num_channels), nn.ReLU(),</span><br><span class=\"line\">    nn.AdaptiveAvgPool2d((<span class=\"number\">1</span>, <span class=\"number\">1</span>)),</span><br><span class=\"line\">    nn.Flatten(),</span><br><span class=\"line\">    nn.Linear(num_channels, <span class=\"number\">10</span>))</span><br></pre></td></tr></table></figure>\n<p>æœ€åæˆ‘ä»¬è¯»å–æ•°æ®é›†å¹¶è¿›è¡Œè®­ç»ƒï¼Œè¶…å‚æ•°è®¾ç½®ï¼š<code>lr, num_epochs = 0.1, 15</code>ï¼Œå°†è¾“å…¥å›¾åƒ Resize ä¸º <code>(96, 96)</code>ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸ç¬¬ä¸€èŠ‚å†…å®¹ä¸€æ ·ï¼Œå› æ­¤ä¸å†æ”¾å‡ºä»£ç ã€‚</p>\n<p>ä¸‹ä¸€ç« ï¼š<a href=\"/posts/24840.html\">è®¡ç®—æœºè§†è§‰</a>ã€‚</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/25122.html",
            "url": "https://asanosaki.github.io/posts/25122.html",
            "title": "åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ç¬”è®°(ææ²)-å·ç§¯ç¥ç»ç½‘ç»œ",
            "date_published": "2023-03-01T01:20:00.000Z",
            "content_html": "<blockquote>\n<p>ææ²åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆPyTorchï¼‰è¯¾ç¨‹å­¦ä¹ ç¬”è®°ç¬¬äº”ç« ï¼šå·ç§¯ç¥ç»ç½‘ç»œã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-ä»å…¨è¿æ¥å±‚åˆ°å·ç§¯\">1. ä»å…¨è¿æ¥å±‚åˆ°å·ç§¯</h2>\n<p>å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªè¶³å¤Ÿå……åˆ†çš„ç…§ç‰‡æ•°æ®é›†ï¼Œæ•°æ®é›†ä¸­æ˜¯æ‹¥æœ‰æ ‡æ³¨çš„ç…§ç‰‡ï¼Œæ¯å¼ ç…§ç‰‡å…·æœ‰ç™¾ä¸‡çº§åƒç´ ï¼Œè¿™æ„å‘³ç€ç½‘ç»œçš„æ¯æ¬¡è¾“å…¥éƒ½æœ‰ä¸€ç™¾ä¸‡ä¸ªç»´åº¦ã€‚å³ä½¿å°†éšè—å±‚ç»´åº¦é™ä½åˆ°1000ï¼Œè¿™ä¸ªå…¨è¿æ¥å±‚ä¹Ÿå°†æœ‰åäº¿ä¸ªå‚æ•°ã€‚</p>\n<p>å‡è®¾æˆ‘ä»¬æƒ³ä»ä¸€å¼ å›¾ç‰‡ä¸­æ‰¾åˆ°æŸä¸ªç‰©ä½“ã€‚åˆç†çš„å‡è®¾æ˜¯ï¼šæ— è®ºå“ªç§æ–¹æ³•æ‰¾åˆ°è¿™ä¸ªç‰©ä½“ï¼Œéƒ½åº”è¯¥å’Œç‰©ä½“çš„ä½ç½®æ— å…³ã€‚å·ç§¯ç¥ç»ç½‘ç»œæ­£æ˜¯å°†<strong>ç©ºé—´ä¸å˜æ€§</strong>ï¼ˆspatial invarianceï¼‰çš„è¿™ä¸€æ¦‚å¿µç³»ç»ŸåŒ–ï¼Œä»è€ŒåŸºäºè¿™ä¸ªæ¨¡å‹ä½¿ç”¨è¾ƒå°‘çš„å‚æ•°æ¥å­¦ä¹ æœ‰ç”¨çš„è¡¨ç¤ºï¼š</p>\n<ul>\n<li>å¹³ç§»ä¸å˜æ€§ï¼ˆtranslation invarianceï¼‰ï¼šä¸ç®¡æ£€æµ‹å¯¹è±¡å‡ºç°åœ¨å›¾åƒä¸­çš„å“ªä¸ªä½ç½®ï¼Œç¥ç»ç½‘ç»œçš„å‰é¢å‡ å±‚åº”è¯¥å¯¹ç›¸åŒçš„å›¾åƒåŒºåŸŸå…·æœ‰ç›¸ä¼¼çš„ååº”ï¼Œå³ä¸ºâ€œå¹³ç§»ä¸å˜æ€§â€ã€‚</li>\n<li>å±€éƒ¨æ€§ï¼ˆlocalityï¼‰ï¼šç¥ç»ç½‘ç»œçš„å‰é¢å‡ å±‚åº”è¯¥åªæ¢ç´¢è¾“å…¥å›¾åƒä¸­çš„å±€éƒ¨åŒºåŸŸï¼Œè€Œä¸è¿‡åº¦åœ¨æ„å›¾åƒä¸­ç›¸éš”è¾ƒè¿œåŒºåŸŸçš„å…³ç³»ï¼Œè¿™å°±æ˜¯â€œå±€éƒ¨æ€§â€åŸåˆ™ã€‚æœ€ç»ˆï¼Œå¯ä»¥èšåˆè¿™äº›å±€éƒ¨ç‰¹å¾ï¼Œä»¥åœ¨æ•´ä¸ªå›¾åƒçº§åˆ«è¿›è¡Œé¢„æµ‹ã€‚</li>\n</ul>\n<h2 id=\"2-å›¾åƒå·ç§¯\">2. å›¾åƒå·ç§¯</h2>\n<p>ä¸¥æ ¼æ¥è¯´ï¼Œå·ç§¯å±‚æ˜¯ä¸ªé”™è¯¯çš„å«æ³•ï¼Œå› ä¸ºå®ƒæ‰€è¡¨è¾¾çš„è¿ç®—å…¶å®æ˜¯<strong>äº’ç›¸å…³è¿ç®—</strong>ï¼ˆcross-correlationï¼‰ï¼Œè€Œä¸æ˜¯å·ç§¯è¿ç®—ã€‚åœ¨å·ç§¯å±‚ä¸­ï¼Œè¾“å…¥å¼ é‡å’Œæ ¸å¼ é‡é€šè¿‡äº’ç›¸å…³è¿ç®—äº§ç”Ÿè¾“å‡ºå¼ é‡ã€‚</p>\n<p>åœ¨äºŒç»´äº’ç›¸å…³è¿ç®—ä¸­ï¼Œå·ç§¯çª—å£ä»è¾“å…¥å¼ é‡çš„å·¦ä¸Šè§’å¼€å§‹ï¼Œä»å·¦åˆ°å³ã€ä»ä¸Šåˆ°ä¸‹æ»‘åŠ¨ã€‚å½“å·ç§¯çª—å£æ»‘åŠ¨åˆ°æ–°ä¸€ä¸ªä½ç½®æ—¶ï¼ŒåŒ…å«åœ¨è¯¥çª—å£ä¸­çš„éƒ¨åˆ†å¼ é‡ä¸å·ç§¯æ ¸å¼ é‡è¿›è¡ŒæŒ‰å…ƒç´ ç›¸ä¹˜ï¼Œå¾—åˆ°çš„å¼ é‡å†æ±‚å’Œå¾—åˆ°ä¸€ä¸ªå•ä¸€çš„æ ‡é‡å€¼ï¼Œç”±æ­¤æˆ‘ä»¬å¾—å‡ºäº†è¿™ä¸€ä½ç½®çš„è¾“å‡ºå¼ é‡å€¼ã€‚</p>\n<p>æˆ‘ä»¬å¯ä»¥è‡ªå·±å®ç°å¦‚ä¸Šè¿‡ç¨‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">corr2d</span>(<span class=\"params\">X, K</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è®¡ç®—äºŒç»´äº’ç›¸å…³è¿ç®—&quot;&quot;&quot;</span></span><br><span class=\"line\">    h, w = K.shape</span><br><span class=\"line\">    Y = torch.zeros((X.shape[<span class=\"number\">0</span>] - h + <span class=\"number\">1</span>, X.shape[<span class=\"number\">1</span>] - w + <span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(Y.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(Y.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">            Y[i, j] = (X[i:i + h, j:j + w] * K).<span class=\"built_in\">sum</span>()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Y</span><br><span class=\"line\"></span><br><span class=\"line\">X = torch.tensor([[<span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>], [<span class=\"number\">3.0</span>, <span class=\"number\">4.0</span>, <span class=\"number\">5.0</span>], [<span class=\"number\">6.0</span>, <span class=\"number\">7.0</span>, <span class=\"number\">8.0</span>]])</span><br><span class=\"line\">K = torch.tensor([[<span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>], [<span class=\"number\">2.0</span>, <span class=\"number\">3.0</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(corr2d(X, K))  <span class=\"comment\"># tensor([[19., 25.], [37., 43.]])</span></span><br></pre></td></tr></table></figure>\n<p>å·ç§¯å±‚å¯¹è¾“å…¥å’Œå·ç§¯æ ¸æƒé‡è¿›è¡Œäº’ç›¸å…³è¿ç®—ï¼Œå¹¶åœ¨æ·»åŠ æ ‡é‡åç½®ä¹‹åäº§ç”Ÿè¾“å‡ºã€‚æ‰€ä»¥ï¼Œå·ç§¯å±‚ä¸­çš„ä¸¤ä¸ªè¢«è®­ç»ƒçš„å‚æ•°æ˜¯å·ç§¯æ ¸æƒé‡å’Œæ ‡é‡åç½®ã€‚</p>\n<p>æˆ‘ä»¬å¯ä»¥åŸºäºä¸Šé¢å®šä¹‰çš„ <code>corr2d</code> å‡½æ•°å®ç°äºŒç»´å·ç§¯å±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Conv2D</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, kernel_size</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        self.weight = nn.Parameter(torch.rand(kernel_size))</span><br><span class=\"line\">        self.bias = nn.Parameter(torch.zeros(<span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> corr2d(x, self.weight) + self.bias</span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æ¥çœ‹ä¸€ä¸‹å·ç§¯å±‚çš„ä¸€ä¸ªç®€å•åº”ç”¨ï¼šé€šè¿‡æ‰¾åˆ°åƒç´ å˜åŒ–çš„ä½ç½®ï¼Œæ¥æ£€æµ‹å›¾åƒä¸­ä¸åŒé¢œè‰²çš„è¾¹ç¼˜ã€‚æˆ‘ä»¬å‡è®¾0ä¸ºé»‘è‰²åƒç´ ï¼Œ1ä¸ºç™½è‰²åƒç´ ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = torch.ones((<span class=\"number\">6</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\">X[:, <span class=\"number\">2</span>:<span class=\"number\">6</span>] = <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n<p><code>X</code> çš„å†…å®¹å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor([[1., 1., 0., 0., 0., 0., 1., 1.],</span><br><span class=\"line\">        [1., 1., 0., 0., 0., 0., 1., 1.],</span><br><span class=\"line\">        [1., 1., 0., 0., 0., 0., 1., 1.],</span><br><span class=\"line\">        [1., 1., 0., 0., 0., 0., 1., 1.],</span><br><span class=\"line\">        [1., 1., 0., 0., 0., 0., 1., 1.],</span><br><span class=\"line\">        [1., 1., 0., 0., 0., 0., 1., 1.]])</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ„é€ ä¸€ä¸ªé«˜åº¦ä¸º1ã€å®½åº¦ä¸º2çš„å·ç§¯æ ¸Kã€‚å½“è¿›è¡Œäº’ç›¸å…³è¿ç®—æ—¶ï¼Œå¦‚æœæ°´å¹³ç›¸é‚»çš„ä¸¤å…ƒç´ ç›¸åŒï¼Œåˆ™è¾“å‡ºä¸ºé›¶ï¼Œå¦åˆ™è¾“å‡ºä¸ºéé›¶ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">K = torch.tensor([[<span class=\"number\">1.0</span>, -<span class=\"number\">1.0</span>]])</span><br><span class=\"line\">Y = corr2d(X, K)</span><br></pre></td></tr></table></figure>\n<p><code>Y</code> çš„å†…å®¹å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class=\"line\">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class=\"line\">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class=\"line\">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class=\"line\">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class=\"line\">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])</span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æˆ‘ä»¬ä½¿ç”¨ PyTorch çš„å·ç§¯å±‚å°è¯•é€šè¿‡æ­£ç¡®ç»“æœ <code>Y</code> æ˜¯å¦èƒ½å­¦ä¹ å‡ºæˆ‘ä»¬ä¹‹å‰è‡ªå·±æ„é€ å‡ºçš„å·ç§¯æ ¸å‚æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># æ„é€ ä¸€ä¸ªäºŒç»´å·ç§¯å±‚ï¼Œå®ƒå…·æœ‰1ä¸ªè¾“å…¥é€šé“å’Œ1ä¸ªè¾“å‡ºé€šé“ï¼Œå·ç§¯æ ¸å½¢çŠ¶ä¸º(1, 2)</span></span><br><span class=\"line\">conv2d = nn.Conv2d(in_channels=<span class=\"number\">1</span>, out_channels=<span class=\"number\">1</span>, kernel_size=(<span class=\"number\">1</span>, <span class=\"number\">2</span>), bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è¿™ä¸ªäºŒç»´å·ç§¯å±‚ä½¿ç”¨å››ç»´è¾“å…¥å’Œè¾“å‡ºæ ¼å¼(æ‰¹é‡å¤§å°, é€šé“, é«˜åº¦, å®½åº¦)</span></span><br><span class=\"line\"><span class=\"comment\"># åœ¨æœ¬ä¾‹ä¸­æ‰¹é‡å¤§å°å’Œé€šé“æ•°éƒ½ä¸º1</span></span><br><span class=\"line\">X = X.reshape((<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\">Y = Y.reshape((<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>))</span><br><span class=\"line\">lr = <span class=\"number\">3e-2</span>  <span class=\"comment\"># å­¦ä¹ ç‡</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">10</span>):</span><br><span class=\"line\">    Y_hat = conv2d(X)</span><br><span class=\"line\">    loss = (Y_hat - Y) ** <span class=\"number\">2</span>  <span class=\"comment\"># å‡æ–¹è¯¯å·®</span></span><br><span class=\"line\">    conv2d.zero_grad()</span><br><span class=\"line\">    loss.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\">    <span class=\"comment\"># è¿­ä»£å·ç§¯æ ¸ï¼Œæ‰‹åŠ¨å®ç°æ¢¯åº¦ä¸‹é™</span></span><br><span class=\"line\">    conv2d.weight.data[:] -= lr * conv2d.weight.grad</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (i + <span class=\"number\">1</span>) % <span class=\"number\">2</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;epoch <span class=\"subst\">&#123;i + <span class=\"number\">1</span>&#125;</span>, loss <span class=\"subst\">&#123;loss.<span class=\"built_in\">sum</span>():<span class=\"number\">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(conv2d.weight.data.reshape((<span class=\"number\">1</span>, <span class=\"number\">2</span>)))  <span class=\"comment\"># tensor([[ 0.9756, -1.0059]])</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"3-å¡«å……å’Œæ­¥å¹…\">3. å¡«å……å’Œæ­¥å¹…</h2>\n<p>åœ¨åº”ç”¨å¤šå±‚å·ç§¯æ—¶ï¼Œæˆ‘ä»¬å¸¸å¸¸ä¸¢å¤±è¾¹ç¼˜åƒç´ ã€‚ç”±äºæˆ‘ä»¬é€šå¸¸ä½¿ç”¨å°å·ç§¯æ ¸ï¼Œå› æ­¤å¯¹äºä»»ä½•å•ä¸ªå·ç§¯ï¼Œæˆ‘ä»¬å¯èƒ½åªä¼šä¸¢å¤±å‡ ä¸ªåƒç´ ã€‚ä½†éšç€æˆ‘ä»¬åº”ç”¨è®¸å¤šè¿ç»­å·ç§¯å±‚ï¼Œç´¯ç§¯ä¸¢å¤±çš„åƒç´ æ•°å°±å¤šäº†ã€‚è§£å†³è¿™ä¸ªé—®é¢˜çš„ç®€å•æ–¹æ³•å³ä¸º<strong>å¡«å……</strong>ï¼ˆpaddingï¼‰ï¼šåœ¨è¾“å…¥å›¾åƒçš„è¾¹ç•Œå¡«å……å…ƒç´ ï¼ˆé€šå¸¸å¡«å……å…ƒç´ æ˜¯0ï¼‰ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># è¯·æ³¨æ„ï¼Œè¿™é‡Œæ¯è¾¹éƒ½å¡«å……äº†1è¡Œæˆ–1åˆ—ï¼Œå› æ­¤æ€»å…±æ·»åŠ äº†2è¡Œæˆ–2åˆ—</span></span><br><span class=\"line\">conv2d = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">1</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)</span><br><span class=\"line\">X = torch.rand(size=(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(conv2d(X).shape)  <span class=\"comment\"># torch.Size([1, 1, 8, 8])</span></span><br></pre></td></tr></table></figure>\n<p>åœ¨è®¡ç®—äº’ç›¸å…³æ—¶ï¼Œå·ç§¯çª—å£ä»è¾“å…¥å¼ é‡çš„å·¦ä¸Šè§’å¼€å§‹ï¼Œå‘ä¸‹ã€å‘å³æ»‘åŠ¨ã€‚åœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é»˜è®¤æ¯æ¬¡æ»‘åŠ¨ä¸€ä¸ªå…ƒç´ ã€‚ä½†æ˜¯ï¼Œæœ‰æ—¶å€™ä¸ºäº†é«˜æ•ˆè®¡ç®—æˆ–æ˜¯ç¼©å‡é‡‡æ ·æ¬¡æ•°ï¼Œå·ç§¯çª—å£å¯ä»¥è·³è¿‡ä¸­é—´ä½ç½®ï¼Œæ¯æ¬¡æ»‘åŠ¨å¤šä¸ªå…ƒç´ ã€‚æˆ‘ä»¬å°†æ¯æ¬¡æ»‘åŠ¨å…ƒç´ çš„æ•°é‡ç§°ä¸º<strong>æ­¥å¹…</strong>ï¼ˆstrideï¼‰ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conv2d = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">1</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(conv2d(X).shape)  <span class=\"comment\"># torch.Size([1, 1, 4, 4])</span></span><br><span class=\"line\"></span><br><span class=\"line\">conv2d = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">1</span>, kernel_size=(<span class=\"number\">3</span>, <span class=\"number\">5</span>), padding=(<span class=\"number\">0</span>, <span class=\"number\">1</span>), stride=(<span class=\"number\">3</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(conv2d(X).shape)  <span class=\"comment\"># torch.Size([1, 1, 2, 2])</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"4-å¤šè¾“å…¥å¤šè¾“å‡ºé€šé“\">4. å¤šè¾“å…¥å¤šè¾“å‡ºé€šé“</h2>\n<p>å½“è¾“å…¥åŒ…å«å¤šä¸ªé€šé“æ—¶ï¼Œéœ€è¦æ„é€ ä¸€ä¸ªä¸è¾“å…¥æ•°æ®å…·æœ‰ç›¸åŒè¾“å…¥é€šé“æ•°çš„å·ç§¯æ ¸ï¼Œä»¥ä¾¿ä¸è¾“å…¥æ•°æ®è¿›è¡Œäº’ç›¸å…³è¿ç®—ã€‚</p>\n<p>ä¸ºäº†åŠ æ·±ç†è§£ï¼Œæˆ‘ä»¬å®ç°ä¸€ä¸‹å¤šè¾“å…¥é€šé“äº’ç›¸å…³è¿ç®—ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæˆ‘ä»¬æ‰€åšçš„å°±æ˜¯å¯¹æ¯ä¸ªé€šé“æ‰§è¡Œäº’ç›¸å…³æ“ä½œï¼Œç„¶åå°†ç»“æœç›¸åŠ ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">corr2d_multi_in</span>(<span class=\"params\">X, K</span>):</span><br><span class=\"line\">    <span class=\"comment\"># å…ˆéå†â€œXâ€å’Œâ€œKâ€çš„ç¬¬0ä¸ªç»´åº¦ï¼ˆé€šé“ç»´åº¦ï¼‰ï¼Œå†æŠŠå®ƒä»¬åŠ åœ¨ä¸€èµ·</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(d2l.corr2d(x, k) <span class=\"keyword\">for</span> x, k <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(X, K))</span><br><span class=\"line\"></span><br><span class=\"line\">X = torch.tensor([[[<span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>], [<span class=\"number\">3.0</span>, <span class=\"number\">4.0</span>, <span class=\"number\">5.0</span>], [<span class=\"number\">6.0</span>, <span class=\"number\">7.0</span>, <span class=\"number\">8.0</span>]],</span><br><span class=\"line\">                  [[<span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>, <span class=\"number\">3.0</span>], [<span class=\"number\">4.0</span>, <span class=\"number\">5.0</span>, <span class=\"number\">6.0</span>], [<span class=\"number\">7.0</span>, <span class=\"number\">8.0</span>, <span class=\"number\">9.0</span>]]])</span><br><span class=\"line\">K = torch.tensor([[[<span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>], [<span class=\"number\">2.0</span>, <span class=\"number\">3.0</span>]], [[<span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>], [<span class=\"number\">3.0</span>, <span class=\"number\">4.0</span>]]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(corr2d_multi_in(X, K))  <span class=\"comment\"># tensor([[ 56.,  72.], [104., 120.]])</span></span><br></pre></td></tr></table></figure>\n<p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œä¸è®ºæœ‰å¤šå°‘è¾“å…¥é€šé“ï¼Œæˆ‘ä»¬è¿˜åªæœ‰ä¸€ä¸ªè¾“å‡ºé€šé“ã€‚åœ¨æœ€æµè¡Œçš„ç¥ç»ç½‘ç»œæ¶æ„ä¸­ï¼Œéšç€ç¥ç»ç½‘ç»œå±‚æ•°çš„åŠ æ·±ï¼Œæˆ‘ä»¬å¸¸ä¼šå¢åŠ è¾“å‡ºé€šé“çš„ç»´æ•°ï¼Œé€šè¿‡å‡å°‘ç©ºé—´åˆ†è¾¨ç‡ä»¥è·å¾—æ›´å¤§çš„é€šé“æ·±åº¦ã€‚ç›´è§‚åœ°è¯´ï¼Œæˆ‘ä»¬å¯ä»¥<strong>å°†æ¯ä¸ªé€šé“çœ‹ä½œå¯¹ä¸åŒç‰¹å¾çš„å“åº”</strong>ã€‚è€Œç°å®å¯èƒ½æ›´ä¸ºå¤æ‚ä¸€äº›ï¼Œå› ä¸ºæ¯ä¸ªé€šé“ä¸æ˜¯ç‹¬ç«‹å­¦ä¹ çš„ï¼Œè€Œæ˜¯ä¸ºäº†å…±åŒä½¿ç”¨è€Œä¼˜åŒ–çš„ã€‚å› æ­¤ï¼Œå¤šè¾“å‡ºé€šé“å¹¶ä¸ä»…æ˜¯å­¦ä¹ å¤šä¸ªå•é€šé“çš„æ£€æµ‹å™¨ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">corr2d_multi_in_out</span>(<span class=\"params\">X, K</span>):</span><br><span class=\"line\">    <span class=\"comment\"># è¿­ä»£â€œKâ€çš„ç¬¬0ä¸ªç»´åº¦ï¼Œæ¯æ¬¡éƒ½å¯¹è¾“å…¥â€œXâ€æ‰§è¡Œäº’ç›¸å…³è¿ç®—ï¼Œæœ€åå°†æ‰€æœ‰ç»“æœéƒ½å åŠ åœ¨ä¸€èµ·</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.stack([corr2d_multi_in(X, k) <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> K], <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># é€šè¿‡å°†æ ¸å¼ é‡Kä¸K+1ï¼ˆKä¸­æ¯ä¸ªå…ƒç´ åŠ 1ï¼‰å’ŒK+2è¿æ¥èµ·æ¥ï¼Œæ„é€ äº†ä¸€ä¸ªå…·æœ‰3ä¸ªè¾“å‡ºé€šé“çš„å·ç§¯æ ¸</span></span><br><span class=\"line\">K = torch.stack((K, K + <span class=\"number\">1</span>, K + <span class=\"number\">2</span>), <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(K.shape)  <span class=\"comment\"># torch.Size([3, 2, 2, 2])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(corr2d_multi_in_out(X, K))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[ 56.,  72.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [104., 120.]],</span></span><br><span class=\"line\"><span class=\"comment\">#         [[ 76., 100.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [148., 172.]],</span></span><br><span class=\"line\"><span class=\"comment\">#         [[ 96., 128.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [192., 224.]]])</span></span><br></pre></td></tr></table></figure>\n<p>PSï¼š1*1å·ç§¯å±‚é€šå¸¸ç”¨äºè°ƒæ•´ç½‘ç»œå±‚çš„é€šé“æ•°é‡å’Œæ§åˆ¶æ¨¡å‹å¤æ‚æ€§ï¼Œå…¶å¤±å»äº†å·ç§¯å±‚çš„ç‰¹æœ‰èƒ½åŠ›ï¼šåœ¨é«˜åº¦å’Œå®½åº¦ç»´åº¦ä¸Šï¼Œè¯†åˆ«ç›¸é‚»å…ƒç´ é—´ç›¸äº’ä½œç”¨çš„èƒ½åŠ›ã€‚</p>\n<h2 id=\"5-æ±‡èšå±‚ï¼ˆæ± åŒ–å±‚ï¼‰\">5. æ±‡èšå±‚ï¼ˆæ± åŒ–å±‚ï¼‰</h2>\n<p>æ±‡èšå±‚ï¼ˆpooling layerï¼‰å…·æœ‰åŒé‡ç›®çš„ï¼šé™ä½å·ç§¯å±‚å¯¹ä½ç½®çš„æ•æ„Ÿæ€§ï¼ŒåŒæ—¶é™ä½å¯¹ç©ºé—´é™é‡‡æ ·è¡¨ç¤ºçš„æ•æ„Ÿæ€§ã€‚</p>\n<p>ä¸å·ç§¯å±‚ç±»ä¼¼ï¼Œæ±‡èšå±‚è¿ç®—ç¬¦ç”±ä¸€ä¸ªå›ºå®šå½¢çŠ¶çš„çª—å£ç»„æˆï¼Œè¯¥çª—å£æ ¹æ®å…¶æ­¥å¹…å¤§å°åœ¨è¾“å…¥çš„æ‰€æœ‰åŒºåŸŸä¸Šæ»‘åŠ¨ï¼ˆä»å·¦è‡³å³ã€ä»ä¸Šè‡³ä¸‹ï¼‰ï¼Œä¸ºå›ºå®šå½¢çŠ¶çª—å£ï¼ˆæœ‰æ—¶ç§°ä¸ºæ±‡èšçª—å£ï¼‰éå†çš„æ¯ä¸ªä½ç½®è®¡ç®—ä¸€ä¸ªè¾“å‡ºã€‚ç„¶è€Œï¼Œä¸åŒäºå·ç§¯å±‚ä¸­çš„è¾“å…¥ä¸å·ç§¯æ ¸ä¹‹é—´çš„äº’ç›¸å…³è®¡ç®—ï¼Œæ±‡èšå±‚<strong>ä¸åŒ…å«å‚æ•°</strong>ã€‚ç›¸åï¼Œæ± è¿ç®—æ˜¯ç¡®å®šæ€§çš„ï¼Œæˆ‘ä»¬é€šå¸¸è®¡ç®—æ±‡èšçª—å£ä¸­æ‰€æœ‰å…ƒç´ çš„<strong>æœ€å¤§å€¼æˆ–å¹³å‡å€¼</strong>ã€‚è¿™äº›æ“ä½œåˆ†åˆ«ç§°ä¸ºæœ€å¤§æ±‡èšå±‚ï¼ˆmaximum poolingï¼‰å’Œå¹³å‡æ±‡èšå±‚ï¼ˆaverage poolingï¼‰ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">pool2d</span>(<span class=\"params\">X, pool_size, mode=<span class=\"string\">&#x27;max&#x27;</span></span>):</span><br><span class=\"line\">    p_h, p_w = pool_size</span><br><span class=\"line\">    Y = torch.zeros((X.shape[<span class=\"number\">0</span>] - p_h + <span class=\"number\">1</span>, X.shape[<span class=\"number\">1</span>] - p_w + <span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(Y.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(Y.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> mode == <span class=\"string\">&#x27;max&#x27;</span>:</span><br><span class=\"line\">                Y[i, j] = X[i:i + p_h, j:j + p_w].<span class=\"built_in\">max</span>()</span><br><span class=\"line\">            <span class=\"keyword\">elif</span> mode == <span class=\"string\">&#x27;avg&#x27;</span>:</span><br><span class=\"line\">                Y[i, j] = X[i:i + p_h, j:j + p_w].mean()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Y</span><br><span class=\"line\"></span><br><span class=\"line\">X = torch.tensor([[<span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>], [<span class=\"number\">3.0</span>, <span class=\"number\">4.0</span>, <span class=\"number\">5.0</span>], [<span class=\"number\">6.0</span>, <span class=\"number\">7.0</span>, <span class=\"number\">8.0</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(pool2d(X, (<span class=\"number\">2</span>, <span class=\"number\">2</span>)))  <span class=\"comment\"># tensor([[4., 5.], [7., 8.]])</span></span><br></pre></td></tr></table></figure>\n<p>ä¸å·ç§¯å±‚ä¸€æ ·ï¼Œæ±‡èšå±‚ä¹Ÿå¯ä»¥æ”¹å˜è¾“å‡ºå½¢çŠ¶ã€‚å’Œä»¥å‰ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¡«å……å’Œæ­¥å¹…ä»¥è·å¾—æ‰€éœ€çš„è¾“å‡ºå½¢çŠ¶ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬ç”¨æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­å†…ç½®çš„äºŒç»´æœ€å¤§æ±‡èšå±‚ï¼Œæ¥æ¼”ç¤ºæ±‡èšå±‚ä¸­å¡«å……å’Œæ­¥å¹…çš„ä½¿ç”¨ã€‚</p>\n<p>é»˜è®¤æƒ…å†µä¸‹ï¼Œæ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­çš„<strong>æ­¥å¹…ä¸æ±‡èšçª—å£çš„å¤§å°ç›¸åŒ</strong>ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨å½¢çŠ¶ä¸º <code>(3, 3)</code> çš„æ±‡èšçª—å£ï¼Œé‚£ä¹ˆé»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¾—åˆ°çš„æ­¥å¹…å½¢çŠ¶ä¸º <code>(3, 3)</code>ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = torch.arange(<span class=\"number\">16</span>, dtype=torch.float32).reshape((<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">pool2d = nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(pool2d(X))  <span class=\"comment\"># tensor([[[[10.]]]])</span></span><br><span class=\"line\"></span><br><span class=\"line\">pool2d = nn.MaxPool2d(<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(pool2d(X))  <span class=\"comment\"># tensor([[[[ 5.,  7.], [13., 15.]]]])</span></span><br></pre></td></tr></table></figure>\n<p>åœ¨å¤„ç†å¤šé€šé“è¾“å…¥æ•°æ®æ—¶ï¼Œæ±‡èšå±‚<strong>åœ¨æ¯ä¸ªè¾“å…¥é€šé“ä¸Šå•ç‹¬è¿ç®—</strong>ï¼Œè€Œä¸æ˜¯åƒå·ç§¯å±‚ä¸€æ ·åœ¨é€šé“ä¸Šå¯¹è¾“å…¥è¿›è¡Œæ±‡æ€»ã€‚è¿™æ„å‘³ç€æ±‡èšå±‚çš„è¾“å‡ºé€šé“æ•°ä¸è¾“å…¥é€šé“æ•°ç›¸åŒã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬å°†åœ¨é€šé“ç»´åº¦ä¸Šè¿ç»“å¼ é‡ <code>X</code> å’Œ <code>X + 1</code>ï¼Œä»¥æ„å»ºå…·æœ‰2ä¸ªé€šé“çš„è¾“å…¥ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = torch.cat((X, X + <span class=\"number\">1</span>), dim=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(pool2d(X))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[[ 5.,  7.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [13., 15.]],</span></span><br><span class=\"line\"><span class=\"comment\">#          [[ 6.,  8.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [14., 16.]]]])</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"6-LeNet\">6. LeNet</h2>\n<p>æœ¬èŠ‚å°†ä»‹ç» LeNetï¼Œå®ƒæ˜¯æœ€æ—©å‘å¸ƒçš„å·ç§¯ç¥ç»ç½‘ç»œä¹‹ä¸€ã€‚æ€»ä½“æ¥çœ‹ï¼ŒLeNetï¼ˆLeNet-5ï¼‰ç”±ä¸¤ä¸ªéƒ¨åˆ†ç»„æˆï¼š</p>\n<ul>\n<li>å·ç§¯ç¼–ç å™¨ï¼šç”±ä¸¤ä¸ªå·ç§¯å±‚ç»„æˆã€‚</li>\n<li>å…¨è¿æ¥å±‚å¯†é›†å—ï¼šç”±ä¸‰ä¸ªå…¨è¿æ¥å±‚ç»„æˆã€‚</li>\n</ul>\n<p>æ¯ä¸ªå·ç§¯å—ä¸­çš„åŸºæœ¬å•å…ƒæ˜¯ä¸€ä¸ªå·ç§¯å±‚ã€ä¸€ä¸ª Sigmoid æ¿€æ´»å‡½æ•°å’Œå¹³å‡æ±‡èšå±‚ã€‚è¯·æ³¨æ„ï¼Œè™½ç„¶ ReLU å’Œæœ€å¤§æ±‡èšå±‚æ›´æœ‰æ•ˆï¼Œä½†å®ƒä»¬åœ¨20ä¸–çºª90å¹´ä»£è¿˜æ²¡æœ‰å‡ºç°ã€‚æ¯ä¸ªå·ç§¯å±‚ä½¿ç”¨5Ã—5å·ç§¯æ ¸å’Œä¸€ä¸ª Sigmoid æ¿€æ´»å‡½æ•°ã€‚è¿™äº›å±‚å°†è¾“å…¥æ˜ å°„åˆ°å¤šä¸ªäºŒç»´ç‰¹å¾è¾“å‡ºï¼Œé€šå¸¸åŒæ—¶å¢åŠ é€šé“çš„æ•°é‡ã€‚ç¬¬ä¸€å·ç§¯å±‚æœ‰6ä¸ªè¾“å‡ºé€šé“ï¼Œè€Œç¬¬äºŒä¸ªå·ç§¯å±‚æœ‰16ä¸ªè¾“å‡ºé€šé“ã€‚æ¯ä¸ª2Ã—2æ± åŒ–æ“ä½œï¼ˆæ­¥å¹…2ï¼‰é€šè¿‡ç©ºé—´ä¸‹é‡‡æ ·å°†ç»´æ•°å‡å°‘4å€ã€‚å·ç§¯çš„è¾“å‡ºå½¢çŠ¶ç”±æ‰¹é‡å¤§å°ã€é€šé“æ•°ã€é«˜åº¦ã€å®½åº¦å†³å®šã€‚</p>\n<p>è™½ç„¶å·ç§¯ç¥ç»ç½‘ç»œçš„å‚æ•°è¾ƒå°‘ï¼Œä½†ä¸æ·±åº¦çš„å¤šå±‚æ„ŸçŸ¥æœºç›¸æ¯”ï¼Œå®ƒä»¬çš„è®¡ç®—æˆæœ¬ä»ç„¶å¾ˆé«˜ï¼Œå› ä¸ºæ¯ä¸ªå‚æ•°éƒ½å‚ä¸æ›´å¤šçš„ä¹˜æ³•ã€‚é€šè¿‡ä½¿ç”¨ GPUï¼Œå¯ä»¥ç”¨å®ƒåŠ å¿«è®­ç»ƒã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> util.functions <span class=\"keyword\">import</span> train_classifier</span><br><span class=\"line\"></span><br><span class=\"line\">net = nn.Sequential(</span><br><span class=\"line\">    nn.Conv2d(in_channels=<span class=\"number\">1</span>, out_channels=<span class=\"number\">6</span>, kernel_size=<span class=\"number\">5</span>, padding=<span class=\"number\">2</span>), nn.Sigmoid(),  <span class=\"comment\"># (6, 28, 28)</span></span><br><span class=\"line\">    nn.AvgPool2d(kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>),  <span class=\"comment\"># (6, 14, 14)</span></span><br><span class=\"line\">    nn.Conv2d(in_channels=<span class=\"number\">6</span>, out_channels=<span class=\"number\">16</span>, kernel_size=<span class=\"number\">5</span>), nn.Sigmoid(),  <span class=\"comment\"># (16, 10, 10)</span></span><br><span class=\"line\">    nn.AvgPool2d(kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>),  <span class=\"comment\"># (16, 5, 5)</span></span><br><span class=\"line\">    nn.Flatten(),  <span class=\"comment\"># (16 * 5 * 5,)</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">16</span> * <span class=\"number\">5</span> * <span class=\"number\">5</span>, <span class=\"number\">120</span>), nn.Sigmoid(),  <span class=\"comment\"># (120,)</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">120</span>, <span class=\"number\">84</span>), nn.Sigmoid(),  <span class=\"comment\"># (84,)</span></span><br><span class=\"line\">    nn.Linear(<span class=\"number\">84</span>, <span class=\"number\">10</span>))  <span class=\"comment\"># (10,)</span></span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">64</span></span><br><span class=\"line\">trans = transforms.ToTensor()</span><br><span class=\"line\">mnist_train = torchvision.datasets.MNIST(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">True</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">mnist_test = torchvision.datasets.MNIST(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">False</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">train_iter = data.DataLoader(mnist_train, batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\">test_iter = data.DataLoader(mnist_test, batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">lr, num_epochs = <span class=\"number\">0.2</span>, <span class=\"number\">30</span></span><br><span class=\"line\"></span><br><span class=\"line\">train_classifier(net, train_iter, test_iter, num_epochs, lr, device, <span class=\"string\">&#x27;../logs/LeNet_train_log&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>ä¸‹ä¸€ç« ï¼š<a href=\"/posts/21165.html\">ç°ä»£å·ç§¯ç¥ç»ç½‘ç»œ</a>ã€‚</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/23526.html",
            "url": "https://asanosaki.github.io/posts/23526.html",
            "title": "åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ç¬”è®°(ææ²)-PyTorchç¥ç»ç½‘ç»œåŸºç¡€",
            "date_published": "2023-02-28T02:34:00.000Z",
            "content_html": "<blockquote>\n<p>ææ²åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆPyTorchï¼‰è¯¾ç¨‹å­¦ä¹ ç¬”è®°ç¬¬å››ç« ï¼šPyTorch ç¥ç»ç½‘ç»œåŸºç¡€ã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-å±‚å’Œå—\">1. å±‚å’Œå—</h2>\n<p>åœ¨æ„é€ è‡ªå®šä¹‰å—ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆå›é¡¾ä¸€ä¸‹å¤šå±‚æ„ŸçŸ¥æœºï¼ˆç¬¬ä¸‰ç« ç¬¬äºŒèŠ‚ï¼‰çš„ä»£ç ï¼Œä¸‹é¢çš„ä»£ç ç”Ÿæˆä¸€ä¸ªç½‘ç»œï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªå…·æœ‰256ä¸ªå•å…ƒå’Œ ReLU æ¿€æ´»å‡½æ•°çš„å…¨è¿æ¥éšè—å±‚ï¼Œç„¶åæ˜¯ä¸€ä¸ªå…·æœ‰10ä¸ªéšè—å•å…ƒä¸”ä¸å¸¦æ¿€æ´»å‡½æ•°çš„å…¨è¿æ¥è¾“å‡ºå±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\">net = nn.Sequential(nn.Linear(<span class=\"number\">20</span>, <span class=\"number\">256</span>), nn.ReLU(), nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">X = torch.rand(<span class=\"number\">2</span>, <span class=\"number\">20</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X).shape)  <span class=\"comment\"># torch.Size([2, 10])</span></span><br></pre></td></tr></table></figure>\n<p>åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å®ä¾‹åŒ– <code>nn.Sequential</code> æ¥æ„å»ºæˆ‘ä»¬çš„æ¨¡å‹ï¼Œå±‚çš„æ‰§è¡Œé¡ºåºæ˜¯ä½œä¸ºå‚æ•°ä¼ é€’çš„ã€‚ç®€è€Œè¨€ä¹‹ï¼Œ<code>nn.Sequential</code> å®šä¹‰äº†ä¸€ç§ç‰¹æ®Šçš„ <code>Module</code>ï¼Œå³åœ¨ PyTorch ä¸­è¡¨ç¤ºä¸€ä¸ªå—çš„ç±»ï¼Œå®ƒç»´æŠ¤äº†ä¸€ä¸ªç”± <code>Module</code> ç»„æˆçš„<strong>æœ‰åºåˆ—è¡¨</strong>ã€‚æ³¨æ„ï¼Œä¸¤ä¸ªå…¨è¿æ¥å±‚éƒ½æ˜¯ <code>Linear</code> ç±»çš„å®ä¾‹ï¼Œ<code>Linear</code> ç±»æœ¬èº«å°±æ˜¯ <code>Module</code> çš„å­ç±»ã€‚å¦å¤–ï¼Œåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨é€šè¿‡ <code>net(X)</code> è°ƒç”¨æˆ‘ä»¬çš„æ¨¡å‹æ¥è·å¾—æ¨¡å‹çš„è¾“å‡ºã€‚è¿™å®é™…ä¸Šæ˜¯ <code>net.__call__(X)</code> çš„ç®€å†™ã€‚è¿™ä¸ªå‰å‘ä¼ æ’­å‡½æ•°éå¸¸ç®€å•ï¼šå®ƒå°†åˆ—è¡¨ä¸­çš„æ¯ä¸ªå—è¿æ¥åœ¨ä¸€èµ·ï¼Œå°†æ¯ä¸ªå—çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªå—çš„è¾“å…¥ã€‚</p>\n<p>åœ¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬ä»é›¶å¼€å§‹ç¼–å†™ä¸€ä¸ªå—ã€‚å®ƒåŒ…å«ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼Œå…¶å…·æœ‰256ä¸ªéšè—å•å…ƒçš„éšè—å±‚å’Œä¸€ä¸ª10ç»´è¾“å‡ºå±‚ã€‚æ³¨æ„ï¼Œä¸‹é¢çš„ <code>MLP</code> ç±»ç»§æ‰¿äº†è¡¨ç¤ºå—çš„ç±»ã€‚æˆ‘ä»¬çš„å®ç°åªéœ€è¦æä¾›æˆ‘ä»¬è‡ªå·±çš„æ„é€ å‡½æ•°ï¼ˆPython ä¸­çš„ <code>__init__</code> å‡½æ•°ï¼‰å’Œå‰å‘ä¼ æ’­å‡½æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MLP</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"comment\"># æ¨¡å‹å‚æ•°å£°æ˜å±‚ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬å£°æ˜ä¸¤ä¸ªå…¨è¿æ¥çš„å±‚</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"comment\"># è°ƒç”¨MLPçš„çˆ¶ç±»Moduleçš„æ„é€ å‡½æ•°æ¥æ‰§è¡Œå¿…è¦çš„åˆå§‹åŒ–ã€‚</span></span><br><span class=\"line\">        <span class=\"comment\"># è¿™æ ·ï¼Œåœ¨ç±»å®ä¾‹åŒ–æ—¶ä¹Ÿå¯ä»¥æŒ‡å®šå…¶ä»–å‡½æ•°å‚æ•°ï¼Œä¾‹å¦‚æ¨¡å‹å‚æ•°paramsï¼ˆç¨åå°†ä»‹ç»ï¼‰</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        self.hidden = nn.Linear(<span class=\"number\">20</span>, <span class=\"number\">256</span>)  <span class=\"comment\"># éšè—å±‚</span></span><br><span class=\"line\">        self.out = nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">10</span>)  <span class=\"comment\"># è¾“å‡ºå±‚</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># å®šä¹‰æ¨¡å‹çš„å‰å‘ä¼ æ’­ï¼Œå³å¦‚ä½•æ ¹æ®è¾“å…¥Xè¿”å›æ‰€éœ€çš„æ¨¡å‹è¾“å‡º</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        <span class=\"comment\"># æ³¨æ„ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ReLUçš„å‡½æ•°ç‰ˆæœ¬ï¼Œå…¶åœ¨nn.functionalæ¨¡å—ä¸­å®šä¹‰</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.out(F.relu(self.hidden(X)))</span><br></pre></td></tr></table></figure>\n<p>æ¥ç€æˆ‘ä»¬å®ä¾‹åŒ–å¤šå±‚æ„ŸçŸ¥æœºçš„å±‚ï¼Œç„¶ååœ¨æ¯æ¬¡è°ƒç”¨å‰å‘ä¼ æ’­å‡½æ•°æ—¶è°ƒç”¨è¿™äº›å±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net = MLP()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X).shape)  <span class=\"comment\"># torch.Size([2, 10])</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æˆ‘ä»¬å¯ä»¥æ›´ä»”ç»†åœ°çœ‹çœ‹ <code>Sequential</code> ç±»æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œå›æƒ³ä¸€ä¸‹ <code>Sequential</code> çš„è®¾è®¡æ˜¯ä¸ºäº†æŠŠå…¶ä»–æ¨¡å—ä¸²èµ·æ¥ã€‚ä¸ºäº†æ„å»ºæˆ‘ä»¬è‡ªå·±çš„ç®€åŒ–çš„ <code>MySequential</code>ï¼Œæˆ‘ä»¬åªéœ€è¦å®šä¹‰ä¸¤ä¸ªå…³é”®å‡½æ•°ï¼š</p>\n<ul>\n<li>ä¸€ç§å°†å—é€ä¸ªè¿½åŠ åˆ°åˆ—è¡¨ä¸­çš„å‡½æ•°ï¼›</li>\n<li>ä¸€ç§å‰å‘ä¼ æ’­å‡½æ•°ï¼Œç”¨äºå°†è¾“å…¥æŒ‰è¿½åŠ å—çš„é¡ºåºä¼ é€’ç»™å—ç»„æˆçš„â€œé“¾æ¡â€ã€‚</li>\n</ul>\n<p>ä¸‹é¢çš„ <code>MySequential</code> ç±»æä¾›äº†ä¸é»˜è®¤ <code>Sequential</code> ç±»ç›¸åŒçš„åŠŸèƒ½ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MySequential</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, *args</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> idx, module <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(args):</span><br><span class=\"line\">            <span class=\"comment\"># è¿™é‡Œï¼Œmoduleæ˜¯Moduleå­ç±»çš„ä¸€ä¸ªå®ä¾‹ï¼Œæˆ‘ä»¬æŠŠå®ƒä¿å­˜åœ¨&#x27;Module&#x27;ç±»çš„æˆå‘˜</span></span><br><span class=\"line\">            <span class=\"comment\"># å˜é‡_modulesä¸­ï¼Œ_moduleçš„ç±»å‹æ˜¯OrderedDict</span></span><br><span class=\"line\">            self._modules[<span class=\"built_in\">str</span>(idx)] = module</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        <span class=\"comment\"># OrderedDictä¿è¯äº†æŒ‰ç…§æˆå‘˜æ·»åŠ çš„é¡ºåºéå†å®ƒä»¬</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> block <span class=\"keyword\">in</span> self._modules.values():</span><br><span class=\"line\">            X = block(X)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> X</span><br><span class=\"line\"></span><br><span class=\"line\">net = MySequential(nn.Linear(<span class=\"number\">20</span>, <span class=\"number\">256</span>), nn.ReLU(), nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X).shape)  <span class=\"comment\"># torch.Size([2, 10])</span></span><br></pre></td></tr></table></figure>\n<p><code>Sequential</code> ç±»ä½¿æ¨¡å‹æ„é€ å˜å¾—ç®€å•ï¼Œå…è®¸æˆ‘ä»¬ç»„åˆæ–°çš„æ¶æ„ï¼Œè€Œä¸å¿…å®šä¹‰è‡ªå·±çš„ç±»ã€‚ç„¶è€Œï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„æ¶æ„éƒ½æ˜¯ç®€å•çš„é¡ºåºæ¶æ„ã€‚å½“éœ€è¦æ›´å¼ºçš„çµæ´»æ€§æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰è‡ªå·±çš„å—ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›åœ¨å‰å‘ä¼ æ’­å‡½æ•°ä¸­æ‰§è¡Œ Python çš„æ§åˆ¶æµã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›æ‰§è¡Œä»»æ„çš„æ•°å­¦è¿ç®—ï¼Œè€Œä¸æ˜¯ç®€å•åœ°ä¾èµ–é¢„å®šä¹‰çš„ç¥ç»ç½‘ç»œå±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">FixedHiddenMLP</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"comment\"># ä¸è®¡ç®—æ¢¯åº¦çš„éšæœºæƒé‡å‚æ•°ï¼Œå› æ­¤å…¶åœ¨è®­ç»ƒæœŸé—´ä¿æŒä¸å˜</span></span><br><span class=\"line\">        self.rand_weight = torch.rand((<span class=\"number\">20</span>, <span class=\"number\">20</span>), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        self.linear = nn.Linear(<span class=\"number\">20</span>, <span class=\"number\">20</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        X = self.linear(X)</span><br><span class=\"line\">        <span class=\"comment\"># ä½¿ç”¨åˆ›å»ºçš„å¸¸é‡å‚æ•°ä»¥åŠreluå’Œmmå‡½æ•°</span></span><br><span class=\"line\">        X = F.relu(torch.mm(X, self.rand_weight) + <span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># å¤ç”¨å…¨è¿æ¥å±‚ï¼Œè¿™ç›¸å½“äºä¸¤ä¸ªå…¨è¿æ¥å±‚å…±äº«å‚æ•°</span></span><br><span class=\"line\">        X = self.linear(X)</span><br><span class=\"line\">        <span class=\"comment\"># æ§åˆ¶æµ</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> X.<span class=\"built_in\">abs</span>().<span class=\"built_in\">sum</span>() &gt; <span class=\"number\">1</span>:</span><br><span class=\"line\">            X /= <span class=\"number\">2</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> X.<span class=\"built_in\">sum</span>()</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥æ··åˆæ­é…å„ç§ç»„åˆå—çš„æ–¹æ³•ã€‚åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä»¥ä¸€äº›æƒ³åˆ°çš„æ–¹æ³•åµŒå¥—å—ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">NestMLP</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        self.net = nn.Sequential(nn.Linear(<span class=\"number\">20</span>, <span class=\"number\">64</span>), nn.ReLU(), nn.Linear(<span class=\"number\">64</span>, <span class=\"number\">32</span>), nn.ReLU())</span><br><span class=\"line\">        self.linear = nn.Linear(<span class=\"number\">32</span>, <span class=\"number\">16</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.linear(self.net(X))</span><br><span class=\"line\"></span><br><span class=\"line\">chimera = nn.Sequential(NestMLP(), nn.Linear(<span class=\"number\">16</span>, <span class=\"number\">20</span>), FixedHiddenMLP())</span><br><span class=\"line\"><span class=\"built_in\">print</span>(chimera(X))  <span class=\"comment\"># tensor(-0.2911, grad_fn=&lt;SumBackward0&gt;)</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"2-å‚æ•°ç®¡ç†\">2. å‚æ•°ç®¡ç†</h2>\n<p>æˆ‘ä»¬é¦–å…ˆçœ‹ä¸€ä¸‹å…·æœ‰å•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\">net = nn.Sequential(nn.Linear(<span class=\"number\">4</span>, <span class=\"number\">8</span>), nn.ReLU(), nn.Linear(<span class=\"number\">8</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">X = torch.rand(size=(<span class=\"number\">2</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X).shape)  <span class=\"comment\"># torch.Size([2, 1])</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬ä»å·²æœ‰æ¨¡å‹ä¸­è®¿é—®å‚æ•°ã€‚å½“é€šè¿‡ <code>Sequential</code> ç±»å®šä¹‰æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç´¢å¼•æ¥è®¿é—®æ¨¡å‹çš„ä»»æ„å±‚ã€‚è¿™å°±åƒæ¨¡å‹æ˜¯ä¸€ä¸ªåˆ—è¡¨ä¸€æ ·ï¼Œæ¯å±‚çš„å‚æ•°éƒ½åœ¨å…¶å±æ€§ä¸­ã€‚å¦‚ä¸‹æ‰€ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚çš„å‚æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">2</span>].state_dict())</span><br><span class=\"line\"><span class=\"comment\"># OrderedDict([(&#x27;weight&#x27;, tensor([[-0.1326,  0.1692, -0.0925, -0.1721,  0.0828, -0.0890, -0.0742, -0.2730]])), (&#x27;bias&#x27;, tensor([0.2011]))])</span></span><br></pre></td></tr></table></figure>\n<p>è¿™ä¸ªå…¨è¿æ¥å±‚åŒ…å«ä¸¤ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯è¯¥å±‚çš„æƒé‡å’Œåç½®ï¼Œæ¯ä¸ªå‚æ•°éƒ½è¡¨ç¤ºä¸ºå‚æ•°ç±»çš„ä¸€ä¸ªå®ä¾‹ã€‚è¦å¯¹å‚æ•°æ‰§è¡Œä»»ä½•æ“ä½œï¼Œé¦–å…ˆæˆ‘ä»¬éœ€è¦è®¿é—®åº•å±‚çš„æ•°å€¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">type</span>(net[<span class=\"number\">2</span>].bias))  <span class=\"comment\"># &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">2</span>].bias)  <span class=\"comment\"># Parameter containing: tensor([-0.2786], requires_grad=True)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">2</span>].bias.data)  <span class=\"comment\"># tensor([-0.1571])</span></span><br></pre></td></tr></table></figure>\n<p>å‚æ•°æ˜¯å¤åˆçš„å¯¹è±¡ï¼ŒåŒ…å«å€¼ã€æ¢¯åº¦å’Œé¢å¤–ä¿¡æ¯ã€‚è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦æ˜¾å¼å‚æ•°å€¼çš„åŸå› ã€‚é™¤äº†å€¼ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è®¿é—®æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ã€‚åœ¨ä¸Šé¢è¿™ä¸ªç½‘ç»œä¸­ï¼Œç”±äºæˆ‘ä»¬è¿˜æ²¡æœ‰è°ƒç”¨åå‘ä¼ æ’­ï¼Œæ‰€ä»¥å‚æ•°çš„æ¢¯åº¦å¤„äºåˆå§‹çŠ¶æ€ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">2</span>].weight.grad == <span class=\"literal\">None</span>)  <span class=\"comment\"># True</span></span><br></pre></td></tr></table></figure>\n<p>å½“æˆ‘ä»¬éœ€è¦å¯¹æ‰€æœ‰å‚æ•°æ‰§è¡Œæ“ä½œæ—¶ï¼Œé€ä¸ªè®¿é—®å®ƒä»¬å¯èƒ½ä¼šå¾ˆéº»çƒ¦ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬å°†é€šè¿‡æ¼”ç¤ºæ¥æ¯”è¾ƒè®¿é—®ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚çš„å‚æ•°å’Œè®¿é—®æ‰€æœ‰å±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(*[(name, param.shape) <span class=\"keyword\">for</span> name, param <span class=\"keyword\">in</span> net[<span class=\"number\">0</span>].named_parameters()])</span><br><span class=\"line\"><span class=\"comment\"># (&#x27;weight&#x27;, torch.Size([8, 4])) (&#x27;bias&#x27;, torch.Size([8]))</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(*[(name, param.shape) <span class=\"keyword\">for</span> name, param <span class=\"keyword\">in</span> net.named_parameters()])</span><br><span class=\"line\"><span class=\"comment\"># (&#x27;0.weight&#x27;, torch.Size([8, 4])) (&#x27;0.bias&#x27;, torch.Size([8])) (&#x27;2.weight&#x27;, torch.Size([1, 8])) (&#x27;2.bias&#x27;, torch.Size([1]))</span></span><br></pre></td></tr></table></figure>\n<p>è¿™ä¸ºæˆ‘ä»¬æä¾›äº†å¦ä¸€ç§è®¿é—®ç½‘ç»œå‚æ•°çš„æ–¹å¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(net.state_dict()[<span class=\"string\">&#x27;2.bias&#x27;</span>].data)  <span class=\"comment\"># tensor([0.0992])</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¦‚æœæˆ‘ä»¬å°†å¤šä¸ªå—ç›¸äº’åµŒå¥—ï¼Œå‚æ•°å‘½åçº¦å®šæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">block1</span>():</span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(nn.Linear(<span class=\"number\">4</span>, <span class=\"number\">8</span>), nn.ReLU(), nn.Linear(<span class=\"number\">8</span>, <span class=\"number\">4</span>), nn.ReLU())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">block2</span>():</span><br><span class=\"line\">    net = nn.Sequential()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">4</span>):</span><br><span class=\"line\">        <span class=\"comment\"># åœ¨è¿™é‡ŒåµŒå¥—</span></span><br><span class=\"line\">        net.add_module(<span class=\"string\">f&#x27;block <span class=\"subst\">&#123;i&#125;</span>&#x27;</span>, block1())</span><br><span class=\"line\">    <span class=\"keyword\">return</span> net</span><br><span class=\"line\"></span><br><span class=\"line\">rgnet = nn.Sequential(block2(), nn.Linear(<span class=\"number\">4</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(rgnet)</span><br><span class=\"line\"><span class=\"comment\"># Sequential(</span></span><br><span class=\"line\"><span class=\"comment\">#   (0): Sequential(</span></span><br><span class=\"line\"><span class=\"comment\">#     (block 0): Sequential(</span></span><br><span class=\"line\"><span class=\"comment\">#       (0): Linear(in_features=4, out_features=8, bias=True)</span></span><br><span class=\"line\"><span class=\"comment\">#       (1): ReLU()</span></span><br><span class=\"line\"><span class=\"comment\">#       ...</span></span><br></pre></td></tr></table></figure>\n<p>å› ä¸ºå±‚æ˜¯åˆ†å±‚åµŒå¥—çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿå¯ä»¥åƒé€šè¿‡åµŒå¥—åˆ—è¡¨ç´¢å¼•ä¸€æ ·è®¿é—®å®ƒä»¬ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(rgnet[<span class=\"number\">0</span>][<span class=\"number\">1</span>][<span class=\"number\">0</span>].bias.data)  <span class=\"comment\"># tensor([ 0.4102,  0.1565,  0.1458,  0.0826,  0.2460, -0.0115, -0.4241,  0.1192])</span></span><br></pre></td></tr></table></figure>\n<p>çŸ¥é“äº†å¦‚ä½•è®¿é—®å‚æ•°åï¼Œç°åœ¨æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•æ­£ç¡®åœ°åˆå§‹åŒ–å‚æ•°ã€‚æ·±åº¦å­¦ä¹ æ¡†æ¶æä¾›é»˜è®¤éšæœºåˆå§‹åŒ–ï¼Œä¹Ÿå…è®¸æˆ‘ä»¬åˆ›å»ºè‡ªå®šä¹‰åˆå§‹åŒ–æ–¹æ³•ã€‚</p>\n<p>è®©æˆ‘ä»¬é¦–å…ˆè°ƒç”¨å†…ç½®çš„åˆå§‹åŒ–å™¨ã€‚ä¸‹é¢çš„ä»£ç å°†æ‰€æœ‰æƒé‡å‚æ•°åˆå§‹åŒ–ä¸ºæ ‡å‡†å·®ä¸º0.01çš„é«˜æ–¯éšæœºå˜é‡ï¼Œä¸”å°†åç½®å‚æ•°è®¾ç½®ä¸º0ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_normal</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.normal_(m.weight, mean=<span class=\"number\">0</span>, std=<span class=\"number\">0.01</span>)</span><br><span class=\"line\">        nn.init.zeros_(m.bias)</span><br><span class=\"line\"></span><br><span class=\"line\">net.apply(init_normal)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">0</span>].weight.data[<span class=\"number\">0</span>], net[<span class=\"number\">0</span>].bias.data[<span class=\"number\">0</span>])  <span class=\"comment\"># tensor([0.0037, 0.0052, 0.0020, 0.0028]) tensor(0.)</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬è¿˜å¯ä»¥å°†æ‰€æœ‰å‚æ•°åˆå§‹åŒ–ä¸ºç»™å®šçš„å¸¸æ•°ï¼Œæ¯”å¦‚åˆå§‹åŒ–ä¸º1ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nn.init.constant_(m.weight, <span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬è¿˜å¯ä»¥å¯¹æŸäº›å—åº”ç”¨ä¸åŒçš„åˆå§‹åŒ–æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢æˆ‘ä»¬ä½¿ç”¨ Xavier åˆå§‹åŒ–æ–¹æ³•åˆå§‹åŒ–ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œå±‚ï¼Œç„¶åå°†ç¬¬ä¸‰ä¸ªç¥ç»ç½‘ç»œå±‚åˆå§‹åŒ–ä¸ºå¸¸é‡å€¼42ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_xavier</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.xavier_uniform_(m.weight)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_42</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.constant_(m.weight, <span class=\"number\">42</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">net[<span class=\"number\">0</span>].apply(init_xavier)</span><br><span class=\"line\">net[<span class=\"number\">2</span>].apply(init_42)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">0</span>].weight.data[<span class=\"number\">0</span>])  <span class=\"comment\"># tensor([-0.7014,  0.1061,  0.2061,  0.2125])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">2</span>].weight.data)  <span class=\"comment\"># tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])</span></span><br></pre></td></tr></table></figure>\n<p>æœ‰æ—¶ï¼Œæ·±åº¦å­¦ä¹ æ¡†æ¶æ²¡æœ‰æä¾›æˆ‘ä»¬éœ€è¦çš„åˆå§‹åŒ–æ–¹æ³•ã€‚åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å…ˆåˆå§‹åŒ–ä¸º-10~10çš„å‡åŒ€åˆ†å¸ƒï¼Œç„¶åå°†ç»å¯¹å€¼å°äº5çš„å‚æ•°ç½®é›¶ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">my_init</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Init&quot;</span>, *[(name, param.shape) <span class=\"keyword\">for</span> name, param <span class=\"keyword\">in</span> m.named_parameters()][<span class=\"number\">0</span>])</span><br><span class=\"line\">        nn.init.uniform_(m.weight, -<span class=\"number\">10</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">        m.weight.data *= m.weight.data.<span class=\"built_in\">abs</span>() &gt;= <span class=\"number\">5</span></span><br><span class=\"line\"></span><br><span class=\"line\">net.apply(my_init)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">0</span>].weight[:<span class=\"number\">2</span>])</span><br><span class=\"line\"><span class=\"comment\"># tensor([[-0.0000,  8.9053,  0.0000,  8.9382],</span></span><br><span class=\"line\"><span class=\"comment\">#         [-9.5017, -0.0000,  5.4470, -0.0000]], grad_fn=&lt;SliceBackward0&gt;)</span></span><br></pre></td></tr></table></figure>\n<p>æœ‰æ—¶æˆ‘ä»¬å¸Œæœ›åœ¨å¤šä¸ªå±‚é—´å…±äº«å‚æ•°ï¼šæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªç¨ å¯†å±‚ï¼Œç„¶åä½¿ç”¨å®ƒçš„å‚æ•°æ¥è®¾ç½®å¦ä¸€ä¸ªå±‚çš„å‚æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shared = nn.Linear(<span class=\"number\">8</span>, <span class=\"number\">8</span>)  <span class=\"comment\"># æˆ‘ä»¬éœ€è¦ç»™å…±äº«å±‚ä¸€ä¸ªåç§°ï¼Œä»¥ä¾¿å¯ä»¥å¼•ç”¨å®ƒçš„å‚æ•°</span></span><br><span class=\"line\">net = nn.Sequential(nn.Linear(<span class=\"number\">4</span>, <span class=\"number\">8</span>), nn.ReLU(), shared, nn.ReLU(),</span><br><span class=\"line\">                    shared, nn.ReLU(), nn.Linear(<span class=\"number\">8</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"><span class=\"comment\"># æ£€æŸ¥å‚æ•°æ˜¯å¦ç›¸åŒ</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">2</span>].weight.data[<span class=\"number\">0</span>] == net[<span class=\"number\">4</span>].weight.data[<span class=\"number\">0</span>])  <span class=\"comment\"># tensor([True, True, True, True, True, True, True, True])</span></span><br><span class=\"line\">net[<span class=\"number\">2</span>].weight.data[<span class=\"number\">0</span>, <span class=\"number\">0</span>] = <span class=\"number\">100</span></span><br><span class=\"line\"><span class=\"comment\"># ç¡®ä¿å®ƒä»¬å®é™…ä¸Šæ˜¯åŒä¸€ä¸ªå¯¹è±¡ï¼Œè€Œä¸åªæ˜¯æœ‰ç›¸åŒçš„å€¼</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">2</span>].weight.data[<span class=\"number\">0</span>] == net[<span class=\"number\">4</span>].weight.data[<span class=\"number\">0</span>])  <span class=\"comment\"># tensor([True, True, True, True, True, True, True, True])</span></span><br></pre></td></tr></table></figure>\n<p>è¿™ä¸ªä¾‹å­è¡¨æ˜ç¬¬ä¸‰ä¸ªå’Œç¬¬äº”ä¸ªç¥ç»ç½‘ç»œå±‚çš„å‚æ•°æ˜¯ç»‘å®šçš„ã€‚å®ƒä»¬ä¸ä»…å€¼ç›¸ç­‰ï¼Œè€Œä¸”ç”±ç›¸åŒçš„å¼ é‡è¡¨ç¤ºã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æ”¹å˜å…¶ä¸­ä¸€ä¸ªå‚æ•°ï¼Œå¦ä¸€ä¸ªå‚æ•°ä¹Ÿä¼šæ”¹å˜ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªé—®é¢˜ï¼šå½“å‚æ•°ç»‘å®šæ—¶ï¼Œæ¢¯åº¦ä¼šå‘ç”Ÿä»€ä¹ˆæƒ…å†µï¼Ÿç­”æ¡ˆæ˜¯ç”±äºæ¨¡å‹å‚æ•°åŒ…å«æ¢¯åº¦ï¼Œå› æ­¤åœ¨åå‘ä¼ æ’­æœŸé—´ç¬¬äºŒä¸ªéšè—å±‚ï¼ˆå³ç¬¬ä¸‰ä¸ªç¥ç»ç½‘ç»œå±‚ï¼‰å’Œç¬¬ä¸‰ä¸ªéšè—å±‚ï¼ˆå³ç¬¬äº”ä¸ªç¥ç»ç½‘ç»œå±‚ï¼‰çš„æ¢¯åº¦ä¼šåŠ åœ¨ä¸€èµ·ã€‚</p>\n<h2 id=\"3-è‡ªå®šä¹‰å±‚\">3. è‡ªå®šä¹‰å±‚</h2>\n<p>æˆ‘ä»¬æ„é€ ä¸€ä¸ªæ²¡æœ‰ä»»ä½•å‚æ•°çš„è‡ªå®šä¹‰å±‚ï¼Œä¸‹é¢çš„ <code>CenteredLayer</code> ç±»è¦ä»å…¶è¾“å…¥ä¸­å‡å»å‡å€¼ã€‚è¦æ„å»ºå®ƒï¼Œæˆ‘ä»¬åªéœ€ç»§æ‰¿åŸºç¡€å±‚ç±»å¹¶å®ç°å‰å‘ä¼ æ’­åŠŸèƒ½ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">CenteredLayer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> X - X.mean()</span><br><span class=\"line\"></span><br><span class=\"line\">layer = CenteredLayer()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(layer(torch.FloatTensor([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])))  <span class=\"comment\"># tensor([-2., -1.,  0.,  1.,  2.])</span></span><br></pre></td></tr></table></figure>\n<p>ä¸‹é¢æˆ‘ä»¬ç»§ç»­å®šä¹‰å…·æœ‰å‚æ•°çš„å±‚ï¼Œè¿™äº›å‚æ•°å¯ä»¥é€šè¿‡è®­ç»ƒè¿›è¡Œè°ƒæ•´ã€‚è®©æˆ‘ä»¬å®ç°è‡ªå®šä¹‰ç‰ˆæœ¬çš„å…¨è¿æ¥å±‚ã€‚å›æƒ³ä¸€ä¸‹ï¼Œè¯¥å±‚éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªç”¨äºè¡¨ç¤ºæƒé‡ï¼Œå¦ä¸€ä¸ªç”¨äºè¡¨ç¤ºåç½®é¡¹ã€‚åœ¨æ­¤å®ç°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ ReLU ä½œä¸ºæ¿€æ´»å‡½æ•°ã€‚è¯¥å±‚éœ€è¦è¾“å…¥å‚æ•°ï¼š<code>in_units</code> å’Œ <code>units</code>ï¼Œåˆ†åˆ«è¡¨ç¤ºè¾“å…¥æ•°å’Œè¾“å‡ºæ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MyLinear</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_units, units</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        self.weight = nn.Parameter(torch.randn(in_units, units))</span><br><span class=\"line\">        self.bias = nn.Parameter(torch.randn(units,))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        linear = torch.matmul(X, self.weight.data) + self.bias.data</span><br><span class=\"line\">        <span class=\"keyword\">return</span> F.relu(linear)</span><br><span class=\"line\"></span><br><span class=\"line\">linear = MyLinear(<span class=\"number\">5</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(linear.weight.shape)  <span class=\"comment\"># torch.Size([5, 3])</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"4-è¯»å†™æ–‡ä»¶\">4. è¯»å†™æ–‡ä»¶</h2>\n<p>åŠ è½½å’Œä¿å­˜å¼ é‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.arange(<span class=\"number\">4</span>)</span><br><span class=\"line\">torch.save(x, <span class=\"string\">&#x27;../save/x-file&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>å°†å­˜å‚¨åœ¨æ–‡ä»¶ä¸­çš„æ•°æ®è¯»å›å†…å­˜ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x2 = torch.load(<span class=\"string\">&#x27;../save/x-file&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x2)  <span class=\"comment\"># tensor([0, 1, 2, 3])</span></span><br></pre></td></tr></table></figure>\n<p>å­˜å‚¨ä¸€ä¸ªå¼ é‡åˆ—è¡¨ï¼Œç„¶åæŠŠå®ƒä»¬è¯»å›å†…å­˜ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">y = torch.zeros(<span class=\"number\">4</span>)</span><br><span class=\"line\">torch.save([x, y],<span class=\"string\">&#x27;../save/x-files&#x27;</span>)</span><br><span class=\"line\">x2, y2 = torch.load(<span class=\"string\">&#x27;../save/x-files&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>((x2, y2))  <span class=\"comment\"># (tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥å†™å…¥æˆ–è¯»å–ä»å­—ç¬¦ä¸²æ˜ å°„åˆ°å¼ é‡çš„å­—å…¸ã€‚å½“æˆ‘ä»¬è¦è¯»å–æˆ–å†™å…¥æ¨¡å‹ä¸­çš„æ‰€æœ‰æƒé‡æ—¶ï¼Œè¿™å¾ˆæ–¹ä¾¿ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mydict = &#123;<span class=\"string\">&#x27;x&#x27;</span>: x, <span class=\"string\">&#x27;y&#x27;</span>: y&#125;</span><br><span class=\"line\">torch.save(mydict, <span class=\"string\">&#x27;../save/mydict&#x27;</span>)</span><br><span class=\"line\">mydict2 = torch.load(<span class=\"string\">&#x27;../save/mydict&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(mydict2)  <span class=\"comment\"># &#123;&#x27;x&#x27;: tensor([0, 1, 2, 3]), &#x27;y&#x27;: tensor([0., 0., 0., 0.])&#125;</span></span><br></pre></td></tr></table></figure>\n<p>æ·±åº¦å­¦ä¹ æ¡†æ¶æä¾›äº†å†…ç½®å‡½æ•°æ¥ä¿å­˜å’ŒåŠ è½½æ•´ä¸ªç½‘ç»œã€‚éœ€è¦æ³¨æ„çš„ä¸€ä¸ªé‡è¦ç»†èŠ‚æ˜¯ï¼Œè¿™å°†<strong>ä¿å­˜æ¨¡å‹çš„å‚æ•°</strong>è€Œä¸æ˜¯ä¿å­˜æ•´ä¸ªæ¨¡å‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MLP</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        self.hidden = nn.Linear(<span class=\"number\">20</span>, <span class=\"number\">256</span>)</span><br><span class=\"line\">        self.output = nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.output(F.relu(self.hidden(x)))</span><br><span class=\"line\"></span><br><span class=\"line\">net = MLP()</span><br><span class=\"line\">X = torch.randn(size=(<span class=\"number\">2</span>, <span class=\"number\">20</span>))</span><br><span class=\"line\">Y = net(X)</span><br><span class=\"line\"></span><br><span class=\"line\">torch.save(net.state_dict(), <span class=\"string\">&#x27;../save/mlp.params&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ä¸ºäº†æ¢å¤æ¨¡å‹ï¼Œæˆ‘ä»¬å®ä¾‹åŒ–äº†åŸå§‹å¤šå±‚æ„ŸçŸ¥æœºæ¨¡å‹çš„ä¸€ä¸ªå¤‡ä»½ã€‚è¿™é‡Œæˆ‘ä»¬ä¸éœ€è¦éšæœºåˆå§‹åŒ–æ¨¡å‹å‚æ•°ï¼Œè€Œæ˜¯ç›´æ¥è¯»å–æ–‡ä»¶ä¸­å­˜å‚¨çš„å‚æ•°</span></span><br><span class=\"line\">clone = MLP()</span><br><span class=\"line\">clone.load_state_dict(torch.load(<span class=\"string\">&#x27;../save/mlp.params&#x27;</span>))</span><br><span class=\"line\">clone.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">Y_clone = clone(X)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(Y_clone == Y)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[True, True, True, True, True, True, True, True, True, True],</span></span><br><span class=\"line\"><span class=\"comment\">#         [True, True, True, True, True, True, True, True, True, True]])</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"5-GPU\">5. GPU</h2>\n<p>CUDA çš„å®‰è£…é…ç½®æ•™ç¨‹ï¼š<a href=\"/posts/15428.html\">Anacondaä¸PyTorchå®‰è£…æ•™ç¨‹</a></p>\n<p>åœ¨ PyTorch ä¸­ï¼ŒCPU å’Œ GPU å¯ä»¥ç”¨ <code>torch.device('cpu')</code> å’Œ <code>torch.device('cuda')</code> è¡¨ç¤ºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.device(<span class=\"string\">&#x27;cpu&#x27;</span>), torch.device(<span class=\"string\">&#x27;cuda&#x27;</span>), torch.device(<span class=\"string\">&#x27;cuda:0&#x27;</span>))  <span class=\"comment\"># cpu cuda cuda:0</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥æŸ¥è¯¢å¯ç”¨ GPU çš„æ•°é‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(torch.cuda.device_count())  <span class=\"comment\"># 1</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥æŸ¥è¯¢å¼ é‡æ‰€åœ¨çš„è®¾å¤‡ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå¼ é‡æ˜¯åœ¨ CPU ä¸Šåˆ›å»ºçš„ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.tensor([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.device)  <span class=\"comment\"># cpu</span></span><br></pre></td></tr></table></figure>\n<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ— è®ºä½•æ—¶æˆ‘ä»¬è¦å¯¹å¤šä¸ªé¡¹è¿›è¡Œæ“ä½œï¼Œå®ƒä»¬éƒ½å¿…é¡»åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Šã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å¯¹ä¸¤ä¸ªå¼ é‡æ±‚å’Œï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿ä¸¤ä¸ªå¼ é‡éƒ½ä½äºåŒä¸€ä¸ªè®¾å¤‡ä¸Šï¼Œå¦åˆ™æ¡†æ¶å°†ä¸çŸ¥é“åœ¨å“ªé‡Œå­˜å‚¨ç»“æœï¼Œç”šè‡³ä¸çŸ¥é“åœ¨å“ªé‡Œæ‰§è¡Œè®¡ç®—ã€‚</p>\n<p>æœ‰å‡ ç§æ–¹æ³•å¯ä»¥åœ¨ GPU ä¸Šå­˜å‚¨å¼ é‡ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨åˆ›å»ºå¼ é‡æ—¶æŒ‡å®šå­˜å‚¨è®¾å¤‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X = torch.ones(<span class=\"number\">2</span>, <span class=\"number\">3</span>, device=<span class=\"string\">&#x27;cuda&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(X.device)  <span class=\"comment\"># cuda:0</span></span><br></pre></td></tr></table></figure>\n<p>æ•°æ®åœ¨åŒä¸€ä¸ª GPU ä¸Šæˆ‘ä»¬æ‰å¯ä»¥å°†å®ƒä»¬ç›¸åŠ ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Y = X.cuda(<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(Y.device)  <span class=\"comment\"># cuda:0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>((X + Y).device)  <span class=\"comment\"># cuda:0</span></span><br></pre></td></tr></table></figure>\n<p>ç±»ä¼¼åœ°ï¼Œç¥ç»ç½‘ç»œæ¨¡å‹å¯ä»¥æŒ‡å®šè®¾å¤‡ã€‚ä¸‹é¢çš„ä»£ç å°†æ¨¡å‹å‚æ•°æ”¾åœ¨ GPU ä¸Šï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net = nn.Sequential(nn.Linear(<span class=\"number\">3</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">net = net.to(device=<span class=\"string\">&#x27;cuda&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net(X))  <span class=\"comment\"># tensor([[-0.0370], [-0.0370]], device=&#x27;cuda:0&#x27;, grad_fn=&lt;AddmmBackward0&gt;)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">0</span>].weight.data.device)  <span class=\"comment\"># cuda:0</span></span><br></pre></td></tr></table></figure>\n<p>æ€»ä¹‹ï¼Œåªè¦æ‰€æœ‰çš„æ•°æ®å’Œå‚æ•°éƒ½åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Šï¼Œæˆ‘ä»¬å°±å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ¨¡å‹ã€‚</p>\n<p>ä¸‹ä¸€ç« ï¼š<a href=\"/posts/25122.html\">å·ç§¯ç¥ç»ç½‘ç»œ</a>ã€‚</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/46068.html",
            "url": "https://asanosaki.github.io/posts/46068.html",
            "title": "åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ç¬”è®°(ææ²)-å¤šå±‚æ„ŸçŸ¥æœº",
            "date_published": "2023-02-18T08:36:00.000Z",
            "content_html": "<blockquote>\n<p>ææ²åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆPyTorchï¼‰è¯¾ç¨‹å­¦ä¹ ç¬”è®°ç¬¬ä¸‰ç« ï¼šå¤šå±‚æ„ŸçŸ¥æœºã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-å¤šå±‚æ„ŸçŸ¥æœºçš„ä»é›¶å®ç°\">1. å¤šå±‚æ„ŸçŸ¥æœºçš„ä»é›¶å®ç°</h2>\n<p>FashionMNIST æ•°æ®é›†çš„è¯»å–ä¸ç¬¬äºŒç« ç¬¬å››èŠ‚ä¸€æ ·ï¼Œæ­¤å¤„ä¸å†æ”¾ä¸Šä»£ç ã€‚</p>\n<p>åˆå§‹åŒ–æ¨¡å‹å‚æ•°ï¼Œæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªå…·æœ‰å•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºï¼Œå®ƒåŒ…å«256ä¸ªéšè—å•å…ƒã€‚æ³¨æ„ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸¤ä¸ªå˜é‡éƒ½è§†ä¸ºè¶…å‚æ•°ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬é€‰æ‹©2çš„è‹¥å¹²æ¬¡å¹‚ä½œä¸ºå±‚çš„å®½åº¦ã€‚å› ä¸ºå†…å­˜åœ¨ç¡¬ä»¶ä¸­çš„åˆ†é…å’Œå¯»å€æ–¹å¼ï¼Œè¿™ä¹ˆåšå¾€å¾€å¯ä»¥åœ¨è®¡ç®—ä¸Šæ›´é«˜æ•ˆã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_inputs, num_outputs, num_hiddens = <span class=\"number\">784</span>, <span class=\"number\">10</span>, <span class=\"number\">256</span></span><br><span class=\"line\"></span><br><span class=\"line\">W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=<span class=\"literal\">True</span>) * <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=<span class=\"literal\">True</span>))</span><br><span class=\"line\">W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad=<span class=\"literal\">True</span>) * <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=<span class=\"literal\">True</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">params = [W1, b1, W2, b2]</span><br></pre></td></tr></table></figure>\n<p>ä¸ºäº†ç¡®ä¿æˆ‘ä»¬å¯¹æ¨¡å‹çš„ç»†èŠ‚äº†å¦‚æŒ‡æŒï¼Œæˆ‘ä»¬å°†å®ç° ReLU æ¿€æ´»å‡½æ•°ï¼Œè€Œä¸æ˜¯ç›´æ¥è°ƒç”¨å†…ç½®çš„ <code>relu</code> å‡½æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">relu</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">    a = torch.zeros_like(X)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.<span class=\"built_in\">max</span>(X, a)</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥å®šä¹‰æ¨¡å‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">net</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">    H = relu(torch.matmul(X.reshape((-<span class=\"number\">1</span>, num_inputs)), W1) + b1)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.matmul(H, W2) + b2</span><br></pre></td></tr></table></figure>\n<p>è®­ç»ƒå‡½æ•°çš„ä»£ç ä¹Ÿä¸2.4èŠ‚åŸºæœ¬ä¸€æ ·ï¼Œåªéœ€å°† <code>net.to(device)</code> ä¸ <code>net.train()</code> ç­‰ä¸ <code>nn.Module</code> ç›¸å…³çš„ä»£ç å»æ‰å³å¯ï¼Œå› æ­¤ä¸æ”¾å‡ºå®Œæ•´ä»£ç ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_classifier</span>(<span class=\"params\">net, train_iter, test_iter, num_epochs, lr</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;---------- Training on cpu ----------&#x27;</span>)</span><br><span class=\"line\">    loss_function = nn.CrossEntropyLoss()  <span class=\"comment\"># reductioné»˜è®¤ä¸º&#x27;mean&#x27;</span></span><br><span class=\"line\">    optimizer = torch.optim.SGD(params, lr=lr)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        <span class=\"comment\"># train</span></span><br><span class=\"line\">        <span class=\"comment\"># valid</span></span><br><span class=\"line\"></span><br><span class=\"line\">lr, num_epochs = <span class=\"number\">0.1</span>, <span class=\"number\">10</span></span><br><span class=\"line\">train_classifier(net, train_iter, train_iter, num_epochs, lr)</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-å¤šå±‚æ„ŸçŸ¥æœºçš„ç®€æ´å®ç°\">2. å¤šå±‚æ„ŸçŸ¥æœºçš„ç®€æ´å®ç°</h2>\n<p>ä¸ Softmax å›å½’çš„ç®€æ´å®ç°ï¼ˆç¬¬äºŒç« ç¬¬å››èŠ‚ï¼‰ç›¸æ¯”ï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯æˆ‘ä»¬æ·»åŠ äº†2ä¸ªå…¨è¿æ¥å±‚ï¼ˆä¹‹å‰æˆ‘ä»¬åªæ·»åŠ äº†1ä¸ªå…¨è¿æ¥å±‚ï¼‰ã€‚ç¬¬ä¸€å±‚æ˜¯éšè—å±‚ï¼Œå®ƒåŒ…å«256ä¸ªéšè—å•å…ƒï¼Œå¹¶ä½¿ç”¨äº† ReLU æ¿€æ´»å‡½æ•°ã€‚ç¬¬äºŒå±‚æ˜¯è¾“å‡ºå±‚ï¼Œå› æ­¤æˆ‘ä»¬åªéœ€è¦é‡ç‚¹çœ‹ä¸€ä¸‹æ¨¡å‹å³å¯ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> util.functions <span class=\"keyword\">import</span> train_classifier</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è¯»å–æ•°æ®</span></span><br><span class=\"line\"></span><br><span class=\"line\">num_inputs, num_outputs, num_hiddens = <span class=\"number\">784</span>, <span class=\"number\">10</span>, <span class=\"number\">256</span></span><br><span class=\"line\">net = nn.Sequential(nn.Flatten(),</span><br><span class=\"line\">                    nn.Linear(num_inputs, num_hiddens),</span><br><span class=\"line\">                    nn.ReLU(),</span><br><span class=\"line\">                    nn.Linear(num_hiddens, num_outputs))</span><br><span class=\"line\"></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">lr, num_epochs = <span class=\"number\">0.1</span>, <span class=\"number\">10</span></span><br><span class=\"line\">train_classifier(net, train_iter, test_iter, num_epochs, lr, device)</span><br><span class=\"line\"><span class=\"comment\"># [ Train | epoch: 010/010 ] loss = 0.35276, acc = 0.87549</span></span><br><span class=\"line\"><span class=\"comment\"># [ Valid | epoch: 010/010 ] loss = 0.38964, acc = 0.85898</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"3-æ¨¡å‹é€‰æ‹©ã€æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆ\">3. æ¨¡å‹é€‰æ‹©ã€æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆ</h2>\n<p>é¦–å…ˆæˆ‘ä»¬éœ€è¦äº†è§£<strong>è®­ç»ƒè¯¯å·®</strong>å’Œ<strong>æ³›åŒ–è¯¯å·®</strong>ï¼š</p>\n<ul>\n<li>è®­ç»ƒè¯¯å·®ï¼ˆtraining errorï¼‰ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šè®¡ç®—å¾—åˆ°çš„è¯¯å·®ã€‚</li>\n<li>æ³›åŒ–è¯¯å·®ï¼ˆgeneralization errorï¼‰ï¼šæ¨¡å‹åº”ç”¨åœ¨åŒæ ·ä»åŸå§‹æ ·æœ¬çš„åˆ†å¸ƒä¸­æŠ½å–çš„æ— é™å¤šæ•°æ®æ ·æœ¬æ—¶ï¼Œæ¨¡å‹è¯¯å·®çš„æœŸæœ›ã€‚</li>\n</ul>\n<p>é—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬æ°¸è¿œä¸èƒ½å‡†ç¡®åœ°è®¡ç®—å‡ºæ³›åŒ–è¯¯å·®ã€‚è¿™æ˜¯å› ä¸ºæ— é™å¤šçš„æ•°æ®æ ·æœ¬æ˜¯ä¸€ä¸ªè™šæ„çš„å¯¹è±¡ã€‚åœ¨å®é™…ä¸­ï¼Œæˆ‘ä»¬åªèƒ½é€šè¿‡å°†æ¨¡å‹åº”ç”¨äºä¸€ä¸ª<strong>ç‹¬ç«‹</strong>çš„æµ‹è¯•é›†æ¥ä¼°è®¡æ³›åŒ–è¯¯å·®ï¼Œè¯¥æµ‹è¯•é›†ç”±éšæœºé€‰å–çš„ã€æœªæ›¾åœ¨è®­ç»ƒé›†ä¸­å‡ºç°çš„æ•°æ®æ ·æœ¬æ„æˆã€‚</p>\n<p>åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸åœ¨è¯„ä¼°å‡ ä¸ªå€™é€‰æ¨¡å‹åé€‰æ‹©æœ€ç»ˆçš„æ¨¡å‹ã€‚è¿™ä¸ªè¿‡ç¨‹å«åšæ¨¡å‹é€‰æ‹©ã€‚æœ‰æ—¶ï¼Œéœ€è¦è¿›è¡Œæ¯”è¾ƒçš„æ¨¡å‹åœ¨æœ¬è´¨ä¸Šæ˜¯å®Œå…¨ä¸åŒçš„ï¼ˆæ¯”å¦‚ï¼Œå†³ç­–æ ‘ä¸çº¿æ€§æ¨¡å‹ï¼‰ã€‚åˆæœ‰æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æ¯”è¾ƒ<strong>ä¸åŒçš„è¶…å‚æ•°è®¾ç½®</strong>ä¸‹çš„åŒä¸€ç±»æ¨¡å‹ã€‚</p>\n<p>ä¾‹å¦‚ï¼Œè®­ç»ƒå¤šå±‚æ„ŸçŸ¥æœºæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›æ¯”è¾ƒå…·æœ‰ä¸åŒæ•°é‡çš„éšè—å±‚ã€ä¸åŒæ•°é‡çš„éšè—å•å…ƒä»¥åŠä¸åŒçš„æ¿€æ´»å‡½æ•°ç»„åˆçš„æ¨¡å‹ã€‚ä¸ºäº†ç¡®å®šå€™é€‰æ¨¡å‹ä¸­çš„æœ€ä½³æ¨¡å‹ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨<strong>éªŒè¯é›†</strong>ã€‚</p>\n<ul>\n<li>éªŒè¯æ•°æ®é›†ï¼šä¸€ä¸ªç”¨æ¥è¯„ä¼°æ¨¡å‹å¥½åçš„æ•°æ®é›†ï¼Œè®­ç»ƒæ•°æ®é›†ç”¨æ¥è®­ç»ƒæ¨¡å‹å‚æ•°ï¼ŒéªŒè¯æ•°æ®é›†ç”¨æ¥é€‰æ‹©æ¨¡å‹è¶…å‚æ•°ã€‚\n<ul>\n<li>ä¾‹å¦‚åœ¨æ•°æ®é›†ä¸­æ‹¿å‡º50%çš„è®­ç»ƒæ•°æ®ä½œä¸ºéªŒè¯æ•°æ®é›†ã€‚</li>\n<li>ä¸è¦è·Ÿè®­ç»ƒæ•°æ®æ··åœ¨ä¸€èµ·ï¼ˆå¸¸çŠ¯é”™è¯¯ï¼‰ã€‚</li>\n</ul>\n</li>\n<li>æµ‹è¯•æ•°æ®é›†ï¼šåªç”¨ä¸€æ¬¡çš„æ•°æ®é›†ã€‚\n<ul>\n<li>ä¾‹å¦‚æœªæ¥çš„è€ƒè¯•ã€‚</li>\n<li>ä¾‹å¦‚æˆ‘å‡ºä»·çš„æˆ¿å­çš„å®é™…æˆäº¤ä»·ã€‚</li>\n</ul>\n</li>\n</ul>\n<p>æ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦äº†è§£ä¸€ä¸‹<strong>æ¨¡å‹å®¹é‡</strong>çš„æ¦‚å¿µï¼š</p>\n<ul>\n<li>æ¨¡å‹å®¹é‡è¡¨ç¤ºæ¨¡å‹æ‹Ÿåˆå„ç§å‡½æ•°çš„èƒ½åŠ›ã€‚</li>\n<li>ä½å®¹é‡çš„æ¨¡å‹éš¾ä»¥æ‹Ÿåˆå¤æ‚çš„è®­ç»ƒæ•°æ®ã€‚</li>\n<li>é«˜å®¹é‡çš„æ¨¡å‹å¯ä»¥è®°ä½æ‰€æœ‰çš„è®­ç»ƒæ•°æ®ã€‚</li>\n</ul>\n<p>æ˜¯å¦è¿‡æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆä¸»è¦å–å†³äº<strong>æ¨¡å‹å¤æ‚æ€§</strong>å’Œ<strong>å¯ç”¨è®­ç»ƒæ•°æ®é›†çš„å¤§å°</strong>ã€‚å½“æˆ‘ä»¬æ¯”è¾ƒè®­ç»ƒå’ŒéªŒè¯è¯¯å·®æ—¶ï¼Œæˆ‘ä»¬è¦æ³¨æ„ä¸¤ç§å¸¸è§çš„æƒ…å†µï¼š</p>\n<ul>\n<li>è®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®éƒ½å¾ˆå·®ï¼Œä½†å®ƒä»¬ä¹‹é—´ä»…æœ‰ä¸€ç‚¹å·®è·ã€‚å¦‚æœæ¨¡å‹ä¸èƒ½é™ä½è®­ç»ƒè¯¯å·®ï¼Œè¿™å¯èƒ½æ„å‘³ç€æ¨¡å‹è¿‡äºç®€å•ï¼ˆå³è¡¨è¾¾èƒ½åŠ›ä¸è¶³ï¼‰ï¼Œæ— æ³•æ•è·è¯•å›¾å­¦ä¹ çš„æ¨¡å¼ã€‚æ­¤å¤–ï¼Œç”±äºæˆ‘ä»¬çš„è®­ç»ƒå’ŒéªŒè¯è¯¯å·®ä¹‹é—´çš„æ³›åŒ–è¯¯å·®å¾ˆå°ï¼Œæˆ‘ä»¬æœ‰ç†ç”±ç›¸ä¿¡å¯ä»¥ç”¨ä¸€ä¸ªæ›´å¤æ‚çš„æ¨¡å‹é™ä½è®­ç»ƒè¯¯å·®ã€‚è¿™ç§ç°è±¡è¢«ç§°ä¸ºæ¬ æ‹Ÿåˆï¼ˆunderfittingï¼‰ã€‚</li>\n<li>å½“æˆ‘ä»¬çš„è®­ç»ƒè¯¯å·®<strong>æ˜æ˜¾ä½äº</strong>éªŒè¯è¯¯å·®æ—¶è¦å°å¿ƒï¼Œè¿™è¡¨æ˜ä¸¥é‡çš„è¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰ã€‚æ³¨æ„ï¼Œè¿‡æ‹Ÿåˆå¹¶ä¸æ€»æ˜¯ä¸€ä»¶åäº‹ã€‚ç‰¹åˆ«æ˜¯åœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œä¼—æ‰€å‘¨çŸ¥ï¼Œæœ€å¥½çš„é¢„æµ‹æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„è¡¨ç°å¾€å¾€æ¯”åœ¨ä¿ç•™ï¼ˆéªŒè¯ï¼‰æ•°æ®ä¸Šå¥½å¾—å¤šã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬é€šå¸¸æ›´å…³å¿ƒéªŒè¯è¯¯å·®ï¼Œè€Œä¸æ˜¯è®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®ä¹‹é—´çš„å·®è·ã€‚</li>\n</ul>\n<h2 id=\"4-æƒé‡è¡°å‡\">4. æƒé‡è¡°å‡</h2>\n<p>åœ¨è®­ç»ƒå‚æ•°åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹æ—¶ï¼Œæƒé‡è¡°å‡ï¼ˆweight decayï¼‰æ˜¯æœ€å¹¿æ³›ä½¿ç”¨çš„æ­£åˆ™åŒ–çš„æŠ€æœ¯ä¹‹ä¸€ï¼Œå®ƒé€šå¸¸ä¹Ÿè¢«ç§°ä¸ºL2æ­£åˆ™åŒ–ã€‚</p>\n<p>é€šè¿‡é™åˆ¶å‚æ•°å€¼çš„é€‰æ‹©èŒƒå›´æ¥æ§åˆ¶æ¨¡å‹å®¹é‡ï¼Œé€šå¸¸ä¸é™åˆ¶åç§» <code>b</code>ã€‚</p>\n<p>é¦–å…ˆç”Ÿæˆä¸€äº›æ•°æ®ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">n_train, n_test, num_inputs, batch_size = <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">200</span>, <span class=\"number\">5</span>  <span class=\"comment\"># è®­ç»ƒæ•°æ®å°‘ï¼Œç‰¹å¾ç»´åº¦å¤§ï¼Œå› æ­¤å®¹æ˜“è¿‡æ‹Ÿåˆ</span></span><br><span class=\"line\">true_w, true_b = torch.ones((num_inputs, <span class=\"number\">1</span>)) * <span class=\"number\">0.01</span>, <span class=\"number\">0.05</span></span><br><span class=\"line\"></span><br><span class=\"line\">train_data = d2l.synthetic_data(true_w, true_b, n_train)</span><br><span class=\"line\">train_iter = d2l.load_array(train_data, batch_size)</span><br><span class=\"line\">test_data = d2l.synthetic_data(true_w, true_b, n_test)</span><br><span class=\"line\">test_iter = d2l.load_array(test_data, batch_size, is_train=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰ç½‘ç»œæ¨¡å‹ä¸æŸå¤±å‡½æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net = nn.Sequential(nn.Linear(num_inputs, <span class=\"number\">1</span>))</span><br><span class=\"line\">loss_function = nn.MSELoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰ä¼˜åŒ–ç®—æ³•ï¼Œæˆ‘ä»¬åœ¨å®ä¾‹åŒ–ä¼˜åŒ–å™¨æ—¶ç›´æ¥é€šè¿‡ <code>weight_decay</code> æŒ‡å®š <code>weight decay</code> è¶…å‚æ•°ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒPyTorch åŒæ—¶è¡°å‡æƒé‡å’Œåç§»ã€‚è¿™é‡Œæˆ‘ä»¬åªä¸ºæƒé‡è®¾ç½®äº† <code>weight_decay</code>ï¼Œæ‰€ä»¥åç½®å‚æ•°ä¸ä¼šè¡°å‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_epochs, lr, wd = <span class=\"number\">100</span>, <span class=\"number\">0.003</span>, <span class=\"number\">0</span>  <span class=\"comment\"># wdä¸º0è¡¨ç¤ºä¸ä½¿ç”¨æƒé‡è¡°å‡</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># åç½®å‚æ•°æ²¡æœ‰è¡°å‡ï¼Œnet[0]å³ä¸ºnn.Linear(num_inputs, 1)</span></span><br><span class=\"line\">optimizer = torch.optim.SGD([&#123;<span class=\"string\">&#x27;params&#x27;</span>:net[<span class=\"number\">0</span>].weight, <span class=\"string\">&#x27;weight_decay&#x27;</span>:wd&#125;, &#123;<span class=\"string\">&#x27;params&#x27;</span>:net[<span class=\"number\">0</span>].bias&#125;], lr=lr)</span><br></pre></td></tr></table></figure>\n<p>ç„¶åè¿›è¡Œè®­ç»ƒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&#x27;../logs/WeightDecay_train_log&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> net.parameters():</span><br><span class=\"line\">    param.data.normal_()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">    train_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    test_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    net.train()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">        y_hat = net(X)</span><br><span class=\"line\">        loss = loss_function(y_hat, y)</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss.mean().backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">        train_loss += loss.<span class=\"built_in\">sum</span>()</span><br><span class=\"line\">    train_loss /= n_train</span><br><span class=\"line\"></span><br><span class=\"line\">    net.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> test_iter:</span><br><span class=\"line\">            y_hat = net(X)</span><br><span class=\"line\">            loss = loss_function(y_hat, y)</span><br><span class=\"line\">            test_loss += loss.<span class=\"built_in\">sum</span>()</span><br><span class=\"line\">    test_loss /= n_test</span><br><span class=\"line\"></span><br><span class=\"line\">    writer.add_scalar(<span class=\"string\">&#x27;train_loss&#x27;</span>, train_loss, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\">    writer.add_scalar(<span class=\"string\">&#x27;test_loss&#x27;</span>, test_loss, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;wçš„L2èŒƒæ•°ï¼š&#x27;</span>, net[<span class=\"number\">0</span>].weight.norm().item())</span><br></pre></td></tr></table></figure>\n<p>é€šè¿‡ç»“æœå¯ä»¥çœ‹åˆ°æ¨¡å‹å¾ˆå¿«å°±è¿‡æ‹Ÿåˆäº†ï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹è¶…å‚æ•° <code>wd</code> çš„å€¼åº”ç”¨æƒé‡è¡°å‡çš„æ–¹å¼æ¥ç¼“è§£è¿‡æ‹Ÿåˆçš„ç°è±¡ã€‚</p>\n<h2 id=\"5-æš‚é€€æ³•ï¼ˆDropoutï¼‰\">5. æš‚é€€æ³•ï¼ˆDropoutï¼‰</h2>\n<p>ä¸€ä¸ªå¥½çš„æ¨¡å‹éœ€è¦å¯¹è¾“å…¥æ•°æ®çš„æ‰°åŠ¨é²æ£’ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå»ºè®®åœ¨è®¡ç®—åç»­å±‚ä¹‹å‰<strong>å‘ç½‘ç»œçš„æ¯ä¸€å±‚æ³¨å…¥å™ªå£°</strong>ï¼Œå› ä¸ºå½“è®­ç»ƒä¸€ä¸ªæœ‰å¤šå±‚çš„æ·±å±‚ç½‘ç»œæ—¶ï¼Œæ³¨å…¥å™ªå£°åªä¼šåœ¨è¾“å…¥-è¾“å‡ºæ˜ å°„ä¸Šå¢å¼ºå¹³æ»‘æ€§ã€‚</p>\n<p>è¿™ä¸ªæƒ³æ³•è¢«ç§°ä¸ºæš‚é€€æ³•ï¼ˆdropoutï¼‰ã€‚æš‚é€€æ³•åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œè®¡ç®—æ¯ä¸€å†…éƒ¨å±‚çš„åŒæ—¶æ³¨å…¥å™ªå£°ï¼Œè¿™å·²ç»æˆä¸ºè®­ç»ƒç¥ç»ç½‘ç»œçš„å¸¸ç”¨æŠ€æœ¯ã€‚è¿™ç§æ–¹æ³•ä¹‹æ‰€ä»¥è¢«ç§°ä¸ºæš‚é€€æ³•ï¼Œå› ä¸ºæˆ‘ä»¬ä»è¡¨é¢ä¸Šçœ‹æ˜¯<strong>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸¢å¼ƒï¼ˆdrop outï¼‰ä¸€äº›ç¥ç»å…ƒ</strong>ã€‚åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„æ¯ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œæ ‡å‡†æš‚é€€æ³•åŒ…æ‹¬<strong>åœ¨è®¡ç®—ä¸‹ä¸€å±‚ä¹‹å‰å°†å½“å‰å±‚ä¸­çš„ä¸€äº›èŠ‚ç‚¹ç½®é›¶</strong>ã€‚</p>\n<p>åœ¨æ ‡å‡†æš‚é€€æ³•æ­£åˆ™åŒ–ä¸­ï¼Œé€šè¿‡æŒ‰ä¿ç•™ï¼ˆæœªä¸¢å¼ƒï¼‰çš„èŠ‚ç‚¹çš„åˆ†æ•°è¿›è¡Œè§„èŒƒåŒ–æ¥æ¶ˆé™¤æ¯ä¸€å±‚çš„åå·®ã€‚æ¢è¨€ä¹‹ï¼Œæ¯ä¸ªä¸­é—´æ´»æ€§å€¼ <code>h</code> ä»¥æš‚é€€æ¦‚ç‡ <code>p</code> ç”±éšæœºå˜é‡æ›¿æ¢ã€‚</p>\n<p>Dropout è¯´çš„ç®€å•ä¸€ç‚¹å°±æ˜¯ï¼šæˆ‘ä»¬åœ¨å‰å‘ä¼ æ’­çš„æ—¶å€™ï¼Œè®©æŸä¸ªç¥ç»å…ƒçš„æ¿€æ´»å€¼ä»¥ä¸€å®šçš„æ¦‚ç‡ <code>p</code> åœæ­¢å·¥ä½œï¼ˆå°†ä¸€äº›è¾“å‡ºé¡¹éšæœºç½®0ï¼‰ï¼Œè¿™æ ·å¯ä»¥ä½¿æ¨¡å‹æ³›åŒ–æ€§æ›´å¼ºï¼Œå› ä¸ºå®ƒä¸ä¼šå¤ªä¾èµ–æŸäº›å±€éƒ¨çš„ç‰¹å¾ã€‚</p>\n<p>æˆ‘ä»¬å¯ä»¥å°†æš‚é€€æ³•åº”ç”¨äºæ¯ä¸ªéšè—å±‚çš„è¾“å‡ºï¼ˆåœ¨æ¿€æ´»å‡½æ•°ä¹‹åï¼‰ï¼Œå¹¶ä¸”å¯ä»¥ä¸ºæ¯ä¸€å±‚åˆ†åˆ«è®¾ç½®æš‚é€€æ¦‚ç‡ï¼šå¸¸è§çš„æŠ€å·§æ˜¯åœ¨é è¿‘è¾“å…¥å±‚çš„åœ°æ–¹è®¾ç½®è¾ƒä½çš„æš‚é€€æ¦‚ç‡ã€‚ä¸‹é¢çš„æ¨¡å‹å°†ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªéšè—å±‚çš„æš‚é€€æ¦‚ç‡åˆ†åˆ«è®¾ç½®ä¸º0.2å’Œ0.5ï¼Œå¹¶ä¸”æš‚é€€æ³•<strong>åªåœ¨è®­ç»ƒæœŸé—´æœ‰æ•ˆ</strong>ã€‚</p>\n<p>Dropout çš„ä»é›¶å®ç°æ ¸å¿ƒä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">dropout_layer</span>(<span class=\"params\">X, p</span>):</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> <span class=\"number\">0</span> &lt;= p &lt;= <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"comment\"># åœ¨æœ¬æƒ…å†µä¸­ï¼Œæ‰€æœ‰å…ƒç´ éƒ½è¢«ä¸¢å¼ƒ</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> p == <span class=\"number\">1</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.zeros_like(X)</span><br><span class=\"line\">    <span class=\"comment\"># åœ¨æœ¬æƒ…å†µä¸­ï¼Œæ‰€æœ‰å…ƒç´ éƒ½è¢«ä¿ç•™</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> p == <span class=\"number\">0</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> X</span><br><span class=\"line\">    mask = (torch.rand(X.shape) &gt; p).<span class=\"built_in\">float</span>()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mask * X / (<span class=\"number\">1.0</span> - p)</span><br><span class=\"line\"></span><br><span class=\"line\">num_inputs, num_outputs, num_hiddens1, num_hiddens2 = <span class=\"number\">784</span>, <span class=\"number\">10</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span></span><br><span class=\"line\">p1, p2 = <span class=\"number\">0.2</span>, <span class=\"number\">0.5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Net</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, num_inputs, num_outputs, num_hiddens1, num_hiddens2, is_training = <span class=\"literal\">True</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Net, self).__init__()</span><br><span class=\"line\">        self.num_inputs = num_inputs</span><br><span class=\"line\">        self.training = is_training</span><br><span class=\"line\">        self.lin1 = nn.Linear(num_inputs, num_hiddens1)</span><br><span class=\"line\">        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)</span><br><span class=\"line\">        self.lin3 = nn.Linear(num_hiddens2, num_outputs)</span><br><span class=\"line\">        self.relu = nn.ReLU()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X</span>):</span><br><span class=\"line\">        H1 = self.relu(self.lin1(X.reshape((-<span class=\"number\">1</span>, self.num_inputs))))</span><br><span class=\"line\">        <span class=\"comment\"># åªæœ‰åœ¨è®­ç»ƒæ¨¡å‹æ—¶æ‰ä½¿ç”¨dropout</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.training == <span class=\"literal\">True</span>:</span><br><span class=\"line\">            <span class=\"comment\"># åœ¨ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ä¹‹åæ·»åŠ ä¸€ä¸ªdropoutå±‚</span></span><br><span class=\"line\">            H1 = dropout_layer(H1, p1)</span><br><span class=\"line\">        H2 = self.relu(self.lin2(H1))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.training == <span class=\"literal\">True</span>:</span><br><span class=\"line\">            <span class=\"comment\"># åœ¨ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ä¹‹åæ·»åŠ ä¸€ä¸ªdropoutå±‚</span></span><br><span class=\"line\">            H2 = dropout_layer(H2, p2)</span><br><span class=\"line\">        out = self.lin3(H2)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\">net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)</span><br></pre></td></tr></table></figure>\n<p>Dropout çš„ç®€æ´å®ç°åŠå®Œæ•´è®­ç»ƒä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> util.functions <span class=\"keyword\">import</span> train_classifier</span><br><span class=\"line\"></span><br><span class=\"line\">mnist_train = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">True</span>, transform=transforms.ToTensor(), download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">mnist_test = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor(), download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">train_iter = data.DataLoader(mnist_train, batch_size=<span class=\"number\">256</span>, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\">test_iter = data.DataLoader(mnist_test, batch_size=<span class=\"number\">256</span>, shuffle=<span class=\"literal\">False</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">net = nn.Sequential(nn.Flatten(),</span><br><span class=\"line\">                    nn.Linear(<span class=\"number\">784</span>, <span class=\"number\">256</span>),</span><br><span class=\"line\">                    nn.ReLU(),</span><br><span class=\"line\">                    nn.Dropout(<span class=\"number\">0.2</span>),</span><br><span class=\"line\">                    nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">256</span>),</span><br><span class=\"line\">                    nn.ReLU(),</span><br><span class=\"line\">                    nn.Dropout(<span class=\"number\">0.5</span>),</span><br><span class=\"line\">                    nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">lr, num_epochs = <span class=\"number\">0.1</span>, <span class=\"number\">10</span></span><br><span class=\"line\">writer_path = <span class=\"string\">&#x27;../logs/Dropout_train_log&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">train_classifier(net, train_iter, test_iter, num_epochs, lr, device, writer_path)</span><br><span class=\"line\"><span class=\"comment\"># [ Train | epoch: 010/010 ] loss = 0.37249, acc = 0.86702</span></span><br><span class=\"line\"><span class=\"comment\"># [ Valid | epoch: 010/010 ] loss = 0.37481, acc = 0.86348</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"6-æ•°å€¼ç¨³å®šæ€§å’Œæ¨¡å‹åˆå§‹åŒ–\">6. æ•°å€¼ç¨³å®šæ€§å’Œæ¨¡å‹åˆå§‹åŒ–</h2>\n<p>æˆ‘ä»¬å¯èƒ½é¢ä¸´ä¸€äº›é—®é¢˜ï¼Œè¦ä¹ˆæ˜¯<strong>æ¢¯åº¦çˆ†ç‚¸</strong>ï¼ˆgradient explodingï¼‰é—®é¢˜ï¼šå‚æ•°æ›´æ–°è¿‡å¤§ï¼Œç ´åäº†æ¨¡å‹çš„ç¨³å®šæ”¶æ•›ï¼›è¦ä¹ˆæ˜¯<strong>æ¢¯åº¦æ¶ˆå¤±</strong>ï¼ˆgradient vanishingï¼‰é—®é¢˜ï¼šå‚æ•°æ›´æ–°è¿‡å°ï¼Œåœ¨æ¯æ¬¡æ›´æ–°æ—¶å‡ ä¹ä¸ä¼šç§»åŠ¨ï¼Œå¯¼è‡´æ¨¡å‹æ— æ³•å­¦ä¹ ã€‚</p>\n<p>ä¾‹å¦‚å½“ Sigmoid å‡½æ•°çš„è¾“å…¥å¾ˆå¤§æˆ–æ˜¯å¾ˆå°æ—¶ï¼Œå®ƒçš„æ¢¯åº¦éƒ½ä¼šæ¶ˆå¤±ã€‚æ­¤å¤–ï¼Œå½“åå‘ä¼ æ’­é€šè¿‡è®¸å¤šå±‚æ—¶ï¼Œé™¤éæˆ‘ä»¬åœ¨åˆšåˆšå¥½çš„åœ°æ–¹ï¼Œè¿™äº›åœ°æ–¹ Sigmoid å‡½æ•°çš„è¾“å…¥æ¥è¿‘äºé›¶ï¼Œå¦åˆ™æ•´ä¸ªä¹˜ç§¯çš„æ¢¯åº¦å¯èƒ½ä¼šæ¶ˆå¤±ã€‚</p>\n<p>Xavier åˆå§‹åŒ–ï¼šä»å‡å€¼ä¸ºé›¶ï¼Œæ–¹å·®ä¸º <code>2 / (n_in + n_out)</code> çš„é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·æƒé‡ï¼ˆ<code>n_in</code> ä¸ºè¾“å…¥çš„æ•°é‡ï¼Œ<code>n_out</code> ä¸ºè¾“å‡ºçš„æ•°é‡ï¼‰ã€‚</p>\n<p>ä¸‹ä¸€ç« ï¼š<a href=\"/posts/23526.html\">PyTorch ç¥ç»ç½‘ç»œåŸºç¡€</a>ã€‚</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/19931.html",
            "url": "https://asanosaki.github.io/posts/19931.html",
            "title": "åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ç¬”è®°(ææ²)-çº¿æ€§ç¥ç»ç½‘ç»œ",
            "date_published": "2023-02-02T11:25:00.000Z",
            "content_html": "<blockquote>\n<p>ææ²åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆPyTorchï¼‰è¯¾ç¨‹å­¦ä¹ ç¬”è®°ç¬¬äºŒç« ï¼šçº¿æ€§ç¥ç»ç½‘ç»œã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-çº¿æ€§å›å½’çš„ä»é›¶å®ç°\">1. çº¿æ€§å›å½’çš„ä»é›¶å®ç°</h2>\n<p>ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†æ ¹æ®å¸¦æœ‰å™ªå£°çš„çº¿æ€§æ¨¡å‹æ„é€ ä¸€ä¸ªäººé€ æ•°æ®é›†ã€‚æˆ‘ä»¬çš„ä»»åŠ¡æ˜¯ä½¿ç”¨è¿™ä¸ªæœ‰é™æ ·æœ¬çš„æ•°æ®é›†æ¥æ¢å¤è¿™ä¸ªæ¨¡å‹çš„å‚æ•°ã€‚</p>\n<p>é¦–å…ˆæˆ‘ä»¬ç”Ÿæˆæ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ç”Ÿæˆæ•°æ®é›†</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">synthetic_data</span>(<span class=\"params\">w, b, num_examples</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ç”Ÿæˆy = Xw + b + å™ªå£°&quot;&quot;&quot;</span></span><br><span class=\"line\">    X = torch.normal(<span class=\"number\">0</span>, <span class=\"number\">1</span>, (num_examples, <span class=\"built_in\">len</span>(w)))  <span class=\"comment\"># å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„éšæœºæ•°ï¼Œå¤§å°ä¸º(num_examples, len(w))</span></span><br><span class=\"line\">    y = torch.matmul(X, w) + b  <span class=\"comment\"># y = Xw + b</span></span><br><span class=\"line\">    y += torch.normal(<span class=\"number\">0</span>, <span class=\"number\">0.01</span>, y.shape)  <span class=\"comment\"># åŠ å…¥ä¸€ä¸ªéšæœºå™ªéŸ³</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> X, y.reshape((-<span class=\"number\">1</span>, <span class=\"number\">1</span>))  <span class=\"comment\"># yä¸ºåˆ—å‘é‡</span></span><br><span class=\"line\"></span><br><span class=\"line\">true_w = torch.tensor([<span class=\"number\">2</span>, -<span class=\"number\">3.4</span>])</span><br><span class=\"line\">true_b = <span class=\"number\">4.2</span></span><br><span class=\"line\">features, labels = synthetic_data(true_w, true_b, <span class=\"number\">1000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;features:&#x27;</span>, features[<span class=\"number\">0</span>],<span class=\"string\">&#x27;\\nlabel:&#x27;</span>, labels[<span class=\"number\">0</span>])</span><br><span class=\"line\"><span class=\"comment\"># features: tensor([ 0.7764, -1.2998])</span></span><br><span class=\"line\"><span class=\"comment\"># label: tensor([10.1756])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># é€šè¿‡ç”Ÿæˆç¬¬äºŒä¸ªç‰¹å¾features[:, 1]å’Œlabelsçš„æ•£ç‚¹å›¾ï¼Œå¯ä»¥ç›´è§‚è§‚å¯Ÿåˆ°ä¸¤è€…ä¹‹é—´çš„çº¿æ€§å…³ç³»</span></span><br><span class=\"line\">plt.plot(features[:, <span class=\"number\">1</span>].detach().numpy(), labels.detach().numpy(), <span class=\"string\">&#x27;ro&#x27;</span>, ms=<span class=\"number\">3</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>è®­ç»ƒæ¨¡å‹æ—¶è¦å¯¹æ•°æ®é›†è¿›è¡Œéå†ï¼Œæ¯æ¬¡æŠ½å–ä¸€å°æ‰¹é‡æ ·æœ¬ï¼Œå¹¶ä½¿ç”¨å®ƒä»¬æ¥æ›´æ–°æˆ‘ä»¬çš„æ¨¡å‹ã€‚ç”±äºè¿™ä¸ªè¿‡ç¨‹æ˜¯è®­ç»ƒæœºå™¨å­¦ä¹ ç®—æ³•çš„åŸºç¡€ï¼Œæ‰€ä»¥æœ‰å¿…è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°èƒ½æ‰“ä¹±æ•°æ®é›†ä¸­çš„æ ·æœ¬å¹¶ä»¥å°æ‰¹é‡æ–¹å¼è·å–æ•°æ®ã€‚</p>\n<p>åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ª <code>data_iter</code> å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥æ”¶æ‰¹é‡å¤§å°ã€ç‰¹å¾çŸ©é˜µå’Œæ ‡ç­¾å‘é‡ä½œä¸ºè¾“å…¥ï¼Œç”Ÿæˆå¤§å°ä¸º <code>batch_size</code> çš„å°æ‰¹é‡ã€‚æ¯ä¸ªå°æ‰¹é‡åŒ…å«ä¸€ç»„ç‰¹å¾å’Œæ ‡ç­¾ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">data_iter</span>(<span class=\"params\">batch_size, features, labels</span>):</span><br><span class=\"line\">    num_examples = <span class=\"built_in\">len</span>(features)</span><br><span class=\"line\">    indices = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(num_examples))</span><br><span class=\"line\">    <span class=\"comment\"># è¿™äº›æ ·æœ¬æ˜¯éšæœºè¯»å–çš„ï¼Œæ²¡æœ‰ç‰¹å®šçš„é¡ºåºï¼Œå› æ­¤è¦æ‰“ä¹±ä¸‹æ ‡</span></span><br><span class=\"line\">    random.shuffle(indices)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, num_examples, batch_size):</span><br><span class=\"line\">        batch_indices = torch.tensor(indices[i:<span class=\"built_in\">min</span>(i + batch_size, num_examples)])</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> features[batch_indices], labels[batch_indices]</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> data_iter(batch_size, features, labels):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(X, <span class=\"string\">&#x27;\\n&#x27;</span>, y)</span><br><span class=\"line\">    <span class=\"keyword\">break</span></span><br></pre></td></tr></table></figure>\n<p>åœ¨æˆ‘ä»¬å¼€å§‹ç”¨å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–æˆ‘ä»¬çš„æ¨¡å‹å‚æ•°ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæœ‰ä¸€äº›å‚æ•°ã€‚åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä»å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º0.01çš„æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·éšæœºæ•°æ¥<strong>åˆå§‹åŒ–æƒé‡</strong>ï¼Œå¹¶å°†åç½®åˆå§‹åŒ–ä¸º0ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">w = torch.normal(<span class=\"number\">0</span>, <span class=\"number\">0.01</span>, size=(<span class=\"number\">2</span>, <span class=\"number\">1</span>), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">b = torch.zeros(<span class=\"number\">1</span>, requires_grad=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰çº¿æ€§å›å½’æ¨¡å‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">linreg</span>(<span class=\"params\">X, w, b</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;çº¿æ€§å›å½’æ¨¡å‹&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.matmul(X, w) + b</span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰æŸå¤±å‡½æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">squared_loss</span>(<span class=\"params\">y_hat, y</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å‡æ–¹æŸå¤±&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (y_hat - y.reshape(y_hat.shape)) ** <span class=\"number\">2</span> / <span class=\"number\">2</span></span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰ä¼˜åŒ–ç®—æ³•ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sgd</span>(<span class=\"params\">params, lr, batch_size</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():  <span class=\"comment\"># æ›´æ–°å‚æ•°çš„æ—¶å€™ä¸éœ€è¦è®¡ç®—æ¢¯åº¦</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> params:</span><br><span class=\"line\">            param -= lr * param.grad / batch_size</span><br><span class=\"line\">            param.grad.zero_()  <span class=\"comment\"># å°†æ¢¯åº¦æ¸…é›¶</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†æ¨¡å‹è®­ç»ƒæ‰€æœ‰éœ€è¦çš„è¦ç´ ï¼Œå¯ä»¥å®ç°ä¸»è¦çš„è®­ç»ƒè¿‡ç¨‹éƒ¨åˆ†äº†ã€‚ç†è§£è¿™æ®µä»£ç è‡³å…³é‡è¦ï¼Œå› ä¸ºä»äº‹æ·±åº¦å­¦ä¹ åï¼Œç›¸åŒçš„è®­ç»ƒè¿‡ç¨‹å‡ ä¹ä¸€éåˆä¸€éåœ°å‡ºç°ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæˆ‘ä»¬è¯»å–ä¸€å°æ‰¹é‡è®­ç»ƒæ ·æœ¬ï¼Œå¹¶é€šè¿‡æˆ‘ä»¬çš„æ¨¡å‹æ¥è·å¾—ä¸€ç»„é¢„æµ‹ã€‚è®¡ç®—å®ŒæŸå¤±åï¼Œæˆ‘ä»¬å¼€å§‹åå‘ä¼ æ’­ï¼Œå­˜å‚¨æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ã€‚æœ€åï¼Œæˆ‘ä»¬è°ƒç”¨ä¼˜åŒ–ç®—æ³•ï¼ˆéšæœºæ¢¯åº¦ä¸‹é™æ³•SGDï¼‰æ¥æ›´æ–°æ¨¡å‹å‚æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># è¶…å‚æ•°</span></span><br><span class=\"line\">lr, num_epochs = <span class=\"number\">0.03</span>, <span class=\"number\">3</span></span><br><span class=\"line\">net = linreg</span><br><span class=\"line\">loss_function = squared_loss</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> data_iter(batch_size, features, labels):</span><br><span class=\"line\">        loss = loss_function(net(X, w, b), y)  <span class=\"comment\"># Xå’Œyçš„å°æ‰¹é‡æŸå¤±</span></span><br><span class=\"line\">        <span class=\"comment\"># lossçš„å½¢çŠ¶æ˜¯(batch_size, 1)ï¼Œè€Œä¸æ˜¯æ ‡é‡ï¼Œå°†lossä¸­çš„æ‰€æœ‰å…ƒç´ åŠ åˆ°ä¸€èµ·ï¼Œå¹¶ä»¥æ­¤è®¡ç®—å…³äº[w, b]çš„æ¢¯åº¦</span></span><br><span class=\"line\">        loss.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\">        sgd([w, b], lr, batch_size)  <span class=\"comment\"># ä½¿ç”¨å‚æ•°çš„æ¢¯åº¦æ›´æ–°å‚æ•°</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        train_loss = loss_function(net(features, w, b), labels)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;epoch <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>&#125;</span>, loss <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_loss.mean()):f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-çº¿æ€§å›å½’çš„ç®€æ´å®ç°\">2. çº¿æ€§å›å½’çš„ç®€æ´å®ç°</h2>\n<p>é¦–å…ˆç”Ÿæˆæ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\">true_w = torch.tensor([<span class=\"number\">2</span>, -<span class=\"number\">3.4</span>])</span><br><span class=\"line\">true_b = <span class=\"number\">4.2</span></span><br><span class=\"line\">features, labels = d2l.synthetic_data(true_w, true_b, <span class=\"number\">1000</span>)</span><br></pre></td></tr></table></figure>\n<p>è¯»å–æ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_array</span>(<span class=\"params\">data_arrays, batch_size, is_train=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;æ„é€ ä¸€ä¸ªPyTorchæ•°æ®è¿­ä»£å™¨&quot;&quot;&quot;</span></span><br><span class=\"line\">    dataset = data.TensorDataset(*data_arrays)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(dataset, batch_size, shuffle=is_train)</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">10</span></span><br><span class=\"line\">data_iter = load_array((features, labels), batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨iteræ„é€ Pythonè¿­ä»£å™¨ï¼Œå¹¶ä½¿ç”¨nextä»è¿­ä»£å™¨ä¸­è·å–ç¬¬ä¸€é¡¹</span></span><br><span class=\"line\">feature, label = <span class=\"built_in\">next</span>(<span class=\"built_in\">iter</span>(data_iter))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(feature)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(label)</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥æˆ‘ä»¬å®šä¹‰æ¨¡å‹ï¼Œåœ¨ PyTorch ä¸­ï¼Œå…¨è¿æ¥å±‚åœ¨ <code>Linear</code> ç±»ä¸­å®šä¹‰ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬å°†ä¸¤ä¸ªå‚æ•°ä¼ é€’åˆ° <code>nn.Linear</code> ä¸­ã€‚ç¬¬ä¸€ä¸ªæŒ‡å®šè¾“å…¥ç‰¹å¾å½¢çŠ¶ï¼Œå³2ï¼Œç¬¬äºŒä¸ªæŒ‡å®šè¾“å‡ºç‰¹å¾å½¢çŠ¶ï¼Œè¾“å‡ºç‰¹å¾å½¢çŠ¶ä¸ºå•ä¸ªæ ‡é‡ï¼Œå› æ­¤ä¸º1ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\">net = nn.Sequential(nn.Linear(<span class=\"number\">2</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># åˆå§‹åŒ–æ¨¡å‹å‚æ•°</span></span><br><span class=\"line\">net[<span class=\"number\">0</span>].weight.data.normal_(<span class=\"number\">0</span>, <span class=\"number\">0.01</span>)</span><br><span class=\"line\">net[<span class=\"number\">0</span>].bias.data.fill_(<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰æŸå¤±å‡½æ•°ï¼Œè®¡ç®—å‡æ–¹è¯¯å·®ä½¿ç”¨çš„æ˜¯ <code>MSELoss</code> ç±»ï¼Œä¹Ÿç§°å¹³æ–¹ L2 èŒƒæ•°ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒè¿”å›æ‰€æœ‰æ ·æœ¬æŸå¤±çš„å¹³å‡å€¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss_function = nn.MSELoss()</span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰ä¼˜åŒ–ç®—æ³•ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">optimizer = torch.optim.SGD(net.parameters(), lr=<span class=\"number\">0.03</span>)</span><br></pre></td></tr></table></figure>\n<p>è®­ç»ƒè¿‡ç¨‹ä»£ç ä¸æˆ‘ä»¬ä»é›¶å¼€å§‹å®ç°æ—¶æ‰€åšçš„éå¸¸ç›¸ä¼¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_epochs = <span class=\"number\">3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> data_iter:</span><br><span class=\"line\">        loss = loss_function(net(X), y)</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        train_loss = loss_function(net(features), labels)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;epoch <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>&#125;</span>, loss <span class=\"subst\">&#123;train_loss:f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-Softmaxå›å½’çš„ä»é›¶å®ç°\">3. Softmaxå›å½’çš„ä»é›¶å®ç°</h2>\n<p>é¦–å…ˆè¯»å…¥ Fashion-MNIST æ•°æ®é›†ï¼ŒåŸå§‹æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ ·æœ¬éƒ½æ˜¯28*28çš„å›¾åƒã€‚æœ¬èŠ‚å°†å±•å¹³æ¯ä¸ªå›¾åƒï¼ŒæŠŠå®ƒä»¬çœ‹ä½œé•¿åº¦ä¸º784çš„å‘é‡ã€‚åœ¨åé¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºèƒ½å¤Ÿåˆ©ç”¨<strong>å›¾åƒç©ºé—´ç»“æ„</strong>çš„ç‰¹å¾ï¼Œä½†ç°åœ¨æˆ‘ä»¬æš‚æ—¶åªæŠŠæ¯ä¸ªåƒç´ ä½ç½®çœ‹ä½œä¸€ä¸ªç‰¹å¾ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> d2l <span class=\"keyword\">import</span> torch <span class=\"keyword\">as</span> d2l</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_data_fashion_mnist</span>(<span class=\"params\">batch_size, resize=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;ä¸‹è½½Fashion-MNISTæ•°æ®é›†ï¼Œç„¶åå°†å…¶åŠ è½½åˆ°å†…å­˜ä¸­&quot;&quot;&quot;</span></span><br><span class=\"line\">    trans = [transforms.ToTensor()]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> resize:</span><br><span class=\"line\">        trans.insert(<span class=\"number\">0</span>, transforms.Resize(resize))</span><br><span class=\"line\">    trans = transforms.Compose(trans)</span><br><span class=\"line\">    mnist_train = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">True</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    mnist_test = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">False</span>, transform=trans, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (data.DataLoader(mnist_train, batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>),</span><br><span class=\"line\">            data.DataLoader(mnist_test, batch_size, shuffle=<span class=\"literal\">False</span>, num_workers=<span class=\"number\">0</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">256</span></span><br><span class=\"line\"></span><br><span class=\"line\">train_iter, test_iter = load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure>\n<p>åˆå§‹åŒ–æ¨¡å‹å‚æ•°ï¼Œåœ¨ Softmax å›å½’ä¸­ï¼Œæˆ‘ä»¬çš„è¾“å‡ºä¸ç±»åˆ«ä¸€æ ·å¤šã€‚å› ä¸ºæˆ‘ä»¬çš„æ•°æ®é›†æœ‰10ä¸ªç±»åˆ«ï¼Œæ‰€ä»¥ç½‘ç»œè¾“å‡ºç»´åº¦ä¸º10ã€‚å› æ­¤ï¼Œæƒé‡å°†æ„æˆä¸€ä¸ª784*10çš„çŸ©é˜µï¼Œåç½®å°†æ„æˆä¸€ä¸ª1*10çš„è¡Œå‘é‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_inputs = <span class=\"number\">784</span></span><br><span class=\"line\">num_outputs = <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\">W = torch.normal(<span class=\"number\">0</span>, <span class=\"number\">0.01</span>, size=(num_inputs, num_outputs), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">b = torch.zeros(num_outputs, requires_grad=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰ Softmax æ“ä½œï¼Œæ³¨æ„ï¼Œè™½ç„¶è¿™åœ¨æ•°å­¦ä¸Šçœ‹èµ·æ¥æ˜¯æ­£ç¡®çš„ï¼Œä½†æˆ‘ä»¬åœ¨ä»£ç å®ç°ä¸­æœ‰ç‚¹è‰ç‡ã€‚çŸ©é˜µä¸­çš„éå¸¸å¤§æˆ–éå¸¸å°çš„å…ƒç´ å¯èƒ½é€ æˆæ•°å€¼ä¸Šæº¢æˆ–ä¸‹æº¢ï¼Œä½†æˆ‘ä»¬æ²¡æœ‰é‡‡å–æªæ–½æ¥é˜²æ­¢è¿™ç‚¹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">softmax</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">    X_exp = torch.exp(X)</span><br><span class=\"line\">    partition = X_exp.<span class=\"built_in\">sum</span>(<span class=\"number\">1</span>, keepdim=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> X_exp / partition  <span class=\"comment\"># è¿™é‡Œåº”ç”¨äº†å¹¿æ’­æœºåˆ¶</span></span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰ Softmax æ“ä½œåï¼Œæˆ‘ä»¬å¯ä»¥å®ç° Softmax å›å½’æ¨¡å‹ã€‚ä¸‹é¢çš„ä»£ç å®šä¹‰äº†è¾“å…¥å¦‚ä½•é€šè¿‡ç½‘ç»œæ˜ å°„åˆ°è¾“å‡ºã€‚æ³¨æ„ï¼Œå°†æ•°æ®ä¼ é€’åˆ°æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬ä½¿ç”¨ <code>reshape</code> å‡½æ•°å°†æ¯å¼ åŸå§‹å›¾åƒå±•å¹³ä¸ºå‘é‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">net</span>(<span class=\"params\">X</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> softmax(torch.matmul(X.reshape((-<span class=\"number\">1</span>, W.shape[<span class=\"number\">0</span>])), W) + b)</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥æˆ‘ä»¬å®šä¹‰æŸå¤±å‡½æ•°ï¼Œäº¤å‰ç†µé‡‡ç”¨çœŸå®æ ‡ç­¾çš„é¢„æµ‹æ¦‚ç‡çš„<strong>è´Ÿå¯¹æ•°ä¼¼ç„¶</strong>ã€‚è¿™é‡Œæˆ‘ä»¬ä¸ä½¿ç”¨ Python çš„ <code>for</code> å¾ªç¯è¿­ä»£é¢„æµ‹ï¼ˆè¿™å¾€å¾€æ˜¯ä½æ•ˆçš„ï¼‰ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ªè¿ç®—ç¬¦é€‰æ‹©æ‰€æœ‰å…ƒç´ ã€‚ä¸‹é¢æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ•°æ®æ ·æœ¬ <code>y_hat</code>ï¼Œå…¶ä¸­åŒ…å«2ä¸ªæ ·æœ¬åœ¨3ä¸ªç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ï¼Œä»¥åŠå®ƒä»¬å¯¹åº”çš„æ ‡ç­¾ <code>y</code>ã€‚æœ‰äº† <code>y</code>ï¼Œæˆ‘ä»¬çŸ¥é“åœ¨ç¬¬ä¸€ä¸ªæ ·æœ¬ä¸­ï¼Œç¬¬ä¸€ç±»æ˜¯æ­£ç¡®çš„é¢„æµ‹ï¼›è€Œåœ¨ç¬¬äºŒä¸ªæ ·æœ¬ä¸­ï¼Œç¬¬ä¸‰ç±»æ˜¯æ­£ç¡®çš„é¢„æµ‹ã€‚ç„¶åä½¿ç”¨ <code>y</code> ä½œä¸º <code>y_hat</code> ä¸­æ¦‚ç‡çš„ç´¢å¼•ï¼Œæˆ‘ä»¬é€‰æ‹©ç¬¬ä¸€ä¸ªæ ·æœ¬ä¸­ç¬¬ä¸€ä¸ªç±»çš„æ¦‚ç‡å’Œç¬¬äºŒä¸ªæ ·æœ¬ä¸­ç¬¬ä¸‰ä¸ªç±»çš„æ¦‚ç‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">y = torch.tensor([<span class=\"number\">0</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\">y_hat = torch.tensor([[<span class=\"number\">0.1</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.6</span>], [<span class=\"number\">0.3</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.5</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_hat[[<span class=\"number\">0</span>, <span class=\"number\">1</span>], y])  <span class=\"comment\"># tensor([0.1000, 0.5000])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cross_entropy</span>(<span class=\"params\">y_hat, y</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> -torch.log(y_hat[<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(y_hat)), y])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(cross_entropy(y_hat, y))  <span class=\"comment\"># tensor([2.3026, 0.6931])</span></span><br></pre></td></tr></table></figure>\n<p>ä¸ºäº†è®¡ç®—ç²¾åº¦ï¼Œæˆ‘ä»¬æ‰§è¡Œä»¥ä¸‹æ“ä½œã€‚é¦–å…ˆï¼Œå¦‚æœ <code>y_hat</code> æ˜¯çŸ©é˜µï¼Œé‚£ä¹ˆå‡å®šç¬¬äºŒä¸ªç»´åº¦å­˜å‚¨æ¯ä¸ªç±»çš„é¢„æµ‹åˆ†æ•°ã€‚æˆ‘ä»¬ä½¿ç”¨ <code>argmax</code> è·å¾—æ¯è¡Œä¸­<strong>æœ€å¤§</strong>å…ƒç´ çš„ç´¢å¼•æ¥è·å¾—é¢„æµ‹ç±»åˆ«ã€‚ç„¶åæˆ‘ä»¬å°†é¢„æµ‹ç±»åˆ«ä¸çœŸå® <code>y</code> å…ƒç´ è¿›è¡Œæ¯”è¾ƒã€‚ç”±äºç­‰å¼è¿ç®—ç¬¦ <code>==</code> å¯¹æ•°æ®ç±»å‹å¾ˆæ•æ„Ÿï¼Œå› æ­¤æˆ‘ä»¬å°† <code>y_hat</code> çš„æ•°æ®ç±»å‹è½¬æ¢ä¸ºä¸ <code>y</code> çš„æ•°æ®ç±»å‹ä¸€è‡´ã€‚ç»“æœæ˜¯ä¸€ä¸ªåŒ…å«0ï¼ˆé”™ï¼‰å’Œ1ï¼ˆå¯¹ï¼‰çš„å¼ é‡ã€‚æœ€åï¼Œæˆ‘ä»¬æ±‚å’Œä¼šå¾—åˆ°æ­£ç¡®é¢„æµ‹çš„æ•°é‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">accuracy</span>(<span class=\"params\">y_hat, y</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è®¡ç®—é¢„æµ‹æ­£ç¡®çš„æ•°é‡&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(y_hat.shape) &gt; <span class=\"number\">1</span> <span class=\"keyword\">and</span> y_hat.shape[<span class=\"number\">1</span>] &gt; <span class=\"number\">1</span>:</span><br><span class=\"line\">        y_hat = y_hat.argmax(axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    cmp = y_hat.<span class=\"built_in\">type</span>(y.dtype) == y  <span class=\"comment\"># tensor([False,  True])</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">float</span>(cmp.<span class=\"built_in\">type</span>(y.dtype).<span class=\"built_in\">sum</span>())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(accuracy(y_hat, y) / <span class=\"built_in\">len</span>(y))  <span class=\"comment\"># 0.5</span></span><br></pre></td></tr></table></figure>\n<p>åŒæ ·ï¼Œå¯¹äºä»»æ„æ•°æ®è¿­ä»£å™¨ <code>data_iter</code> å¯è®¿é—®çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥è¯„ä¼°åœ¨ä»»æ„æ¨¡å‹ <code>net</code> çš„ç²¾åº¦ï¼Œè¿™é‡Œå®šä¹‰ä¸€ä¸ªå®ç”¨ç¨‹åºç±» <code>Accumulator</code>ï¼Œç”¨äºå¯¹å¤šä¸ªå˜é‡è¿›è¡Œç´¯åŠ ã€‚åœ¨ <code>evaluate_accuracy</code> å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬åœ¨ <code>Accumulator</code> å®ä¾‹ä¸­åˆ›å»ºäº†2ä¸ªå˜é‡ï¼Œåˆ†åˆ«ç”¨äºå­˜å‚¨æ­£ç¡®é¢„æµ‹çš„æ•°é‡å’Œé¢„æµ‹çš„æ€»æ•°é‡ã€‚å½“æˆ‘ä»¬éå†æ•°æ®é›†æ—¶ï¼Œä¸¤è€…éƒ½å°†éšç€æ—¶é—´çš„æ¨ç§»è€Œç´¯åŠ ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">evaluate_accuracy</span>(<span class=\"params\">net, data_iter</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è®¡ç®—åœ¨æŒ‡å®šæ•°æ®é›†ä¸Šæ¨¡å‹çš„ç²¾åº¦&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, torch.nn.Module):  <span class=\"comment\"># å¦‚æœæ˜¯ç”¨torch.nnå®ç°çš„æ¨¡å‹</span></span><br><span class=\"line\">        net.<span class=\"built_in\">eval</span>()  <span class=\"comment\"># å°†æ¨¡å‹å…ˆè®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼</span></span><br><span class=\"line\">    metric = Accumulator(<span class=\"number\">2</span>)  <span class=\"comment\"># æ­£ç¡®é¢„æµ‹æ•°ã€é¢„æµ‹æ€»æ•°</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> data_iter:</span><br><span class=\"line\">            metric.add(accuracy(net(X), y), y.numel())</span><br><span class=\"line\">    <span class=\"keyword\">return</span> metric[<span class=\"number\">0</span>] / metric[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Accumulator</span>:</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;åœ¨nä¸ªå˜é‡ä¸Šç´¯åŠ &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, n</span>):</span><br><span class=\"line\">        self.data = [<span class=\"number\">0.0</span>] * n</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">add</span>(<span class=\"params\">self, *args</span>):</span><br><span class=\"line\">        self.data = [a + <span class=\"built_in\">float</span>(b) <span class=\"keyword\">for</span> a, b <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(self.data, args)]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">reset</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        self.data = [<span class=\"number\">0.0</span>] * <span class=\"built_in\">len</span>(self.data)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, idx</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.data[idx]</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥å¯ä»¥å¼€å§‹è¿›è¡Œè®­ç»ƒï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_epoch_ch3</span>(<span class=\"params\">net, train_iter, loss_function, updater</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è®­ç»ƒæ¨¡å‹ä¸€ä¸ªè¿­ä»£å‘¨æœŸï¼ˆå®šä¹‰è§ç¬¬3ç« ï¼‰&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># å¦‚æœnetæ˜¯ç”¨torch.nnå®ç°çš„è¯å…ˆå°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(net, torch.nn.Module):</span><br><span class=\"line\">        net.train()</span><br><span class=\"line\">    <span class=\"comment\"># è®­ç»ƒæŸå¤±æ€»å’Œã€è®­ç»ƒå‡†ç¡®åº¦æ€»å’Œã€æ ·æœ¬æ•°</span></span><br><span class=\"line\">    metric = Accumulator(<span class=\"number\">3</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">        <span class=\"comment\"># è®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°å‚æ•°</span></span><br><span class=\"line\">        y_hat = net(X)</span><br><span class=\"line\">        loss = loss_function(y_hat, y)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(updater, torch.optim.Optimizer):</span><br><span class=\"line\">            <span class=\"comment\"># ä½¿ç”¨PyTorchå†…ç½®çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°</span></span><br><span class=\"line\">            updater.zero_grad()</span><br><span class=\"line\">            loss.mean().backward()</span><br><span class=\"line\">            updater.step()</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># ä½¿ç”¨å®šåˆ¶çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°</span></span><br><span class=\"line\">            loss.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\">            updater(X.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">        metric.add(<span class=\"built_in\">float</span>(loss.<span class=\"built_in\">sum</span>()), accuracy(y_hat, y), y.numel())</span><br><span class=\"line\">    <span class=\"comment\"># è¿”å›è®­ç»ƒæŸå¤±å’Œè®­ç»ƒç²¾åº¦</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> metric[<span class=\"number\">0</span>] / metric[<span class=\"number\">2</span>], metric[<span class=\"number\">1</span>] / metric[<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_ch3</span>(<span class=\"params\">net, train_iter, test_iter, loss_function, num_epochs, updater</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;è®­ç»ƒæ¨¡å‹&quot;&quot;&quot;</span></span><br><span class=\"line\">    writer = SummaryWriter(<span class=\"string\">&#x27;../logs/FashionMNIST_train_log&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        train_metrics = train_epoch_ch3(net, train_iter, loss_function, updater)</span><br><span class=\"line\">        test_acc = evaluate_accuracy(net, test_iter)</span><br><span class=\"line\">        writer.add_scalar(<span class=\"string\">&#x27;train_loss&#x27;</span>, train_metrics[<span class=\"number\">0</span>], epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\">        writer.add_scalar(<span class=\"string\">&#x27;train_acc&#x27;</span>, train_metrics[<span class=\"number\">1</span>], epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\">        writer.add_scalar(<span class=\"string\">&#x27;test_acc&#x27;</span>, test_acc, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\">    train_loss, train_acc = train_metrics</span><br><span class=\"line\">    writer.close()</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> train_loss &lt; <span class=\"number\">0.5</span>, train_loss</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> train_acc &lt;= <span class=\"number\">1</span> <span class=\"keyword\">and</span> train_acc &gt; <span class=\"number\">0.7</span>, train_acc</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> test_acc &lt;= <span class=\"number\">1</span> <span class=\"keyword\">and</span> test_acc &gt; <span class=\"number\">0.7</span>, test_acc</span><br><span class=\"line\"></span><br><span class=\"line\">lr = <span class=\"number\">0.1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">updater</span>(<span class=\"params\">batch_size</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> d2l.sgd([W, b], lr, batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\">num_epochs = <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\">train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)</span><br></pre></td></tr></table></figure>\n<p>å¯ä»¥åœ¨é¡¹ç›®è·¯å¾„ä¸‹æ‰“å¼€ Anaconda çš„ PyTorch ç¯å¢ƒï¼Œç„¶åä½¿ç”¨ TensorBoard æŸ¥çœ‹è®­ç»ƒæ›²çº¿ï¼š</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensorboard --logdir logs\\FashionMNIST_train_log</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-Softmaxå›å½’çš„ç®€æ´å®ç°\">4. Softmaxå›å½’çš„ç®€æ´å®ç°</h2>\n<p>é¦–å…ˆè¯»å–æ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils <span class=\"keyword\">import</span> data</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"></span><br><span class=\"line\">mnist_train = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">True</span>, transform=transforms.ToTensor(), download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">mnist_test = torchvision.datasets.FashionMNIST(root=<span class=\"string\">&quot;../data&quot;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor(), download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">train_iter = data.DataLoader(mnist_train, batch_size=<span class=\"number\">256</span>, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>)</span><br><span class=\"line\">test_iter = data.DataLoader(mnist_test, batch_size=<span class=\"number\">256</span>, shuffle=<span class=\"literal\">False</span>, num_workers=<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰æ¨¡å‹ï¼Œæˆ‘ä»¬åªéœ€åœ¨ <code>Sequential</code> ä¸­æ·»åŠ ä¸€ä¸ªå¸¦æœ‰10ä¸ªè¾“å‡ºçš„å…¨è¿æ¥å±‚ï¼Œè¿™10ä¸ªè¾“å‡ºåˆ†åˆ«è¡¨ç¤ºå¯¹10ä¸ªç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># PyTorchä¸ä¼šéšå¼åœ°è°ƒæ•´è¾“å…¥çš„å½¢çŠ¶ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨çº¿æ€§å±‚å‰å®šä¹‰äº†å±•å¹³å±‚ï¼ˆFlattenï¼‰ï¼Œæ¥è°ƒæ•´ç½‘ç»œè¾“å…¥çš„å½¢çŠ¶</span></span><br><span class=\"line\">net = nn.Sequential(nn.Flatten(), nn.Linear(<span class=\"number\">784</span>, <span class=\"number\">10</span>))</span><br></pre></td></tr></table></figure>\n<p>å®šä¹‰è®­ç»ƒå‡½æ•°ï¼Œç”±äºä¹‹åå¾ˆå¤šæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¹Ÿæ˜¯ç›¸ä¼¼çš„ï¼Œå› æ­¤è¯¥å‡½æ•°å¯ä»¥å¤ç”¨ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ä»¥åè¾ƒä¸ºé€šç”¨çš„å‡½æ•°å°†å®šä¹‰åˆ°util.functions.pyä¸­</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_classifier</span>(<span class=\"params\">net, train_iter, test_iter, num_epochs, lr, device, writer_path=<span class=\"literal\">None</span>, save_path=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear <span class=\"keyword\">or</span> <span class=\"built_in\">type</span>(m) == nn.Conv2d:</span><br><span class=\"line\">            <span class=\"comment\"># nn.init.normal_(m.weight, mean=0, std=0.01)  # ä»¥å‡å€¼0å’Œæ ‡å‡†å·®0.01éšæœºåˆå§‹åŒ–æƒé‡</span></span><br><span class=\"line\">            nn.init.xavier_uniform_(m.weight)  <span class=\"comment\"># Xavieråˆå§‹åŒ–</span></span><br><span class=\"line\"></span><br><span class=\"line\">    net.apply(init_weights)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;---------- Training on <span class=\"subst\">&#123;device&#125;</span> ----------&#x27;</span>)</span><br><span class=\"line\">    net.to(device)</span><br><span class=\"line\">    loss_function = nn.CrossEntropyLoss()  <span class=\"comment\"># reductioné»˜è®¤ä¸º&#x27;mean&#x27;</span></span><br><span class=\"line\">    loss_function.to(device)</span><br><span class=\"line\">    optimizer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> writer_path <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        writer = SummaryWriter(writer_path)</span><br><span class=\"line\"></span><br><span class=\"line\">    best_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        net.train()</span><br><span class=\"line\">        train_loss, train_acc = [], []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> x, y <span class=\"keyword\">in</span> tqdm(train_iter):</span><br><span class=\"line\">            x, y = x.to(device), y.to(device)</span><br><span class=\"line\">            y_hat = net(x)</span><br><span class=\"line\"></span><br><span class=\"line\">            loss = loss_function(y_hat, y)</span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            loss.backward()</span><br><span class=\"line\">            optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">            y_hat = y_hat.argmax(axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">            acc = (y_hat.<span class=\"built_in\">type</span>(y.dtype) == y).<span class=\"built_in\">float</span>().mean()</span><br><span class=\"line\">            train_loss.append(loss.item())</span><br><span class=\"line\">            train_acc.append(acc)</span><br><span class=\"line\"></span><br><span class=\"line\">        train_loss = <span class=\"built_in\">sum</span>(train_loss) / <span class=\"built_in\">len</span>(train_loss)</span><br><span class=\"line\">        train_acc = <span class=\"built_in\">sum</span>(train_acc) / <span class=\"built_in\">len</span>(train_acc)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;[ Train | epoch: <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>:03d&#125;</span>/<span class=\"subst\">&#123;num_epochs:03d&#125;</span> ] loss = <span class=\"subst\">&#123;train_loss:<span class=\"number\">.5</span>f&#125;</span>, acc = <span class=\"subst\">&#123;train_acc:<span class=\"number\">.5</span>f&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        net.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">        valid_loss, valid_acc = [], []</span><br><span class=\"line\">        <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">            <span class=\"keyword\">for</span> x, y <span class=\"keyword\">in</span> tqdm(test_iter):</span><br><span class=\"line\">                x, y = x.to(device), y.to(device)</span><br><span class=\"line\">                y_hat = net(x)</span><br><span class=\"line\">                loss = loss_function(y_hat, y)</span><br><span class=\"line\">                y_hat = y_hat.argmax(axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">                acc = (y_hat.<span class=\"built_in\">type</span>(y.dtype) == y).<span class=\"built_in\">float</span>().mean()</span><br><span class=\"line\">                valid_loss.append(loss.item())</span><br><span class=\"line\">                valid_acc.append(acc)</span><br><span class=\"line\"></span><br><span class=\"line\">        valid_loss = <span class=\"built_in\">sum</span>(valid_loss) / <span class=\"built_in\">len</span>(valid_loss)</span><br><span class=\"line\">        valid_acc = <span class=\"built_in\">sum</span>(valid_acc) / <span class=\"built_in\">len</span>(valid_acc)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;[ Valid | epoch: <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>:03d&#125;</span>/<span class=\"subst\">&#123;num_epochs:03d&#125;</span> ] loss = <span class=\"subst\">&#123;valid_loss:<span class=\"number\">.5</span>f&#125;</span>, acc = <span class=\"subst\">&#123;valid_acc:<span class=\"number\">.5</span>f&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> writer_path <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            writer.add_scalars(<span class=\"string\">&#x27;loss&#x27;</span>, &#123;<span class=\"string\">&#x27;train&#x27;</span>: train_loss,</span><br><span class=\"line\">                                        <span class=\"string\">&#x27;valid&#x27;</span>: valid_loss&#125;, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\">            writer.add_scalars(<span class=\"string\">&#x27;acc&#x27;</span>, &#123;<span class=\"string\">&#x27;train&#x27;</span>: train_acc,</span><br><span class=\"line\">                                       <span class=\"string\">&#x27;valid&#x27;</span>: valid_acc&#125;, epoch + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> save_path <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span> <span class=\"keyword\">and</span> valid_acc &gt; best_acc:</span><br><span class=\"line\">            best_acc = valid_acc</span><br><span class=\"line\">            torch.save(net.state_dict(), save_path)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Saving model with acc &#123;:.3f&#125;&#x27;</span>.<span class=\"built_in\">format</span>(best_acc))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> writer_path <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        writer.close()</span><br></pre></td></tr></table></figure>\n<p>æœ€åè®¾å®šè¶…å‚æ•°è®­ç»ƒæ¨¡å‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">writer_path = <span class=\"string\">&#x27;../logs/FashionMNIST_train_log&#x27;</span></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)</span><br><span class=\"line\">lr, num_epochs = <span class=\"number\">0.01</span>, <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\">train_classifier(net, train_iter, test_iter, num_epochs, lr, device, writer_path)</span><br><span class=\"line\"><span class=\"comment\"># [ Train | epoch: 010/010 ] loss = 0.60980, acc = 0.80254</span></span><br><span class=\"line\"><span class=\"comment\"># [ Valid | epoch: 010/010 ] loss = 0.62191, acc = 0.79395</span></span><br></pre></td></tr></table></figure>\n<p>ä¸‹ä¸€ç« ï¼š<a href=\"/posts/46068.html\">å¤šå±‚æ„ŸçŸ¥æœº</a>ã€‚</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/15604.html",
            "url": "https://asanosaki.github.io/posts/15604.html",
            "title": "åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ç¬”è®°(ææ²)-é¢„å¤‡çŸ¥è¯†",
            "date_published": "2023-01-18T08:37:00.000Z",
            "content_html": "<blockquote>\n<p>ææ²åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ï¼ˆPyTorchï¼‰è¯¾ç¨‹å­¦ä¹ ç¬”è®°ç¬¬ä¸€ç« ï¼šé¢„å¤‡çŸ¥è¯†ã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-ç¯å¢ƒå®‰è£…\">1. ç¯å¢ƒå®‰è£…</h2>\n<p>é¦–å…ˆå®‰è£…å¥½ PyTorch ç¯å¢ƒï¼š<a href=\"/posts/15428.html\">Anacondaä¸PyTorchå®‰è£…æ•™ç¨‹</a>ã€‚</p>\n<p>å®‰è£…éœ€è¦çš„åŒ…ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install d2l</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-æ•°æ®æ“ä½œä¸æ•°æ®é¢„å¤„ç†\">2. æ•°æ®æ“ä½œä¸æ•°æ®é¢„å¤„ç†</h2>\n<p>å¼ é‡è¡¨ç¤ºä¸€ä¸ªæ•°å€¼ç»„æˆçš„æ•°ç»„ï¼Œè¿™ä¸ªæ•°ç»„å¯èƒ½æœ‰å¤šä¸ªç»´åº¦ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.arange(<span class=\"number\">12</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)  <span class=\"comment\"># tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬å¯ä»¥é€šè¿‡å¼ é‡çš„ <code>shape</code> å±æ€§æ¥è®¿é—®å¼ é‡çš„å½¢çŠ¶å’Œå¼ é‡ä¸­å…ƒç´ çš„æ€»æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(x.shape)  <span class=\"comment\"># torch.Size([12])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.numel())  <span class=\"comment\"># 12</span></span><br></pre></td></tr></table></figure>\n<p>è¦æ”¹å˜ä¸€ä¸ªå¼ é‡çš„å½¢çŠ¶è€Œä¸æ”¹å˜å…ƒç´ æ•°é‡å’Œå…ƒç´ å€¼ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒç”¨ <code>reshape</code> å‡½æ•°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = x.reshape(<span class=\"number\">3</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[ 0,  1,  2,  3],</span></span><br><span class=\"line\"><span class=\"comment\">#         [ 4,  5,  6,  7],</span></span><br><span class=\"line\"><span class=\"comment\">#         [ 8,  9, 10, 11]])</span></span><br></pre></td></tr></table></figure>\n<p>ä½¿ç”¨å…¨0ã€å…¨1ã€å…¶ä»–å¸¸é‡æˆ–è€…ä»ç‰¹å®šåˆ†å¸ƒä¸­éšæœºé‡‡æ ·çš„æ•°å­—ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(torch.zeros((<span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>)))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[0., 0., 0., 0.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [0., 0., 0., 0.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [0., 0., 0., 0.]],</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#         [[0., 0., 0., 0.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [0., 0., 0., 0.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [0., 0., 0., 0.]]])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.ones((<span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>)))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[1., 1., 1., 1.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [1., 1., 1., 1.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [1., 1., 1., 1.]],</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#         [[1., 1., 1., 1.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [1., 1., 1., 1.],</span></span><br><span class=\"line\"><span class=\"comment\">#          [1., 1., 1., 1.]]])</span></span><br></pre></td></tr></table></figure>\n<p>é€šè¿‡æä¾›åŒ…å«æ•°å€¼çš„ Python åˆ—è¡¨ï¼ˆæˆ–åµŒå¥—åˆ—è¡¨ï¼‰æ¥ä¸ºæ‰€éœ€å¼ é‡ä¸­çš„æ¯ä¸ªå…ƒç´ èµ‹äºˆç¡®å®šå€¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.tensor([<span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)  <span class=\"comment\"># tensor([2, 3, 4, 5])</span></span><br></pre></td></tr></table></figure>\n<p>å¸¸è§çš„æ ‡å‡†ç®—æœ¯è¿ç®—ç¬¦ï¼ˆ<code>+</code>ã€<code>-</code>ã€<code>*</code>ã€<code>/</code> å’Œ <code>**</code>ï¼‰éƒ½å¯ä»¥è¢«å‡çº§ä¸ºæŒ‰å…ƒç´ è¿ç®—ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.tensor([<span class=\"number\">1.0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">y = torch.tensor([<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x + y:&#x27;</span>, x + y, <span class=\"string\">&#x27;x - y:&#x27;</span>, x - y)  <span class=\"comment\"># x + y: tensor([3., 4., 5.]) x - y: tensor([-1., 0., 1.])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.exp(x))  <span class=\"comment\"># tensor([ 2.7183,  7.3891, 20.0855])</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬ä¹Ÿå¯ä»¥æŠŠå¤šä¸ªå¼ é‡æ‹¼æ¥åœ¨ä¸€èµ·ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.arange(<span class=\"number\">6</span>, dtype=torch.float32).reshape(<span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">y = torch.tensor([[<span class=\"number\">2.0</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>], [<span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>]])</span><br><span class=\"line\"><span class=\"comment\"># dimè¡¨ç¤ºåœ¨å“ªä¸ªç»´åº¦ä¸Šæ‹¼æ¥</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.cat((x, y), dim=<span class=\"number\">0</span>).shape)  <span class=\"comment\"># torch.Size([4, 3])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.cat((x, y), dim=<span class=\"number\">1</span>).shape)  <span class=\"comment\"># torch.Size([2, 6])</span></span><br></pre></td></tr></table></figure>\n<p>é€šè¿‡é€»è¾‘è¿ç®—ç¬¦æ„å»ºäºŒå…ƒå¼ é‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.tensor([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">y = torch.tensor([<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x == y)  <span class=\"comment\"># tensor([True, False, True])</span></span><br></pre></td></tr></table></figure>\n<p>å¯¹å¼ é‡ä¸­çš„æ‰€æœ‰å…ƒç´ è¿›è¡Œæ±‚å’Œä¼šäº§ç”Ÿä¸€ä¸ªåªæœ‰ä¸€ä¸ªå…ƒç´ çš„å¼ é‡ï¼Œæˆ–è€…æŒ‡å®šåœ¨æŸä¸€ç»´åº¦ä¸Šæ±‚å’Œï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.tensor([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.<span class=\"built_in\">sum</span>())  <span class=\"comment\"># tensor(9)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.<span class=\"built_in\">sum</span>(<span class=\"number\">0</span>))  <span class=\"comment\"># tensor([2, 3, 4])</span></span><br></pre></td></tr></table></figure>\n<p>å³ä½¿å½¢çŠ¶ä¸åŒï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥é€šè¿‡è°ƒç”¨å¹¿æ’­æœºåˆ¶ï¼ˆbroadcasting mechanismï¼‰æ¥æ‰§è¡ŒæŒ‰å…ƒç´ æ“ä½œï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.arange(<span class=\"number\">3</span>).reshape((<span class=\"number\">3</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">y = torch.arange(<span class=\"number\">2</span>).reshape((<span class=\"number\">1</span>, <span class=\"number\">2</span>))</span><br><span class=\"line\"><span class=\"comment\"># å¿…é¡»ç»´åº¦ä¸€æ ·æ‰èƒ½å¹¿æ’­ï¼Œå…ˆå°†xå¤åˆ¶æˆ3è¡Œ2åˆ—ï¼Œå†å°†yå¤åˆ¶æˆ3è¡Œ2åˆ—ï¼Œç„¶åè¿ç®—</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x + y)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[0, 1],</span></span><br><span class=\"line\"><span class=\"comment\">#         [1, 2],</span></span><br><span class=\"line\"><span class=\"comment\">#         [2, 3]])</span></span><br></pre></td></tr></table></figure>\n<p>ä¸ NumPy å¼ é‡ç›¸äº’è½¬åŒ–ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = x.numpy()</span><br><span class=\"line\">b = torch.tensor(a)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">type</span>(a), <span class=\"built_in\">type</span>(b))  <span class=\"comment\"># &lt;class &#x27;numpy.ndarray&#x27;&gt; &lt;class &#x27;torch.Tensor&#x27;&gt;</span></span><br></pre></td></tr></table></figure>\n<p>å°†å¤§å°ä¸º1çš„å¼ é‡è½¬æ¢ä¸º Python æ ‡é‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.tensor([<span class=\"number\">3.5</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x, x.item(), <span class=\"built_in\">float</span>(x))  <span class=\"comment\"># tensor([3.5000]) 3.5 3.5</span></span><br></pre></td></tr></table></figure>\n<p>åˆ›å»ºä¸€ä¸ªäººå·¥æ•°æ®é›†ï¼Œå¹¶å­˜å‚¨åœ¨ CSVï¼ˆé€—å·åˆ†éš”å€¼ï¼‰æ–‡ä»¶ä¸­ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\">os.makedirs(os.path.join(<span class=\"string\">&#x27;..&#x27;</span>, <span class=\"string\">&#x27;data&#x27;</span>), exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">data_file = os.path.join(<span class=\"string\">&#x27;..&#x27;</span>, <span class=\"string\">&#x27;data&#x27;</span>, <span class=\"string\">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(data_file, <span class=\"string\">&#x27;w&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NumRooms,Alley,Price\\n&#x27;</span>)  <span class=\"comment\"># åˆ—å</span></span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NA,Pave,127500\\n&#x27;</span>)  <span class=\"comment\"># æ¯è¡Œè¡¨ç¤ºä¸€ä¸ªæ•°æ®æ ·æœ¬</span></span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;2,NA,106000\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;4,NA,178100\\n&#x27;</span>)</span><br><span class=\"line\">    f.write(<span class=\"string\">&#x27;NA,NA,140000\\n&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>ä»åˆ›å»ºçš„ CSV æ–‡ä»¶ä¸­åŠ è½½åŸå§‹æ•°æ®é›†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"></span><br><span class=\"line\">data = pd.read_csv(data_file)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"><span class=\"comment\">#    NumRooms Alley   Price</span></span><br><span class=\"line\"><span class=\"comment\"># 0       NaN  Pave  127500</span></span><br><span class=\"line\"><span class=\"comment\"># 1       2.0   NaN  106000</span></span><br><span class=\"line\"><span class=\"comment\"># 2       4.0   NaN  178100</span></span><br><span class=\"line\"><span class=\"comment\"># 3       NaN   NaN  140000</span></span><br></pre></td></tr></table></figure>\n<p>ä¸ºäº†å¤„ç†ç¼ºå¤±çš„æ•°æ®ï¼Œå…¸å‹çš„æ–¹æ³•åŒ…æ‹¬<strong>æ’å€¼</strong>å’Œ<strong>åˆ é™¤</strong>ï¼Œè¿™é‡Œï¼Œæˆ‘ä»¬å°†è€ƒè™‘æ’å€¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inputs, outputs = data.iloc[:, <span class=\"number\">0</span>:<span class=\"number\">2</span>], data.iloc[:, <span class=\"number\">2</span>]  <span class=\"comment\"># å°†dataçš„ç¬¬0ã€1åˆ—ä½œä¸ºinputï¼Œç¬¬2åˆ—ä½œä¸ºoutput</span></span><br><span class=\"line\">inputs = inputs.fillna(inputs.mean(numeric_only=<span class=\"literal\">True</span>))  <span class=\"comment\"># å°†inputä¸­ä¸ºNaNçš„æ•°æ®ç”¨å¹³å‡å€¼å¡«å……</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(inputs)</span><br><span class=\"line\"><span class=\"comment\">#    NumRooms Alley</span></span><br><span class=\"line\"><span class=\"comment\"># 0       3.0  Pave</span></span><br><span class=\"line\"><span class=\"comment\"># 1       2.0   NaN</span></span><br><span class=\"line\"><span class=\"comment\"># 2       4.0   NaN</span></span><br><span class=\"line\"><span class=\"comment\"># 3       3.0   NaN</span></span><br></pre></td></tr></table></figure>\n<p>å¯¹äº <code>inputs</code> ä¸­çš„ç±»åˆ«å€¼æˆ–ç¦»æ•£å€¼ï¼Œæˆ‘ä»¬å¯ä»¥å°† <code>NaN</code> è§†ä¸ºä¸€ä¸ªç±»åˆ«ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inputs = pd.get_dummies(inputs, dummy_na=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(inputs)</span><br><span class=\"line\"><span class=\"comment\">#    NumRooms  Alley_Pave  Alley_nan</span></span><br><span class=\"line\"><span class=\"comment\"># 0       3.0           1          0</span></span><br><span class=\"line\"><span class=\"comment\"># 1       2.0           0          1</span></span><br><span class=\"line\"><span class=\"comment\"># 2       4.0           0          1</span></span><br><span class=\"line\"><span class=\"comment\"># 3       3.0           0          1</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨ <code>inputs</code> å’Œ <code>outputs</code> ä¸­çš„æ‰€æœ‰æ¡ç›®éƒ½æ˜¯æ•°å€¼ç±»å‹ï¼Œå®ƒä»¬å¯ä»¥è½¬æ¢ä¸ºå¼ é‡æ ¼å¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">x, y = torch.tensor(inputs.values), torch.tensor(outputs.values)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x, y)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[3., 1., 0.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [2., 0., 1.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [4., 0., 1.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [3., 0., 1.]], dtype=torch.float64) tensor([127500, 106000, 178100, 140000])</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"3-çº¿æ€§ä»£æ•°\">3. çº¿æ€§ä»£æ•°</h2>\n<p>æ ‡é‡ç”±åªæœ‰ä¸€ä¸ªå…ƒç´ çš„å¼ é‡è¡¨ç¤ºï¼Œä½ å¯ä»¥å°†å‘é‡è§†ä¸ºæ ‡é‡å€¼ç»„æˆçš„åˆ—è¡¨ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.tensor(<span class=\"number\">3.0</span>)</span><br><span class=\"line\">y = torch.tensor(<span class=\"number\">2.0</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x + y, x * y)  <span class=\"comment\"># tensor(5.) tensor(6.)</span></span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.arange(<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)  <span class=\"comment\"># tensor([0, 1, 2, 3])</span></span><br></pre></td></tr></table></figure>\n<p>è®¿é—®å¼ é‡çš„é•¿åº¦å’Œå½¢çŠ¶ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(x))  <span class=\"comment\"># 4</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.shape)  <span class=\"comment\"># torch.Size([4])</span></span><br></pre></td></tr></table></figure>\n<p>çŸ©é˜µå’ŒçŸ©é˜µçš„è½¬ç½®ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A = torch.arange(<span class=\"number\">9</span>).reshape(<span class=\"number\">3</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.T)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[0, 3, 6],</span></span><br><span class=\"line\"><span class=\"comment\">#         [1, 4, 7],</span></span><br><span class=\"line\"><span class=\"comment\">#         [2, 5, 8]])</span></span><br></pre></td></tr></table></figure>\n<p>ç»™å®šå…·æœ‰ç›¸åŒå½¢çŠ¶çš„ä»»ä½•ä¸¤ä¸ªå¼ é‡ï¼Œä»»ä½•æŒ‰å…ƒç´ äºŒå…ƒè¿ç®—çš„ç»“æœéƒ½å°†æ˜¯ç›¸åŒå½¢çŠ¶çš„å¼ é‡ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A = torch.arange(<span class=\"number\">12</span>, dtype=torch.float32).reshape(<span class=\"number\">3</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">B = A.clone()  <span class=\"comment\"># é€šè¿‡åˆ†é…æ–°å†…å­˜ï¼Œå°†Açš„ä¸€ä¸ªå‰¯æœ¬åˆ†é…ç»™B</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A + B)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[ 0.,  2.,  4.,  6.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [ 8., 10., 12., 14.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [16., 18., 20., 22.]])</span></span><br></pre></td></tr></table></figure>\n<p>æ±‚å’Œä¸æ±‚å¹³å‡å€¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(A.<span class=\"built_in\">sum</span>())  <span class=\"comment\"># tensor(66.)ï¼Œæ‰€æœ‰å…ƒç´ æ±‚å’Œ</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>))  <span class=\"comment\"># tensor([12., 15., 18., 21.])ï¼Œåœ¨ç¬¬0ç»´ä¸Šæ±‚å’Œ</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">1</span>))  <span class=\"comment\"># tensor([ 6., 22., 38.])ï¼Œåœ¨ç¬¬1ç»´ä¸Šæ±‚å’Œ</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.mean())  <span class=\"comment\"># tensor(5.5000)ï¼Œæ‰€æœ‰å…ƒç´ å‡å€¼</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.mean(axis=<span class=\"number\">1</span>))  <span class=\"comment\"># tensor([1.5000, 5.5000, 9.5000])ï¼Œåœ¨ç¬¬1ç»´ä¸Šæ±‚å‡å€¼</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">1</span>, keepdims=<span class=\"literal\">True</span>))  <span class=\"comment\"># è®¡ç®—æ€»å’Œæˆ–å‡å€¼æ—¶ä¿æŒç»´åº¦ä¸å˜</span></span><br><span class=\"line\"><span class=\"comment\"># tensor([[ 6.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [22.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [38.]])</span></span><br></pre></td></tr></table></figure>\n<p>ç‚¹ç§¯æ˜¯ç›¸åŒä½ç½®çš„æŒ‰å…ƒç´ ä¹˜ç§¯çš„å’Œï¼Œ<code>torch.dot</code> åªèƒ½å¯¹ä¸€ç»´å‘é‡åšç‚¹ç§¯ã€‚æ³¨æ„ NumPy ä¸­çš„ <code>np.dot</code> å‡½æ•°è®¡ç®—çš„æ˜¯ä¸¤ä¸ªçŸ©é˜µçš„çŸ©é˜µä¹˜æ³•ï¼Œè€Œéå¯¹åº”å…ƒç´ ç›¸ä¹˜æ±‚å’Œï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.arange(<span class=\"number\">4</span>, dtype=torch.float32)  <span class=\"comment\"># tensor([0., 1., 2., 3.])</span></span><br><span class=\"line\">y = torch.ones(<span class=\"number\">4</span>, dtype=torch.float32)  <span class=\"comment\"># tensor([1., 1., 1., 1.])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.dot(x, y))  <span class=\"comment\"># tensor(6.)</span></span><br></pre></td></tr></table></figure>\n<p>çŸ©é˜µå‘é‡ç§¯ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.arange(<span class=\"number\">6</span>, dtype=torch.float32).reshape(<span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[0., 1., 2.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [3., 4., 5.]])</span></span><br><span class=\"line\">y = torch.tensor([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], dtype=torch.float32)  <span class=\"comment\"># tensor([1., 2., 3.])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.mv(x, y))  <span class=\"comment\"># tensor([ 8., 26.])</span></span><br></pre></td></tr></table></figure>\n<p>çŸ©é˜µä¹˜æ³•ï¼Œ<code>torch.mm</code> ä¸ <code>np.dot</code> ç±»ä¼¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.arange(<span class=\"number\">6</span>, dtype=torch.float32).reshape(<span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[0., 1., 2.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [3., 4., 5.]])</span></span><br><span class=\"line\">y = torch.ones(<span class=\"number\">6</span>, dtype=torch.float32).reshape(<span class=\"number\">3</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[1., 1.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [1., 1.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [1., 1.]])</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.mm(x, y))</span><br><span class=\"line\"><span class=\"comment\"># tensor([[ 3.,  3.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [12., 12.]])</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"built_in\">print</span>(np.dot(x, y))</span><br><span class=\"line\"><span class=\"comment\"># [[ 3.  3.]</span></span><br><span class=\"line\"><span class=\"comment\">#  [12. 12.]]</span></span><br></pre></td></tr></table></figure>\n<p>L2 èŒƒæ•°æ˜¯å‘é‡æ‰€æœ‰å…ƒç´ çš„å¹³æ–¹å’Œçš„å¹³æ–¹æ ¹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.tensor([<span class=\"number\">3</span>, -<span class=\"number\">4</span>], dtype=torch.float32)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.norm(x))  <span class=\"comment\"># tensor(5.)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.norm(x, <span class=\"number\">2</span>))  <span class=\"comment\"># tensor(5.)</span></span><br></pre></td></tr></table></figure>\n<p>L1 èŒƒæ•°ä¸ºå‘é‡æ‰€æœ‰å…ƒç´ çš„ç»å¯¹å€¼ä¹‹å’Œï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(torch.<span class=\"built_in\">abs</span>(x).<span class=\"built_in\">sum</span>())  <span class=\"comment\"># tensor(7.)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(torch.norm(x, <span class=\"number\">1</span>))  <span class=\"comment\"># tensor(7.)</span></span><br></pre></td></tr></table></figure>\n<p>F èŒƒæ•°ï¼ˆå¼—ç½—è´å°¼ä¹Œæ–¯èŒƒæ•°ï¼‰æ˜¯çŸ©é˜µæ‰€æœ‰å…ƒç´ çš„å¹³æ–¹å’Œçš„å¹³æ–¹æ ¹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(torch.norm(torch.ones((<span class=\"number\">4</span>, <span class=\"number\">9</span>))))  <span class=\"comment\"># tensor(6.)</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"4-è‡ªåŠ¨å¾®åˆ†\">4. è‡ªåŠ¨å¾®åˆ†</h2>\n<p>å…ˆä¸¾ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.arange(<span class=\"number\">4.0</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)  <span class=\"comment\"># tensor([0., 1., 2., 3.])</span></span><br><span class=\"line\"></span><br><span class=\"line\">x.requires_grad_(<span class=\"literal\">True</span>)  <span class=\"comment\"># ç­‰ä»·äºx = torch.arange(4.0, requires_grad=True)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad)  <span class=\"comment\"># é»˜è®¤å€¼æ˜¯None</span></span><br><span class=\"line\"></span><br><span class=\"line\">y = <span class=\"number\">2</span> * torch.dot(x, x)  <span class=\"comment\"># è®¡ç®—yï¼Œæ³¨æ„ä¸€ä¸ªæ ‡é‡å‡½æ•°å…³äºå‘é‡xçš„æ¢¯åº¦æ˜¯å‘é‡ï¼Œå¹¶ä¸”ä¸xå…·æœ‰ç›¸åŒçš„å½¢çŠ¶</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(y)  <span class=\"comment\"># tensor(28., grad_fn=&lt;MulBackward0&gt;)ï¼Œéšå¼æ„é€ äº†è®¡ç®—å›¾ï¼Œæ‰€ä»¥æœ‰ä¸€ä¸ªæ±‚æ¢¯åº¦çš„å‡½æ•°</span></span><br><span class=\"line\"></span><br><span class=\"line\">y.backward()  <span class=\"comment\"># é€šè¿‡è°ƒç”¨åå‘ä¼ æ’­å‡½æ•°æ¥è‡ªåŠ¨è®¡ç®—yå…³äºxæ¯ä¸ªåˆ†é‡çš„æ¢¯åº¦</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad)  <span class=\"comment\"># tensor([ 0.,  4.,  8., 12.])ï¼Œy=2*x*xçš„å¯¼æ•°ä¸º4x</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad == <span class=\"number\">4</span> * x)  <span class=\"comment\"># tensor([True, True, True, True])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ç°åœ¨è®¡ç®—xçš„å¦ä¸€ä¸ªå‡½æ•°</span></span><br><span class=\"line\"><span class=\"comment\"># åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼ŒPyTorchä¼šç´¯ç§¯æ¢¯åº¦ï¼Œæˆ‘ä»¬éœ€è¦æ¸…é™¤ä¹‹å‰çš„å€¼</span></span><br><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y = x.<span class=\"built_in\">sum</span>()</span><br><span class=\"line\">y.backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad)  <span class=\"comment\"># tensor([1., 1., 1., 1.])</span></span><br></pre></td></tr></table></figure>\n<p>å½“ <code>y</code> ä¸æ˜¯æ ‡é‡æ—¶ï¼Œå‘é‡ <code>y</code> å…³äºå‘é‡ <code>x</code> çš„å¯¼æ•°çš„æœ€è‡ªç„¶è§£é‡Šæ˜¯ä¸€ä¸ªçŸ©é˜µã€‚å¯¹äºé«˜é˜¶å’Œé«˜ç»´çš„ <code>y</code> å’Œ <code>x</code>ï¼Œæ±‚å¯¼çš„ç»“æœå¯ä»¥æ˜¯ä¸€ä¸ªé«˜é˜¶å¼ é‡ã€‚</p>\n<p>ç„¶è€Œï¼Œè™½ç„¶è¿™äº›æ›´å¥‡ç‰¹çš„å¯¹è±¡ç¡®å®å‡ºç°åœ¨é«˜çº§æœºå™¨å­¦ä¹ ä¸­ï¼ˆåŒ…æ‹¬æ·±åº¦å­¦ä¹ ä¸­ï¼‰ï¼Œä½†å½“è°ƒç”¨å‘é‡çš„åå‘è®¡ç®—æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šè¯•å›¾è®¡ç®—ä¸€æ‰¹è®­ç»ƒæ ·æœ¬ä¸­æ¯ä¸ªç»„æˆéƒ¨åˆ†çš„æŸå¤±å‡½æ•°çš„å¯¼æ•°ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬çš„ç›®çš„ä¸æ˜¯è®¡ç®—å¾®åˆ†çŸ©é˜µï¼Œè€Œæ˜¯å•ç‹¬è®¡ç®—æ‰¹é‡ä¸­æ¯ä¸ªæ ·æœ¬çš„åå¯¼æ•°ä¹‹å’Œï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># å¯¹éæ ‡é‡è°ƒç”¨backward()éœ€è¦ä¼ å…¥ä¸€ä¸ªgradientå‚æ•°ï¼Œè¯¥å‚æ•°æŒ‡å®šå¾®åˆ†å‡½æ•°å…³äºselfçš„æ¢¯åº¦ã€‚</span></span><br><span class=\"line\"><span class=\"comment\"># æœ¬ä¾‹åªæƒ³æ±‚åå¯¼æ•°çš„å’Œï¼Œæ‰€ä»¥ä¼ é€’ä¸€ä¸ª1çš„æ¢¯åº¦æ˜¯åˆé€‚çš„</span></span><br><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y = x * x</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y)  <span class=\"comment\"># tensor([0., 1., 4., 9.], grad_fn=&lt;MulBackward0&gt;)</span></span><br><span class=\"line\"><span class=\"comment\"># ç­‰ä»·äºy.backward(torch.ones(len(x)))</span></span><br><span class=\"line\">y.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad)  <span class=\"comment\"># tensor([0., 2., 4., 6.])</span></span><br></pre></td></tr></table></figure>\n<p>æœ‰æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›å°†æŸäº›è®¡ç®—ç§»åŠ¨åˆ°è®°å½•çš„è®¡ç®—å›¾ä¹‹å¤–ã€‚ä¾‹å¦‚ï¼Œå‡è®¾ <code>y</code> æ˜¯ä½œä¸º <code>x</code> çš„å‡½æ•°è®¡ç®—çš„ï¼Œè€Œ <code>z</code> åˆ™æ˜¯ä½œä¸º <code>y</code> å’Œ <code>x</code> çš„å‡½æ•°è®¡ç®—çš„ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬æƒ³è®¡ç®— <code>z</code> å…³äº <code>x</code> çš„æ¢¯åº¦ï¼Œä½†ç”±äºæŸç§åŸå› ï¼Œå¸Œæœ›å°† <code>y</code> è§†ä¸ºä¸€ä¸ªå¸¸æ•°ï¼Œå¹¶ä¸”åªè€ƒè™‘åˆ° <code>x</code> åœ¨ <code>y</code> è¢«è®¡ç®—åå‘æŒ¥çš„ä½œç”¨ã€‚</p>\n<p>è¿™é‡Œå¯ä»¥åˆ†ç¦» <code>y</code> æ¥è¿”å›ä¸€ä¸ªæ–°å˜é‡ <code>u</code>ï¼Œè¯¥å˜é‡ä¸ <code>y</code> å…·æœ‰ç›¸åŒçš„å€¼ï¼Œä½†ä¸¢å¼ƒè®¡ç®—å›¾ä¸­å¦‚ä½•è®¡ç®— <code>y</code> çš„ä»»ä½•ä¿¡æ¯ã€‚æ¢å¥è¯è¯´ï¼Œæ¢¯åº¦ä¸ä¼šå‘åæµç» <code>u</code> åˆ° <code>x</code>ã€‚å› æ­¤ï¼Œä¸‹é¢çš„åå‘ä¼ æ’­å‡½æ•°è®¡ç®— <code>z = u * x</code> å…³äº <code>x</code> çš„åå¯¼æ•°ï¼ŒåŒæ—¶å°† <code>u</code> ä½œä¸ºå¸¸æ•°å¤„ç†ï¼Œè€Œä¸æ˜¯è®¡ç®— <code>z = x * x * x</code> å…³äº <code>x</code> çš„åå¯¼æ•°ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y = x * x</span><br><span class=\"line\">u = y.detach()</span><br><span class=\"line\">z = u * x</span><br><span class=\"line\"></span><br><span class=\"line\">z.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad == u)  <span class=\"comment\"># tensor([True, True, True, True])</span></span><br><span class=\"line\"></span><br><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad == <span class=\"number\">2</span> * x)  <span class=\"comment\"># tensor([True, True, True, True])</span></span><br></pre></td></tr></table></figure>\n<p>ä½¿ç”¨è‡ªåŠ¨å¾®åˆ†çš„ä¸€ä¸ªå¥½å¤„æ˜¯ï¼šå³ä½¿æ„å»ºå‡½æ•°çš„è®¡ç®—å›¾éœ€è¦é€šè¿‡ Python æ§åˆ¶æµï¼ˆä¾‹å¦‚ï¼Œæ¡ä»¶ã€å¾ªç¯æˆ–ä»»æ„å‡½æ•°è°ƒç”¨ï¼‰ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥è®¡ç®—å¾—åˆ°å˜é‡çš„æ¢¯åº¦ã€‚åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œ<code>while</code> å¾ªç¯çš„è¿­ä»£æ¬¡æ•°å’Œ <code>if</code> è¯­å¥çš„ç»“æœéƒ½å–å†³äºè¾“å…¥ <code>a</code> çš„å€¼ã€‚å¯¹äºä»»ä½• <code>a</code>ï¼Œå­˜åœ¨æŸä¸ªå¸¸é‡æ ‡é‡ <code>k</code>ï¼Œä½¿å¾— <code>d = f(a) = k * a</code>ï¼Œå…¶ä¸­ <code>k</code> çš„å€¼å–å†³äºè¾“å…¥ <code>a</code>ï¼Œå› æ­¤å¯ä»¥ç”¨ <code>d / a</code> éªŒè¯æ¢¯åº¦æ˜¯å¦æ­£ç¡®ã€‚</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">a</span>):</span><br><span class=\"line\">    b = a * <span class=\"number\">2</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> b.norm() &lt; <span class=\"number\">1000</span>:</span><br><span class=\"line\">        b = b * <span class=\"number\">2</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> b.<span class=\"built_in\">sum</span>() &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">        c = b</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        c = <span class=\"number\">100</span> * b</span><br><span class=\"line\">    <span class=\"keyword\">return</span> c</span><br><span class=\"line\"></span><br><span class=\"line\">a = torch.randn(size=(), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">d = f(a)</span><br><span class=\"line\">d.backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a.grad == d / a)  <span class=\"comment\"># tensor(True)</span></span><br></pre></td></tr></table></figure>\n<p>ä¸‹ä¸€ç« ï¼š<a href=\"/posts/19931.html\">çº¿æ€§ç¥ç»ç½‘ç»œ</a>ã€‚</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/33687.html",
            "url": "https://asanosaki.github.io/posts/33687.html",
            "title": "å®ç”¨æœºå™¨å­¦ä¹ è¯¾ç¨‹ç¬”è®°(Stanford)",
            "date_published": "2022-12-22T02:28:00.000Z",
            "content_html": "<blockquote>\n<p>Stanford 2021 ç§‹å­£å®ç”¨æœºå™¨å­¦ä¹ è¯¾ç¨‹å­¦ä¹ ç¬”è®°ã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-æ¦‚è®º\">1. æ¦‚è®º</h2>\n<h3 id=\"1-1-è¯¾ç¨‹ä»‹ç»\">1.1 è¯¾ç¨‹ä»‹ç»</h3>\n<p><strong>Challenges</strong></p>\n<ul>\n<li>Formulate problemï¼šå…³æ³¨æœ€å…·å½±å“åŠ›çš„è¡Œä¸šé—®é¢˜ï¼ˆå¦‚è‡ªåŠ©è¶…å¸‚ã€è‡ªåŠ¨é©¾é©¶æ±½è½¦ç­‰ï¼‰ã€‚</li>\n<li>Dataï¼šé«˜è´¨é‡æ•°æ®çš„ç¨€ç¼ºã€éšç§é—®é¢˜ã€‚</li>\n<li>Train modelsï¼šæ¨¡å‹è¶Šæ¥è¶Šå¤æ‚ï¼Œéœ€è¦å¤§é‡æ•°æ®ï¼Œæˆæœ¬ä¹Ÿè¶Šæ¥è¶Šé«˜ã€‚</li>\n<li>Deploy modelsï¼šè®¡ç®—é‡å¤§ï¼Œä¸é€‚åˆå®æ—¶æ¨ç†ã€‚</li>\n<li>Monitorï¼šæ•°æ®åˆ†å¸ƒçš„å˜åŒ–ã€å…¬å¹³æ€§é—®é¢˜ã€‚</li>\n</ul>\n<p><strong>Rolesï¼ˆä¸åŒç±»å‹çš„äººåœ¨ ML ä¸­çš„ä½œç”¨ï¼‰</strong></p>\n<ul>\n<li>Domain expertsï¼ˆé¢†åŸŸä¸“å®¶ï¼‰ï¼šå…·æœ‰å•†ä¸šæ´å¯ŸåŠ›ï¼ŒçŸ¥é“ä»€ä¹ˆæ•°æ®æ˜¯é‡è¦çš„ä»¥åŠåœ¨å“ªå¯ä»¥æ‰¾åˆ°å®ƒï¼Œç¡®å®šä¸€ä¸ª ML æ¨¡å‹çœŸæ­£çš„å½±å“ã€‚</li>\n<li>Data scientistsï¼šåœ¨ Data miningã€Model training and deployment æ–¹é¢åšå…¨æ ˆçš„å·¥ä½œã€‚</li>\n<li>ML expertsï¼šå®šåˆ¶æœ€å…ˆè¿›ï¼ˆstate of the artï¼ŒSOTAï¼‰çš„ ML modelsã€‚</li>\n<li>SDEï¼ˆè½¯ä»¶å¼€å‘å·¥ç¨‹å¸ˆï¼‰ï¼šå¼€å‘/ç»´æŠ¤æ•°æ®ç®¡é“ã€æ¨¡å‹è®­ç»ƒå’ŒæœåŠ¡ç®¡é“ã€‚</li>\n</ul>\n<p><strong>Corse topics</strong></p>\n<p>æœ¬è¯¾ç¨‹çš„å†…å®¹ä¸ºæ•°æ®ç§‘å­¦å®¶éœ€è¦çš„æŠ€æœ¯ï¼Œä½†æ˜¯æ²¡æœ‰å¤§å­¦ä¼ ç»Ÿçš„ ML/ç»Ÿè®¡/ç¼–ç¨‹æ–¹é¢çš„æ•™å­¦ã€‚</p>\n<ul>\n<li>Data\n<ul>\n<li>æ”¶é›†ã€å¤„ç†æ•°æ®ã€‚</li>\n<li>éƒ¨ç½²çš„æ—¶å€™åœºæ™¯å‘ç”Ÿå˜åŒ–å¯¼è‡´æ•°æ®ä¸ä¸€æ ·ï¼Œå¦‚ covariateï¼ˆåå˜é‡ï¼‰ã€conceptsã€label çš„æ”¹å˜ã€‚</li>\n<li>ç‹¬ç«‹åŒåˆ†å¸ƒä¹‹å¤–çš„æ•°æ®ã€‚</li>\n</ul>\n</li>\n<li>Train\n<ul>\n<li>æ¨¡å‹éªŒè¯ã€èåˆã€è°ƒä¼˜ã€‚</li>\n<li>è¿ç§»å­¦ä¹ ï¼ˆTransfer learningï¼‰ã€‚</li>\n<li>å¤šæ¨¡æ€ï¼ˆMulti-modalityï¼‰ï¼šå¦‚ä½•æŠŠä¸åŒçš„æ•°æ®æºèåˆèµ·æ¥åšä¸€ä¸ªæ¯”è¾ƒå¤§çš„æ¨¡å‹ã€‚</li>\n</ul>\n</li>\n<li>Deploy\n<ul>\n<li>æ¨¡å‹æ€æ ·éƒ¨ç½²ã€‚</li>\n<li>è’¸é¦ï¼ˆDistillationï¼‰ï¼šå°†æ¯”è¾ƒå¤§çš„æ¨¡å‹æå–å‡ºç²¾ååšçš„å°ä¸€ç‚¹ã€‚</li>\n</ul>\n</li>\n<li>Monitor\n<ul>\n<li>å…¬å¹³æ€§ï¼Œä¹‹åä¼šè®²æ¨¡å‹çš„å…¬å¹³æ˜¯ä»€ä¹ˆå«ä¹‰ã€‚</li>\n<li>å¯è§£é‡Šæ€§ï¼Œæ€æ ·ç†è§£æ¨¡å‹åœ¨å¹²ä»€ä¹ˆã€‚</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1-2-æ•°æ®è·å–\">1.2 æ•°æ®è·å–</h3>\n<p><strong>Flow Chart for data acquisition</strong></p>\n<p><img src=\"data:image/png;base64,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\" alt=\"\"></p>\n<p><strong>Discover what data is available</strong></p>\n<ul>\n<li>æ‰¾å·²ç»æœ‰çš„æ•°æ®é›†ã€‚</li>\n<li>æ‰¾åŸºå‡†æ•°æ®é›†æ¥æ£€éªŒæˆ‘ä»¬çš„æƒ³æ³•ï¼š\n<ul>\n<li>ä¾‹å¦‚è¦åšä¸€ä¸ªæ–°çš„è°ƒè¶…å‚æ•°çš„ç®—æ³•ï¼Œå¯èƒ½éœ€è¦æ‰¾ä¸€äº›æ•°æ®é›†ï¼Œä¸”æ•°æ®é›†ä¸èƒ½å¤ªå¤§ï¼Œè¦å°ä¸€ç‚¹çš„æˆ–è€…ä¸­ç­‰å¤§å°çš„ï¼Œä¸ºäº†å®¢è§‚åœ°æ£€éªŒç®—æ³•è¿˜è¦è€ƒè™‘æ‰¾ä¸åŒæ–¹é¢çš„æ•°æ®é›†ã€‚</li>\n<li>å¦‚æœè®­ç»ƒæ¯”è¾ƒæ·±çš„ç¥ç»ç½‘ç»œå°±éœ€è¦éå¸¸å¤§çš„æ•°æ®é›†ã€‚</li>\n</ul>\n</li>\n<li>æ”¶é›†æ–°æ•°æ®ï¼ˆåšä¸€ä¸ªåº”ç”¨æˆ–äº§å“å¾ˆå¤šæ—¶å€™æ²¡æœ‰ç°æˆçš„æ•°æ®é›†ï¼‰</li>\n</ul>\n<p><strong>Source of popular ML datasets</strong></p>\n<ul>\n<li>MNISTï¼šæ‰‹å†™æ•°å­—ã€‚</li>\n<li>ImageNetï¼šç™¾ä¸‡çº§åˆ«çš„æ¥è‡ªæœç´¢å¼•æ“çš„å›¾ç‰‡ï¼Œå¯è®­ç»ƒè¾ƒä¸ºæ·±åº¦çš„æ¨¡å‹ã€‚</li>\n<li>AudioSetï¼šYouTube ä¸Šçš„ä¸€äº›å£°éŸ³çš„åˆ‡ç‰‡ï¼Œç”¨äºåšå£°éŸ³çš„åˆ†ç±»ã€‚</li>\n<li>Kineticsï¼šYouTube ä¸Šçš„ä¸€äº›è§†é¢‘çš„åˆ‡ç‰‡ï¼Œç”¨äºäººçš„è¡Œä¸ºåˆ†ç±»ã€‚</li>\n<li>KITTIï¼šæ‘„åƒå¤´æˆ–æ¿€å…‰é›·è¾¾ç­‰å„ç§ sensor è®°å½•ä¸‹çš„äº¤é€šåœºæ™¯ã€‚</li>\n<li>Amazon Reviewï¼šAmazon äº§å“çš„ç”¨æˆ·è¯„è®ºã€‚</li>\n<li>SQuADï¼šç»´åŸºä¸­çš„ä¸€äº› Q-A å¯¹ã€‚</li>\n<li>Librispeechï¼š1000å°æ—¶çš„æœ‰å£°è¯»ç‰©ã€‚</li>\n</ul>\n<p>æ•°æ®é›†ä¸¤å¤§æ¥æºï¼šå„ä¸ªç½‘ç«™ä¸Šçˆ¬å–ï¼Œé‡‡é›†æ•°æ®ã€‚</p>\n<p><strong>Where to find datasets</strong></p>\n<ul>\n<li>Paperwithcodes Datasetsï¼šå­¦æœ¯æ•°æ®é›†ä¸æ’è¡Œæ¦œã€‚</li>\n<li>Kaggle Datasetsï¼šæ•°æ®ç§‘å­¦å®¶æäº¤çš„ ML datasetsã€‚</li>\n<li>Google Dataset searchï¼šæœç´¢ç½‘é¡µä¸Šçš„æ•°æ®é›†ã€‚</li>\n<li>Various toolkits datasetsï¼ˆå¼€æºå·¥å…·åŒ…ï¼‰ï¼šTensorFlowã€HuggingFaceã€‚</li>\n<li>ä¼šè®®/å…¬å¸çš„ ML ç«èµ›ã€‚</li>\n<li>è‡ªå·±ç»„ç»‡çš„ Data lakesï¼ˆæ•°æ®æ¹–ï¼‰ã€‚</li>\n</ul>\n<p><strong>Datasets comparison</strong></p>\n<table>\n    <thead>\n        <tr>\n            <th>æ•°æ®é›†</th>\n            <th>å¥½å¤„</th>\n            <th>åå¤„</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>å­¦æœ¯æ•°æ®é›†</td>\n            <td>æ•°æ®å¹²å‡€ã€éš¾åº¦é€‚ä¸­</td>\n            <td>é€‰æ‹©é¢è¾ƒå°ã€å¤ªç²¾ç®€ã€è§„æ¨¡å°</td>\n        </tr>\n        <tr>\n            <td>ç«èµ›æ•°æ®é›†</td>\n            <td>æ›´æ¥è¿‘çœŸå®çš„ ML åº”ç”¨</td>\n            <td>ä»è¾ƒç²¾ç®€ï¼Œä¸”åªä¸“æ³¨åœ¨è¾ƒçƒ­é—¨çš„åº”ç”¨</td>\n        </tr>\n        <tr>\n            <td>åŸç”Ÿæ•°æ®</td>\n            <td>å¾ˆçµæ´»</td>\n            <td>éœ€è¦å¾ˆå¤šç²¾åŠ›å»é¢„å¤„ç†</td>\n        </tr>\n    </tbody>\n</table>\n<p><strong>Data integration</strong></p>\n<p>äº§å“æ•°æ®é€šå¸¸å­˜æ”¾åœ¨ä¸åŒçš„è¡¨ä¸­ï¼Œå› æ­¤è¦æ¶‰åŠåˆ°è¡¨çš„è¿æ¥ã€‚</p>\n<table>\n    <caption>Table 1</caption>\n    <thead>\n        <tr>\n            <th>ID</th>\n            <th>Val 1</th>\n            <th>Val 2</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>1</td>\n            <td>1_val1</td>\n            <td>1_val2</td>\n        </tr>\n        <tr>\n            <td>2</td>\n            <td>2_val1</td>\n            <td>2_val2</td>\n        </tr>\n    </tbody>\n</table>\n<table>\n    <caption>Table 2</caption>\n    <thead>\n        <tr>\n            <th>ID</th>\n            <th>Val 3</th>\n            <th>Val 4</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>1</td>\n            <td>1_val3</td>\n            <td>1_val4</td>\n        </tr>\n        <tr>\n            <td>3</td>\n            <td>3_val3</td>\n            <td>3_val4</td>\n        </tr>\n    </tbody>\n</table>\n<table>\n    <caption>Inner Join T1 & T2</caption>\n    <thead>\n        <tr>\n            <th>ID</th>\n            <th>Val 1</th>\n            <th>Val 2</th>\n            <th>Val 3</th>\n            <th>Val 4</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>1</td>\n            <td>1_val1</td>\n            <td>1_val2</td>\n            <td>1_val3</td>\n            <td>1_val4</td>\n        </tr>\n    </tbody>\n</table>\n<table>\n    <caption>Left Join T1 & T2</caption>\n    <thead>\n        <tr>\n            <th>ID</th>\n            <th>Val 1</th>\n            <th>Val 2</th>\n            <th>Val 3</th>\n            <th>Val 4</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>1</td>\n            <td>1_val1</td>\n            <td>1_val2</td>\n            <td>1_val3</td>\n            <td>1_val4</td>\n        </tr>\n        <tr>\n            <td>2</td>\n            <td>2_val1</td>\n            <td>2_val2</td>\n            <td>/</td>\n            <td>/</td>\n        </tr>\n    </tbody>\n</table>\n<h3 id=\"1-3-ç½‘é¡µæ•°æ®æŠ“å–\">1.3 ç½‘é¡µæ•°æ®æŠ“å–</h3>\n<ul>\n<li>ä¸€èˆ¬ä¸èƒ½ç”¨ <code>curl</code>ï¼Œå› ä¸ºç½‘ç«™æ‰€æœ‰è€…èƒ½ä½¿ç”¨å„ç§æ–¹æ³•é˜»æ­¢ã€‚</li>\n<li>ä½¿ç”¨æ— å¤´æµè§ˆå™¨ï¼ˆä¸€ä¸ªæ²¡æœ‰ GUI çš„ç½‘ç»œæµè§ˆå™¨ï¼‰ï¼š</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> selenium <span class=\"keyword\">import</span> webdriver</span><br><span class=\"line\"></span><br><span class=\"line\">chrome_options = webdriver.ChromeOptions()</span><br><span class=\"line\">chrome_options.headless = <span class=\"literal\">True</span></span><br><span class=\"line\">chrome = webdriver.Chrome(chrome_options = chrome_options)</span><br><span class=\"line\"></span><br><span class=\"line\">page = chrome.get(url)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>ä½ éœ€è¦å¤§é‡çš„æ–° IPï¼Œå¯ä»¥é€šè¿‡äº‘è·å¾—å¾ˆå¤š IPã€‚</li>\n</ul>\n<h3 id=\"1-4-æ•°æ®æ ‡æ³¨\">1.4 æ•°æ®æ ‡æ³¨</h3>\n<p><strong>åŠç›‘ç£å­¦ä¹ Semi-Supervised Learningï¼ˆSSLï¼‰</strong></p>\n<ul>\n<li>é‡ç‚¹å…³æ³¨æœ‰å°‘é‡æ ‡è®°æ•°æ®å’Œå¤§é‡æœªæ ‡è®°æ•°æ®çš„åœºæ™¯ã€‚</li>\n<li>å¯¹æ²¡æœ‰æ ‡æ³¨çš„æ•°æ®å’Œæœ‰æ ‡æ³¨çš„æ•°æ®çš„æ•°æ®åˆ†å¸ƒåšä¸€äº›å‡è®¾ï¼š\n<ul>\n<li>è¿ç»­æ€§å‡è®¾ï¼ˆContinuity assumptionï¼‰ï¼šå¦‚æœä¸€ä¸ªæ ·æœ¬çš„ç‰¹å¾å’Œå¦å¤–ä¸€ä¸ªæ ·æœ¬ç›¸ä¼¼ï¼Œé‚£ä¹ˆè¿™ä¸¤ä¸ªæ ·æœ¬å¾ˆå¯èƒ½å…·æœ‰ç›¸åŒçš„æ ‡å·ã€‚</li>\n<li>èšç±»å‡è®¾ï¼ˆCluster assumptionï¼‰ï¼šæ•°æ®å…·æœ‰å†…åœ¨çš„èšç±»ç»“æ„ï¼Œé‚£ä¹ˆå‡è®¾ä¸€ä¸ªç±»é‡Œé¢å…·æœ‰ç›¸åŒçš„æ ‡å·ã€‚</li>\n<li>æµå½¢å‡è®¾ï¼ˆManifold assumptionï¼‰ï¼šå¾ˆæœ‰å¯èƒ½æ•°æ®åœ¨æœ¬è´¨ä¸Šæ˜¯åœ¨ä½ç»´çš„ä¸€ä¸ªæµå½¢ä¸Šåˆ†å¸ƒçš„ã€‚</li>\n</ul>\n</li>\n</ul>\n<p><strong>è‡ªå­¦ä¹ Self-training</strong></p>\n<p><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA6UAAAFUCAIAAABTEg2EAAAgAElEQVR4AeydB1gTPxvA765lI3upTAFBxYGgqLgniODAvRX3/tx7T9x77/13770VByJbRWWJyJC9Ke3dl2vp0dIrtKXs3NMHcrnkzZtfcsl7uSSHEgSBwAMSgAQgAUgAEoAEIAFIABKooQSwGpovmC1IABKABCABSAASgAQgAUiAJADtXVgPIAFIABKABCABSAASgARqMgFo79bk0oV5gwQgAUgAEoAEIAFIABKA9i6sA5AAJAAJQAKQACQACUACNZkAtHdrcunCvEECkAAkAAlAApAAJAAJQHsX1gFIABKABCABSAASgAQggZpMANq7Nbl0Yd4gAUgAEoAEIAFIABKABKC9C+sAJAAJQAKQACQACUACkEBNJgDt3ZpcujBvkAAkAAlAApAAJAAJQALQ3oV1ABKABCABSAASgAQgAUigJhOA9m5NLl2YN0gAEoAEIAFIABKABCABaO/COgAJQAKQACQACUACkAAkUJMJQHu3JpcuzBskAAlAApAAJAAJQAKQALR3YR2ABCABSAASgAQgAUgAEqjJBKC9W5NLF+YNEoAEIAFIABKABCABSIBZ/RCw06KCg378TWMxtepZN7VroK1Y/fIANYYEIAFIABKABCABSAASqCACVWp8lxNxbqa7Wx+vQ0Ficp8RdGFh3zYOHfuOnDB1xrSJIz29DoSwxISF3pAAJFDFCaTdX9bXrc/Q7R/yq5CiLP99Y/u4ecz7LxavQlpBVSABSAASgATKQkDC8V1O2o+3T15+CgyLSkjNyC1gqmgbmlk3a9OtR8fG+vIbXiXyEn6FBn9Ldcimy1J+6KEJIzZ9SEfULdr369bSRAPNTVdubSxhDugklrcf58/jHZsu/tR3n79kQEOlMqcmZ3Fl1odGQJGKqwc0pLle1b3KVM+lj8wKPDJn87O0en3XeA+3ZlR1OPLXD2cnR4cEB6tZpxPyFy6zRCLr77eQ4H+Mf3lVSSuZswMjQgKQACQACQACpVqLePrX6zvX7bzkE5NTvPW/cGTb6rpOg2YvXTC0hVZ5DxTjf69u2fcxHTXotvb8wdE2ylKWXm7Sn3/ZuJJufUP1CrMr2D+v7D54J5iNfdPr5raxQ1kNXkFxAzZ2kBJAhQQXUHH1gI0VkqS8EilTPZc1MpEa7vv+fVKD5lkcBKmweikvZJLJqYw7TzLNYChIABKABCCB2kOgZHuXFXVj0dhF1yLyGJo2PccP7N3RsYlVfV01LC8tPjrU7/XDq1cefTi7ePDbT5tOe3uay2+gV5Q/nvTswfsMQqnVxFUjpDZ2ESTv1VrXyTdz2qx6c9GrXnmb5nztmSbO3R0v/Y7Q69nZVoHvKft/QXGySynXmAIqlms68hZepnpepsjyzkmVk1cpd16VowAVggQgAUgAEqhkAiXZu7lfdk8Hxi5Lr92cPbtmtTcSCKtrYGzZzNlj9ISPh+bP3P7i+uLJ+sbXljmpl1tuCsJ/RBYgTCunNsbVZxxMrfX//vv4P7kxkbM4ueklIKgaqCigbaGzTPW8TJFFdYE+kAAkAAlAApAAJCB/AuLHOvGE2/tOB+cxTIdsOzRHyNgt0oKh7zT9wMGpTZXyv53acOI7u+iKvF1EZjY5n0JLSxuVt2gor1YTKFM9L1PkWo0dZh4SgAQgAUgAEqhAAuLt3dxPrz5lIMyG/UZ3LHFyrprDxOmuemh+8I2rgeW4VwJBAHMXRVAU2rsVWD1qQVJlqudlilwL4MIsQgKQACQACUACVYKAwBwFYX3w9MSkXATB6puZiw1TGEOrXXt75ZtPfgd+SUQcjIXFFJ5xsv7+/B6ZkEWo6Js2tDHVKk0kXwj+L/Rt4N98AuGEJoDRYyI94v3TJ995Ji+mY+PsYFrSwjUQ+03gXxYwlDmhiRwCIdIifJ4+0SSjY3XMHVtba/LMfdYf/zffkhWNWzg30uP65Cb+/B4el47XsWhqb6bBV4b/n5UW9fNXXHI2R6mOnrGVdX0NsTMssiI+fgzPVDZ1bGsj8MzAS07F1LEN5ctK/xsdFROXVqCib9awoYkmPR96cYjM8vgZ4v7PT476FfU3KRutY2hhY22kxkOTE/Xp/c/MOtZtWpurCQUXc0Kp6GyjJSZIXlJ4WER8ei6hpKlvZm1lpCYWnxgBQt6SF4ZQNOqkTPVctsi4g7H4x0xKMRkcGeEffSOyBAuLk5MYE/k7NimXoVnX0qaBvopowuzsxD/Rv2P/5YAgDRpaGqiKBhFVpbT7WdI7T1QyItmtUCwiWafC49LyEBVtY0sbc11J14bmp0aHR8SCSq8uWOmLCYenkAAkAAlAAtWfAL1hBfKFqdYhdzJgJyfGcxDLkk0SdbuuA/sqZ9Y1FN2vEk8LvXFw19H/nn9NLiikxdSwaNd/4tw5w1vqltq1sr4cmzXpWgq1M0TY+fkTzhfKUXBa+fryhPolyGB9OTpz0vU0Kjby7ezcCWe50RkNp924v7gFd4kdnvFi+6Rlb7SHnHi7tU30je3rdl5+F5UJVswjCu3Xh18YXZgegqeH3jy8/+TVZ8HxuVROmXXMHF2GT5szvrOJSCfL/n1j9cTd3+qNvfhsbVvqKi+5t0ZjLj5f15b57/Olg4dOX3/xPYXPR0GnUbfRC5bP6G5abAEgvThEZnmF+cLTAi9v8z58631EeuGEFFTJsGnP4TMXTOllHHNzzcQd3xrPf3hrVsOSKwFXWpGKb9e25XPj/8/4dhNUhavPQxLAA0zhASpDK9dhU2eNo8HHD0P7X+rCoJVSxnou201CZV6MSrJ6s39fXzFx7y/b/92//T/bnG+3Du87efWpf1xuYXqYSt2WfSYuWjzeSZ97z3CS/K4cPnru5rOgBP7ut6iyUYve4xcunuhsJKawJbyfJbzzhHLK4d4KZ66/+Fb6rcCPCNS5eXjviavPgxOozcMw1XrNuw+aOHNyHxvx6wnwtKArO7wP3fAJF6z0PYbNnD+1V32+dPgfEoAEIAFIoMYQEGvvInVatmyk+NQ/5PbVoPGL7FVKyjGz8YgNe0eIhsgOOT136voH0flKBk26DmptY6SOp0UHv3v16fXppR9e+mw4sXOINWUGikYHPgqNBy5dbw+6Ms6PG95n/PIs3Od5ORUOuDIMWwsMmtJFV2g8aPn6lmRHyAm7tuWsf76lx4JxrbmdIKZlV3znXhzPCz003mvz+xRMw9jOqYGBKpFvZcSXm+F/dO4M78cx+Qp6jTsOdLIz1VNBcpNjvn58+fbDlU2fnj6bfeTY/5zEjWnypQj8Z3MKckNOzpuw/kmCqkWrnkObGGthuUnRQe/eBHx7uGtSaPSuKzs9pNhLQjZ5nD93F438338R+cDGtevi3MJSXw3P+Bvm9+7hzslv3s7YP4fNt4UEVJfByYq4tmDckhuReUxNq7buTk3M9VSRnH+Rwe9f+76/vPHjwweT9x1b1IlniJUuXp6FUaZ6XqbIpedTphBsdt6fOwsnLLgczjRz6DzYxVRbgZUa+/3zO9/wz1fWjgr8ffjy6i7MgEMzJ3u/TFQwsmvXv4elgRqRnRgZ6PMu2P/6xrH+4Xv/2+JiKPIkKfn9LN2dB17cZAcdXzBx49NEaW4FqhZgasYtezk3tzRURzLiwvxev/W/vXvakzuP1x72HkK3mQvn7/3FI2df/iVc6X988Xm0a/KbN9P3elFPszIVAIwECUACkAAkUAUJgHmxYg5Ows1pDmYmJpbtp138liUmkHjvgsgLXo7mJqZNei+79UMwOvvfp4NjW1mYmFh1W/MuXVBAQeg2FwsTM+cVPoK+XHfuwznNTU0aeB75zRG5JoFH7oOZdiD64GOxNNE5/86MaEAq2q+bVYPWI7Y9DBdUl5TOjr7kBVCY2vVZLpwXcC3r28XpHSxNTMzbLniWJqxKUX7yBC7wkjNr6bV0WhuLRj3mXghMFVQqN+rOgq5WJiZmrec/EaJD0IsjZJZHEDn+29xsTEC+3Fffi8wV0JHI/nVv3YDmFs07dWpmZmLhtjuMLXhVrLtIRaEgBaG7PRqamDRwnnwqQCizBCc14PT0jiC7pi28LscIchASIHgiY2EIihByl6melykykfdioaOZiXmXDV/yhVSS7aQg2LuHhYl5+1FeLjYNu8w8I4yak/rlyBhwQ5pYdFx58/xER3OrduP3vY0VrJlEbuTt+dy657TgmXDdIwgZ7mcyG5LceXYj5k5ykupWIIj87ydGNAetk1WHSYc/JAjVztzfz7aPIBsYizbTbsQIXeJqFLDT3Za+0oc/2ODZwqJp2zaNTE0sPPb9EokrW8HAWJAAJAAJQAKVTgApSQNO4vPVLramJiYmNh1Gr7/0KU6ocywpJsGOPDmsiamJZZflL1NorJicgB3uwNCy6r0jpKBIjhhriQxQ/vYuyKVp85GnftDkMeflIiczEzOnOffBLGCaI+fTuq6ge7UdfT5B6HpRfgSF8uxTE1NTM6tuy1/8E4rBE579dnl78KTQdNodocToxRXau5LJyxQUyI48Nhh0/Bbt5z0U1rswUKavtxuwUkGIMtq7+R9WgvyYtV30Qih9vi4FYYcGknr02iZYGfhXi/+XtTCKyxE4L0M9J4iyRC4PexeUl1mrqddF7TygatLtaS3B7WzRwMLMccKlSIFbj6KR7bOyA6h7dlNvCRm8Mt3PpFAJ7F3yziv9VhCqOgXfDwwA7YdF22nXouhyQeT9OD2mJXhCbT7+kvBTFDvqxNBGIGZJlR5IBiGgvUtVCuiABCABSKD6ExB5Zyk4BI3pd1lx8cKaAY0086JeHF7g6dym5+iF288+CvybIxiMxp3z5tAhnwzMdMiaxZ20adJQaT5l8SAzRn7o1Yuf5PPCnEYJab1UWk1dPZJmggXru49vAs4wcRnajf6Fu4p9/94NmUhOyJdgyXeoIBiWozcu6cxbICesqqqja6d6GJH5NVDYv8QzieT9EBDBDvnvom82qtF5+vweBjRlhKg7zlw92lr8jBcBWSU7cyOj4jiIQiMHR9oJlcyGA/s5KiHs8KCgrJIFgavlURiy13OgUJkil5pdGQKgGh1nLe1Lt001ptvNvb0WirALlNvPXDWIdiGqqoNrF2MGkRUa8F2gLpfz/cy0Kv1WEKy6Gc8OHffLwer2X7W+nxltBVWyHrlxQVdNJOX5gRO+Ai0MO/S/ix+zSq7068bZ0MqUoSxgFEgAEoAEIIEqQqC0hh3Tsh+7636fcbdPHz975ZHf95eXwG/3ChXDJu17urp7DnRtaUQzAzfrxbUHcTiz6eAx7cSt6ldx7NfL7NyR3x/efGe3a16aGhVBS8VpQH8LumU6io2nnn8zsoCpUbfYAjJKK6aJSV0M+ZqRlib5zD/l1qPGO6pSIoQcCuYWwF75k5Qg5FvyiUTyEotksMNfvIpgo3WcPVyM6KxdMqRy03YOukd/JhfFksmlqKmhgiLZcTExbKQRXVHr9t36oFU6rgImYJZ2lE9hILLV80JlyxS5tAxLex3V6jzYQ9wGEIpmpvUYSCqjpYuruKnhTHNzcCn6X3wCuWKTd5Tz/Sxt1U17fv3JP5xpN2RCN7qHaZ7OWL1+E/rte3E6+v6tTwudOvD2ceGASv+rtErfuF0r/YNh//iZh/8hgdpJgMhNIn7fJ5IDkYJMhAOeGstrpW3txAtzXToBlIEwVRFlPbR+N9SoHYrRWQ+lSykKIVF8hl7z/vP29J+THvHh8b1Hz169evclMvjJWfDbbejYb/KCeWPbCn58DckP8PFNJ5g2nbs2oLMfeakrNmrWWBWJ+B0Wlo001yzSSDoX+/uRybP/iy7qmgujY/U9d5yeaieFMFRJR1eD3vBT0jIyLnklmgKTAXY5Iwhc4hYBLIWvK3Z/CkxVTRlFiAKBEbbSciKZPAGBOSEh4WyEaevgILLhWmlpSXtdqXWPDjq374aeWXOgw8EZrWhsFHUjq4bU0sCSxZdHYRSmKG09F1K0TJGFJJXtBNPQ1xe7SR+qogIeT1HNunXr0Fd1csMKVfBwgrBYRXWlnO9naatufsD7L1kE07pz95JfPig79OxoePZcot/HcHaHJtyWLjs05FcFVfqylSKMDQlUIgEi9RseeRNJ/IAQko/gVKK+MOkaTSDrN5H0hfiujZq4oGbuqGIdmXMrkb1bKJ2h2cB50EzwQ1hJX1/euXb1yo1nIZ8vrx3+7OHUnQfmd+K/FMfTfoX/wxEFbcW0L58+iVWNk0qAvT6Tk/8lcxBN8Xax2Pi8C5z8rMyMDJEvuzG08kVs4FIkSX4Zz0+L/xOflJHNYuM4+R0MpCA6Q2JLV5J0eDsMy+95mi+vSElOfGw8C0E1TMzo52hIoqWkYTBdt6VrXn2dd8Vn25DO97r2H+Dh2qujg7nEuzCXmI78C0PSek6rVpki00osF8/CCkEru/gnXSr0fhbRSKTq4skRUSk4omJta1VK66XUuAkI8jc2EnyKnGvvcuL/xFVUpRfJCPSABKoFAfzvayJwO4JAS7daFFetUTI/lfh1kYh/i7XeiCqVPP4olkkpPYaYeIp6jXuOA7///XpwcPWaw68/7Z86UfH8xTn23PfzeFpaJjCscn22DfcRI6DIm1nAIj8IIevBbDLzss9MWWNLFy//78cb5y/dfvou4Gd8loiFDWSJm+4gXTIVE5qTlQU+0IzV0SplTzf5aMMw9th6w9Rhh/fBaz6PT2wAP6aGceOWbZw7dnXp093eSOyApNjkK6QwSq7nYnXjXShT5FJkV+jliryfJcgYnpEOmhdMU0e31IdkNR0dMFadm56ehyDkjooVW+klyAsMAglULQLFjV0VQ9SkF6phiTBL3JK0amUCalNTCBAc8AEiIvETEfcawbk2V1YM/mmpzCavbPYun6a6leuCU00sZw2ad9f/4IazfS5PtiL7IDYbaIZqt/QcXLi1PT88zX+GYSsdca9WaYJXlld26Lmlszfd/JFJKOnZtHLt3sTa1EhHQ12ZyRt+Kgg8s+JsUGUpJ1O6YK0liMdglGo0yCRdNBKm3WL4ugtDF0X7Pnv84u1HX78vQa+uBr28enCTXrM+ExYtmtShnqSVscILQ0w9F80knU+ZItMJrHC/KnY/4zgYeUJBzS1pkJoHCcNA2wKmGXFADLKVqehKX+FFBROEBGQnQCS8LxrZVdDA7KYjhm1QtBr0z7LnGcas8gRQI2fCdjzx8yLx+x6pLM/kbbMNVRCz/kl8jiQ1MUqQYNpv6dQrz1a++3LnfvjkWQ1BV6SsDMbrUPWmg+YvKfqsmHgJVf4KJ+rirNHLnySpNxm8fvX8oU5GIgO5uczHq88GlWGcusIZYKoqYOiLyMvlf36rYjTA1M2c+k4EP5Bc7t8vT29ePnP6+scbm8f4fF597uBoG5rFj8UUq6zCYIrU82KKlXQqFHmCRJ+qK0lcxV6rYvczqqYOmjk8Nzur1Beu7MwsUL0ZquqFH0nG1Mi5yRVe6Su2uGBqkIAsBMCzIB52unAag6IGOYRWx0wWQTAOJCBvAqiiJtpkCq6oAaY0kLKzYojYp6i5h7TpiHl0Y4cd8+reuevg7b5Fq1bEisaM2rQG8+TYUT9+csMwDOsbKiF4clwseI1YA46Mp3t2PPuHmQ/fe8F7NI2xWy2zyDQwAu+D8ZS4uNzK0l+lXkv3aVuuPL6yvJM+nvB0w/LT4aXPuZZvYZSpnssamf/h6MriLm26Vex+ZujXr6uGEqm/o5JLMXjZEZG/2QjDyJj/5oBpWFe/kiu9tPBheEiggggkByDZsdy0UMxxNTR2Kwg7TEZiApj1cNS4Jy84EX2X97ZO4thkQDH2LqapkBMV8cs/4Ed6KX0KKQRVVCTHidnsQnNFpXkLGwUkL/D9p2zycjU/8gNevgW7HzXyHNuBZmeBapu5Oja2YM8z1rfAEIHtSSsjN5otJmya2RZ8nfnL4+d/S6ttci6MMtVzWSNXp9cA3ApRxe5n5eYtbBWQgq/vfVJLrC6c2A8fwY576nb2jfgvZNRsbE2rRKWvjBsNpgkJlEAAj75beFXfEdW0LiEkvAQJVBYB1GoIMDjJ1HPikKQv0qohzt7Vc3ICm67n+z14UKoJAgaXQ79GcRBGPVNjXvIMs14uLZTwxMcXbseW2CNJq20ZwnMXnctkaeCpKcDoRzW1xVu7rPCIP6UPTZZB+3KIqti4vZMBhse9evhZ/AhvblpankzQBBTOf7GyR5vWzl6nRXeNKwyFGTSyNQTjbqlJydwp6QKRizvlXBhYWeq5rJErasZ0cXYyn5ftfpb9zhOjMFavR097JSTjzeVrkSXcdfkhl69+YaHaHV06UjvuKTbq0MaotEqfn5GZX9ZKL0Z16A0JVEkCREEOkujLUw0z61MldYRKQQIIqmKAGLTigSD+vpKWiBh7FwHfvBrRURPNert3zX9RJc9pyPE/dvhJKsE069KjSWHyDItBE/sYoekvdqy+Gi3OhGH/fnTm+tfSv6glbZbowoMpiEpg4l5Odpb0HRmmrw8+gsb5GeAvRtcs/wMrTn4js8nmVKN31SptBnk0YOIxN/dfjKAvo4yPew88T5eemHAJME0MVP7Fx7y99yRGjHWCp0VGJYEHJl0D/dLmk8u7MMpUz2WMzB9sFMZUlc/KcD+X5c4Th4RhPmiCuxGW63twnbiqi+SGHl13OozNtB48rqfA3jXKrQf1sy6x0uf4Hzn4KKWslV6c6tAfEqiSBFhpRZ+T0GtRJVWESkECJAFUryUPBJGfKi0RcfYughkPXrm4mz6S8GjZkPHbHkfRT8XN+/1s24RJ+4PymPX7LpjkQK02wnR7LlrR1xgDsUf/7+I3UUMx4+ul+WNmLJ8/a59/RbxOBx+NAp+cYkf4fQYbA0t5KLVw6VwfwxNub9nw8G9xwzAn/N660eP2/FLVB3knsjMzpRRemcGV7CfM6W2IZrz1nr7+WXyxnOGpnw9On3HiR0Hpi+BLyQOjwYCRXXTQ3I97Fuz5SPMGOjfs0vJdL7MQNUeXbmK/9MZPQ7rCkKCsy1TPyxSZn6Xq8F/2+7ksd554Mlo9Fq7wqM9Ifr5m3Lz/wAdrhA88PfDEzPE7PmUqNhy9epqj0GZ3is285vatK67SpwUcnzX1cDiTasiEBcMzSKCGEmDnFGaMqQY3ZKihZVxTskV9b4JdvOUvNYcljKcxG4zYewZfNGPDndd7JnS/0KRTz65OLWzMjXQ1lInc9MTfYYEfnj987h+XSyiZ9V5xeIOboaDxjBm5bzqWkuO19tGtRR6+1z0GeXRt1bC+lnJB2p8wv1d3rtx4/4dj0HHR9hngzWT5Hwzjrl2a7PALfLV1xuqCcV0t6xSkEaZdOtmI+9qxkEaq7WatGPRmxuVfF6e5hbgO6tepuZmOQkHa35+BPk8fPg/6p+406+CEtCVTTsXEx/xBEBOhyFX5BDPss27316iJB4NOTOz9ufcQz+72lobqRHps2JeXt689DM62Gjm55aMjD1LKlgms3sD1W4NjZp35uHN4j+eunn27tmpirq/GKMiI++X/5t7V668jszGDLovWjDAv/VW/VIVRgJiUXrvKVM/LFLkQK+fPzSWDfcmPmok/ML2eK45OrcRxF1nv5zLdeSXwMHLffCItz2v1wxvzPb7c7D/Io7O9pZE6kRH3w/fZzf9ufYpjKZn33XB4SXuBwV2uOEyv16o9MyK99n4RrvR/f/i/vHv9YWCB4/yVtjeWnogUnzi8AgnUNALUd9TAF1zhAQlUYQIowih8/UZVWom1LcHeBTLUmozad69D/9P7j1568PHJhdAnF4oJVtCx7Tlm8pxp/e1oPlug2njModuNznhvPnDz45XdH68IxGVq2rjOXbJ8WleTCnq5y7QZu3LaK6/dvp9Orfh0CmjCbLHwcScbKwGdxDsxQ5dNF48YLVt19EXwnUPBd6iQCrqNe8zZuGR6D5P0c2ZMJPqv30cEaUtdrvoOTLvdwtNnDNcu3XE76Pb+oNuUxkydpn1Xr105NGPT4yPgDULxT25R4SRzYEY91l270XLnhl2X394+GHj7oGA0pmZDl/8tXjatu1nptimIJ01hRLHbglnopR9lqudliszVLS/+65f4krXEjGzSSw5R/ldlu59p77z2NtyNusuks2qjUQeuW53auvHAzbcXtr0VaJpQJaPWI2YuXTiiJe2Ue0zLae6pswbrlm69LlzplYycRuxcv8gdP3S/xIePMqkNI0MCkAAkAAlUBgFU0j0d8v599/sU8C38T1JmbgGhoKqpX9+ysYOTg7Vu6RYrOznM5/X7oIj4tBxcSdPAzNbBub19fan3Ci4zH3Zi4KMHr0Jj0lkKdeo26zXItRG1kEUi2eyk729f+QRFJGTiyjqGxg1bd+nQWK/07Esku3ID4dm/fZ+98AuPT81GVA1MGzt27NCSLKC8h7NbT76R3XbtuwtjS51rIEEW8KyYgPcfAsJ+J6XnFCioahlYNLJv17a5kQzf7imnwihLPUfKFFkCfFUkiPT3c1nvvBIzzkoOe//y/deYf6nZHCWtupbN2nRqa6Nd+nMOt9K//BIel5KDqhmY27Xt3MHOQKJnrhLVgRchgWpHgEj7gb+fR6qtoMHofr7a6Q8Vrj0EiLh3eMBmMr8algznXVJlXGJ7VyqpMHDNIMCJOjSo68YvusNOvd3SGVoCNaNQYS4gAUgAEhAiAO1dIRzwpAoTKIu9KzjltgpnEapWGQQ4kQ8eBbNRzdYdKmSSdWVkEaYJCUACkAAkAAlAAjWfALR3a34Zi80h5+/DJX37LXv4p9jeDLwI+T/OrT3yJZ/ZYODobppiZcALkAAkAAlAApAAJAAJVHEC0N6t4gVUnurlJfz4GeF/dpr7gIUnXoWnF+2Oy0r0v7Jm5LA1L5MVbcaum+kkw/Ta8tQbyoYEIAFIABKABCABSEAKAqWv6pBCGAxavQio2c86cVFv7cJN1y6tHvRwoKgAACAASURBVHV5k46phbGBhkJ+amxEZHwWG2HoOEz03rdUZEen6pVJqC0kAAlAApAAJAAJ1HYC0N6t3TVAw274tjuu45/euHHn0dugyJjQyGxcSbuuXTe3Lu4jR/Vtrgd3Y6zdFQTmHhKABCABSAASqAEEoL1bAwqxjFlgaDfuNR78yigGRocEIAFIABKABCABSKBKEoDzd6tksUClIAFIABKABCABSAASgATkRADau3ICCcVAApAAJAAJQAKQACQACVRJAtDerZLFApWCBCABSAASgAQgAUgAEpATAWjvygkkFAMJQAKQACQACUACkAAkUCUJQHu3ShYLVAoSgAQgAUgAEoAEIAFIQE4EoL0rJ5BQDCQACUACkAAkAAlAApBAlSQA7d0qWSxQKUgAEoAEIAFIABKABCABORGA9q6cQEIxkAAkAAlAApAAJAAJQAJVkgC0d6tksUClIAFIABKABCABSAASgATkRADau3ICCcVAApAAJAAJQAKQgNwJ5CTFxsal5MhLLis9MTb2XxZbXvIqQU5FZ0HK9ORcYPICDO1deZGEciABSAASgAQggVpMgJ0RGxb4+dPngLA/6fIzJ7PvzGvn6LzgoZwMXpb/jv5ObUYe+ik/DSu6yHlZGH0sgiNZyuykMP+wfyzJAtOEkjI9foHRSKpUL2alpg4ThwQgAUgAEoAEIIHqTSAj7M6RPcf+e+wXk1VogjHUjFt0HzRh1mSPxppwXK1SS5flt8Wz374I08lX3612qlRNKjlxaO9WcgHA5CEBSAASgAQggWpLIC/s0vwJS6/9Qoxb95o0pq2tibZyXtqfsI9P7z7YNfXRzXurjuwea6dabbNX/RVnaJlYGGhkWJhqV/+8lCkH0N4tEz4YGRKABCABSAASqK0E8IS7i0YvuJ5kPXzfwbWeNmpFHEZNmxd+Z/20eaeWj0LUbh8aZMIougZdFUmAYTn6lN/oikyxiqYF3zNU0YKBakECkAAkAAlAAlWZAJ7ycMOKq7FG/Xee9xYydrlKq1q6rz+3d6hJ0r01q68n4FU5I1C32kAA2ru1oZRhHiEBSAASgAQgAfkS4IRfOHg7QbPH/JV96tKP3mL6PZYu6q2b8vjIma/Vd3mYfKlBaZVFANq7lUUepgsJQAKQACQACVRbApxfd+8GFBj2Gu5uKN6SwPRchveuh3+/fzeEMnhZvuu7WtuMOpeEI6y4j+c3TB7Qxal5I1s7h44eXqvP+QFv8Qcee3aUXYNGw07E0O9NkH5npr2ljcfuMPEixF3J+LJvaEsr2y5z7wjJZiX6Xdow2bOns33jRs1adR4wac2Zj4lUXoSFSRCW9WFNJ6tGk65lI/kxb44tG9eng30TG1s7x059J6w6/ekffa6EUxE8Y8d/urBxSskAc65Nsm1gN+22yAYX7HifE8vH9+ngYGdjY+fQqf/kdRc+J3E40UcG2jTst+8nnS6SpCeoHyJxgYlBKiSsbCfia2nZ5MLYkAAkAAlAApAAJFBTCeApn3zD2Kr2zq1LXoym7OjsoM4J9/1cNKUBL8jPzc3JSfqwbWjPQWvuJRm0ch04zLNHU9WYp4cXDBq06kWqWJMXq9vL1Z6Z7nPjViSdOZb2/M7ThIIGXV2spMSe/nn3uNGbfBS6rzm22Z2aa8z583BF344ec08FIZYdB44d49nRPPvD8UUDe4zc/yWjWAoShiVwVl5uTkbC661DXUdsfZlRr43H0BEDQd5/Pz+y2LOX16mwvGKCxZ4SmR+3D+kxcPXdfyUDJNgk7vxiBmVO8KFRvYYsO/kuxcCx99ARg11bav6+sdzTZcLpoNTMnNy8ApEykDQ9IYUlLrDyX01W/ikI5RyeQAKQACQACUACkEC1J8COioguYNSztBRYpEabKaUGViYMzp/I6AKkvhIVAo+/M2/qb+XR51//r4NRoSWCp33cOnzE7lPrjw7ssLA5vXmCGbh6dl7/7MGdmz+mzG9ULEzqs3uv0xVbevSzop9fQaUu7Ej33Tlu7LbP6u5bL+wZYqnIv5j1ccv4acejrL2OH1vualKoOp7qu2/y+C2bJi03f7DLTZ8/ZihNWAQp+LJnbpj9lEtvZ7TT52ua/f383DGLb6+a7G17f2Wbkp8hSA2J5MdLp/5VlxogL3dpz1ZP2vAqu9H4E8dX9TLhZzkn8s66yQsXfeJwkAZ8Cvz/sqZXHgXG10m6//yyki4WDA0JQAKQACQACUACtZcAnpaWiaOa2jpoKQwwLU0NlMhMTyMEA3IiAjPd9x9fQBm74CKm5TRzXl8j/MezJyV8DUK7u2cPA/zrnRvBxUYskaSn995kKDu69zHlG5GCKdK7gY29feyYbZ/V+mw9L2jsIuzgQyuPhKr1WntsNWXskjpqt5qxb527XtyNnadC+QpIE5ZUg8jVG7D38OwiYxf4qdmO2Ll7QkP8x9k9V2NFxlbJWMIHJyY0VzaACML5cXbnf9FKbebtX1Nk7ALxqhbu648tc0CyhIqKl67s6cm3wIQpSHMG7V1paMGwkAAkAAlAApAAJAAIFBQUICiTySjN3kWYTAwhOAUcISMO1ek1Z047reIkVR0cGytwoiMi+KZk8QDgXL3TQNd6ePi9m5/zBa/iSc/uvctUbdvXrb6klg2e+n77mLHb/dTdtl7YO8SKP8xJSs15ffpCCKfx6HkDqdkN/MQwg94TBjQgwh7cLzR4pQnLFcJsMmB0Ww2+POq/amuvsW2Vsz7cf5ooxIoKIOgoA0DOr3v3Alna3ccOty42QI4gDNOBY13oJmSXIT35FZggAKndktYKqQXDCJAAJAAJQAKQACRQYwnQDAJKnleGaRM7bRoLRFlDQxnJy+Z/p41WoLKTp3sDJOr+jY8CS7Dw5Kf3fDLrdPBwNaARSyMHT/XZNnrcTv86fbyLG7sIwgp6+S4Rs+npaitiEQJRinZOLbU4kSFfM0m50oQt1IOpKGhbF3qCweO6HdrbMvO+BoSU/vHfMgDMDPD/wVZs7txOk0pZwIGpqijRPMOUIT1EPgUmoKNMTrqSlEkQjAQJQAKQACQgCQH87l18wwbm+/e8wPjmzURSEmPbNtq4+LFj+K1bzDt3aK/Ky5Pt7o717YtNmEAJ5Myfj+rpYYsXUz48B/AHDnHaFgsMT2syAYwBZg0QeOlWL4dDICjGZEhmhqIoihAEUqJYxRaeHo2O7np8/e3Kjj1584fxpMd3fbK1uvbtqSdROqzvRyet2PU5o0635asGWxXNKy4ssaxfv+I4jEbJvpfOBdAUIv43WQFlJyUmcRBthjRhaWQJejHqWZiqEiFxsVkIoix4QQp3qQDZcTHxBZi+mUUdKaSKD1pqeiCqHApMvAKSXoH2rlhS7LZtyQ5ApLmnjSBVn0R2LZMnY336CIoCfR7+7p24Xk1c3yMoQdBNBARwpk7Fli0TTKVUJWGfJ8gQuiGBciJAvHyJOjtLe1MDZchb+PhxWq2KrGfxYXgRQdKUtUq2csKtBNU6EWFhqK0tbVo8T57VLi4A4+BBtEULcVehfw0ggNZRV0WJrMxM8Oq9RAsThMkmUDV1dZpBQ1k5MG3792uxb8PTG8/Te7qTo5R44qN773N1XPt2leiruZyfJxdsYunYt1AIfLF50dk2p8ZYCVlDnMwMMMKcH3B6KZ21W6g1U7+ADcxyacKWml+GmpoqRoDNK0oNKXsAPCcnl8DUNNQln+Use2KFMctaYGVWAAgQKmF5CKyKMjjjxhHfv5esGWjZGSdPUmGA9YnwxzbERac6GCoWz1FynwQsUczZGYzugD6P6nVARNTFBQ0LA50NvcmbnIzw+54S5FN9DPHwIejVBI1dkATx7h2w4ItpC05hnyfKBPpAAuVEALQA4E7k3argfie4w6gSpgXGXwWHYMXG0tOjb0ZA18wdnaUiAjXIB2P+szfviRc1NgZKIklJkqQl2gzyHrapJKCjphJgmpjUwzg/f0ezkMYlWhIFv3//5WCmJiYlhpISE6NB3wFO25e9uPE4yW2QHoYnPLr/Mc+gb78uorNi6SQTuey6Q3af8+4S6z1o5IE1071trixtIxAVxTAGihmPPPVgeWsFOgGkH8pUVgd5wqUIK04U5U/ks1gEypBwLJyKJpUDYygwUAJn46VPEpZKbomBy1hgJcqW8KI865+ESVZ8MEFDljZ18n1iWNH21KC9Bi8QwbAHL7BodN7QL60o4FlynwTGPMifiwvoZmgtVyCckkwNvQB7HZs9m+cvKp/XwQCTHUgW7GwKRXE7PzAYA4SAn+D4EK/ThX0eBRw6IIHyJkA+i3JvVZAQY9068Bf40CYq+KTNu5dFjUvaiJJ7ghZDUCZlJZMP/NwnYUoUqbONDWgYeT5AH/BETV2FjlpIgGFk38wY+/zlYwjLtTXtbNTCuvLdLzAVNXKzryfX4USsntuADpvfvrn18J/nSP24h/c+5tcb3K996ft4cbViNPTa7d3PTBExW7h/xbf+yw/OXNLk5t6+1EI3TFNPW5H4mp6joqlZ2n5r0oQtrZ7gWf+Ssgmmlo5Eo9SlSRNzHdPV1UHxn8klfthDTFzZvctWYLKnWxSzVti7RdmVzIXv3s0bHAX2KDkSIzDuy7MmMS8vauRDtj6J6mYoOUA1IAr0KMVmUFDmL7CPeerzjFQqK4UGrp6eoJ5UGNKk5nZRxLVrgmoLvouklOHJhH0exRY6IAH5EgB3K7gfQfMieAPykqDudN4pMEN5dzQ10wnELRZGUDcgs+h9UVJSySF5EUnJfPsV+IAnYd7DMGgowNwqqrkghwP404tB60TN3yUfod+9KyEhQfWguwYSULR36WZ84uT9a+8XtO4k1ijM97997ydeb4SLvcgc2bIxwQxcPDuve/rk5t3YoT0f3/vMMh3Z10nSOa+osrIKbxKGovWYXTu+9ptwftGsJlbnpzUplKDWrLk141HAB/+8vu1LEypN2FLyzAoO/lHANGsoOqG4lIjSXMYMrC31UN9vwVHsnrTL8aQRJnnYMhWY5MmID1kr7N1CI1V4mpo4JrzGncm1cUHrT43ygvCUaYs6OlLRpe2TwDBJMRuaEkXrAN0eZXYXmrbC4Xh2MGWkCl8sPCN7JtBjCSxGoYLBPo9CAR2QQHkTAM/SvCTAFAJqFkGxibykKXz4MKUJMD157mLPpby5B4IPzFQUMBdLXIMgOJ8BGK+8p2uyZUtKIicwcFcsgDYBuMkf9wCXwMK1IuHCLmp4mGw5w8JAe0jbTAlHgmc1g4CS05gxrS6tu7Ll4LBW81vQjqyyf53beiFcodmCMc6018sEQqvbwJ4Gd6/fuvWR/cKvoMH4fg4ymdSYfs81++f9GLLFe9q6RjfWddEhDWGGpZt7y10b7py4NaPdEGrYl15dacLyJBDpKUlsxEJkwDvr7d0X8Wh9l47FP6RBn7CsvkqturTTOX/r/q3QmbbNiw/N42m/Y9NwRGSnOFkTE4gnpwITkCiVs8RZ5lJJqimByd6FOzoCxi3I1p87sw30B+Qwhq4uOejCnfEGTkG3RGW6WJ8EgvF+5CRgLy/qlByAMTIC/QeIDnoFKnopDtDx6OqCMMSfP+Av6Pao8GTPBO7MgwcpH1oHGNwFI8eCXR0vGBAFOjyeesAQB9oCf5Br4FPY4Unc5/GEgLhADnCXqhKtntATEqjBBMgHV2A7ikwDICdTiTEoQRSe3Uk2OMAtwQEsYHHGLogNmqCiYWDuAjggmTdXijesSz4AgzZQT4+a4lWCerTq8OxywWaKNhj0rAEEGNbjVs9wZAbsnjj7XJjoCitWzN3FXhve5jeZsHpiyVN8ZWSh1mGgqzHH/8yik75sG/f+zYqbbhKLVW0xY9/GPrrhp/43/79o3neKGVYj5gw1S3+0bs5B/+KfDkZYkVfmDJp0IrAwz9KE5erECT+3du/n4mIzPu3ZeuOvYrNhI1vLZLhLnF1EvdvYwdbIt5Prjn8r9vVidvS15d5P0kvcHUPydIqHlFuBFRcs0XktsnfBEjHQstP+BF/qga4CmGtkn8RdrwYGUUAU1NOTtOG4GwbxWnNwCgQCOxhglqpPAgY0SAIYhfi5cxIVETBzqYXS8fGi/SIQVWrXAgZdsJEjgRzaLhN4wj5PwrKAwSABmQmQL3a4E3aLSwBGsMArI8GrvMkPwOQFD5DgdRN4SAYtEu8plxcMuIEPz817LKdt4mg9yWHd79/J5o7/CA2aJpAi+As2kAGXgFjysZxOPTJR0Bxx5/jyhIOIIEpRQnyteLrBvzWUgHLzWccOTbHLuLfQreeYtScefP7xJyktKTbc/+n5rVP79JxyPqbeoO1HFzmpl0/+lVsN7NOAiAmPRuzcPMo0Jsow8dy6d1LjjIcrpu38ks3VVrPL8n0L2yA+G4b2nbLztl8MuSUwOzs28OHh+f3d5978q6qvR810kCYsEM6oZ5Z7amS/aXvu+Mdmk2LTI9+dXjx03P5ghVazN0wsU04kIq3kOGvTlKZsn43DR6y+6BOemodzchK+PT+1fHC/JYH6jXTLyzSUX4FJlE3hQLViPgMvy9TaL2EC5BnoM6jBDPKUN22XO2gKmn7R8Dwf0E/wHLw+iezMuEO/oOvirFgBNmHgvSskBYrsNcabBQEu8bocnhzwl1xPxp9RBwxZXjDgWbhYDXQ8NjZkT8MfduVFBH0MzwGi8EJSk31Jf+7QEejSQB8GbHSgHtW9gYukyc4dt+ZJAH9BloFA0qDn7hIKfEro88CALghAKcATUnQq/r0qLyT8CwnUHgKFd73wgy75CMq9Q8FdU3jLc+1IgAW0G2AiAfAkn3i5C8vId0qgEXBxoaCR7lu3gD94kKZaFfLOPXy4hLaLig4c4O4GzQXVPPKaNSANtBVkctxnbKrF4LWNIBZo68jXTQI3OK8VpXQQTAK6azIBzKDryqu37Xdv8D59dNljgVeNmKpJ21Hbli0cZk/3WQk5IVFsNtCjyZHt31u4e1iJzA6QMg3Ndov3r/g+YPnu6Sua3NpGfrVCreXMszfMtq3YeHrr5FveCMZkImw2jjC1bF0WnF03vYORgFkoTVgENeq7e7Pe6UUbp/fexGYqMIgCNgdBVRu4LNvmPdVe/jM/aEhotlty5oTy/AX7D8/1PDy3MICKccfx+y50fjti6HdyV91yOORZYNKqV4vs3RLQUIYpCEN2Fdxpu1QTX8wkpeTw1nNI2yfxovOsTPLdosBiOOApul6N7HL4cxjAe0ZgXwq9juTPmaO0Im1Tbm/E0x/0T5QBDfowsAkamEFYmCi3l+W5YZ9HAYQOSKAiCYDnZPBszDNnQQsA2hPqHQ4wc8HjK/H5M6UPuXGv8PscEBG8jAITlhD+nmIgMLk4lW7nQUoOzwEmOIHUeW7Sut2wAbgLbW7g4IoFEzCAelR4MgD3FKQLFCthXi8vCvxbOwio2bgvPeM+NyHY58PXmMSUXFRd36xxKyd7Uw0Bg7AIhaLTmnd/1hSdC7mUe+//9ne/oJfakNPRQwQ9hNwcgoOoOHq4i06GFQpWdFJC6ooNx10IIV/aFh2q1h4rL7nNjvR9+/FbTEoupmZg0dSpXQsTNZqcSRMWUW001Ptev7nB7975hydkYxpGDVt1drbRlshoLyEL4DMVkgLEDDvOO/tuzPc3r31/JWQi6vVsWrVvY6unmPf0cS6O1q+jQRm88kmvEKrUBVZUGGV0QXu3CCDPBuWdU60/MGopk5Q0hQW+isQLKVufRA7Z8vc7K9KAzgWMVOANxn7IDkyyHTHpxBT6AVsZiCJtYv4YEuzzSsAFL0EC5UoANClFb2/AYypvmeyxYzw7svBZlG/vgtuWNI5F2g20c2fQLoGrvEdcoDCQCX68zRZE9acsWtAaAPMaPEVTI8G8R25eFDADiveaiBoO4D1pFy0D4K4rAFFAWlQq1Lsd6vUXdQk6qhoBgsCR9F9EchARcVUeuikbNu3at6k8JEkugxV0406YUpsNbqUsKZNcIl1IhqZFGzeLNnSXRPykCYsoGzXt5tm0m4iQivNg6tl2GWDbRSBBTszX7ymoYUPbchmWr5gCE8iOgBPau0UwyJEMke3Aii6LccnQJ5FvMMGyMIHxGDGyC71BSPAjX3fyB1pKDl/yVV4/RA0awT6vZFzwKiRQfgSAnQqeYyk7tTAh4dlKVOpgxj8wVUXbDeADZi+Q2/pS03D5U62ouJSjyFrlevFe/gCrFxi14C9oA6nHeyqKoCVNeQIHOcsCjAFzXzpRNjHw540LCIaE7ipFgMiMJm3c5EAkJQTMRxXSjakidFrlT7Jen7sZodp+uqshzXBrlde+MhXEkz7c/qzr4mJNTUEu1Cbt7YnLwYTpaHfZNrsoJU+VWmCwjhSWDjnkCboZOzuqtIAPMDGLdQ/UVXGOEvok8JqSt7E86CGktVx5k/xARHIQWk4H9S6S7POSksgXqdwpg6TdL/IVZZIP3UH2edwPv4FuG1jS1E90FIouNvSDBGovAd4TrOi9BgZcwbwmUS7F2w0Bs5j8ZCN/ZoJoREEf6oblefJuWOAGyoB2gBroBfc7GNwFzRS4u8FqBEEJPDcIAIZ1xS2zEw0PfSqXAJETj8c8wgO2cp6Nwt/OIL4dQRI/Fjd2GSqozZjK1VO61LN8D2y/lVDXY7SbPjRlpEPH/nlp47yJnkOWXw4AG6Pxj5zIR5u9Zp6NNnBfNKNNcUOYH6gM/yu5wGrF+G7hsEdIiOAUt2JlxrNEeWMnha/4wVIM8cMkxaJTp+Roh5cXdUra0PyD1yeh3H5CKAw/gLj/oGvhTSkG6gF7F6jHe7EoLjzwF12vViww0JO3xxnw52UT2Lugz6NOgYPq85DkZNDnUX0hJYrX55FTDCXra6mI0AEJ1HIC5MwBgS9EkPPsjx8vZML/knkxRLz7tLB1AtdAMP6O2sBopu3vi002AJFAolQscMq7x4EDtEjAeOWZ4MDGJRsc7l684BIQAtbIFrv9yQd77rRjEAAYyrxxYuCGR9UhQOSlgHFcJCWQ/JubSK8YykC0bFDdZqhOM0TbFsXEfjuXPnql+GaEPnn0NTk94s2VM7dCNdz2zO2sXil6VOdEmTZTj57In79o/xzXs+ssGzc01lbIT4r8+i0mU7nhgC2HvPvVpW1RZMtyVSkwlCDKaZ812biUVyyh7kRMIqDFBz0BaNmBYUoNuoh2GIKxqS6BlC8wOiLYJxXvJ7jfNOJ1XaI7LQgKB27y9eXs2eTqaYEvugmGAQmBU0Hzl9eBgdXTPCtfULFiyVHWfLE+jxrXKdbngXFfKi+8dHmagNTFUaKSENQZuiEBSKAqEODdttTODDyVeE0l1YDwPMkGDSyeA6PI3N1jQHMEGodC+1tklS3tOoeqkN/aoANRkIUkB4O5CuR0hew/YrKMIhoNUN3mwMxFtJugzHIYyBOTsFy8Ob8PDnBe+4mNKBo6Dl68Zc3QxhWyn4FcdAdC2KEnZq95rDl81/p+gts7yEu8dHLyE/yf3nnwKiAiLiWXoW7YoLmzq6d7KyOZ9zGmTV2uBUbEvcMDyHfRiIYlw3kXbYLiPGuLvSsu/1XfH/RJxYZkgM5gLJYaUCnWXUmbI9jnSUsMhocEIAFIoOoQINh5SGpo4ZTcjAgwak+vm5pxoY2r0xRVrEMfpnr44vmpsX+zVAzr66nKcRSyeuS9WmopxwKD9m61rAFQaUgAEoAEIAFIQAYCBF6ApH4nUsCysyAkLQwBe3LRHsr6qF5zRIccykWVdWiDQE9IoBoRKIu9Wyvm71ajsoSqQgKQACQACUACogT424dx5+OmfkPwfNEwpI+iFqrbFCGnKzRHVY3ow0BfSKD2Eaix9i6YxkT8eSJ2kn7tK+nKzLFCHdS4B6qiX5k6wLRrGQEi/j2REiz23W4towGzW0hA0xqt2wnFJNrUv4pA424fxrVxRbcPo1RkqiE6duQgLrBx65hR3tABCUACFIGaa++GnSZiHlL5hI7KJUAkBTDaeleuDjD12kOASAnF/TfWnvzCnEpBgMBR4+5ShK+MoGD7MHLBGbnsLBhhpdGrgCkhOo3BvgrksjNNSxTstAAPSAASEE+g5tq76T/F5xpeqXACGTWuOFjpsVFRf1JYKnqmVlaGZVwgnB392S8yi1A3d3Q0V5OscLIiff2is9E6Fg4OZhJGkUxwTQhFpP+oCdmAeSgPAum/kCpp7xZuHwZs3JRStw/jbq0A9hGrFtuHlUchVkmZrHi/h/deBf9J5ygbNO89qm9TDSnVZKUn/stCNY301eGzi5ToJApeY+3dotwzVRF1k6JT6KpIAqwMJCeuIhOsgLTyI+/vWr/9xPU3P9MKyIXQKKZs0Mxl7MJ1y4fZybgNJDv85OTua76w1bruCn48S5LvwHN+HBrTaeGbXKbDar8Pq5rWgvtY9pLVovl2g+zSYMxqSgAs6qp6B3f7MHLNmWTbhzVHtBtXu+3Dqh718tCI8/vWwjHzL37PQhXV1ZVxTrDeAPemGnhSWHCyThMbfYk2+GIF7Ow/4LjWohe3Z1pBg7ccSqnm95OoXku0DrR3y6HuSCCSYGUQ0fckCFhtgqS/39i/36pXuQ1cx21Y1q2luTYjMzbk3c0TR7aNbP8s4OrDTd11Zd8gh8h5c/JU8LQ1LUq9LVl+J099yBOz7VC1gVkRiqoZY/otKyIhmEbVJoAjKJL2vSroyN8+jDslt4Ttw9RNuHMVmiO6TVEFGZ+kq0J+a4MOnKgzCxZe/KXZY8WpjeOd6ysjHDaHgbH8Nnn22xdhOvnqi9VOElm8tYFVJeax1I61EnWDSUMCVYxA+qMlo1e/xnpsf315TgtqA8vObkMnjDo8pNv0HZOWdQ081Iu6IJ32DKP6BknBZ4++WrS/WynTI7KeHj3/HTE2rx8XK10aMDQkAAlUAoGi7cOSAhEw2Ubc9mEqBmDBGcJbdqakXQmKwiRlIcAJ4fDcpQAAIABJREFUv/WfT6au+7Zd05x5pcZgkgO0WiYWBhoZFqbaVXK0Nu/Jom5zHzdZ8fzI4FpS1aC9K0vthnFqJQE89uLOsxFqPQ8cmlVk7PJIKDea4D3r9MNlV0493NprkGwGL2buOaLR8Z1Xjt5Z121ISTtl4gnXj13/q9510YC0rXuLPn1eK8sEZhoSqKoECGDUpodzP3UWhKR+RXAWvabk9mHNuNuHNYPbh9Ejquq+BT/CIjkKDs7the1GhuXoU36jq67y+ZnJySmZeWK2bq66esusGbR3ZUYHI9Y2AqyPb31zmA5uHsY0UxYYFh3ammOfvwX9Yg+yl+22wg0GjO99auz945eiB00zo0mDB5wTcf7Eo3QDzwkeWlu21rYygPmFBKo4Af72YYEIuX1YDr225PZhTbnbhzWD24fRI6pOvnhOdi6hqFZHqTopXQt1Fdup1kIWMMuQQIkEmM299p4+vdLNgPauwVRVlVGCxWLhJQop4SKHo9530iDT3FcnToWIH7ZlfTl5yodlOXSSqwpHXFKs+A8nlwzt6mBjrKdb16Jp5yHzD7+NFxbJ8lncXFO7++4oTvb3a6tGdmlioqetYz76soB+7L8v980e0K6RqYG2toGpXaehi46/T+RwInZ109bquOW7yKiABKkKSIdOSKDGECCy4/CYR3iAN+fZKPztDOLbUSTxU3FjF2wfpmeP2ozF2u3Aul9gOCzDzN2hsVsj6gABl1JUi3KUbSCqWmQNKgkJyJcA07LLcEtxIvHET58jOeo9m1nLvC6Bw+GodJ40qumxjeeOv120u7MyXVpZz46e+4o5rpvQVin/ETBhFYoHAuuE5w0ct8+PY9HJrdcoN62CuJCXd/dOvXHh+vob/y100uSHx1l5Odk56Z+93aeueM0ysXds21kdM6M20Mn23+HptvhxoppVx14DXE01OMk/PlyY1eXS3W3b7dKzc9ACYVtb0lT5qcP/kED1J0DEv8PDryD5qUh+Cn1uUCai1ZD8BgSYlQsccPswekwy+3JSAm4cP3n1qe/338l5DHV9c7t2rsMnju1lRbdFIyvu/eVjZ26+9PsZm85W1jQwb+bsMnTi6O7mwsslWL7rXYafrb/q3emRGgkfr5w4ce1pQHh8OkfVoEGLroOnzRjuoMcf8WB/29mv796vbITDYiGc+zPtGswhs8KwnHj53pKWikjOtUktF/h03fXpgIdwGuwEn7N7j117FRiVmIXUMbJu2c1z4tRhzcVyYCX6XT965MqrkIg/KRw1Qyv7Lv28pg53MhA04CTWO/3yeKclL8HsGg4rl+C8WdG6wWqQsIL9wkf/TTGvkjONxXKR8oIgLimjwuCQACRQSIDz++riLc9YjWbN6lfSzNuSebHZbIRpP258xx1zLh+9u7rzQOHJYGRkPPHmsWuxdbqvGGPLwD+zOURxezfz7Yr+I/aG2868dnVLP/PC12t4is+WIQNWLBs8y+rTyQGG/MYaiIs49j9v1Z77Puyd5KhT5I0gqQ/mDV78JKvpjOvXt3mY8S34nF9XFgyZMuUth4NYC2VFulSFosITSKB6EsB/nCXC/6PTHUU0LHmfOiO/B8GgfW6liwf9pCOQ5X9oyoSNz/5pNOrQrU+HenWI1IgvL65uGHftylDvk5sHWPDbLVIqO+be6knzTwbk6jXr2LVfV0OFrLhfX16cXXPv4vmBm45vHdJQoJTwgvzc3JycpA/bJk3eE1KnVdf2rvbqBSkRfi+fHl7w4lXY8etrumhzm0tMv+O4BapJODv08uYrEY095w+wIe1FTKt5fa5pRbBJSfnCr9aQnJCjE0euff5P1aJN595d66uzUyP8b670vPV0xby6NAQ4fx6unjjnRCDHtG33zgO7a7ITvvs8Ob7owfX7i08emd6SGqJAJNVbucWgBYucgJH+4+a2CyEmvWcPbwFyzzByqprL6miQyOoF7V1ZycF4kAAgwEqLCnp9+9RO72MflDx2X1rfkW5cQTJSBKeAjSMM82ETeq8deff4fzEDJpsI2qBACifywvGH6YaDJg6qhyEs0j4WPtj+2+fsDFT3OHp1ez+BB3VMp92is7uCHEZeXHdgjseaounFnMQ0i833T06xE+wZQDLfDq87HaHcwfv8Dg8zgSZC1WrQnqtpv1tPuSuUrLSpCkWGJ5BA9SRAZP2hVxxMzDVqR9q7cN93ekBy8cXjbs73Wv+S6Lzixp4pDtTTen7UnRVes8/Nn1LX4vYCe/582vR3G8bMOBFRb8D2oxuHN6YsxOxftzfOWHBy/ghE9c5udyPB1haPvzNv6m/l0edf/6+DUWEbiKd93Dp8xO5T648O7LCwOemJ6Tl4TnRAkOzLPt5XYsw6j51cbByXJqvpL9ZNXvsiq9H4E8dX9TLht7x5UXfXTF6w2icfR7SEImV93DJ+2vEoa6/jx5a7mvBHMFJ9900ev2XTpOXmD3a56QsoLoneSjauXjYgkby7gXsufq3XdsTk0XpCadbYEwFQNTaPMGOQgLwJsIPXOiozmUyGso5Fq75zjka23PDc97/JdgKDBNInyeHZr7oekweb5bw4ceabiDkbcPLkO5bVsIku3FkJYItH4URynh48HsBpNnnVKAFjlxcEMxowa4Q1EXrzeqCAVMyo/9ypxYxdYO5+v3btM0vHbZqXrYCxy5PDsBg1rV9doXdeUqcqrDQ8gwSqJQHMZiyi24JG9ZQg4ush/M00zvMxeOB2/M8TIjeRJhj0KguBnPd7N9/9ZzJix/5pRcYuEKhk7r7xwFxHJOTkwQephQnk+x9Ycfy7SqdVp3cJGLvgopqVx7pT3n31/15f4/0sXUgdTkRgpvv+4wsoYxdcxbScZs7ra4T/ePbkp0ArKhSvtBPOz3M7L0UqtZm3f02RsQsiKZv3WX9sRVvFYpuqs4MPrTwSqtZr7bHVlLFLaqLdasa+de56cTd2ngoVUqW89C4tX9XjOrR3q0c5QS2rFgGsXs//bdm61XvTuhXzJ3o6G6c+WDZowIJr4WJ2HJJIeQKM13KXPah2nDiyGf7lzPEP+UIRs8HU3VBGq7FebbhP+SA8mM8gcLD8Hr2Ix5q497cTMVNBKEX79k46nJ8BgRlFURgmDW2E55WR1zJ8P31lKzp26Sw80FAYDVMD6/KKRCDSpyoQGTohgepKAFWry2i9Dut5HWu9AbUcjGjZgk8tCmUmP4X4+5II3oO/9OK8mogH78XjXhP5wnaVUAR4IimBnNeX78QwW46a0pFakEBFZVoP6u+okO77xp/Xfua8On05jLAZtWiElWjDiBn1WTjJSenv3bP3/wkuSUB1es2Z006kBVR1cGyswImOiBAyMqmkS3Vwft2765+v3X3scGsRXRgmnhP61BeqQjmvT18I4TQePW+gidAYA0gHM+g9YUADIuzBfSGDt5z0LjVj1SOACPPqoTbUEhKoVAKYbpsRs9tQKnASXnuPGbZyhFuu6rt9rrJ+YQ3HCxtcZtPx4zvtmH3p6INV7fvx23P8361jV/+QU3e5U8RA2nix/Rkyv3//w2E0/edz8qgvpVqRA49JUkDZifGJHESneONZFArMdPsTHVuAGVla8VMWvCjqllOqooKhDyRQ9QmgDAXu5yGaAVUJsPtYSij348ABSGaUkPI58UROPPLnMfmEqm5auIJNxw5VkH0ClJD82nXCCv3ol4pZte8oYgaSHDC9nvN2qf7Ws+SaN/kBr97/wxoO6yPyIovHjGHm7tZy84fPbz/lDXOjnv4Zpk3seHN0hckqa2goI3nZWcVerQkHEn+WGeAfxlZs49yOtnFFlZQVhcYSgl6+S8RshrmKvmgDSSjaObXUOnQ75Gsm0pxa6lFOeovPUbW6Au3dalVcUNmqSYBh2HHJhYM/7QccX7ZnUg8JvgdMnw1qtBYzGzahz9oRt45d+esxAUzVBQcn+sKxB2lGgyYOrFs0AkBF4IZIT8/kEHm+B6fTWbuFKSoYsgqEYhX6C/zDs7NzCExdU6Mko5gKz5FTqpRA6IAEqikBlKmKGLRCDVoB/cGn1JHkYO7HJgKRnL9COcr6TYBf9B1gmSGaYGUb2L2hGaINVrbxp5sKhYYnogTYMb/jOMxO5hb0BgyjvlO/IU6F0TLDI+JxVZfGPOtXVBaC6TdpVBf7GB0Zx0EsS230UBRFwPZjpTSiNMmQXuy4mPgCTN/MQrJPEmX9+hXHYTRK9r10LoBGIv43GYxgJCUmcZDSV5qVSW+axKulF311qZZZgUpDApVJQKfXcLf6Z449fhi+pgW5GKBsh477pMFmV4+dOBM2bnEj0Aazg06eeptvPXsSb+ounXAUwxgow2zSTd8t7UV2KeNHQJkqdUq56TGmAhMlwORgwdd7/Pgi/+WVqohg6AEJVGMCqKIGUtcZresM8kDkJhEpQUhyIBj6RfKSBHKFI+k/CfCLuIpgYOcyW1SnGarXHNEEO5eVcpcKCKmFzrycXA6qoqZWqnUKBgqyMrPxkh/fMU1NDRTJysyUzYiVgj+ek5NLYGoa6hIoDlTPzADjyPkBp5fSWbuFyTL1C3jT4KRQo9YGhTdVrS16mHEpCXBiP933jddv6dbGlLa1YpqY1sPwxL/xCFJ2exdR7TBxVPMjG06f+DR3a1vFnJdHz4YwWm/was1fzyuqPKZtoKtEBKVmq2hpqYteltgH09fXRfHv/xIlsnfllarE6sGAkEA1I4Cq6KH1uyLgB2zf7L9g0BdJDiItYDAGTB04G3yPjQC/XxcQsIUZGO7ljftqNECLTQumotReB4OBIRI+kqNgWTEK5n6VNOGWxS4A+88yxY4SyA00xlDAUAJn82eulSyYO5aAGY889WB5a7G6oUxldWjGlQySulr0apTygg5IABKgIVDw5dBEz4ELr/wWM3WLyMrKRjDVOnKakMe0Gze+k8rPi0cfZuLJt45ciVHvOWFUQ1pLu1BZdQfHRozMz28+5dFoL7kXZtTIxgBNCfL/VVIXQcmTU6qUPOiABGowAVStHmbqitkvwrqew5z3oLZeiH4rhKkilGVOHpL0hQg7ifv8D382gvNlIx59l8iKEQpTq0+UdHTroLkpydmlP5NjOoZ6ykRaQny2WGKsuL+JHEzXgP7DmWKjyXAB09PVQfHU5KTS9QbSMU09bUUiIz1HRVP8oaGmBK04SYsCkpKUlHzCsXISElL/5UhU26VMkZWckBqXXpYNAsQmyMrMiE3IlHWKvlix1eyCYgvHZsqcgEcP/tAWHx7r4/OLo9mspRwGd7lkMLOhE/roxt84ceXz+WP3U436TxCcuksDj9HQc6CT4u//9l2OodWQJgqtl1I7l856nKDrlwNpahOeEvE7RVC8vFKlVQV6VhUC7PTk1NiUPDHPelVFy2qkB5hPiWpYYBb9GI4rse4XsTZb0YajEPAZtmLfYCvIQhLeE18P8zc424bHwA3OFBo1smZyfgYF0j/ac6KenTxw5OEP7gO7UrPmNsz8wA8fssTUDlbwe780hkWzZnTr08TEkdEb07e1NkDTvgVHSTSWoNasuTUjK+CDP302ZVSiFkeD9i5t4ef/+R7+PiQxTbBfpw0opWd+6KO+gzeOv5Ei/24jJ3DesPXtvUOk1EiS4OyA0wfaDDlxMlbeOCRJvOqEweoPmuJZN+f5hllHvwlvFAZ0xONurd71pqDBUC8XgaUI+X+D3gfFiQSWNE86HpOGmGc92DBqxxtWwxGTeglIphXBsJm4fFyDtNsLxm37JLLrEevX2fHdh+zzEz/MQcms03vamEZI8P6Fe4OLNbTsiPOzVt4Vvi/klSqVfLV35MTHfPD/5SP0C/8Q9Ds0OjVdon6u6hEoiNk5c2PbJe8i5d9yVb3MVrhGKMpAtW0xy8GM1uux7pe5G5wNEbPB2SsihLvB2csJ5AZnf8EGZ2kVrm+lJ8io361rM2bii9sv6TLP+X1/96qNp96ncjsshmlvNwfl5MdnrkTTVV486eHpW1FoQ1e3phUwLUDJoYuzLufr/VuhdGMJWX//pgt2sgxLN/eWirF3Ttwqn74Xw8i1dwQimGall215KgDtXTq67ORLWw8NWvnKv5p2TnR5gn5lJoDp99t2bFazzLvTO3bw2nbd9zd3xJuV8uP1meX9Oo44k9h09sE1nYumM+Q//V87B2cH5/nPZbV4ldtPGN0cifzxm+k0bnwr8VN3qaxp9dpydm1H5OWSXh2Grf/vQ3QmaOHZWTF+t3ZO6uTsdTFGzdBA+M0pFVPIodR2yf559uyXS1x7zzvx6kdKHs7Jjgt+eHB2j47T/Qyb6hWbVSGnVIVUqMYnnKj7VwbPOjhQ6HdgwPTdPUaut+u9znX53Sth5fKKpxozg6rzCYANzsB2DVjDkYy2W7HulzCHVah5P6SOBf86/39uAgF2Nwvcij8fxXkzHf96hEj4QBRI8DTLF1Ct/zMsh03uY5B4c/Pmp0Lb5oJMceLubT/5BbXp28+e12IyLIb/b4hFzuutcw/4Fx/jzf9xceHq2//03WaOqwhzF3ziosuYoTbot5Prjn8rNpbAibmzatODZKE1cwyrEXOGmqU/WjfnoL/AXG9e0bEir8wZNOlEYI6sJYlqadRBiaTEhFpj71bAE42shQHjQQJVjQBm4LLj+aumKxdtPrt04ImFCIOpgHEKCnBEqW7rEXvObZ3qRH3XEqjO0DWz0FHNMzfTLWYfSp4tpt1Yr87b/D919RplLZkQdafFd183WD176cFVQy+tBBoyEXYBB1HQseu75u7uhd14u5uVqoFWpw13rqtMmrxlp1fnHRPAFjzkHjyqZt1nnn3Q83nvXiEY6VV0yCnVIoHV3oXVcZ0x3MtKYECBU5Cekvw18OuNpy9nvw96MnvcHo+6ZfoeX7VnBDNQCgGwmwpi4IgaOIJwhRucpXA3eciOFYpZfIOzZmCfB0QHbHBWc+sXpue2euuYb5NPTRmQPG3BtMHdmhmrIVkxXx5f2Ot9+FmG/f8OTC80dwEpjY7L9y0JH7Nx87D+P2fNnTigU2MjZXbSz3d3Tu7aef5zto3XkfUe5T95l1dkSi1nbZ7xZtSujcNHJCycN8qlpYUGnvTz48OL+/dcSW/eqUHsK6Gi1eyyfN/CH6M3bxjaN3jK/yYO7NrCRJ3Ijg19c/fs3r2XQzU9u+nJXMhKjRybaZx6eHXfld4bBlgrZWajetrUBsRCWtSUE2jv1pSShPmoIAJa9uP2PB63Ocb3pU9odFxyvoJ2PdtWnZybGoo0O0z7RS8SFkmiFrPZaj/WarqQmOnURxlT6a4gSt0ORLMP0FxStR3s/chz6S+f52+CopJysTpGVvYdOrcyUxcwvhDF9jvCCnbQxOZ7YXW7r7wTNjXk2ROf73EZSB3jJu26drQzUMy7dycHR001NIUMXgSRKFW+8Frwn2nQoEE7++INrGvP9tOH+C1YfPnarnMmZrNWNIdbrtaCuiCPLAptcJaXXLjJA9jqgX6Ds2sICjY4swFDxWCfB9JR4zY4w/S7r7901njFst07Jt/dCvZzY6Lgi5OospHjQO/DK0Y0F9qjRs1+2qlrxttWbji1fvyVdeQwAE5+zVJB337ghnUrxziU/9Tdojqg7jT/zEmlBfN3H5nreXguzx9Va9Br5tF9Ln7jHwvbu2BEuOXMszfMtq3YeHrr5FveZD4RNhtHmFq2LgvOrpvewUiwWS9KRRKXttucmRc+bLg5t/tNoIeyy57Qk4NqtMFbvDmWBBIMAwnUegKqJq16DyH3la+qB0PLqsMAqw5lVI+pb9druF0vASmcqKCQJLReYzvar8jJJ1WB5GqgU9nUYcvi2MBZr89fCpzStLW+7N1VDYQDsyQJAVRZt/QNzgg2khpKgN+viwj4kkXhBmfNkRq0wRlm0G7a4RdjY/3fvg+JSc7FNOtat2zftiH9xxdUrT1WXnSbE+X75mNYbEoOVgcEbtemsYHIE6ei05p3f9aIKQfl3vu//d1f/KLakNPRQ4p7gnMx/pi+8+xTb0Z9f/fq88/4DETDuFGrDm24ajvfj5klKodU/ZLb7Ejftx+/xaTkYmoGFk2d2rUwURNqO2TQW8lu2qUXHZ4+/RiRylYxbNFWgilzotpVIx9o71ajwoKqQgIVRAD/9+Y/H/1+fW2LD1qnPt976gthMWVgW5FuooJUqwnJqDZ29LB8szPkl19BaxcIsiYUaaXlAWxwBn6IqSu58CgzivyaMdjZNyUYYecW6cTJR5L8CfADXkw1RLcpubkv+LZFHdOiMNXWpVrfvudAe8nUZ2iYt3EzbyNZ4PINxdSx7dTftpPEiTA0Ldq4WchddaZ+U5dhTSXWonoHhPaufMoPz4i9ff3ttfeRX/9mZnOYdXT1mtrbDRvo3MNUzBNTQeq72y9PPP0REJORjSobmJh06dlphruFPt0kTVZy9PUrr6/6xkbEZ3FUNS0b2fQf2HlYMw0JC0+K6OyM97efHXv8IzA2IwtRNjIz69qzw1Q3E/kwglKqDQH2txNLJq4I3z91087lIx31Cyta9q/bmyZNPhJhNOjsoo7FDeFqk7cqoShT18KQSURkJIANRIu2z8wLe/n22IPQjz+TE3NxRVUNc2uL7q4dxnYy0hBVuiDD7/Gbo4/CQmJSU3AlQ1PTzt3bT3VrYCDYKLB+LBtz6pqJ++v/s3cdcFEcXXx37+hNOkhHFBABxQL2GnvXJLZojD3WxJrYYq/5YmKLFWvsFXtv2BVRUBSxoFTp5YDjbvd7y94tew1pyt0x++MHs7Mzb977D7f337dv3ixvqhidKLi0u9GKl61mzvu3g8w9SpQSs3vvjaP3P75Ny8cMzWr7ePf7ts1AL0UNJDXCTzEHD985fu99dLJApGto4+DQvGXgyN7erug/RCVmX+QCvWGsqRvkOMPcelGUGMt8TXNfCHhIf4GRnGwAolwMVrbBD2ihZ05H+hbFPOCGtl9ELSQUIaA2CHDvjmqjlIYpQqY/vTp+wfnrGYa+Tbx7NDY3xQsS3769cubU+Qthw+eMWNjCTOatA1iX/2Hd9BN/Ptdp0Nijq68hkZv+7GHUtj8jT93ttWdBC28Zfw/58ebJUctuPRVbNG3m1b+pQWFqwp3bt2beeHxm1PBNg12UfBHKoFeW7vlxW+ZsXXQv29DRvU0rLwcjMv1D7Im1G0/e6f6rtYxQdKLtCPB9ph06WjB63MqfmmyaUcffx8VCJz/59dNn77IMvAdt3P/vAAf5f2ltR6Sy7SMLYbtmHMIIpUAWJh9atn3WpVQ9Z492LQNdTAlBauKDe4+Whz462KFv8G9NanNIqTgpYsGc/dtfks7167bpVNdUlPXyyfPtq58du95l+8J2AcWBi6QwX5gnFMss+WYtEYvy8guFkMCDcwiib4yaHnI1XdfN36trUA0TseDNi7D5k55c/rmjPaeZtCj+cP3k6BWh4QXGfo28eweZ6ggyXz+P2r3+2b6QhkuXfPu9q8pdoaQS0N8vggAkOKNjdmt4YrW+pcSFWEYUEF+a+2a+wijOavyCdCrhOpZwnf4PMbDFrRrg7v0R8f0iU4KEqgECiO9WdBLIpEfT5py9ZeC3/N9vf6hdnOwp5/XNcdNOBK8OaeIzqKdMNDwVfeTIO9emwbs7tbeV4i9MPfX39skhJ8dstjs70YNNaZXz9OyIhbfeubTYuqh7F3tJYzLr7br5O1Zu2TXHccqa1ibSL0wlhpSle97VDbsX3S/w7vfjtvH1HKXfU/lxTxfOP7ggDOLji01TMhKq0jIEePbfzAuJHPXg9KFjFx68iksRGHi0G/l92z5Dvm1Wk8O8tMzqr2ZOfmxYjJhnbeUu+VSRMUcP/34ps/Z3I3aO87JlX/LkJR1cHTzj4tEpbo4nhtaUfP4Fb1b+vndbnM2IxcNmt7KQPB2Tggd7d43YenbMGqszv/uVMyY4O2rR/JBrAvuflvw4r4WFdJoL310LGbvy5G0hhckmgM58fPrHhaFvbBusXth3kAd7fyh4feXMhFWh06djhhsH9LAq4f701eCu1gNBgrOiAAZ4Zz2EgiCHtEgJ981+K4MLJDj7cI7KS+I1XihTj04QAtqCALoZVXAmxa/O3rqYadJvogzZBaHGHs0XD3DTTX1+/J5cnj0qR8976aIuxWQXWutadp8yeKI3ERNy+WCi9Plb9PHff25EGvgsWNSTJbvQljB1mzCnd48amcd3hEaWkCG4LN3F7++sOZ2i599x3YRisgtj6Tv4LVrUo6kOLGVFR7VDQM++cd9JS//dfTjk7JnjB7aumjEYkd3K+CcQRZ+8eiIZd2zq24B5sCQzr4a+E5j6TPiJQ3ZhJAPb737p0ddS9Oxy+HPJJ138bP+Jza91O00cNp8lu9CSMGw8eNDCtsYJly7ueC3rsy2txmT0yYsHPuoE/jT4j2KyC511XNv03vJzLR3gu9xDGLvxn1tR+nXmLR/AIbvQQs+jXa8d0+pbJz9euPWFwrYnXBGo/LURgARnkN2M8B7Ba/EP0X4v0WAW7twFM3Io1iMzpriMSggB7UIA8d0KzieuX6fR1JHdhgaw7g1WIGFfz9mRV/ghLp2tKioQtTu37KK4ul3HbkivOsb5b86ESr4jBA9v74sm6/bqqLiNLGHpO6KjNfU24kyMyu+2snQnY649DSs07NAnsLbU48zqzLNvOKJNDfSPwgKCCgiBciNACpIv7Ng5+N9ogbX/zMHukhhXiiyEJ0oeX1fxY2bsPnBEh/EdHCT3l/zoXafixLWa/trJgvUCS5QhTLv2D3DHEs9djy/hKVil5uLkM9diC0y9f+zGvnVi2xJOHVt0t5FJQCd4cPvAW8qzV5fBzvKKAPu2a9N5tB8//trdMzJ7T7MCUaHqEYAEZ7hdc8LnZ16rf4mA36teIaQBQuALI6DAbr7weFonnnBt1nJyM+VmEXo68LYRcgLKXTY2NpStiRlzAAAgAElEQVT56pBcJiwauNflPX/xAnKJm0O/p/dfJ+N2A1rZKZskfj0/5xr7n0S+LsA8lWbMK1P3/LAXSSIdt+YNFFk7rZyeHl+ZwnJmoVOEAEJAigCZe3XbzmEHpafwlxTlZmW8fvMpOR+vUafJqjl9erNhBzyzJrBpXUTE5gPvm/zgIvtwadC4e2c28Z3wZVRoGu7ZzddL2U1Bt7ZbA5PrIa/jszEnuIOU7RDEhr0jdf09mskGLUiE4Dr6utx7gOjJg5hPuO2ANiqiW3gW3Vu7LA9/F/pMNLC1bkHYpfEH3hdyHcSEYath345QakbZ9EatKwMBPcvKkIJkIATUGgFld021VliNlSOFSe/jnsemp+QUCkk6OQyVkpBJYcWrRz6nO2FhCXvEPP7EbAle8Do2U8yzT332YM8LJT2p5FwdnExJhR1jDRUdLBhWlu6izI8pIsLCypUNHFYyIKpCCCAESo+AOD87+1OxoxVWzxP6RjYtuvg3DvTvGWQvmyOU32BI/8nPd63Zur7VDe/e7f2+CarTxN1EZuVq0cg575MTxIRXxrv9Jz8oUYXKSINk9OnZKWJMVr6StnJVouT0xELcuqaVUror1xiW3L75kEka+NZV4txl2hLWte3tiTfvP2aIMRtMLBLkFcgERBB8uaVyCkOgCoQAQgAhUJkIIL5bGWgKEkP+u7Dh9POnKYUUQRgY6hsw/lBxYRZZBr6L4XqGehhVUJQ7Br4uBSQm/LDrL2VfbBKtCWsRyXWaFBtTpu6UUJCPEQb6Ja19KxaNSggBhMDnECBMu0yZsKxhaW+whEmtqf/7tcXZG1tPh+/fHLF1I25gZR/YxKdH18A+/ubS1F5kdm6BGBOFHz8arnp8voW4HOH2ZL5QgOFGxvrKHp4VBhPnZ+VRhKG+qWIAhrQtYWwA2WNycgvgBqXXqPN/9J646EAIIAQQAlWGQGlvx1WmoNoPTGa+Wjp158bXOg06tf+nk29LbxsbA8mXgCj6XOdRl+WjGUqwiCoUgkOIKHpvCO4gAidsg4K3dG+iepb4EGqgVGCZuuOEDgFpakgViYuUDoAqEQIIgUpFQMcssGcP+ClIT3z0JOb2o5cXblyZevbGxvbdN0xvVq8oagluCThhPmTplNl+KnkprMc3Vn5TKElbgscDiWIxKV0tW1JjOpMaD8dIyPKq+hCRhbDYjZaKDoQAQgAhUPUIlP2+WPU6q5UGBaHbDm16bdh33s9r2pX1FaKCIQU5KTkU36QoqoAwsDLlUzF5Aj0DM6UBugq9ZSrK1J0wtjDDyfc5KaX6rpMZB50gBBAClYuAnrlds7bw03za+KTj6/fOOHlsjInV+V/rGGOEmbmhLhWfka9jpiTYoUJaEObGFjgVnZFTqnsAYWhrrkM9z0yAPbykecvkhhcmpyeRuK8lemkkBww61VwEhJnJn3JwMztrY/QYp4mzqPp1lCZa8/V1Fn44dzcd9wya3LrCZJcOuY17JSIcXZl9bvT8vGx4gg/3XoCXpBxHWboTJl4uJnhWQkRcSf6aciiBuiAEEALlR8DAtveU70d5YO+uPb5dQIsx8nSqTRSEh8fK5ThUPgSuY6CHUxCooDzmSaYTYW7nYYFlxMS9K445lmkge6Lj52nHL/x4N1yVIqJnT2IzCWs/T0P0HSMLHTrTWASET/7qExj0Y/Db4u9JUcrLsJefONvXVZpxX05ypamocYLQvahiU0bl5+ZhuL6eMXftskQkmfjiY5wSbwmV8CEpV8mwBfevRcVjZs0a1yy6SLi38Q/gp5888kSZECX9ZavK1J3fMNDDkow/czleyQeXLIhPhlBidCAEEAJfBIGCB4cbt5nRdWdi8dcoOw7fqpY9n8oVZBZd4zn5da/Li7t662RSKT6RRI2alpg4IfmVkk914dOXSTLMVtelbYCx+PXTEzEy1YwipCAjIZvLmgnn1r4BurkXjz96r0RpjEyP2HU5BXet1602coSxc4kK2oaA8NGKfh26dui9tNIN+3KSK11VDRKI+G7FJotvV8eJEEU9PflR7q5PpoZdmPBvFORnKCyUu0TFnw9ZdAtWsskcOZFXl51L49du8kN9yeZmPOegyd0ss0JDftkXmyXTFk5Eb8/t/27erafwPlHFUabuRoHNBrjhL46d2h4j504mP149sfxGLve7TsWAqBohgBAoDwJ6ddwbGJMRF26HZst3J1OjLj8v5DvY1WHCBng2g4c1ccmOXLjsWliOfGPhx4e/TNm1/WWRKxgu8mo09bfhpb84dD1T/m4TcXnxqU+yNya9tr0be+KJOzbceiEVIBlAnBay9szZDJl7AM8x8JeuVoKH56bui5VXRJi0b9XJk+km3YY0r4ci5uRnCZ1rDwK8Gk5uNqZWbs7lNin/4szmvg1GH5RL0g+f3YpKLrdKWtwR3Y1UTi6Vl3ju4NUXKp4IeFbuYzq6YDyL774PCJ7/YPmMndmj2vdvZGfNK4h78/bS+Vtbz3/y6BcYcODemzS5LzHCv5Xj/aXrfujZflznugHORkTmpwfXbq3cfjec5zz1l9Y+xXNi0HbsoOnvtq3YtKl3dJsp3zZs52VhTBXExUSfPnF57Zl4s07eloopi4oNKkt3XZeJU9vdnHFp6bQtiSM7/dDS2c2ITHn/9vzpq/+cy/NrYh13v1julytRpAhLj8Qt/b/cEEgyQkDtEDDznz7y8f01t0dPzBs/rEWfQCdHQ0IsSHt67/Gm7VdC0s16/tzUV3pbMAvsvnZk0tAtZwaOjxs7rFX/IGhM5SbF37x2Z92eB5EmDdvVkO4GjvHq9WjVLuTQ2b+3/ybsOa6ti7MhmRb38dbV2+sOvDL2dTK6n8CFQs+n/bLB0UN3nR48PWv68KDOda1MyZzop5H7/rt0ONuptVPGdW5rzKDV2EG/fdi+dMvmvu/a//JdQOtaZvri7OjH4cG7Lv0XUeDZb+iidiXkb5CRhU4QApqIAK/W0B2PhlZI84Ls1NS07HzZZ094Vq245AqppZ2dpTdR7bSuQlZROe92b3qnSgS/blea72KEVes+u6bjUzY8/POPyD8lrQkTpzpDZ/88temnWWfvhUfHYpgfRw5u1aTPss43Z645/v3eg1KfCW7g6DNrRv/xPrIE1tBl4srxLtuPLzt+fuzlcxhB8CFtPYnxTew6jRixaFAdOxV0XDJcWbob+3XcuZQ/Y+XlLcs3bF7OCMCNnHwmLBrUJXLHxS/Pd6mUJ+TzTZggnmj+D24C2KIDIVBNEODV7j30SI2L8zffXjHv8TKM0NHFyUKxmMINa9YeO7/P9LbmnA+6XsCQkcdqnp+36faq+U9WYjifh4kgtQrPwKtl512T27a0Km7Ls2/858KsKcsu7161YfcqCZg8E/teP42YaxPa/oEM34XtwwN/GrFd99D03TemTro+lWmO67m3aLd5br1HsyNl+S6GGTqPWzbOYfuJpcdOjzh/CuMRfJKEVGg6Fs79p/Se29uFq3Q1mUhkJkIAIaC2COD0vgjaeIhDp2BZMWAZbtcCN3H60iaSgtSHD2IiEgSkoYmTu1vLuhafX6Yhynn5JPrB24wczMDW1bV1AzsL1U8f4uyUB4/fvEjIzSf0bBwcAhvQHqDSG1WG7qLcqLCXD99lZWP6DrXcWvrbVmQhHiXMot6fpvUk+LxOx1QpTOWlkFFbsMTbkgbmPrwgCeNW1QXVIwRKQIB8e4yK2k43MHIkarYsoaV6XSLzP7x48yAm9VOumGdo7OTmGuRjZaYqAlac9zYi+l5MWloBJFixrOfvUd9OT/lNQZgV8Tg67EN2Dqlj5eAQFODsVOLdQ5SZEHr/fXRqHmZk7u1bJ8hV6Y42xciJc1IePHr7KilXgOvbuTo3869poyJpQ3Gfr14iP4VhGVEwLO7cjfAZ+9XHV+sBqYxX5J2iBxwdU16HvWqtaxUqJ7z/R9u+22rMvHpyooeqT2UZ1cs/9XP90acbLH+0b6hVGbtW0+ZUQij5pIgemNbiNV9TJhRUM6wyian2jQlDyyatLZuUCQe+sWejBp6lS8POM7EKam0VVCb5nMZl6M438moc4MVuYMoR8iWKEMBAvT1OxezHxGzMIIGbuFLiQkgj+iVGRDIRAuqLAKHv5FPXyad0CvIM3Pz93EoT+6NrWi+oYb1S3z74Zvatv7FvXTotoBXPuEJ3p1KPgxpWJwSEdxd8M2S/54qHm7un3dz97/bjN568Tc7DTWxr1W/Td/SEIU2suZRT+GBx50G7LWdc2j84/+z6NdtP3YlKFBh1XHFxba8aUtSEyY+Obtl86HrEm49pYiNbjwZte48YNyjQRgkLEiXd3r1265Hr4e+SczATu9oB7fuNGjdQ8bMmODI6YPrtdmsiNvSUjsL8Fac9ObYt+PClB1Gxqfk8Y2vXes26DBr1YycPyR6mmQd+CvztGiwkFQvzKPHNuU3c/4COOg1mnD8y1pUWoVIyJky4c2DrruPXHkXHZYr0zWxc/Zp3HjBqaAdX2bylDCIO80N3DjFNundo+/Yjl57EJGaKDW3c67f77ucJgxpyXgTRI8KR8/LUti0Hzt+LjE3OFema2Lr6BH7z3Ygfu3nC1jHacCiZaW0wC9mgCQhIAhhyPxYrW8OL8BmHm7oX16ASQgAhgBBACFQ3BChSmJ8nyEq6sWrA9LXPzRq3btYz0ESc9vbRtSubZ50Pubpo378/euqzqJCFBXmCvKwn63+YteKusKavf8NmRoSjsdRpIv547o9RU7aHi52bdmjTv4OZKCnq9sVtM88ePTMrePP4ABk+J4jYMmrIwiufDN2C2nRt52AsSn8TdnxevxOX5k61Z8djCpSoIC9PUCCX0iQn7N+xI5de/mTq3bJ995Y1Taj0N4+vHl4y/MihASuDl/d1g7cf+vW/nT4zUISJXx1f/V+EU9fJg+qDLTy7QHPJCMoliz6c/mP0tOAneVZ+rdr1bmerk5Pw+vHV3QtO79vbf9m2Vd/XKQYEoxHJEwhS7q4ePeafCJPG7Vp0aWBcmPbm0bVLm6Zfvf5y29EF3DgpYczBX4bOOvZez6N5+84DXcz5gqSX968eXnbh8IHeS4PXDKgjG2opB4RmnCK+qxnzpGVaQgADFbWVSgwttkvXFPf8EXfogONKUrsVN0MlhABCACGAEKgeCBQ+/ufXlw3G7r81oRnrzs2N2vvrsFkn549Z6XVmXhDXqUm+/2/+eoPWS08v+aG+TPB4zr0VP/287V3tEdu2zuniJCFuZPqDdWN+WrFs9BzXs2u6WUtDgTKvLhqz8GqO90/bt83v5CQNzMl/d2rBmOl/3C4gMdZfrHwKyITj00Ysvka1mXvsn7ENLaRiC96FzB0xec+0sfZuJ6c30NPz7DLCEwTknwr/Z9/zmk0HjylFPENm6JJhE7a/qdn3zy1LB9VlOXru65NLJ0wPnjYYMwz5u4fMmh4yMWTquFj9oXtv/NLSTsL2yIx7qwYN/nvH4i39W87wl1SKY4Jn/H4ssfbo3bvmtrVlPeeCVwdmDJ9x9PcpXn4nJ9fVeLoonQzlM4dqEQKVjAAEMJAxh8mbYzlkl6Aj6lptIhy/QWS3kuFG4hACCAGEgMYiQOVZ9V27aXIx2QVLjLwG//X3yDrkq93/HJbNTU+mZDpP2rpmmCzZxUTP/p23OdKo08Ktf7BkF+QQ5o0nrFvUwyrh2F87IqUeWnH0nr/2v9ULmrp+QTHZhcb6rt0Xb53bVDf/c+udBHfWLj/1yWnw/9b/XEx2QYCea4+lG35thEUEbzybDudlPwrCNszdFmXQev7ONRyyC3KMPHou2rGyl3X80QUrL2fKCBa/Cc/usX7bdJbswlWiRuDEqb3syFeXL0ZLzSYTr154IDDvNGEah+xCW8M63y+d39e24NnxkyxEMgNo1onGE3bNgruaa0slPyAfLZQDAa87hg5gyPkINxJKLMQECZi+Fa4jCXOSa4xOEQKlQYAqlM8JW5peqA1CACGgVgjwffoObco6MlnVDJuM+LHpzt/vnrmUPGRYsUMTt+k6ZpiX1CUrbS24sfO/CHHdKVP7O7F+S8k1wqbryL7up7acPRP5iy/t6hS/Pn0qrMC824+DaitwI55Tv5Hd/7pU8mo+wY0DIR/4AbPHtjKTjs/+5df+tk+j1XMe3Awr6N2uzNEBgus7D7ykPCfMHOyhoBpG2HWfMXrn+YWndp/5rf1A1leN4RadpkxppuCRNmzYqK7Ovodv3ogw7yJhlEhYCCledJQseDUNGjR9il2KN9eRzpqkYQVF4DTMAKSupiBAJd0hHy9V1JZ6vlHxkVmxRrEjqkEIqETAvJRrvlQKQBcQAgiBqkeArytPX4t0IuxbtvDi33r+JEI4zI6NWeXVdK9lIK+z8Om10GTCc2AXL2VsR7deYECNf09GPM/G/CF0NvtJ2EuRblDzZopsFeTievq6JYfbCSPvPUonPFq0UqDWtFqEVcepawxjrWop00Reb7nzgifX73wi6gzsXk8pIBjPpUe3gOV3H966nz+wG8tNec4+9WQiOyRS9U1N9bH83Bxp2l+efWBjN97DC5s2PWoyuWENmff+po0HTf9aC9jljK7s03LgXtkqIHnVAwEqJbx6GIqsRAggBBACCIEviQCvppuzIRWREJdDYvoy9Ex+1JzXrxPEPO/UB/v3PJG/BudkfKoOLkpJThFj5jxRwofEQsLaxc1EScvSVIk+xCaI+a1d3ZQzK55DYO/vA0sjSKFNdsybRNKwc12VXJmw9vG2J+69f5sgxmrJO7IVxNGhg5CLlnUs6TaYuGJy2Kg1K/u0PNuhd++uHdu1buJlXWYntMI46lWhfFbUS0ekjVYggDt1omJPKzFFl/O2hRJj8Caab4ARyh9ilXRHVQgBRQQI6bpsxUuoBiGAENB4BHhGRoYEBfkHWMqm3CRxdhZ4MQue7PxdGduV9OFbF8JGKUB+BYI8ijAyNf4sX1Q+GJYvyBPjBkZG5e2vQiwEWuRk55KEsZmpasmEmZkpjuVkZ38GEeVjEDWaTtt/qeXBzVv3hexfenbrIsLAzjuwdaeeAwb2CXJkXejKO2tKLeK7mjJTGq8nbupGfHOAit5HvT+JUaTEHkIHd+6Cu/fHeYjgavwUq48B9H4TqSV8v6mPpkgThABCoBwIUAVCIYXzeETJAQYYThA8nHAcsuPsnCYqH4Jxvr4xzYUIng6B02uqpd9PZVUM9IFVKCJxefurHA/n8/k4RoqlC8yUNRSKCiGFL1+llcr6yNTp2gUOmQc/BSkvH925ffvWtfNn1v56cNOGXnM3rh5WTwuW1JT4IkAGCnSCEKgoAjjfkPAeAdsFYxb1JLLIQur1PvLmz7CUraLSUX+EAEIAIYAQqA4IkDmfUnIpfg0LZdGpXAAIMytzXSorU2BgpvowNWIWahFWlhY4mZ6aUl6+qmdhaYLnpaXmllcAV3VumbCwtdKnMpISc7m1MmVhQnyymLC0sakwq9Oz8mzWY/i0FTsv3ru08Qe3xBNzRi++oQ0rgCuMjAzg6OTzCAizs+KSstk48c930LoWuIkLL3AZ7j8N07OQGJeXBHkbxI8WUYJErTMXGaQpCAhTk9ITMmHLo/IdooyU9Li0fOkKkPIJUd5LkJ4e9ylXoPxixWoL85KT0j8JKvL1LMpM/VKGV8w21Ft7ERA+e/aqkO9Sx+OzIaZGfv61eTlP7oblfx4Nwtqrtg2e8eLZu5L8qCXI0fH2rs0XRz8NVz6Y+N3l4A2bz70qh3Q9P39PfkH43buqeKfw2Z1HGTw3P7/PPQGUoL7CJcM6vZf8NdoHe3fqyG3lJil0UecKxHe/8uyInuzcEPT99mDZvIFfWQl1GI6o2ZpotRF37Q0vnCT6JN8HRy8Z/R+dlQwdCIGvjIAgfOrAxS1WRpRzWOG71eOXNP39dmzlE96CUyuWNR506NwX+MIRvrjY9/ulw4/Cap3yHoUf/pq4tOlvoW/LL6K8Q6N+2o4AlZmWoowc5tw6dTURd2jWikmnVRIMvFrdegToxoVsP1GKL129hm2bW4qfnzkRqeQ7iMyJj88s+cmQ59C+nR8/+erJaxlKdBLHnvl7/tIdd9I5QggIyKBg5RinSklP2HrNuWu3hvqpF3Ydeq/sg0amnNt54h1ep0s333IEqRZcn9nYyaXLmpdKRPPdaznrUjmZGUquKdVUjSulVEONVUSqaSsCKsMbbk1ElFdbJx3ZhRBACCAESomAOGbPwrUPs+RaZ93/Z9WxeF2/gUOafNa9C0zRY/CUAS6Z5xdN2RgmLwkTvj005dvR28OlL0+M2g4b4Im/CF607YXc46X4Q8j8ZWdTP7MYjFdr4JjuNsnHly+/9EmOwooTTv8Z/Bj37NW7QfFiFbyGqQlOpSQnyTWWsxhOeW6DfvneTXBj1a8bwuR9vAWv9s344+Qn624Th5eH7mJ6vkENTAsjjuwMVaDpZPLlS4/z+S6e2rCfMOK7iv9Xal5TeHH1cr8+uw4pfHLVXG9V6knDG6ZiepKtw3Hrhmj5miq4UD1CQNsQKIicOWh+wLyH5dt2StvQQPZwEODVdMnbMaT3z/+EhMXlgoNRlPk2dOesAcPXP9NpPHnJqM97d4tkmbWds25GEHZ7yYBeY/86+egDHU4oyo0LP7dpWp8evx6PN7S2YhMQ6AVMWj7Bn7y9dNDgP/bdjknPJ8WC5Kiru+Z/3+e3qHqt3VXnR2DUJqy6/bFqmEfcrrF9x/zvZNhHWmtxzocHR1cM7zPlWFaDicvHc+gupufdyM9UHHV43aHItAJhbkq6lHhzQJAWTVvNWfdbC/695QP7TNpw9lmiQIyRsLTsSvCsb/vPOpfp+dOfi3uWM3jXosf0Ge0s3u4Y1Xf82pDHRQDRWoeF/D3u21+Of7LrNmmoXzn8xlLN1eWvFpigLlB+NT2EuTmpmflfJE7wq9mgMBBRsw1l04TO3pB4E689WOE6qkAIIAS0FQFxTkZuWm7hZ11c2mo/sksVArhdr7+XW+2cuXR812Uivg6PKhSJMdzQvfPs1SvHNWC3VVDVna03Cpi4+5jL6rlLd64ac2IlRvD5mEhEYvwaXp2n7140vmXxHm0YZhw4bVew3vRpf2/+td+mXxkRuJF7p4lb1nV+9NOF66xQFQXCusPi/bsd587++39jTq2ix8JFIjGub9eo/8pNcwf7G8v0M+82ZeJ/d5cc/7XDcRhLv/M/b4O/lWnAPTFq8POOI46r5y3ZsfinQ4swHp9PiiCRmo51g/5LFs0b1rD8obv82sM2H7X8a/6ynctHH11K77TGI4VCMYUbOrcau3HxjB4O2uAbRXyX+9+EylWJAIQ34N4jqDqDcR77sF2V+qCxEQIIAYQAQqBqETD0HrDydO9fn4WGhsUk5RKmdnUat2nuaS7nZ9UNXBD6cUFJmhrW7jlvf7fJbx/cuvfiQ1oeYWTj5hvYrL6TkSKRI6ybT95x84eo0OsPoxOzMFNH78Ytg+rQQzY/82ESdxCj73e+/55bwZQJm2Y/b7r6Y1zYrTsRH1LzCDP72gEtmhZJUGisV+/n/VdbXrp07026yMC2flNJAxWSMdqMfd2mvHtw897LuDQBYQKimwXVtVEI7CgREf2u61/Er5fVxbBW99l7uk7+8OTug+fvk7OEfGMrJ69GQQ3dzOSwlu2mSWeI72rSbFUHXRHZrQ6zjGxECCAEEAKlRkDfzrd9P9/2pW6vqiHPzC2om1uQqsvcer6FV+s+Xq25VWUsGzo06Ni/QSk68a19Ow/0LUVDaROeqWtQN9dSmSHtUsq/hLFTQAengFK21rRmiO9+sRkTZd05eXnrhVfhcVk5mL6di0u7ji3HdXNSPh4piLhyK/jCi/uvUz/lkbpGpm51anXu1nJYcxv2lU3m2eCgP1/CqlGxqJASR8/9dtYfIEvHecbWsWOK3zWQ6dHhO448uvQ0/n16AaljYOPo0LRlk5F9fGohn6ly6FEtQqBEBErx2ZTtL4p7fPffw2HXoz4l5+Emllb+gQ1HDw5qYqHoR4J+ouTIx1sPPrwe/eljBmVkZd2gScBPA5sEWpbOpVKY9ejCzS3nX0Z8SE8j9Wydndt0aDGum7uNkvu6OCnszrpDj6+/TEkWYCZWtg2CGo4a2MRfVvWSz0QpMbv33jh6/+PbtHzM0Ky2j3e/b9sM9FLR6fO45R38fclv92H5PSksoMSPjjXpcAJk6dTtfO6vNq4sAJ+Xo0IBVI0QQAggBDgIKLkvcq6iYnkRyI/bMmfronvZho7ubVp5ORiR6R9iT6zdePJO91+t5WWSWW/WLdz7v/s5Nep4tm/n6WCE5aYk3r/7YNGtx8f6Dtw1qR4TW6Tv1WjaKHeIUH916cJ/0eZdhwbWh1cYhGmgqfR7lBTc27tnfPCrVFOHNkH1W9vq43mZL59GHdwQefRi839W9upkJW0prwI6RwggBJQgUMrPJqenMHzv1vnbY/Xr1mnR2rUGkf/hVfS1w0cuXI1asOqH4bVktz4Sp59bt/OXox/F9u4dmjRqbyJOfhNz8cjhs5eezlwydLyPAUeskqI4KWLBnP3bX5LO9eu26VTXVJT18snz7aufHbveZfvCdgEyUYLCiEM7f1gf9cnAKqiJb1tbfXHmp7DLJ/pfeT5neA0lopVVCaJvjJoecjVd183fq2tQDROx4M2LsPmTnlz+uaO9QvvS4abj37nTTH8SEycdC74Xaec3qbsT2ExYubMvq0snR2F4VIEQQAggBBQQQHxXAZJKqMi7umH3ovsF3v1+3Da+nqP0Oy4/7unC+QcXhEGYPOebjEw/vHznyoe6XadOWt3LwZQdXRC/7Y/N848eXujnuq6dMRBVPTffEW5wufB01OV9MTWa9mj9gySfAdOH/Hj+wKit0Yat+4XMaFqv+NsuP/LwnsFrQ2eud2s0t74lYrwswqiAECgZgePy/aUAACAASURBVFJ/Nlkx4ve3fo+zG7Js+rSm5tKcQ6L3V48NX3Lvj/lnPDf3asa+r8Hy720NHn8ktXa/YVvG+TpJWpPpz66OnX12+bxjblsGdFXuEi4aTfBm5e97t8XZjFg8bHYrC0nwHil4sHfXiK1nx6yxOvO7n7X0w555L2Ts+pc5tVpsW9Kjk530nl+Qcnr97unrYgpI7POcNztq0fyQawL7n5b8OK+FhdS0wnfXQsauPHlbSGEmLAbgri3lPY3v2aqlJ/QreBq+5/4Lm1pDvm9qyRFTajncPqiMEEAIIASUIyC9Iyq/imrLg4D4/Z01p1P0/Duum1BMdkGQvoPfokU9murAesriQ/TuwfbbuTadesmQXbhuWPPHKW0a62RfvBSVWdxcdUmUdOjI8zSLhgtkyC601/fp02ecLy85NOyKfNY+1dLQFYRAtUegHJ9NSqDT7tehs4rJLoDId2nbZ90PTvzYu/+cS2NTEIheXZ9/MN6oRa8tE1iyC40Jc9+2ayf5W6WE/XUsXlmifWZWxM/2n9j8WrfTxGHzWbJL9zZsPHjQwrbGCZcu7ngNeZCKDnHSnp333+q6TZ3Xs5jswhU9q26Th82pz8vn3o8kfeT+kNEnLx74qBP40+A/iskutNFxbdN7y8+1dIDvco5y4MbpXVysLDnFElFJgxDgmdVq1Ly5n6MBrkFKI1XVGgHEdyt9esiYa0/DCg079AmsLfWksGPw7BuOaFODCzqu59j/py6/9/Io9uxKW/OsXRvYEgUJKXGqv/ekbTEM1/Ht1GnGmGbNiz270os8s4be5jxh2rsk6Veg9Ar6ixBACKhCoByfTb5Lo5Et2QAjVjDfq2fTVoaF968/T5AQXuHN4/cixDV/GN7QiQ1UlTQnbFq37OuIvbz57LmqD35+9K5TceJaTX/tZKHQ27Rr/wB3LPHcdQldFsc+PfVcbN6s+UAX+bYYz6Jff/+a3PsRqzK3IE4+cy22wNT7x262Crc0wqlji+42MpSkHLhxR2PLlSWHFYgKmoQA3+en9Qf3L+3NTRWmSfojXdUPAYXbl/qpqGka5Ye9SBLpuDVvwAla4Nigp8fnfjnwHOqOHFqXc51TxHX04cWhWKzqW4/TFHZfserwbYcOMlXsCa5PDwqZ+tgaVEAIIAQ+g0B5PpuGBmbcj7d0BMLMI8iDuPAm9lkh5gDBB4Ufrz3OJtyadHFT4KDQRcehSV3Df6/ERwowP8XnYAwTvowKTcM9u/l6Kbt/69Z2a2ByPeR1fDbmBBFP2S8+vBLzAgNqmUmV4f7FdXX0lCnMbYMJYsPekbr+Hs24QQtsC/o2JSOiPLix0jiFypLDEYmKCAGEQPVFQNn9svqiURmWizI/pogICytXo7JKIwUpyRGvk+My8vMKSRLeEFKZUdkUVmY5GJmfFf0qPiYpJ6tAJCYxCqOS3uSRGErQUNYZQe0RAgwCFf5sEibOdvpYZGZ8NonpEZggOfoTyXPPfXjm7hMlGFPxmQQuzk5OJzFFZzGG5bxPThATXhnv9p/8oKx3Rhpk00/PThFj5jxxQmJmIWHi6qD88VtJd4UqUXJ6YiFuXdNKKd1VaM6tqDBuEmGVJYerGyprKgLi4cMxS0ve6tWlN4B68kQ8bhy0523ciNevX8qOTC+8efPSj0Vu3Upu21amUcjly8nQUH5IiCqtaJknTnAbiJo2VTUEozMxezbRvTsrUFECe6lMBRiXf+dOyV0YBVSpV3LfL30V8d3KRpgSCvIxwkDf5LNvCYtHLnh19erq/+5dfpmVR+F8PT0TA16Rw4TMLyPfzX0bvj746v7bHxMLKIKnY2ykyy9SgyxAfLcYblRCCJQagcr6bOJG+jo4VSgo2i5UnJsH24wWRN3+PUq1IjyTQplQf7YlmZ1bIMZE4cePhrN1CgW+hbioNyXIF1K4nqmRjAtWoXlJFWS+UIDhRsb6ynzRqjpWFm6VJUeVnqi+ihEQT5tGhYaWrIQcx6KiooDPMcxSaUdixAhi5Ei4BMwYGjNtGApInjrFEF+ZjlZWwCa5jblXQT3gedwaKONeXrzgYLlKOIVxoT3599+KVxUVBlIIXYDLwm92CEXJIJBo3pw7FtGrl3juXC4DZq9S584BQeeSXbhES+jVi23DFBSRhzaMMnIt6VMrK96iRdCAodpgIAss0xjgxSIiqJcvicmTlXRXjyrEdyt7HnBCh8AokhTLLOFQPQqZe2PT5tH74vW9G06a06hzQycPSz3J94oobuXINevYFS6qZRRdIdMenhk099pzPad+Pwzs36p2A2dTQ4kgccTWv7ruKaVCnxkGXUYIVBcEKu2zCYBRBYVwSyB4RXdcHMcJHHfoOfzcWHeVt2Cc0Jd+gOUAJ6A3YT5k6ZTZfiopKA6Pu7RonM8n6Fim0t6P5IaiTwkeD4YRi8lS34oq6Z5WmfgrsQtVqQkCJThQgZ6SS5Zw9QTWCNwL+BxTUOR8oh49uO2BohGzZoEc6sgRrHt36Ag/QPWgDeO1BTlAB+lTZfyVK0qxzLqNFS+x/JW5xNhIs+EiTzPr/mToI+NyZi7h/fpxpUElMEvoLicQ2nBrgCUD0WSpvORSEY+nbY+Kgh9wPLOSQQGu05rxMQNQ8MO0AYhwwFl6ylSCnlRKCrlnD5wywDL1XE2YGvX8rfJmq57qaoBWhLGFGU6+z0kp3ZeD4PG5GQfizToOPvJbfUeVX16lsDvv9apV1yNNAtavHdDTtgy+5VKIRk0QAtURgUr7bNLgFaak51E8A4ui9z6EiYmFDvYiW6hvYlD2eCXCzNxQl4rPyNcxM5EkIlM9PbhlDSOcTErNKP/jLmFubIFT0Rk5pbulYZWFW2XJUQ0OuqJ5CIADEphWWfWmOe61a8DqGAJH+ztHjJAISUmRk1Yye2OpKttLsYa9pFigHj4EbsoQXBgI3KJsfAW4bGnPNCcOAboDuaT9tSNHMh5rRYFsDTBjKLPK0O7kIs8xEH3W4U0L5DxCACDw8IABhYV4CdlABRqiIvczK58pMCyZDikBUQqBFnKN1e0U8d3KnhHCxMvFBH+WEBEn7uj+WQIrenIz6iPmOGOoX4XILqSwjIq4koj5jezQDZHdyp5SJK9aIlBpn00aPWF8xDsxz962NhNFb+Do54qfj3obVtCgxWcpqwL6Rp5OtYnI8PDY/PYSeQpN2ArC2t3GBn/74lWKqLl9+W73hLmdhwX2ICbunchH6Qo5drCiQmXhVllyZLVDZ5qMAHA1IGeYnV2ZjGBf3NPPfPXqkZs20d7QooAHqACHJUQDywlkgh/kKhn/q1wle8rwSC5r5HqR2WbAIxkPLlwF4g7ea64DG1ywjBeWUYB27kpDEWhyyXHQsgKhoBgCwV6lnbspKTypsWw9U8A7dwaSDZACS2ZqWKzglPUWQxka0MxbwePL9NKU3+W7AWqKdVWiJ79hoIflycdnLsdPcJdmkWcVIQvikwWc/Sao7DyIrtM1Ls5CzzbFyJQPz5IpzKq4hinh4L2lKAoDb0uxH5fKFQoo3NBQ2WJrMvPJqwwxpnR9trxwdI4QQAgUIVCezyb56dPrPMxNISeg4Gn4lWTMvkeduszuMzzrbm1c/t70JPhK22ZdzIs/xqWDnufk173uxaVXb50cXOu7zz3f6tX1albj7rHrT54PsfdjRi8ehcxJzsj47H4Tui5tA4z3XHx6Iqadl6f8VwYpyEiAZQbFa9nKgRsOwcVwS6Nkb2nluDcWW4ZK2ogAUFUZs1JSSvbFMu/xoQvj9aTf2i9ZwoQWcOkjy/ZY4XI0lK1XWuAGsyrqw9QwHlaafUJoQRHHpb28Q4Zg4K4uWlvGJcesEJDMjlgaFy/bmC2Acxf39ATh3OgFuMo4leE3BITAcLTXWbqMj8GnWIJ0qR/epg1DzeWCHNiW6l8o651W/S2qeg2NApsNcMNfHDu1PaZQVhvy49UTy2/kct4s8uq4WumIP5y5kiKXK4xMf/3nwlNXsilKJJbN5o7XMDbAqZykVI4YOvO7rTufDL8e/kZeUM7t4P+W3s2jMHFBoUwXWd3QGUIAIcBFoByfTYxMfrRwQ0SS3It/wfv1mx/G8hwG9KolTZJCePTo8H3NvPMbDmx8nscdlS4Xphxe9u+YIx+K1rbJX6TPeTaDhzVxyY5cuOxamMImMsKPD3+Zsmv7ywJJT0OvYV1t8Tehi44k5MsKEyeGz9/yLO3zdwW9tr0be+KJOzbceiGVKpEkTgtZe+asTLBE2XHDDcyMMSo9Sxa3ssuRtQ6daRkCwFbBvyhjFMSn3rkDP0DR4Icp0y/opQdTQzcoInNA1KDMMD+gj3JXpZ0wtl5pgeWFbHsInIWWQFuhhtuFqxXjTqZjiIvId2lCMoCRg2sWaDEzEJgPxFT5j2zIMqsYPVZwMDFkCCwjA2nceihDTAIjDcrgOYYyw7mZZtBePhK6e3fay3viBO1lV4MDfH6iMh7yD+tqYIXmq6DrMnFqu5szLi2dtiVxZKcfWjq7GZEp79+eP331n3N5fk2s4+6zNhIuXVr3Prr74Kato3K6TOhcx9uCyE5KuH/7UfChRzEuLQbXvb73A51XCCt2zPC96zmYHos8svdh1ykNa+vk5+LG5gYYr2ajMR1Cx549PXRu3swhjVq6m/Bz0188e37k6M0jsTbDezhvDvmUAumN0IEQQAiUCoFyfDYxvpev37P9vWcETRrY+Bsfa3Nc8OZZ+Lat5/dGEQHD+4714AQ4mXjNmdM5etbZpVPXRQz4ZmQnr/p2+pQg/fmjp7v3XDnw2qBfkLGUHCtR1yyw+9qRSUO3nBk4Pm7ssFb9g5wcDancpPib1+6s2/Mg0qRhuxrsLYMf8EO/8Y+2/f3v5iEpnaf29G3gqE+mJ927dX/DroeZXp7uSS+VDCBbpefTftng6KG7Tg+enjV9eFDnulamZE7008h9/106nO3U2injenH7suOmW7NhHf0dtx6tP++3+BsbvVwhbm5oiJVdTrEOqKRJCMAreyBbn9UYSBuwN7alKn+n3Ao2tn0J8oGkMldVpWiQ71u0Doyt5DJgueGA8rLNGP7KnrIFri+Z2x08wZASgXXxAlkvjWOVG4TAUH9QjxgzhnZsN2rEVZVZn8eGYYDt8DhBR3eoPqA7g5W4iLirbvg1rpAkmc/kuyn1aIjvlhqqsjQ09uu4cyl/xsrLW5Zv2Lyc6YkbOflMWDSoS+SOi8V8F/YP9Vu64lve0pBDwXvOB0vG4BlZt+o98Mhw7zd/Ptj7Mi4sRtTVp3imzFt/M/HUmyWXDn5z6SA8T3aevXB7Zz2MMOn6y4iVxL5F5y6Mu3VBKkjfvVHTv9d2avfhyMGQj89eJGCtXcpiB2qLEKi+CJTjs0mY11k0tdHWVUfn/HJ1qtRviutbdRr97YpBLnJRS0Y+7Xets/zz7zM7t+0+sRXSIBAYnQOBqOFeb9qK3uMbmZX49k0vYMjIYzXPz9t0e9X8JyshDwMPo5Mw8Ay8WnbeNbltSytOb0P3acuH6606+M/Bg/0OwE2DPnAD605Dhq1t+X5E6Of5LmxLHvjTiO26h6bvvjF10vWpEhF67i3abZ5b79HsSA7fLcc9zbDbsPb7wk8fX/7ncbhb6tb759Tw/gblkMOohX5rGAJACuXetrMGMGyMOeXmT1BKTLlkkRvSyg3G5YYNgFiufGYUbtoBVg1uAWgrsw4MKqmPH9lLTOYH9lSxwETiKsbgqopnUIWJomRuDRO5ATVcPUE3CpbrsVnSOC5wti/tS4bUENeusTXy3nT2AqdQmjac5pVZ5PEIU1Nl+/GoHqSYRalug66UAwHCOqBD8J6mUWEvH77Lysb0HWq5tfS3NQf/TsDk2B9kBBrWavLnFr9JEa/uRKdlknpW9vaBDZ0dDeivK4/fF8T9LtOYPtF1GPfn9BZ3nt/7KBDrmfo3kE6igf2AWVO6D31/IyzuQzZlZG7u5V87wA6y22OY84CnNwYoCEIVCAGEgBQBw8Y7rjSWnkj+luGzqeux+MDqxUX9ZqyeNeJtzM1niQkC3MTSpnETD08zjmeXM4ahS/25//Ob9PFdaHj8h8xC3NDUrbZbM28LIw5ZxTC975av/I7TS1rUrd2ux77WHd5GRN+LSUsrgNQwlvX8PeozH3lpI+YvYeExednMH968vh6RnJSLmdjaN2nkXpvezMLj9LX2sm1VnBEmzYf+dKNXQuj999GpeZiRubdvnSBXOmVa802rJsl2KgNuRR31arfdt7P2pTtv32aKDaycg6S+6bLKkdUCnWkAAiyro/2L/fox2QmAhsKrf/pdfFH6MEUzuNwXXrtLWFcZN6FQFMvW0JG+RckN2BoocDl0cb2VlSJpLr7K6QU60ykUFNac4Y6O3PaqyiWMUsIDAysNcIbnAVqBxES2ki3Q9cB3HR2lD+kYvS5Q2QFog7dYckXZUj9lndSlTkqV1EUf7dKDb+TVOMBL/jtUmY2Evoufn4ufsktK6/gmvi0DfZVcIoxrunWt6abkCqpCCCAEyoFAWT+b9BA8S7c6vd3qlG40wszRvauje+kaK7TiGbj5+7n5K9QrqeBZuHv2cfdUcqXUVXwz+9bf2LcuTfsy4sa3cOzcTdkXfxnllEY11EbdEAC3K+1f5KgFp0Ct5IITONclReBw4B8F5yWcAx8F0sylwkwjbsAAU8P1BDM1ir/l2C0wYAiokG8WEQFUmyHlTAPu6LQTGlIfqE7rC6vEQCA3AuGzirGhF6wm3KBbtlJpgenLDCrXgA1UwIpy68JVMBYWusk1Y2kxUWQU/YhS1IaRTEZEyLVXt1PEd9VtRpA+CAGEAEIAIYAQqC4I0GQXNtSVBtGC2QyDBDoF/I9bz0WEccEyr+8hty7da+RI0s6OYcCMn5hpX6Z4BnYICJ+VY5/AgNmrTAH2AWZXnkFwLbhgoQs0A5oL/lEYlyebTJfpxRBcuhnscyENBeYGWsiNKzdoxU8/G4RA+9eLtqiQixjmJg9m24AJzGo8pjHNidX1QHxXXWcG6YUQQAggBBACCAGtRoB2gkZFKSW14BkFFqjIXwEPmlYWJWSQw4YhyuAYZsIh5K6W6VTOv6vYFwJkaVLLSW3LpksDQgmUl87GoIzvMhydiU8o3vZCcYBy1XC9xdxUFawwmmQr5Btmr0LYAxBWEMLweBr8Xr3Y2YG+rNMXvOZwic7gO24cdOfiwEpTtwLiu+o2I0gfhABCACGAEEAIfEUECGnENCmXQ/ML6sDwKhiApVOKgwH9AsoL1AoucV22JXShBYaEcEWVI55Bzq8J0hh6yohluCCQP2Cr9LIwaUguu1aMaQZdWE8tE2JbHDYAAQPXrkGlHE1k2D905xrLSGN+swK5lSCHPWV14K5XgwcAbjxuCegxvnZ2PzbAAUYENzYDKTyZQPI1ZuJo5Yt2GwY3Nj1BdnaqdGZ1q5QCRQolcth/2lLLxemNC7TxEIdOwbJiwDLcrgVu4qSNJmqATZQwi3p/mlaU4PM6HdMAjZGKWoEA+fYYFbWdNsXIkajZUitsQkZUCAHyUxiWEQUicOduhM/YCsnSus5UXjJ5bQRjFtFhP65T9l2uy44JcDvoVEJ4KyuS+66frSxlgfZQFm3ooLQ9w2JL4H9Ke2lHJUNtwRaGizNQMGU5A5mZgtWE4MBmUpvJQUr3hUvNmzOL/D7rGpeTX6ZTMuYg9Wo33cW6Ea/R/DL1RXy3THChxmVDAPHdsuGFWlcSAojvVhKQ2iMG8d0S5pIiC8nLP2CiXGiD1x1DuHQvoTG6hBCoQgTEN3/Gcj6AArhbH8LrpzJpIpP2pkw9UWOEAEIAIYAQQAggBDQdAZzQwR2/Yayg3p/S1re+mj5NSH8q5QlDdgEK3KlzWQFBfLesiKH2CAGEAEIAIYAQ0CoEcJduQCFok3LjqDeHtMo2ZIxWIEAV5pAvtkhMsWqIG9Usq1mI75YVMdQeIYAQQAggBBACWoUAbmiH2UhyxUN8JPnmiFaZh4zRcARosnt/DpYTy9hBuJYn5AblZ9Dw/wKkPkIAIYAQQAggBCqMAFF3HAl8QkDvv0W93CFOf0649sQtS7WXSYUHRwIQAsoRoApzqbjL1NtjWL5kyzcc/i2tGylvXWIt4rslwoMuIgQQAggBhABCoBoggBtYEU2Wkfd/xwQJtLnJ98nk+5ihPWbihvMNqwEAyEQ1Q4ASU8JMLD0SExewmuGuvQlvSS4RtrKUBcR3SwkUaoYQQAggBBACCAFtRoCmvIHLyAfz2BfHNPcVJGhn1lJtnkmttA3H3fsRnsPKbRviu+WGDnVECCAEEAIIAYSAViGA61sSLdZinx6TsaewT4+0yjZkjIYioGMC+UNw5664oW1FLEB8tyLoob4IAYQAQgAhgBDQKgRwnMBsGvFsGlGCRCo1HCvMwcT5mJZuTaU4c+KiQ1dXV/ESqvmqCMD/oY4xPIBh1o1xXiVMB+K7X3X60GAIAYQAQgAhgBDQCAQgaQOdt6GaHTlZWfr6+gTiu1o37ygfmdZNKTIIIYAQQAggBBACCIGyIyASiWC7DR0dnbJ3RT3UHQHEd9V9hpB+CAGEAEIAIYAQQAh8BQQKCgr09PRwvGjrja8wHhriKyKA+O5XBBsNhRBACCAEEAIIAYSAWiJAkmRhYSGK3FXLyakEpbQ/fpdKvEWlGFUCVEhEORAQ5ZajE+qCEKg0BHI/km9PVpo0JEhzEUD3Is2du6+lOTh3IZKBIJAf8Gsh/nXH0V6+i/OKkUR3umIsqqiEo3CoKkK+eg6Lc+5s6ONfPf8HVFlNcP43VLVB9dUPAQjbBb5rYmJS/UyvLhZr7XMMXrN1dZlDTbATr9lGE9REOmoJArhNE4xvoCXGIDMqEQGcj9s1r0R5SJTWIACRDLyiQ2ssQobIIYDDM41cldacUrkJWP4nrTGncg2BbfqomENY9lvMNohw6VG5wuWlQbJoUzf5SnSOEPiSCFCiPCzzNYaV//5GkSKsII3etD0/hcqjf2M572mVISWk10jcwPpLqo9kfxkEjF1wPbMvIxpJ1WwEsorSkKHgXc2exRK11+Y3O7iRPQY/6FCGAPVyJ0124Ui6izl1xq0bKmuF6hACmooADv5dS99Sak8/9uenYrkfqdx4TBBH5cTBb0yQjGGkEgmQfl+Ui1u2V3IJVSEEEAIaiABKQ6aBk1ZmlbWZ75YZjOrUAfcYRH16iGW/A6PJp2uIFuuQ26M6zT+yVQYB6vlGKvasTFWJJ7ixc4nX0UWEAEJAkxBAacg0abbKq6vWxu+WF5Dq0g/n6RD+0zGiaBmZMIOM+Ke6WI7sRAgoImCgYlt22NASU3aTtPRTlIFqEAIIAU1EAKUh08RZK4fOyL9bDtC0pAtu4ox7DqdebKbtSb5Pxp4lnLtoiW3IDIRAWRDAjRzoOF/dGpixI25Yk/2N5SWTT1ZhhdlcYbhrb5zmwehACCAEtAEBlIZMG2axFDZo83q1UpiPmmDiB39gKY9oIAg9ovka3NgRgYIQqG4IUGIhRopwHUOu4WTsGer5ZowScyuhTDT7CzfzkKtEpwgBhIAmIgCx+5mZmZCGDHIzaKL+SOfSI4C8FKXHSjtbEn6TMV1T2jaygAxfTa9JRwdCoJohgPN0uWSXIsVk5AYqcqOE7BK6mImrBBIjR0R2q9l/BzJXmxEQCoUoDZk2TzDHNsR3OWBUyyKuZ07UmyQxPSuGztuADoRANUaAzE0gr48sXr6mZ0EErcAoSaIGlNi7Gv9rINO1EAFmpZoWGoZMUkAA8V0FSKpfBW4biDtJInepd8cpyFCGDoRAtUSAyo6l7k6nU+0yh1kdCPLBYLPGnFimArdvXS2BQUYjBLQQAZSGTAsnVbVJiO+qxqY6XcG9R7BvbCE9GSVIrE7WI1sRAjQCVPID8u40TJgpgcPCjwhcDi9AqPhrkpoannRWb3QgBBACWoEASkOmFdNYWiMQ3y0tUtrdDufpEQ1mYbyiLVhFuWTYCoos1G6TkXUIAS4CZMxh8tEiDHZlYw77lrzAJZC2D5azUAk3mDq0LTYXMVRGCGg0AkwaMj09PY22AilfegQQ3y09VlreElIy4b4TJEZmvaZebNNyg5F5CIEiBChxIRn+J/UKIteLNh/mGRAN5/Hqz5DAkxYhCW/ACdyuJcIMIYAQ0A4EwLkLuwfjOK4d5iArPosA4rufhagaNSDsW+HSFLxU7Gkq4VY1Mh6ZWi0RoPLTyHuziiMWDO2Ipqtxm8YsGMWXLBugPQhZWFABIaDRCMBrG7RSTaNnsBzKI75bDtC0uQvuNQozrcVYCJuuUbnx2mwtsq16I0BlviZv/4JlvpLAAAG7Tf8H+7CwqEBUD5UYypyiYAYWFlRACGg6AigNmabPYDn0R3y3HKBpcxd6n2EI5OUXJd4X5ZFhy+lU/OhACGgdAmT8DfLuTKwgjbEMd+5KNF6I65rIGJodC4mp6RqeHm4bJHMJnSAEEAIaiwA4d/X19TVWfaR4eRBA+6uVBzWt70Ml3iHDljJm4o4dCd+JWm8yMrD6IEAvQXu1m3pzSGIyzsPrjiacuypFgH7eS75P5acSbr2UNkCVCAGEgGYhAGnIcnNzTU1NUfCuZk1cBbVFfLeCAGptd/LFFurdScY83G8q4dBGa01FhlUnBCh4axH+PyxZmmRax4Ro8Btu6VudMEC2IgSqNQI5OTl8Ph/5d6vbPwGKZ6huM15ae3HP4ZhZHaY1FbmOyvlQ2p6oHUJAXRGgBEnknenFZNfYmWj2P0R21XW6kF4IgcpHANKQgX8XpSGrfGTVXiLiu2o/RVWkIE7wiQYzMR1jenxxQVEgb34V6YKGRQhUAgJUWgR5+1cs571Elk0Toukq3NCuEkQjEQgBhICGIIDSkGnIRFW+mojvVj6mWiMRN7Ah/H6VmJMTS0Vu1BrTkCHVDQHyw3ny/hysMIsx41TtVgAAIABJREFUHHfvTwTMxpl1mdUNC2QvQqC6IoDSkFXXmaftRny3Os/+522HRKS4W1+mHRV3hfxw8fN9UAuEgDohQJFiMvJfKmIdRolpvQgd3H8q4TkMx9HdT53mCemCEPjyCKA0ZF8eY/UdAd3x1Xdu1EQzvM5QzLwuowz1/F8qM0ZNFENqIAQ+iwBVmEM+nA+bp0ha6lkQgcuJmm0+2xE1QAggBLQPAZSGTPvmtPQWIb5beqyqaUuc4BGwt6quKW0/KSQfL6YK0qspFshsjUIAFlnSAbup4RKtzWrTq9NqSFZhapQpSFmEAEKgogjAMjWIZ4DMDBUVhPprJgKI72rmvH1drXF9S8J/Osa8/81PIR8vhX2nvq4KaDSEQNkQoD49JO9MxQQJTDfcvjV4duE/uWxSUGuEAEJAWxDIz8+HtAwo5662zGeZ7UB8t8yQVc8OuFV93GukxPaMKCpiQ/XEAVmtEQiQb46SDxdiorwibXGIySHqT8N5uhqhPFISIYAQqHQEUBqySodU4wQix77GTVmVKUy49iCz31EfL4AGVNwl0sSFcOtdZdqggRECyhCgxIV0uui4K5KLPAPCfypuG6isLapDCCAEqgsCKA1ZdZlp1XYi/65qbNAVBQRwn3GYuQ9TTUUFU58eKTRBFQiBKkMAIsvJ+78Xk10DWzrDLiK7VTYhaGCEgFoggNKQqcU0VLUSiO9W9Qxo1Pj0JhQBv2EGNkVak+STlVTOR42yACmrtQhQma/J279gGVESCy3q0avTTFy01mBkWJUiIJ42DX5KUIHculXUo0cJDSp4iXryRNS0KXnqFFfOZwcFlaANtwtYQS5fzq1hyp81ULGL2tagNGRqOzVfUzEUz/A10daGsXBdMyJgDnl3BibOx0QC8tEiotmfOLMNmzbYh2zQSATIhJvU078xsoDRHnfqgtcdDY9nGmkMUlrrEACKSW7bptQs/p07TH0JbZgGePPmvNWrWSHUuXNQQ3TvztZAgQoNJXr14tYwZWDGxOzZ3MZAfIkxY6CGevkS9/JS7MLWAKUmlyxhT+UKvI0b8fr15SrV7RSCGQwMDNRNK6TPV0YAfR98ZcC1YTjc1I3w/xWyNNDGCOLJsBVE4z9wnKcNtiEbNA0BeFNJRe+lYg5IFMcJ3Hs04dJN0+xA+qo1AuDsBCqpqCLwSG6lHCVlLxEjR8IPe6qyYGXFDwlRepXrSwbPrnjcOKaZRIGijkBMqago+OFya4aPwm/owvJdmuz26oU7OoIoLCWlNLqxvJxVj6sGW6mGhcLCQpSGTA3n5eurhPju18dcG0bEbZvitQcDz6CNSX1CvdgG7jRtMAzZoFEIUKJ88un/sCSJhwzTMSYazMIt/TXKCKSsBiDAdawy6jIEVLEeroqHDwfSyTRj+KgiWay4zaxjlXYMnzgBAqkjR4gRI1jyyvXLgguWqwPLqplIBi5rB18v7unJCASZcAlIfMW1rUIJ4NxFaciqEH/1GRrxXfWZCw3ThPAYQGbHUok3QW/qfQhp4ko4ddQwG5C6mowAlZcM4TRY9juJEcZORMBc3Mhek21CumsDArzgYDADqCQZGgrMkgm0VWWYjEs4JYVLPeW6lMw7aeduSgpPmReZ1qSIEDMCwfvLOICBHIOGLEWGZrSEopAJYtYsltDTkkNDS1BMTk+1OmXSkBkZGamVVkiZKkEA8d0qgV1LBsX9JlOCeCyL3mGYitxIGTngFpLsDVpiITJDXRGg0iLJsKWYMEuioHUj2BIF1zFUV32RXtUOAaCSjM1yvlUmloD1wsrgUrp4Bpku0hNw7oJfFkiqnMsZRocf4K/QkHY8p6TQAQy9ekEN7dwtOmVkwCXcykoqT/4v6x6mafHLl8DpNSKeAaUhk5/IanyO+G41nvwKm47z9Oi1a7AoXpiBUSLgH0Szv3BJ9oYKS0cCEAIqECA/XIDnK/iXY67jbn1xz2E4s/+fii6oGiFQbgSARCoN3gWBil5PCZWEHAhAJa2soAHrQC1ZAWDAyklwUTc5FqsoSkJA586F8AZFOcxiODqKd+5c2q0L7t4i9zNoCOSVkfbZhWtyg8rxeLmr6nDKpCEzMTFRB2WQDlWOAOK7VT4Fmq0AbmBFNJxD3puFkSJwttHpGgJXIDebZk+qGmtPUWIIFof4GYmOBB+vN5FwaKfGKiPVNB4BRa7JRgio4rJAKCH8AFgys1AMb9SIJpqQTqHIzwqI0BKKoh2gzI33LQ1YIJPuJV2yRncp8svSftwxYyCXAgwHZVYUyMcsLVkHLdRDlAUQcahhY3yZhWvQke3FFBhvNJTlmH3xqWqftJyor38Kacj4fD6Ph9ZSf33s1XFExHfVcVY0Sye8hidwDurpX7Ta2e/Ix4uJRgtwno5mWYG0VX8EqMIcSPmMpYRJVNUzJwJmw7+f+muONNQmBJgX+kw0Le0otbNj8x4wZkIDCAyAhV+0x7RooRjQSnD34p07szjQ5RMnoB76MvG+cIlmn5s2sYvJ2MZyBZqbYpjiejWopPOLXbtG/v23RGYRD2bKTPgBm5WMob/QHvgxrV5iIpBmliWDP5hxacMo1MePcInVijGf1VlON7U6RWnI1Go6qlwZtN9ElU+BNigADjbcvb/EkrRn1NM/KYrUBsOQDWqDAOxsQt6eWkx2TWvRwTOI7KrNBFUTRejYhqLoVcZeYIESvsixHxoQkydzKjDgoHTeA47PFcq0A/jIEZlmkGBBWfZcbpvPlsEbTWclA04MFLboAJ3BHcv4g0FbKNOn4PQtOhg1gLiD+5ltDxKgnv4BnRMTS4jrZbqo4W8mDZmODvK8qOHkVI1KyL9bNbhr36h4naFYQRqzlSuVGIo934z7jNU+M5FFVYIA9ekx7dkV5TKj4/Ytcd/JED5eJcqgQastAvByH9aEybk2wVEK9VhEBBurIPGnPnzIAAXUE3yl4FiVww1v0wbYJ1xleTDNU2Wz53K7AGOWG5p7lVtmfLeUVAFgwNzwCWgJZBcMYboQQ4YwVLhY/6IUDcCSJTIhENnSUi7ogo1nYMbijq4mZXDu6uvrq4kySA11QAD5d9VhFrRBBxyOepMw64aMMVTsafL1fm0wDNlQ1QiQb4+TDxcUk93aQ4j6MxDZreppqV7jA18EhgfOV8VYXgACvLyQ3AAa0F5VhYPcsweoqlzMA7Sia2C52LlzbA/gjqp+wNUKpJNtWcoC65el4y5SUsAK6EgHJECKBmkkMStKqfJwlV3HBuZz1VNk8KyoKi8wach0dXWrXBOkgPoggPy76jMXGq8JTvAg2z95bzaW+QqMgd0oSIiwdOqk8YYhA6oIAYospCI2UHGXJOPz9GFjP9jrpIrUQcNWUwRo12ZKSsmOTIYHA+UFYirHiWnn7ogRxdiBu1R6QAgBnQFXelrCXzpGQjbUQXG9mlx3OgBXSpEZ5RnWDs1YW4DjghyaTKemwoo6NkiXFQUNwOUM4RlMOC9br+aF/Px8ILvghFFzPZF6XxMBxHe/JtraPxYOjKTRfPLuTCz3I1hLkxVdM9w2SPstRxZWNgJUQQa9Z3XGC4lgAxui4VzcxLWyx0HyEAKfQaCUUQQgheWRXIlMZXFSMysrNl8YOFmVkl254AGQBpSU7cUIV7pejY6s4PBpVh+G10JHYN6QhIHh5eB1ho0ngEYzvl4YFLrLUV7aOc1E8YJjGBbYcfat4NqoVmVIQwaZGVAaMrWaFHVQBof/DHXQA+mgTQjQG1/dmQ7hvLRRhA7ReBHah0Kb5vcr2EJlvSEfLcbyP0nGMvchAn7Ddc2+wtBoCISAliHAsGc2MwNjHZuRl40ehnpmNR7tdS7itXSm3m3bJHy9KOSXGwVBZ5NYsoSl1OoDGkTuwmI1Y2Nj9VEJaaIOCCC+qw6zoIU6UNnvaS8vs8CIb0QErcBNXLTQTmTSl0GAhO36Ys8wsnHHjrjPOJxAL6O+DNZIKkJAuxDIysoyMDBAmRm0a1YrwRrEdysBRCRCKQL0jq8P5mGkkL6qZ0E0XaWhW69RgiSae8Eecuj4WgjQ+ewgzy5sF2zmgRs7FQ+rZ4m7dMP1y7xwp1gCKpUBAWFGYlI2XqOmrUmVp+yHR2jqw3l22WIZjEBNtRgBHRPcuQtu5MCaCJ5dgUBgZobeBbGQoIIEAcR30b/CF0SASrpHh2BiRbl4jRyIoJW4rukXHO/LiBbfn4ulKll2/WVGQ1I/h4BtU17A759r9BWuk4Lk16/efMrjm9q61XG3rFhytNz3Dx+9zZFNWo0TOgZmlvYuHk41qsi3LQyd6ttmrcWiZ7dmeUoJryj5eViKpX9d26+59B3i7sgbYzFB/FeYVzSEhiFgWovXfA2rc05ODnh29fQq9nlkxaGCFiFQRbdRLUIQmVICArhtIF5vPBWxlm6TGwdZpYjAJbCmrYQu6ngp+406alVtdcp+W9WmC14dXzVv6ZaQR/ECkl7/gPMMa9bvOuL3xTP7ehqWSzlRTPCYDgseFyrpjPNNHBt0HDTht5lDGporXdykpNMXqxLenduu1YpXbr9cefZni6/IeMkCRHa/2KRquOCs4huCWCwWiURGRkYabhJS/4sggPjuF4EVCWURIJw6krAPRfReuibzFfloCb3KnvcVvylZVSpeMLTH0Jv0isNYPgmCRCy/OJFT+WRUQi8y9crc7v2XP6C8e/78v/5t/JxMxCkx98/t3rRr0XdXrs4/dXpuU5NyDsOz7/u/XRP9ODdlcV5G4pvwGyH/7V/945kjp9Yc2zW6XtU+LfIsXD3szDJqu1lK/b1lNDb/1Dj/kSH1Vz49MNSijF2lzc08MI17Zpbqjv5WGgKF2Vj2ezlpsFINpSGTwwSdsghwbq1sHSogBCoVAcJjAFmQATtQ0FJTn5CPFhEN52jifgG4pS+KHK3Uf40yCKMMrKm4q2Xo8EWakomHJw5d8dCo14Zze0b7SH25rTr0GTai9+Rv+q1fPHZZx/tLA8v5LlXPrl7LNm3kO/cePH7mr3tG9xy5Z9IgV+87K1tWpfOKV2fM8dgxFcG2IOvTp5TMPHG5ZeAWvji/all/uXVHHSsNAUqYDSHdXHEoDRkXDVRWRKDKX48pqoRqtBABvO5ovGZriWFFlJcSF2ihncgk7UZAFLl55ZFE2+//2jKSJbuMxYRtl8VLBtYURx7Ye6fy/7P1PYf8u22CFxm55c9DSbJBvtoNOLIOIVBqBCDnLp/P5/HK+eah1OOghpqKAOK7mjpzmqU3jhO43y8cyhtOPlxIifM1ywqkbTVHQBx7/uIzsV2XQd0tldw5zdq0bWJAfnzxPP1LMFLDoKHf+fKybl+9W5TwpJrPBDIfIaCAAOyphpapKaCCKooRUHLXLr6ISgiBykMAx3m43694zbYSkWlPEeWtPHSRpK+BgDi1wMDDu3kTbx2lo+mYmBjgGEl+CboLW3fVqu2iS2XGx2cygwtvz/I3M+/w9ztxbtSR+UPa+jhZmVu4Dj3AVU2YeDf4twHtGno6Wlnau/m2+X7apluJIm4LaVmUcH395L7NvJ1tzM1tXOq1/m76lttJymIOcvd+Z2FsM/igQNpT+lec+nDP/B87NarjYGluYevs3azXuJUnX+ZIL2fs7GsB64iMLAcfzKCElye70idG5u3+FyNtgf4iBMqPAKQhg92DUc7d8iNYDXqi+N1qMMlqYyJ4eTG/KaAOFV8UiJn2jM7Y0Gi+5mVsUBtIkSJfEwHdxrMvRM5WNaL4Y1R0Bu5Q10eZ81dVpzLUFwoLxRiuqyMl26QwX5AryHy4sse4uTeETg0aNW1jTLiw+f7EsSem9h++7pHYrXW3Tj90q1GYEHHt1Npxx/47uvjYwRmB3PSkgid/9+82/VySkUerTn27OJuKUl/d3/9L2wOnV853lFeQEhVAetN8OdKcff9/A/v/diaphm/7Lv07OJlSqdF3z+/5rc/e3cP/PbZhkIcuZtBo6ILFLUWY6Pm+BdueuPSdPbKxAYbxarZEqZTlIUbn5UAAVqoh5245cKtWXRDfrVbTXfXGSigvTlBxl2lt0iJoyttwPlqAUvVzgzSoEAKiyL2HHlG1fv6umfyCswqJZTsLHtx/Vshz9KjN3SWVfLP1l5WGHdfdXTu6kQX3bV32rbl9Bq+N8Zp45PCK3q4Sjci02yu+7zt39neTPO4H97WVtM84P/376eezfSccPbq6p4s0c0p+zJFp34+eei2fxD6XR4GM2z+638zzVMeV13f9GsSy/YKYw5P7/bhl1AAHj9AFTfR8ek/0AWPyjzxctv2pU+tRv4yxZm1DBYRARRBAacgqgl716cu9Q1Yfq5GlVYkAHcvrOwl36CBRgqa88ylRXlXqhMZGCFQMAfHbHbPXhRt3mjr5y9Bd4YvNK/Z/wF269gmUMlJaYXFyhttvh4PHypJdTBT255S/wo17/nX4T5bsQmvCotnM3Wu+tYnbt2hDuMRDK47a/P/2zgOuiaQL4LubQEKJ9KKAVKUpqCjF3ntFztPDrnd6p+d99nKe9ayn3p3t7N2zYUdsp9iVohSlqDRpUqUHErK734aahAQCBgjJ258/2d158+a9/2R3XyazbzYej2H2Wnt2V3WwS8kyrcf/7bO9jyoV79axsR9vXe2TbjH76Nkl1cEuVYdh7bX37G8eaOi+HVe/1KEDioHAVxCANGRfAU+JqkK8q0SdLT+uVoS8poMqTMqJJILXQcgrPx0EltSPADdy/5wVd4i+a3fMtJD52+FEwfubG8cPX/GwyHTC78t7C2XiwozHLfqxg2AEzDec/d8/R0Nxpzlrp9SwBjP2XODdjoy4dqU84MXfX/YJ5OiO+GmWXY0f+2gWkxd4mdXlT9H9E5cS6G5zFg/UrgGNbj/1Ow+V3BcPAmWfs6JGY3BCaQlQmRmYTKELQ2lRgOO1EKhxi6tFFopkT4CTFpumZmmu1aDvHUR21Mt36aWkdGZh2tauncxkdk/42lVFqXcLkA4/U0tTkcn3+A5QIW/QWqzbOpRemdRUOrdACgg0MwHiy4OV363wZ445enhezaCxHsYRmXfWeI3+C62ugnMKs5Oi331IY6M6nWceOrV7oonwrYJm1r7mim7c13f90zDHmeM6iLu/q3bu6aa782JoWD7ioovkBwZG8lR79etbM1ilzECZagwBc6oNq97jhj19lY3ZzRlYI7Tmy2CGo9YeV483bC/OkmolsAcEGkyAegBSacgwTPjKaLA6qKi4BOAu1Dx9y8sM9z1z9MSpC/eLJt1592cv0QEaqaziPtk02uvslzp/byxXptJje9TjpdZ1jdZI1TJStaoo9/1O6WqIkSoLeedTBRUhb24UP+Ttuh5VgZBXDC44JZcESt7u8/beHWO38OahyWJDvnpYzSvOSU8vrQowqZ9B6GpatgOmf9N9iNe3wzvqSnnxFkRHJ+O0jpkvjh8OEtM6kZSlgvIy0jJwRJdM/pTCxYytbQRfXxNTR/Kp0oT4FJw+yMZG/LOEZtZz4vSekqtDCRD4agIkvKn21QyVQoH4e5RSuN4sThJ57+/9e+z4qX99A1OKaXQaj7RouB2qvX+98XC28PgukXxu/owjGcO2nV/UVbhzqfFdEymfl3WbVLWqaN2itUpUhLzU62tJd/iCudFEwHKs6zpYxqxWbFAoJwTwpEs/jl/ygOF55NLmfkLvizXEQKz1uD1P9/X/2tfd8Ly8ApwsCfpnnrhot8IwFSMu/85BFBWxSUxTq1WDbw0lRWweqq6pKXy3aYj7UAcINJAApCFrIDglqwY3qabrcN7bvRM8f70RW6Bi3GXYD7v2TnMJmd1/U0UyzYaYgenZ9+hjL1wTj3ymgSKqhg49+/aV2dwF4Sb4R1+/qmiVTn7I6/gTgqJk4m3+yYIE4uUSfsjLMq+SgR0gIIcEcp+sGT/7dHb33+8em2olP7dSFMNoKM38h2tB23pW5i6rQQ+lq7Eok3l0FRpK4jxcyl+JauhB+MtZUQp4DVZQUyWcAQL1IlD1i0i9aoGw0hGQn5u04qPHczJLHads3TJjymgXI2oCAy8iXPGdlspDfsjr8CNC1yDjfPgVSrKIV8uxLr+ieh2lqg9CQKDJCXAi9nl/uz3C/CefC8u6ajR587U0iOkY6jHI8JwiNW1twdxl4qpghgb6KBGVmdHgcJWpb6CFsrOyCghEHWZQimMM5xqXAES7jctXgbTDDarpOpPRe/3Na3uXeJUFu03XbMtoiQp5MdtpKBX1ImWfSV4REbSGSH3cMqwHK5WMAJFy5SfPxfdVxuy7smuYobzdRTVdutrTCoKfBta9Xjdm1MHOGP0SHhIjsoCE1B2q0rGjHR2Pev1afGN47O19O/66HtVQ9VLbAYJAAAgAgVoJyNudulZjofCrCdS5BinxJfT8xtkj3e3MqHVF9YwtOvQcN2+H74cai4dWripabVG56lGHqZEibsqzIysn9nWybqNHLSzq0HP84sOvpBpAwsyHY11WIVjZDEaSR4btIGLLRnyrm4E9INDcBHKfrRs/82Sm2zqfE9MlvKbVrCbS2o/3clNNvLj3QlKdw7YM96H9DPDwKxfCuDVtJgqSknPqUEFrO3yYCz3tzoW7OTUVIHj8lU2LVu5/nF2tBcNQhKS26jNi6sEpIAAEgICMCUC8K2Og8q6ueg3SXt9uupmg3t6jby/nijVIiS/Ptozo5O692S/NuOeEuQsXzp861I54fWLZGNeeC26kCj2fxKwqylfNLirKeLJ+iMuAJZczWncfO2Xm5JFdNBJu/Tln4MBFd6XKJIEauWFumxDVimVRyQ8niYh/4OEo758r5bGPE3Vg6oQt4aZzTl9c4VrXdAGEkxr+MvxzUyefpdl+v3qGVe6NpTN2BNZ4QYAbc3rmwG/3vi4q7zPNoT/OcETf7lu2563ICC3+6dLCX69mCV33YvqZ1n7mIi/jtPO//uqXLiKLp1xevz8Adfx2kmtVBhpUR1sLJTM+fxaRFaNZ0U5xs9NzPueJ+V4hnaO83KyclC8luHTS9ZMqKUxJz/si8gGonwoJ0qXFGek5mWzl620JPOB0MxKA+bvNCL+5mha/BimReHq2128PNDz3vzw8p1N1eqKCsD2Thi3cN3dJT48zEwzq+IJEpFz6/rt4tTl+kb8NaFPx4SJynq0dNnzz/uV/TRmwwUWKTxyqbYu576AWXUPYnylGZKIfWZKNdVqK0r72zfXmIg7tKggB4sudxZ4LfTMNB022ibu4b494t2gmvad6OlOxMOe/hd2HHUgxm3c3as9Xp10Q35aEs9pDtp3eEDVq9cohvUIWr/5lyrBu5iyyMCnsgc/BrVtPhGpPHmaoVlGV4bZy//IHIzetHDY8dcPaOWPdbLTwjKhn149t33wqp+vgdoll+bEltMM/jRl67jz449uJ+yf2zVy6fum04S5tNanXTgNuHt26Zpdfruvqs8u6VYW7CMPJo4vW/utntp3y3ONtz8gvRA10m336Mzf5fVJSKcvewVBb8h2Ok5kSkszRtbBoryNZqBZO7LDFk84/9fCO3dSlFimJRdyEHfMOnNIZ/nhff8sGZ9OQoL3I/2KPzR8HrFl/dFB1T0mQrd9pbtR9zwVPtWcvvT7ZUNZW188SkAYCUkQfAEnRCPDXIN3qd3yu0LJMvMiTe3yzjCcfEgp2KddZzj/tXuLjuMT33O3cCVN1a4fB+xic9/Ntv/X9darlMJ2eK9Z+e2LUST/fqDUuHaX6yKEarTGPP4jgDUjeB76mjAAiYBXmsgZlVAfi1S3AHhBoGgLE56BXsSUkL/XeH4skh4Gqff4cOdZZE0NoeuaWuuolFuZ6Tf+o13Rb4fvEat0vq/5ZO/H8GoRGpyO8UhxR0e0wZr3v38sGtKmO2Vg91924ypzzw+a/ZvfdNZt6eRQhEZTVbvSKS6fHvvK8KdnRSuiY0Yi/795s+78FmzdM9FnLbwvl8XCU2cZjyoEL22e7sCoF+X91x69eefTJivOzOp2bhaBqY0+yr04RLG+GfTzn8s4Df2R2O31hQj+J8R6R6X/t2z2pwzasPSBZqBmMhyaBABCQjoBUwYd0qkCqpRAQuwYpqtZl6rqNOgP71QwoaaYerua0lwmxidTDqnYnMb3Rq1f3FQh2y8U13D2cVY69+PCRh0gX71LVUFUtzG0zEbodyQjka8n7QLxays9TptGmXCn8DwSamgDd8bdg7m9St0rvvNw/fbk04nSnda+566SRrJJR7bnrfemuqkMxO+p2E7bfHb8q5sXDp+EJWcUYy9imc6++3cypSFxkw4z6rboWNeed/72XUal5iFbbjj0G9rbnr2/R7xV3pZCw5rTrJdOEzpQdYMZ9l54P/ykp8OHj0IRMNk3bxM59QJ8yFaLCjE5L7r4dcOvW04/ZPPU23fqIlsMxEAACQKARCEC82whQ5V2l2DVIadYjFqwaId50TE2NiVKjQ6XiiwXO0qw6dRaXdl9NW0sNKS4sqN9b2tQEBiorGRl5kJrSwG+E/Zmfmtd5CWrQoB8EBeyEXSCgJARo2ja9PG16SeEtXa/DoEkdBkkhKVFEw8x11GRXicVVBXSjzmNmdq46hB0gAASAQKMTgHi30RG3vAYI9ueokLD3iRl5bC5OkCRCpL6l3tKueIOsYf7wU+zyX8qub20qTRnq+CPBNKBeXOPXLS0ggtehNhP5/9Aaw1T11Q7yQAAIAAEgAASAgBIQgHhXCTpZehcLIy9tX/fHsVuvU6lFRlXUWK00VMpiSrw49yvjXeltECeJWXsRaobk290IQb3qTpIx58jcaP5Ab2UaB3GV4BwQAAJAAAgAASAABPgEIN6Fz0EFASL7v5VDv9kRpuY6edWpKWMHuNoZa1S8ZcMLXdPVdWuj5MGRGj/WpjfJaku82YKwU/mVskKI579gnVdQyRyk1gGCQAAIAAFZEeAFHfjL+7rOmn9nTNYsCLjz7Pgb8VTpAAAgAElEQVS9yNCkvDycYWBm1n9ov/kjzfWl+QmKYL97SNWNCozJziwmVDVaWba3Hjqi17QehuriLeWlvHl1wCfkcXRmRjHK0tN3dnP5wdvdVdxEMmoZz4yIN0cuBj/+mJmcS2roG3R27TJzkqubtG9QSl8dTw95uffSm8fvszLYCEvfqLO7y/eTXJ3FuwBngUAzEIB4txmgy2WTRf5r5uwK1fE+++j4hLZN/za5NExQlgXW/U/i7d9I+gu+PH/Z4RWo/SzMfKQ01UEGCAABICBDAkQpr7iEw86J27nm9O6PzG7uNkMdmLzczODAyEN/vH8SP+3yz3a15y4j8uP2bji7K7BQu73tgP62JhpIUVZa4Kugjc/eXPWcdGpBB2PRiJkbdvbI2mOJTIf2PftYaGMlSR8+PvK5fM8/ev0fU2ZYqwh5h+fc2Xty4ZVkvLXVQNeuA1h4Rlzs/cs+t/8LX75p6jzHyox0QnUEDupRnfvu0skp+6Iz1fTdXTv2M2LieZkhD657PYxcPUNbQCPsAoHmJADxbnPSl6O2OUHXbn9CXTb+Ol5Og91yVqiKOq3LSiL+Gvn+OEKt0EStwRZ5kMiJRDv8jNLrun3LEW4wBQgAAYUgQOb7bjuTyPA4c2ZQL/2KgQKiIO6PJUd2X/U9PLTdMlvJowdEjs/Wk9uDVYcvXrBjjEn1CxLs1KPrDq294rPByWJvf6FsGvinZ6tSjCdvWbrEQ6cycxrvk//VGZsC1q31sz00pnv1mHBJwJHj8y5ntxs/7fCPHc0qpImct/5zf729dc1Vy8MTh4sfEi7vl3pUzwu4OXff+0Lrnkc3jRpiXBlUcLJu7Tu9dG8sh0Ag5lWIz3qLd0L0y2OLdwgcaBgBMr+wiEQ1WCwq+aboRqQEvUls3tkMwiZhlmMxty0IoyI5Gvn5KfFiEVmQKCwFR0AACACBRiaAZ4YVOe/dNLQq2KXaw1hWP8/oZEymP3yeUUtKGl5C0LEXRYZDxggFu1R99TbT/9e3m0rB/f+iRZbHI9kq/RdNXVEd7FLSdPN+4/ZOMaMnvtp9p3oNS96Hx2svpmr0HHN4flWwyzdNp2O/PQuc9bNC/ryaWptt0lfH08+cDIxXtVy8ZnR1sEs1xdAf8cu01Z1oJfV+S5mqDBsQkD0BiHdlz1RWGpt0KVIVB4d2KrzgKxepFLlCG5H5aP3kFbdzCJLL4QqVNOsBquOA9fgb0aucHlaUTLxcRKQ+blajoHEgAASUjACqMXjaoO5CK2rwCag7mjvQyU9JmSL3U0E6KMPUa+awVWNsqkd2K4tpBhadjTDO56wU4fp0866ze7Wq8dim24326K1eGvg4snKZZu7TawHv8DZTZriYiY4vY4Z9enmaIu+fvo0UVl7ZOPW3HtXxxHDfSFyne49J5qItITTd8V7OAiubCLQAu0CgyQnUuHCa3AJoUDwB/lKkLj1ceix5SGUkaPyNZjVt0SSz4kerRnqtv/AqLruInfc5+tmlHXP7dxlxiDl7trsKkZWe3vh21KMFlKGNdduAWn9bUQfnkGE7iPC/yNLCemgBUSAABIBAgwlguh3aqYt5jqqqtWIgJcWcWn4Yo5k4zJ46wMuBKaZxVIVJzUDAcdGIVF1NS8xPcAimZeNug3HiEt+WJ0kvTX70pgCzdBgmdulhFRNXB3U8KTWCLaZl/qn6VC+ISvqA05y6WNdcqYjShKqqMMQZLKFhOA0EGpFA5VSbRmwCVDeIQFMvRYoZeu69eZA2femp9ROvrys3GaVrtRs09+SjdcM//HjySHAItc6ZZ4OcaaxK/Oy87SeT2nZE+E6kLMwlUx6QWW8wx59QI/fGahX0AgEgAATqIFC2LrO0KccJdlbGu5iMlNyS4lKCoCYAkHnRBSSiUUcb1cUYq60xE4nISy0gEAaGsDM+ZhI0q6Jgv1eh1UJVe2RqHobiBRn8tOpiYvX6VCc/p+WVYiwLE3h9ogov7MgpAYh3m69jal+bVPqlSIU8oDmsDuKuFjoleFDrGqQaHWccCfJa9fL+45CEHELT0KJjrwFu5hr8+6Ht8TT8uKCimquK1qqaOe5MNn5GUIEM91HDrtTcBiJkG7XmMF8tJ4d4swk17oU6zEEZYgcdZNg4qAICQAAINJgA54O//45/Ax68zy8mUTqDwVKjlY2HEiX1incRVIOpgpKl7LIhW7youAhHONEvVkVLNozGKuWJn1pbn+oku4RLooxWGjCKKxk1lMgHAYh35aMf5MYK6k2LHp5WPeTGHikNQdUMMY/tJJW34eNZhOD/pEemPSWzw1CH77E2faVRQubHo60spZEEGSAABJSRQFlwKMuwjih6cvDQD+dSmfYuC1Z3HepiZqPHqJgDy0vZPvuvvYT0mElOKU4iGK3skU4tZ4mhqMnoGXfmWkl8xqMYU73GjNuyButTHafTMRQheFTjsAEB+SYg8VqQb7PBOiAgSgBFaajVeNLInaCWYcuJ5BeX5pNhO/HPT/nTG5h6ohUqj8nizLIq77Duf6OstpWnleIvtyA/k41q6bM0xT/4aofAzU4v4jI1WmtVZkaqXRxKgYB8EkCZGkyUKOEU1hZfkgVFXBJT1VQTNwGgQX6x39xZdiFVa7D35ZWdTBtyAQq2WpqVU0zS1HRZfPMwFktXBYkq4DJZatLPiahSV5/qqJ62BkqkZ+dCvFvFD3bklIDMLl059Q/MUjICqIYJ5raVmsmA0CrfAskIJJ7+RCTdE0uCml9HBK1BskOpEQoi/E+SqOX1ErEKpD5Z/CUsNOZFSFJSsdRV2NmhITEvQpOSpa8ite4yQV7oyf3u3x47nlLbc16iSnbY4km/99z+TqIAFACBFkEA07A21cCK0yISarn8OZExWTim385cVg9NXujT6GTE1Huq01cHu1RChdR3CTittVG78tuemqmTBVoYHR/SsLed61EdM7AyNETZUR+yRF+taxFdD0YqEwFZXbrKxAx8lW8C/B/jzEdivfYhep0qLOWxyXd78MDVJFs0xQRf2H5WhVh+DBl3qZGc46UELfvfP14L9i/yza7loSrQOhF7/Zzngn+8/udzIVW6GgKVYRcIAAGpCdC7ebQ3IDNu+MVKyu2Cp76+8Jqjamffz1BWD02yoJia+aqqWb1CRLW9RFbS2wwxI6ZEZmaMuG+/7PCwhxlI687tHcpXWKMZjOhrrpoeevwh9Upa/bf6VGc42HXXJiMfh0aWp4YQao0ozMjNbYgFQlrgAAjIhICsLl2ZGANKgIDMCFAzemmuG9EOCxB65Q962WH8gd4PZ0ie0BMDNeiKmg4qb5iMOU9N5JWZEWIUcQP8gqKkGQkpTb7g96lEjAY4BQSAgIwJaHr0memg8unmlVX3s2oOiRL58bu33H3O0fGc7Gb9tRMPqiyntbfQV8GT/B6KjowSOTE7N/g+LCBJHs4VDnqJjNcb9r9LF4kg2Z/2HQpOpJlMHGNd+asWZjNq4Ldtiu/uv/BPpNDtjt98aZbPlgNzLidJSkdGTYioR3V1u2nDjdC45xsvfxa5X+FpYWsPv/0i7EKV/7ADBJqYAMS7TQwcmmtSApjZIP5Ar6FrRasEl4y9QDz+gUi6S5LVg6ao3WyEacCXIXEifBdJSBOQNsAR1ECfRca9Phta98odRcGvriQibYxbyezx2gB7W3IVKg0zmfmmJXsAtjchAXqbH3/1HGuc47Np95jf718OSUtn8wi8NOdz0v2rN6b+cGhHOOY2/bs1PcrS1cjGLsx8WJ+xhqUvDh75/ljI69Qidklx+qe4m+cuec06cobh7u2AEbkFWdV3KX6rdLuOTm/Pj13me+51elYJgXMKPwY/X7Ho6O5orMtkz7k2AncLlt3q1UPdkZjNi/f+eDL0dVoJpYnHzgl/+njp/D2L/stV19WsDI7F+VOP6vQuU8bPsyNfHDg0eW/Ay0R2CUGwsz/7X78+cd6V9za2VgJGiWsJzgGBJiIA76s1EWhoprkIUG+q0Vx+I1KfkFGHEW4u3wxuLvluL5lwA20/BStL04uqqGMdFxBBv/FLCxKoUV4qrS9/X8YbatbXpZ3v45s3I5Z17axTi3KiwO9meJpau/l9ivf7iAzm1FINivgEqDnZZPJ98v1JBOdgvfdTI/3ABQjUSYBu2nXPAb2uB/3237vz8907AvKYrrXj/zYOn9fbUNzUAwHBeu5iOk6bt31D23zz0vEzd49XVKZpGPQeO+nyDPu4nUFn36eExPKGO1Y/pjGd9hsXdz3yx5XVC/0XV46bokz9IT98s+07cxHzNBwHnNqrt/Nvv5NHT18/QuVuwBCcIBBM26rDkm1j53XVqn24qx7V1a2WbJ3B+OPi7osXx1+4WO4JqmYwZPK0Pb0+zXr+vp5gQBwINAoBVNp82I3SOigFAk1HgJrGQMZdpnKWIYTAL5Y0JjXnAW3dg5rHS0T8Qyb68Q1CMcxjB6rVrtw4/IE3ws3nnzYbXEueh3JhSf/zYu6OmP0fbca8WbHHfnll8vup76cbS3zc4MmPvpnuG9d3yjHTh2NPIL8cXbBYdj+jCljIC9y7Y7yP2rJTP//cVqIxAvLCu+yg6SPPP/Xwjt3URbigUY5IdhqZ4s9XrW5M63NYUhtkXgwReQDJrXzEGnnQuqySJAznWwoBEi8h7n1Tbi1qOQ6l1zY0+ZVO4YXZYeGfotIK8jmIWisdGzvLbtYsxlcqraU6UfLp3YeXH7/kEQz91q3dXNqa1p0CAs+Oj336Nu0zG2XpGXZztbHVqmUQlchLTngelpqUV4qqt7JsZ9ndXrc+w9TSV8e/xMU8fpeRXoSwjFq7drVqJ3Yxi1pQ1KeI5BaQn3zLamC0YdfrUxVklZRA9RdHJQUAbisNAZSuxl+Mre0w8sOpssipbHgELyHDtpMf26BWnmi7ydTabAg7DSEJKlcDPz0ZrfztD5kxIgjGkNHOJk8CzvulTZ7ZRsLlx3vrFxTM058x2o4Z/IAKs8U1z/scGnT0esijiIyUApzJamXR3mboiF5TPPRFxngq6vLyX954cOTeh7CU/EKEaWxu3n9wrx9HmInTzD/Hzf505dITn6CUuLRCXF3L2t52nFffSU6tJBgsrIaddsvnyYXn8RGp+UU4naWn7+jkMMGr+3DLxl2BiT+BgerZRGpkrnLgi/oyo20rbBwcAYE6CNA09bp012uK73DlhmBMcycnc6c6rBIupulZth9r2V74pKQjTMvUariplaTius5LX52ma2U7zgquuLqIQnkzEZDq+dVMtkGzQED2BKgBWtRpIWkxhgjbgRQmVTTATuXPcKDWqmhlzY93qa0wifx4BrWbIVsLqJ8TmZ3cvaxe7b4XEOg9rrvYUSP2x7N30zHbYd6OdE4ANZmhxsgN74vfvlNLriQV65j2duvUX59emJnxJuDl+seBZ4eMO7rUtZ2I2pKUw6uPbAwoUDe16tvbzkSDyElKvL7nnxsvRy4qm7Qs7COR/PTG91ueheO6Ht3tvDzUSrM/v3zxbPmTN37fzzjobd5KWFrkiJsYvGiFz9VUunVn+6Ej9LRp3Iz4eP+7fvfuBo1dOOPPEUYipolUb9hhxQSGDyfLh+HLlfAX2LOf1eDx+IZZArWAABAAAkBAPglAvCuf/QJWNS4BtJUVrdd+Iv0VQs3rTXuOIGVzZDk5SGZwVcNk/FVq9QpUx77qzNfv8HACoZtMHGF9cHfo2RdDuverORpLZD0NuJXF6DW9qw2NDMMJUjTeLX5+4Nj8y5ltBk04tNDNQbPSKHbGjUNnl1255I0wbqxyFpgrUey///TGQI79+OlH53UwrRywLkkJ37D24voQHoEIDbsWht+eteFZgnnPIxtHDmtdcX+g3k/fu/bE9sOnVpv+768+ZRntK5sV+otnnNhx5WqW0ffbZv3mVv2mHTshaNmqS1f/PG9rO/8XwVdqhCo38IDMiyUi/6mewECp0TDFHOeies4N1AjVgAAQAAJAQOEI1H/SnsIhAIeUlgD1shrWeRnW5yDadhiCVUaC1ThI4tUyauJg9Ymv3sN5/PdFzAa6DWhVdP9WmJh1HvAvV3yj83U6ePfjv03Cj4+FN06k/5rLaWrdRp1YKRDsUjLqhqMXzNw2gJV6/8YfL6szEOGfXv5Fhc/Og/fOrw52KXGmidPGjaM8VHiVv/2XNcNLPrD7SYSa4/qNo6uCXaoAa2U5f/XYUdp51048j5Ccu4LIen/vLVenR/8lAsEu3zSLbpvnuRiVJl/3T5Vcu8yA+vxHTWAgIvYTLxZWB7vUBAbb6VjPPRDs1gckyAIBIAAEFJ8AjO8qfh+Dh7UQoJZXoyJd1GQgwrIk35+gEvaICJMfzoqc+ZpDAsf51bUcp/TT8fMN8Pnk+oul0HQFXkzQhbe4pZd7v7KBW1w03uU8vh70njSa/727Tc1rF9MaOav3yae+vjfCV3i4GfC/zBKxj8JDStVHjHNrV0Oe1tplVt/7/92sdogd/OLcR8Jh6mCv1qLfhDG9jrMGG/hefOcXO6ijrZDNVfVJnFdKDUer0EUrI0grZ9clU1tlWctm5WH+BIaEa2T0saqm+Tt0Df4EBoYekh1OBfFkaRHC/oxomFDztoXE4KAFEhDMHtgCzQeTgQAQaH4CNZ6BzW8SWAAEGpEAtcQaf6ICJxspKfvHoTKUiY6hCjZPZgQIHn7dPpU/npqfQG2q7qNdHG48uOT7ae7PVgJTWjlPb7x+TzNbPtK8/CSOk0Ljr9ykJ6EFmIXrCDHRLl8vrY3zCMfbAe9igrhuw/mvsJeERKXzVCx7dBYf8zEYdIG34XjhgTEZqPHE3sbi7gv0Dk5ttc+HRsRwENua0zDKWjew6maKBj97fCjCcoGjulDUq2n53SxLvpAsNjL+Cv/LicjGKyLf7hbCVSZQ84xIPThsAQQw2XxTagGegolAAAg0DgFxz7XGaQm0AgG5IEAlZEi8Jb0l1FQHMs5HevnaJYnycJcai7Ryndj58W8PXj2cYTWscg4ukRPx76Ncza6DJlRmB6uSr1BblBmXSar3amMt6cLFWI5WWlhYdlwGgVBKeHnJWTxMV9+ico25Ws3jxCTm4bTW2W+DzkSJESQzilRQIiu7AEfUxQ/wqpjNXzLwzW//bZ+/7bZH5zF9HPp3s7LTlWSrmCakPEXmREspCWJAAAgAASAABCgCsn8UAVYgINcEmHpizKPWHKbOU6kbqF/D+Tu6FTtqRqgqC5ddvFvdNKY7dqTDrg0R//rnDRlVnvidSP7v1cNC1qhRTkbVQ6NCo5M4u6SIQDU1meLDTb52VIulhiKcQnZZRZLLLkEwNabkV8yqLULwkgI2gXCTTv2ZJHBWZBcz4FXG7CIl/ENMu9OQ88fbXbz49PzDwC1Pn/6OqRpbWfbp6fztyC7uRjVnSItRIc0pzMqTyHglKonSETWBfBM4l7+8iKo2QoOhQVFULe+Yml5fmNjyzAaLgQAQkBsCEO/KTVeAIU1CAFXRRC3GIAwdhKHHT1ZVHt3SGjF9vSS3dHp4jDYO//dWcOzwAe2oAJaXet4vnmvae7Kb+LkHlB6UTqOhCEG98yZ5K+VPEabRyq9sFFPB+NmEcaGwWUJlaskNDKXe4Tt+eKSr5BsDnZoDIUFB+WlVfavJP1H/eFnxCS9DYp8FRtw+c/HihUdjfpr8x1gTqQaaa9VPFVJJM7CBF8iYs/yE89QM7PINxVCT/qjleJlnTa7LHChvdAKC6000emPQABAAAopIoHocSRG9A5+AgBgCmP1szGo8ZtIX1euIarRBmyPY5ZvFtPQe0oaIDj4XxU9awA4N8InHOg937Sx5GBRrxdJnILlZeUVi3Co/haem5+OYhpFu2bxcTFNXCyXyC7MqY0KJ9agCTE2/FZ0sKmYz1KhBYkn/NFSlvGnQ9S1tRnkO2bZ10avjkyeb5l3/69SmYJklu+AvAW3/Pdbjb0THocIpgktlUCaezSMzX9fmJpQBASAABICA8hGQ8tGlfGDAYyDQ6ARodsNdPVQzr92MLiSK7t4IS1Wz/W6IgeS5CtR7bmbOlhjnfdwr0TQSlbaWJr+MLKaZmjqVr+SJsezMWWj+53cpZXkhKqUk/GU42RnS2EkBUaUSBBp4Wt2i86aVvR2RbN97sTILeMtsQVkWNPdtqNMi/ryF8o39mQheh7/eRBZnNNBcqAYEmpoALy87J+VLiTRXaVObBu0BAUUhAPGuovQk+NECCWDGnb/roZHxJPBm9Jt/X7INe7uN1K/1kqTpDu9jzsyNOH0nW9yjkVqr4sWNFKR9L6cOFXMO6C5uNnpEqt+DVG5NPgQnNYOasVu1YVZ9nbvQc25cDhWTGLhKSuIO7/GO39v2/+vveAGVlcJ0U0MzVbKwoFic2ZVCDf2LmfTDeh9ELUYjaCW9jFfEkx+JmPMkLuPYvaE2Qj0gIJlAadKfP2/2WPk8vjEuD8nNQgkQUCoClY8HpXIanAUC8kJAffDoTmbF0X///jig1MBztG1lqgZJ9mGWIwd9a8p9cvTC/kjRoVJOQuDyvWGZOk7zPU2qpthquHWfaIlGXfU9FisS+RHJ/te3PikSnNlLa+v+ywi9/Oc3F55LzBc1gRd/5/yENc/Cq9eyEJGgd3Ru24qXcvlaDJXjTXij3i6LDOFg5paNsp4w1ZbE6Q0By4UtgSMgAASAABBQRgIQ7ypjr4PP8kOA2dHtGxskMSmH7uA60a4qTJVsoGb7X38b3pMev23J/gX/vn2bxcURgpOT5n/l8oRfLt8pNJq5YuxoPYHrWtX858X9nYnYzUsOr7sVG5tfSuCcjLjo03sOjtuV5ugqMn1Crd/c75Y6Iy8OHhy77v6NiC+F1IATj5Py/t2h7ftGbw1JVWPpCaQLFrFSt9+QZe4a8VdPjt/wwLe8LkIUpiX6njo7YUtopr7Tz2OqA3GRujI5rJzesLBqegP1BptMNIMSICDXBDgRy79b22VNcI5cWwnGAYHmJCDF87U5zYO2gYCiE6AbTxhh/c+HxJ4jXaxqm7pbzUHDvt/x3To7d986ceCEzz9ULgaM4C9jQTNw6LppwaipIgs9IIim0+CTm+nLtj84vHX/oa3lelANM8f5G78bFnHifmC1Zv6euvnP2+eZH7u25drduQ/uIBhGRwgegdBZxkNmzdr4XXtjgVhauCaV3tBo6oaf9E5c33Lt9g/3/SjLGBjJLSVIVLVt1z7//G/oSIFEa6J1ZXeMmfQnDd3Jj2fInEj+StGwAQHFJ4AX5hZ9KSoVM5dI8X0HD4GAVARQamFOqQRBCAgoKwH8gTfC5f+8j5oN5qcwk5eNyE9JeBaelpzHxdS12jlYu9u0kjz2Sg3TFkWHvA9OyC9AmCbWlr2cjXRqDa/xgqygN3FRn4tKMIahiYlbZzNT4RXTasFAsL+EhiZEpuYX8Gia2jq2HaxdTNVqba0WZRVFJDuNTPHnH6gb0/ocrrsCtaQwwUOpcB22lk9AMB8ZajkOpTdDAsFGpFgav27a/mOsoQ/3D7Bp2HXCCZ837tQt+/Gvd3rIzx2qEYlRVze3gJ+OkL9htGHXG7UtUK4YBOBhoBj9CF4oIQGslYnVcBMraT2na9h162LXTVpxGkvfvY++u7TiQnKYum6X7rpdhM41wwEEu80AHZoEAkAACMglAYh35bJbwCggAASAABBQOAK8rNjTZ59cCUyO/1KCUD/LONqP/6bvJDsJfhLsdw+fHb8XFRiTnVlMqGq0smxvPXREr2k9DNUrahRfXLVpZSCVwJvgckj89VXXgfyRThWHoXf+7GtRNVRctx4JBsBpIKBABCDeVaDOBFeAABAAAkBAXgmwPz75fulN/xxVS2e74e7aLJwdFxWydkHog58Gt65hM5Eft3fD2V2BhdrtbQf0t6VWJizKSgt8FbTx2ZurnpNOLehQNpNexXnokOXOBIKnXz0eEGHstGCkGbU8I6ZvVTVbSTo9NZqHE0BA4QhAvKtwXQoOAQEgAASAgLwRKIjeuPbmI3brmZumr+mpq1phXmnCo5tzt994wSURloDFRI7P1pPbg1WHL16wY4xJq6oSdurRdYfWXvHZ4GSxt78mhtBte/eypUo54WFnAqMMrSd/Kzx/V1o9VQ3ADhBQWAK1vGutsD6DY0AACAABIAAEmpAA8fHG/QvJKm4zvddVB7tU+yoWfcce/slahYp3BTZeQtCxF0WGQ8YIBbuUgHqb6f/r202l4P5/0XkC8pJ2ZaVHkn44DwRaEAGId1tQZ4GpQAAIAAEg0AIJ4Bl+jxI5reynjzCq8aMqZja450hDVNArlGHqNXPYqjE21SO7lcU0A4vORhjnc1YKNWu3rk1WeupqB8qBQAsgUOPSawE2g4lAAAgAASAABFoOAXZiSAKh6mzTXXDSQpX5qApTVSjepZk4zJ7qUFUutMMXRhAclyLcRWSlR8gAOAACLZMAxLsts9/AaiAABIAAEGghBHgZOWmlqEEbfbHhbq1OEOysjHcxGSm5JcWlBLWuDELmRReQiEatlcQUykqPGNVwCgi0CAIQ77aIbgIjgQAQAAJAoKUSIEq4bATV0GRWpQiTwhPOB3//Hf8GPHifX0yidAaDpUYrGwQmSuoX78pKjxQmgwgQkGMCEO/KceeAaUAACAABINDyCWA0GhXp4jgh7Xq/RNGTg4d+OJfKtHdZsLrrUBczGz1GRazMS9k++6+9UiqSlZ6W3wXgARCAeBc+A0AACAABIAAEGpEApqOpi5IfcwulDFPZb+4su5CqNdj78spOpvUZExbxQVZ6RNTCIRBoiQQgP0NL7DWwGQgAASAABFoMAUzH2EYXyY1NSZDmLTOEF/o0Ohkx9Z7q9DXBLiIzPS2GMxgKBGohAPFuLXCgCAgAASAABIDAVxNQNe/XRROPCb8eKybgJdi5n6kpudUbWVDMJVFVzcpVg6tLqIWDs5LeZggKlxei1D8QxG8AAAYcSURBVNRektqEBpAboEewKdgHAgpFAOJdhepOcAYIAAEgAATkjwCj39hutmjaif3PojjC1uFfbu7xu50rGMLS2lvoq+BJfg+zRKJjIidm5wbfhwUkycOFVqhA1bQ0ETInP10o3q2/HmHT4AgIKBIBiHcVqTfBFyAABIAAEJBHAgzHAVu8TYmQW95Lb5wLycjhEHhxfnTAy7WL9q2KM+ljJvgsxsyH9RlrWPri4JHvj4W8Ti1ilxSnf4q7ee6S16wjZxju3g4YkVuQhQu4qdrGpT0Tj3+9727qFy6vKIfN5hfWX4+AStgFAgpGAN5XU7AOBXeAABAAAkBADgkw3WbOOqZ6aenpJ4sXPF5cbiDKsOrZ/9BvHV7/GvFYwGRMx2nztm9om29eOn7m7vGKApqGQe+xky7PsI/bGXT2fUpILG+4Y9UTXH3EtAHnwm5d27rz2lYEUe2w23eGlxpSfz0CRsAuEFAsAig14UexPAJvgICMCeAPvBFuPqUUNRuMMvVkrB3USUeAZKeRKf58WXVjWp/D0lUCKQUhQOIlxL1vyp1BLcehdGbLdYyX9/l54KeP2cWIho59x/buFuoSEzAQJZ/efXj58UsewdBv3drNpa2pmuAwsCgD3pfk/17Gx+fhavptB/a3Mq0KhuupR1SvXB6T3ALyk2+ZaRht2HW5tBGMki8CVReEfJkF1gABIAAEgAAQUDwCdK3WfQa17iONYxjT3MnJ3EkaUb4MXdd06AhTMdL11CNGA5wCAi2fQG1fFlu+d+ABEAACQAAIAAEgAASAgLITgHhX2T8B4D8QAAJAAAgAASAABBSbAMS7it2/4B0QAAJAAAgAASAABJSdAMS7yv4JAP+BABAAAkAACAABIKDYBCDeVez+Be+AABAAAkAACAABIKDsBCDeVfZPAPgPBIAAEAACQAAIAAHFJgDxrmL3L3gHBIAAEAACQAAIAAFlJwDxrrJ/AsB/IAAEgAAQAAJAAAgoNgGIdxW7f8E7IAAEgAAQAAJAAAgoOwGId5X9EwD+AwEgAASAABAAAkBAsQlAvKvY/QveAQEgAASAABAAAkBA2QlAvKvsnwDwHwgAASAABIAAEAACik0A4l3F7l/wDggAASAABIAAEAACyk4A4l1l/wSA/0AACAABIAAEgAAQUGwCEO8qdv+Cd0AACAABIAAEgAAQUHYCEO8q+ycA/AcCQAAIAAEgAASAgGITgHhXsfsXvAMCQAAIAAEgAASAgLIToCs7APAfCEhNgEy6R2KqUouDoEwJEFyZqgNlLZUAGX8VLsOW2nkytBtuCDKEqRyqIN5Vjn4GL7+GAKZSXRtustUsmmkPvnI0E/jmbBalIQj1ayRRYQNchs3ZGXLWNk3g/ixnpoE5ckUA5jPIVXeAMfJIADUdLI9mKalNKHSHEvY8iqmgJv2V0HFwuU4CqNmQOmVAAAhQBFCSJAEEEAACtRMgizMQbl7tMlDaFARUdVA1/aZoCNqQPwJkUSrCK5I/u8AiUQKcEg6JkEwmU7RA5scqLFTdWOZaQaFCEoB4VyG7FZwCAkAACAABINAMBKhBtLy8PBaLRaNRs1BgAwLyQgDmM8hLT4AdQAAIAAEgAARaOgEul0tFuhDstvR+VDz7Id5VvD4Fj4AAEAACQAAINA8BDofDYDCap21oFQhIJgDxrmQ2UAIEgAAQAAJAAAhITYDH41HzGVRUIGeC1MhAsKkIQLzbVKShHSAABIAAEAACCk2gpKSEGtxFUVShvQTnWiQBiHdbZLeB0UAACAABIAAE5IoAQRDU+C5MZpCrTgFjqghAvFuFAnaAABAAAkAACACBBhKgZu6qqqrC4G4D8UG1RiYA8W4jAwb1QAAIAAEgAAQUnQA1bRfeVFP0Tm7Z/kG827L7D6wHAkAACAABINDsBCANWbN3ARhQOwGId2vnA6VAAAgAASAABIBAHQSowd2mWFCtDiugGAhIJADxrkQ0UAAEgAAQAAJAAAjUSaA8DRmdTq9TEgSAQHMRgHi3uchDu0AACAABIAAEFIEApCFThF5UdB8g3lX0Hgb/gAAQAAJAAAg0GgFIQ9ZoaEGxLAn8HwQ4fEuqA9QMAAAAAElFTkSuQmCC\" alt=\"\"></p>\n<p><strong>ä¸»åŠ¨å­¦ä¹ Active Learning</strong></p>\n<ul>\n<li>å…³æ³¨çš„åœºæ™¯ä¸ SSL ç›¸åŒï¼Œä½†æœ‰äººå·¥å¹²é¢„ï¼Œå³é€‰æ‹©æœ€æœ‰è¶£çš„æ•°æ®ï¼ˆæœ€é‡è¦çš„æ²¡æœ‰æ ‡å·çš„æ•°æ®ï¼‰ç»™æ ‡æ³¨å·¥æ ‡æ³¨ã€‚</li>\n<li>ä¸ç¡®å®šæ€§æŠ½æ ·ï¼ˆUncertainty samplingï¼‰ï¼šé€‰æ‹©ä¸€ä¸ªæœ€ä¸ç¡®ä¿¡çš„é¢„æµ‹è®©äººæ¥åˆ¤æ–­ã€‚</li>\n</ul>\n<p><strong>Active Learning + Self-training</strong></p>\n<p><img src=\"data:image/png;base64,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\" alt=\"\"></p>\n<p><strong>å¼±ç›‘ç£å­¦ä¹ Weak Supervision</strong></p>\n<ul>\n<li>åŠè‡ªåŠ¨åœ°ç”Ÿæˆæ ‡å·ï¼Œé€šå¸¸æ¯”æ‰‹åŠ¨æ ‡æ³¨çš„å‡†ç¡®ç‡å·®ï¼Œä½†æ˜¯ä¹Ÿæ˜¯å¥½åˆ°å¯ä»¥è®­ç»ƒä¸€ä¸ªè¿˜ä¸é”™çš„æ¨¡å‹ã€‚</li>\n<li>æ•°æ®ç¼–ç¨‹ï¼ˆData programmingï¼‰ï¼šç”¨å¯å‘å¼çš„æ–¹æ³•èµ‹äºˆæ ‡å·ï¼š\n<ul>\n<li>å…³é”®å­—æœç´¢ã€æ¨¡å¼åŒ¹é…ã€ç¬¬ä¸‰æ–¹æ¨¡å‹ã€‚</li>\n<li>å‡è®¾åˆ¤æ–­ä¸€ä¸ª YouTube çš„è¯„è®ºæ˜¯åƒåœ¾ï¼ˆspamï¼‰è¿˜æ˜¯æœ‰ç”¨çš„ä¸œè¥¿ï¼ˆhamï¼‰ï¼š</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">check_out</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> SPAM <span class=\"keyword\">if</span> <span class=\"string\">&#x27;check out&#x27;</span> <span class=\"keyword\">in</span> x.lower() <span class=\"keyword\">else</span> ABSTAIN</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sentiment</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> HAM <span class=\"keyword\">if</span> sentiment_polarity(x) &gt; <span class=\"number\">0.9</span> <span class=\"keyword\">else</span> ABSTAIN</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-æœºå™¨å­¦ä¹ æ¨¡å‹\">2. æœºå™¨å­¦ä¹ æ¨¡å‹</h2>\n<h3 id=\"2-1-æœºå™¨å­¦ä¹ æ¨¡å‹æ¦‚è§ˆ\">2.1 æœºå™¨å­¦ä¹ æ¨¡å‹æ¦‚è§ˆ</h3>\n<p><strong>ML ç®—æ³•çš„ç§ç±»</strong></p>\n<ul>\n<li>ç›‘ç£å­¦ä¹ ï¼ˆSupervisedï¼‰ï¼šè®­ç»ƒæœ‰æ ‡ç­¾çš„æ•°æ®æ¥é¢„æµ‹æ ‡ç­¾ã€‚\n<ul>\n<li>è‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-supervisedï¼‰ï¼šæ ‡ç­¾çš„ç”Ÿæˆæ¥è‡ªäºæ•°æ®æœ¬èº«ã€‚</li>\n</ul>\n</li>\n<li>åŠç›‘ç£å­¦ä¹ ï¼ˆSemi-supervisedï¼‰ï¼šåœ¨æœ‰æ ‡ç­¾å’Œæ— æ ‡ç­¾çš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½¿ç”¨æ¨¡å‹æ¥é¢„æµ‹æ— æ ‡ç­¾æ•°æ®çš„æ ‡ç­¾ã€‚</li>\n<li>æ— ç›‘ç£å­¦ä¹ ï¼ˆUnsupervisedï¼‰ï¼šåœ¨æœªæ ‡è®°çš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚</li>\n<li>å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcementï¼‰ï¼šåˆ©ç”¨è§‚å¯Ÿä¸ç¯å¢ƒäº’åŠ¨çš„ç»“æœæ¥é‡‡å–è¡ŒåŠ¨ä»¥æœ€å¤§åŒ–æ”¶ç›Šã€‚</li>\n</ul>\n<p>æœ¬è¯¾ç¨‹æœ€å¤šè®¨è®ºçš„å†…å®¹ä¸ºç›‘ç£å­¦ä¹ ã€‚</p>\n<p><strong>ç›‘ç£å­¦ä¹ çš„ç»„æˆéƒ¨åˆ†</strong></p>\n<ul>\n<li>æ¨¡å‹ï¼ˆModelï¼‰ï¼šå°†è¾“å…¥æ˜ å°„åˆ°æ ‡ç­¾çš„å‚æ•°åŒ–å‡½æ•°ã€‚</li>\n<li>æŸå¤±ï¼ˆLossï¼‰ï¼šè¡¡é‡æ¨¡å‹åœ¨é¢„æµ‹ç»“æœæ–¹é¢æœ‰å¤šå¥½ï¼Œå³è¡¡é‡æ¨¡å‹é¢„æµ‹å‡ºæ¥çš„å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œéœ€è¦æŒ‡å¯¼æ¨¡å‹å°½é‡å‘çœŸå®å€¼é è¿‘ã€‚</li>\n<li>ç›®æ ‡å‡½æ•°ï¼ˆObjectiveï¼‰ï¼šä¼˜åŒ–æ¨¡å‹å‚æ•°çš„ç›®æ ‡ï¼Œä¾‹å¦‚éœ€è¦ä¼˜åŒ–æ¨¡å‹åœ¨è®­ç»ƒé›†åˆä¸Šçš„æ‰€æœ‰é¢„æµ‹ç»“æœçš„æŸå¤±ä¹‹å’Œæœ€å°ã€‚</li>\n<li>ä¼˜åŒ–ï¼ˆOptimizationï¼‰ï¼šè§£å†³ Objective çš„ç®—æ³•ï¼Œå³æŠŠæ¨¡å‹ä¸­æ²¡æœ‰æŒ‡å®šçš„å‚æ•°ï¼ˆå¯å­¦ä¹ çš„å‚æ•°ï¼‰ä¼˜åŒ–ä¸ºåˆé€‚çš„å€¼ï¼Œä½¿å¾—èƒ½å¤Ÿè§£å†³ç›®æ ‡å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯æœ€å°åŒ–æŸå¤±ã€‚</li>\n</ul>\n<p><strong>ç›‘ç£å­¦ä¹ çš„æ¨¡å‹</strong></p>\n<ul>\n<li>å†³ç­–æ ‘ï¼ˆDecision treesï¼‰ï¼šç”¨æ ‘æ¥åšå†³å®šã€‚</li>\n<li>çº¿æ€§æ¨¡å‹ï¼ˆLinear methodsï¼‰ï¼šå†³ç­–æ˜¯æ ¹æ®è¾“å…¥ç‰¹å¾çš„çº¿æ€§ç»„åˆåšå‡ºçš„ã€‚</li>\n<li>æ ¸æ–¹æ³•ï¼ˆKernel machinesï¼‰ï¼šä½¿ç”¨æ ¸å‡½æ•°è¡¡é‡ä¸¤ä¸ªæ ·æœ¬çš„ç‰¹å¾ç›¸ä¼¼åº¦ï¼Œè¾¾åˆ°éçº¿æ€§çš„æ•ˆæœã€‚</li>\n<li>ç¥ç»ç½‘ç»œï¼ˆNeural Networksï¼‰ï¼šä½¿ç”¨ç¥ç»ç½‘ç»œå­¦ä¹ ç‰¹å¾è¡¨ç¤ºã€‚</li>\n</ul>\n<h3 id=\"2-2-å†³ç­–æ ‘\">2.2 å†³ç­–æ ‘</h3>\n<p>ä¼˜ç‚¹ï¼š</p>\n<ul>\n<li>å¯ä»¥ç”¨æ¥è§£é‡Šï¼Œå³è®­ç»ƒåçš„æ¨¡å‹å¯ä»¥çœ‹åˆ°å¶å­ç»“ç‚¹æ˜¯ä»€ä¹ˆå†…å®¹ï¼Œå†³ç­–æ˜¯æ€ä¹ˆä¸€æ­¥æ­¥åšä¸‹æ¥çš„ã€‚</li>\n<li>èƒ½å¤Ÿå¤„ç†æ•°å€¼å’Œç±»åˆ«çš„ç‰¹å¾ã€‚</li>\n</ul>\n<p>ç¼ºç‚¹ï¼š</p>\n<ul>\n<li>éå¸¸ä¸ç¨³å®šï¼Œå¯èƒ½æ•°æ®å†…äº§ç”Ÿäº†ä¸€ç‚¹å™ªéŸ³åæ•´æ£µæ ‘æ„å»ºå‡ºæ¥çš„æ ·å­å°±ä¸ä¸€æ ·äº†ã€‚</li>\n<li>å¦‚æœæ•°æ®ç‰¹åˆ«å¤æ‚ï¼Œä¼šç”Ÿæˆä¸€ä¸ªç‰¹åˆ«å¤æ‚çš„æ ‘ï¼Œå¯ä»¥æŠŠæ•´ä¸ªæ•°æ®é‡Œé¢çš„å„ç§æƒ…å†µåˆ—å‡ºæ¥ï¼Œç”Ÿæˆå¤§é‡çš„èŠ‚ç‚¹ï¼Œæœ€åä¼šå¯¼è‡´è¿‡æ‹Ÿåˆã€‚</li>\n<li>ä¸å®¹æ˜“å¹¶è¡Œè®¡ç®—ã€‚</li>\n</ul>\n<p><strong>éšæœºæ£®æ—</strong></p>\n<ul>\n<li>è®­ç»ƒå¤šä¸ªå†³ç­–æ ‘ä»¥æé«˜ç¨³å®šæ€§ã€‚\n<ul>\n<li>æ ‘æ˜¯å¹¶è¡Œåœ°ç‹¬ç«‹è®­ç»ƒçš„ã€‚</li>\n<li>å¯¹äºåˆ†ç±»é—®é¢˜å¯ä»¥ç”¨å¤šæ•°æŠ•ç¥¨æ³•ï¼ˆä¾‹å¦‚è¶…è¿‡ä¸€åŠçš„æ ‘è§‰å¾—ç±»åˆ«æ˜¯1ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯1ï¼‰ï¼Œå¯¹äºå›å½’é—®é¢˜å¯ä»¥åœ¨å¤šæ£µæ ‘ä¸Šå–å¹³å‡ã€‚</li>\n</ul>\n</li>\n<li>ä¸ºä»€ä¹ˆå«éšæœºå‘¢ï¼Ÿ\n<ul>\n<li>Baggingï¼š<strong>éšæœº</strong>æŠ½å–è®­ç»ƒæ ·æœ¬å¹¶è¿›è¡Œæ›¿æ¢ã€‚ä¾‹å¦‚æ ·æœ¬æœ¬æ¥æ˜¯ <code>[1, 2, 3, 4, 5]</code>ï¼Œåš Bagging çš„æ—¶å€™åœ¨é‡Œé¢éšæœºé‡‡æ ·5ä¸ªå‡ºæ¥ï¼Œä½†æ˜¯é‡‡æ ·å¯èƒ½æ˜¯æœ‰é‡å¤çš„ï¼Œé‡‡æ ·åˆ°çš„ç»“æœä¸º <code>[1, 2, 2, 3, 4]</code>ï¼Œç„¶åæ‹¿åˆ°è¿™ä¸ª Bagging å‡ºæ¥çš„æ•°æ®é›†åæˆ‘ä»¬å°±åœ¨ä¸Šé¢è®­ç»ƒä¸€æ£µæ ‘ï¼Œç„¶åä¸€ç›´é‡å¤è®­ç»ƒ N æ£µæ ‘ä¸ºæ­¢ã€‚</li>\n<li>éšæœºé€‰æ‹©ä¸€ä¸ªç‰¹å¾å­é›†ï¼Œå³æŠŠ Bagging å‡ºçš„æ•°æ®æ‹¿å‡ºæ¥ä¹‹åï¼Œå†ä»é‡Œé¢çš„ç‰¹å¾ä¸­<strong>éšæœº</strong>é‡‡æ ·ä¸€äº›ç‰¹å¾åˆ—å‡ºæ¥ï¼ˆå‡è®¾æ ‘æ˜¯ä¸€ä¸ªè¡¨ï¼Œé‚£ä¹ˆå°±æ˜¯å…ˆéšæœºé‡‡æ ·å‡ºä¸€äº›è¡Œï¼Œå†éšæœºé‡‡æ ·å‡ºä¸€äº›åˆ—ï¼‰</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-3-çº¿æ€§æ¨¡å‹\">2.3 çº¿æ€§æ¨¡å‹</h3>\n<p><strong>çº¿æ€§å›å½’</strong></p>\n<ul>\n<li>ä¸€ä¸ªç®€å•çš„æˆ¿ä»·é¢„æµ‹æ¨¡å‹ï¼š\n<ul>\n<li>å‡è®¾æœ‰3ä¸ªç‰¹å¾ï¼šå§å®¤æ•°é‡ <code>x1</code>ã€æµ´å®¤æ•°é‡ <code>x2</code>ã€å±…ä½é¢ç§¯ <code>x3</code>ï¼›</li>\n<li>é¢„æµ‹ä»·æ ¼ä¸ºï¼š<code>y_hat = w1 * x1 + w2 * x2 + w3 * x3 + b</code>ï¼›</li>\n<li>æƒé‡ <code>w1, w2, w3</code> å’Œåç½® <code>b</code> å°†ä»è®­ç»ƒæ•°æ®ä¸­å­¦ä¹ ã€‚</li>\n</ul>\n</li>\n<li>ä¸€èˆ¬æ¥è¯´ï¼Œç»™å®šæ•°æ® <code>x = [x1, x2, ..., xp]</code>ï¼Œçº¿æ€§å›å½’çš„é¢„æµ‹ä¸ºï¼š<code>y_hat = w1 * x1 + w2 * x2 + ... + wp * xp + b = &lt;w, x&gt; + b</code>ï¼ˆå…¶ä¸­ <code>w</code> å’Œ <code>x</code> ä¸ºé•¿åº¦ä¸º <code>p</code> çš„å‘é‡ï¼Œ<code>&lt;&gt;</code> è¡¨ç¤ºå†…ç§¯è¿ç®—ï¼Œ<code>w</code> å’Œ <code>b</code> éƒ½æ˜¯å¯å­¦ä¹ å‚æ•°ï¼‰ã€‚</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># weight w has shape (p, 1)</span></span><br><span class=\"line\"><span class=\"comment\"># bias b is a scalar</span></span><br><span class=\"line\"><span class=\"comment\"># data x has shape (p, 1)</span></span><br><span class=\"line\">y_hat = (x * w).<span class=\"built_in\">sum</span>() + b</span><br></pre></td></tr></table></figure>\n<p><strong>çº¿æ€§å›å½’ç›®æ ‡å‡½æ•°</strong></p>\n<p>å‡è®¾æˆ‘ä»¬æ”¶é›†äº† <code>n</code> ä¸ªè®­ç»ƒæ ·æœ¬ <code>X = [x1, x2, ..., xn]</code>ï¼Œå…¶ä¸­æ¯ä¸ª <code>xi</code> å‡ä¸ºé•¿ä¸º <code>p</code> çš„å‘é‡ï¼Œå°†å…¶è½¬ç½®åå³ä¸ºä¸€ä¸ª <code>n</code> è¡Œ <code>p</code> åˆ—çš„çŸ©é˜µï¼Œå…¶å¯¹åº”çš„æ ‡å·ä¸º <code>y = [y1, ..., yn]</code>ï¼Œæ˜¯ä¸€ä¸ªé•¿ä¸º <code>n</code> çš„å‘é‡ã€‚</p>\n<p>ç›®æ ‡å‡½æ•°æ˜¯æœ€å°åŒ–å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼Œå³ä¼˜åŒ– <code>w, b</code> çš„å€¼ä½¿å¾— <code>sum((yi - &lt;xi, w&gt; - b)**2) / n</code> æœ€å°ã€‚</p>\n<p><strong>çº¿æ€§å›å½’åœ¨åˆ†ç±»é—®é¢˜ä¸­çš„åº”ç”¨</strong></p>\n<p>å›å½’çš„è¾“å‡ºæ˜¯ä¸€ä¸ªè¿ç»­çš„å®æ•°ï¼Œè€Œå¯¹äºåˆ†ç±»é—®é¢˜ï¼Œæˆ‘ä»¬è¦è¾“å‡ºå¯¹æŸä¸ªæ ·æœ¬çš„ç±»åˆ«çš„é¢„æµ‹ã€‚</p>\n<p>å¤šç±»åˆ«åˆ†ç±»ï¼š</p>\n<ul>\n<li>å‡è®¾æ ‡ç­¾ä¸ºç‹¬çƒ­ç¼–ç ï¼Œå³ <code>y = [y1, y2, ..., ym]</code>ï¼Œå¦‚æœè¯¥æ ·æœ¬ä¸ºç¬¬ <code>i</code> ç±»åˆ™ <code>yi = 1</code>ï¼Œå¦åˆ™ <code>yi = 0</code>ã€‚</li>\n<li>é¢„æµ‹ç»“æœ <code>y_hat = [o1, o2, ..., om]</code>ï¼Œå…¶ä¸­ <code>oi</code> è¡¨ç¤ºé¢„æµ‹è¯¥æ ·æœ¬ä¸ºç¬¬ <code>i</code> ç±»çš„æ¦‚ç‡ã€‚</li>\n<li>ä¸ºæ¯ä¸ªç±»å­¦ä¹ ä¸€ä¸ªçº¿æ€§æ¨¡å‹ï¼š<code>oi = &lt;x, wi&gt; + bi</code>ã€‚</li>\n<li>æœ€å°åŒ– MSE æŸå¤±å‡½æ•°ï¼š<code>(y_hat - y)**2 / m</code>ã€‚</li>\n<li>é¢„æµ‹ç»“æœæ‰€è¡¨ç¤ºçš„ç±»ä¸º <code>m</code> ä¸ªæ¦‚ç‡ä¸­æœ€å¤§çš„é‚£ä¸ªï¼Œå³ <code>argmax(y_hat)</code>ã€‚</li>\n</ul>\n<p><strong>Mini-batch éšæœºæ¢¯åº¦ä¸‹é™</strong></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># &#x27;batch_size&#x27; ä¸ºæ‰¹å¤§å°ï¼Œ&#x27;features&#x27; ä¸ºæ‰€æœ‰æ ·æœ¬çš„ç‰¹å¾å³ Xï¼Œ&#x27;labels&#x27; ä¸ºæ ‡ç­¾</span></span><br><span class=\"line\"><span class=\"comment\"># &#x27;features&#x27; shape is (n, p), `labels` shape is (n, 1)</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">data_iter</span>(<span class=\"params\">batch_size, features, labels</span>):</span><br><span class=\"line\">    num_examples = <span class=\"built_in\">len</span>(features)  <span class=\"comment\"># æ ·æœ¬æ•°</span></span><br><span class=\"line\">    indices = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(num_examples))  <span class=\"comment\"># ä¸‹æ ‡</span></span><br><span class=\"line\">    random.shuffle(indices)  <span class=\"comment\"># éšæœºæ‰“ä¹±</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, num_examples, batch_size):</span><br><span class=\"line\">        batch_indices = torch.tensor(</span><br><span class=\"line\">            indices[i:<span class=\"built_in\">min</span>(i + batch_size, num_examples)]</span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> features[batch_indices], labels[batch_indices]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># w ç”¨å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º0.01çš„é«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ–</span></span><br><span class=\"line\">w = torch.normal(<span class=\"number\">0</span>, <span class=\"number\">0.01</span>, size=(p, <span class=\"number\">1</span>), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">b = torch.zeros(<span class=\"number\">1</span>, requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x, y <span class=\"keyword\">in</span> data_iter(batch_size, features, labels):  <span class=\"comment\"># éšæœºå–å‡ºä¸€ä¸ª batch</span></span><br><span class=\"line\">        y_hat = np.dot(x, w) + b</span><br><span class=\"line\">        loss = ((y_hat - y)**<span class=\"number\">2</span> / <span class=\"number\">2</span>).mean()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> [w, b]:</span><br><span class=\"line\">            param -= learning_rate * param.grad</span><br><span class=\"line\">            param.grad.zero_()</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-4-ç¥ç»ç½‘ç»œ\">2.4 ç¥ç»ç½‘ç»œ</h3>\n<p>ç¥ç»ç½‘ç»œå°±æ˜¯å°†æ‰‹å·¥ç‰¹å¾æå–çš„éƒ¨åˆ†æ¢æˆäº†ä¸€ä¸ªç¥ç»ç½‘ç»œã€‚</p>\n<ul>\n<li>ç¥ç»ç½‘ç»œé€šå¸¸éœ€è¦æ›´å¤šçš„æ•°æ®å’Œæ›´å¤šçš„è®¡ç®—ï¼Œä¸€èˆ¬éƒ½æ˜¯å¤§<strong>æ•°ä¸ªæ•°é‡çº§</strong>ã€‚</li>\n<li>å¯ä»¥é€‰æ‹©ä¸åŒçš„ç¥ç»ç½‘ç»œæ¶æ„æ¥æ›´æœ‰æ•ˆåœ°æŠ½å–æˆ‘ä»¬çš„ç‰¹å¾ï¼š\n<ul>\n<li>å¤šå±‚æ„ŸçŸ¥æœºã€‚</li>\n<li>å·ç§¯ç¥ç»ç½‘ç»œã€‚</li>\n<li>å¾ªç¯ç¥ç»ç½‘ç»œã€‚</li>\n<li>Transformersã€‚</li>\n</ul>\n</li>\n<li>è®¾è®¡ç¥ç»ç½‘ç»œä»¥ç»“åˆæ•°æ®çš„å…ˆéªŒçŸ¥è¯†ã€‚</li>\n</ul>\n<p><strong>çº¿æ€§æ¨¡å‹åˆ°å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMultilayer Perceptronï¼ŒMLPï¼‰</strong></p>\n<ul>\n<li>å¼•å…¥ä¸€ç§å…¨è¿æ¥å±‚ï¼ˆç¨ å¯†å±‚ï¼Œdenseï¼‰ï¼Œå‡è®¾è¾“å…¥æ ·æœ¬æ•°é‡ä¸º <code>n</code>ï¼Œæ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾é•¿åº¦ä¸º <code>m</code>ï¼Œé‚£ä¹ˆå…¨è¿æ¥å±‚å…·æœ‰ä¸¤ä¸ªå¯å­¦ä¹ å‚æ•° <code>w, b</code>ï¼Œå…¶ä¸­ <code>w</code> æ˜¯ä¸€ä¸ª <code>n</code> è¡Œ <code>m</code> åˆ—çš„å®æ•°çŸ©é˜µï¼Œ<code>b</code> æ˜¯ä¸€ä¸ªé•¿ä¸º <code>n</code> çš„å‘é‡ã€‚åˆ™å…¨è¿æ¥å±‚çš„è®¡ç®—ç»“æœä¸ºï¼š<code>y = np.dot(w, x) + b</code>ã€‚</li>\n<li>çº¿æ€§å›å½’å¯ä»¥è®¤ä¸ºæ˜¯ä¸€ä¸ªåªæœ‰ä¸€ä¸ªè¾“å‡ºçš„å…¨è¿æ¥å±‚ã€‚</li>\n<li>Softmax å›å½’å¯ä»¥è®¤ä¸ºæ˜¯ä¸€ä¸ªæœ‰ C ä¸ªè¾“å‡ºçš„å…¨è¿æ¥å±‚ï¼ŒC è¡¨ç¤ºç±»åˆ«çš„æ•°é‡ã€‚</li>\n</ul>\n<p>å¤šå±‚æ„ŸçŸ¥æœºçš„ç›®çš„æ˜¯å®ç°ä¸€ä¸ªéçº¿æ€§çš„æ¨¡å‹ï¼Œä½†æ˜¯å¦‚æœåªæ˜¯ç®€å•ä½¿ç”¨å¤šä¸ªå…¨è¿æ¥å±‚æ˜¯æ²¡ç”¨çš„ï¼Œå¤šä¸ªçº¿æ€§æ“ä½œçš„å åŠ è¿˜æ˜¯ä¸€ä¸ªçº¿æ€§æ“ä½œï¼Œå› æ­¤è¿˜éœ€è¦åŠ å…¥éçº¿æ€§å‡½æ•°ï¼ˆæ¿€æ´»å‡½æ•°ï¼‰ã€‚</p>\n<ul>\n<li>æ¿€æ´»å‡½æ•°æ˜¯ä¸€ä¸ªåŸºäºå…ƒç´ çš„éçº¿æ€§å‡½æ•°ï¼š\n<ul>\n<li><code>sigmoid(x) = 1 / (1 + np.exp(-x))</code>ã€‚</li>\n<li><code>relu(x) = max(x, 0)</code>ã€‚</li>\n<li>éçº¿æ€§çš„æ¿€æ´»å‡½æ•°èƒ½è®©æˆ‘ä»¬å¾—åˆ°éçº¿æ€§æ¨¡å‹ã€‚</li>\n</ul>\n</li>\n<li>å¯ä»¥å †å å¤šä¸ªéšè—å±‚ï¼ˆä¾‹å¦‚å¤šä¸ª dense å±‚å’Œ activation å±‚å †å ï¼‰ï¼Œå¾—åˆ°æ›´æ·±å±‚æ¬¡çš„æ¨¡å‹ã€‚</li>\n<li>è¶…å‚æ•°ï¼šéšè—å±‚æ•°é‡ <code>hidden layers</code>ï¼Œæ¯ä¸ªéšè—å±‚çš„è¾“å‡ºå¤§å° <code>outputs of each hidden layer</code>ï¼ˆæœ€åä¸€å±‚çš„è¾“å‡ºæ— æ³•æ”¹å˜ï¼‰ã€‚</li>\n</ul>\n<p>ä»£ç å®ç°ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">relu</span>(<span class=\"params\">Ã—</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> torch.<span class=\"built_in\">max</span>(x, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># &#x27;num_hiddens&#x27; ä¸ºè¶…å‚æ•°ï¼Œrandn() äº§ç”Ÿå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„æ­£æ€åˆ†å¸ƒ</span></span><br><span class=\"line\">w1 = nn.Parameter(torch.randn(num_inputs, num_hiddens) * <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b1 = nn.Parameter(torch.zeros(num_hiddens))</span><br><span class=\"line\">w2 = nn.Parameter(torch.randn(num_hiddens, num_outputs) * <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b2 = nn.Parameter(torch.zeros(num_outputs))</span><br><span class=\"line\"></span><br><span class=\"line\">H = relu(np.dot(x, w1) + b1)</span><br><span class=\"line\">Y = np.dot(H, w2) + b2</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-5-å·ç§¯ç¥ç»ç½‘ç»œ\">2.5 å·ç§¯ç¥ç»ç½‘ç»œ</h3>\n<p><strong>å…¨è¿æ¥å±‚åˆ°å·ç§¯ç¥ç»ç½‘ç»œ</strong></p>\n<ul>\n<li>ä»¥ä¸€ä¸ªå›¾åƒè¯†åˆ«ä»»åŠ¡ä¸ºä¾‹ï¼Œä½¿ç”¨ MLP æ¨¡å‹å­¦ä¹  ImageNetï¼ˆæ¯å¼ å›¾åƒå¤§å°ä¸º300*300åƒç´ ï¼Œæœ‰1000ä¸ªç±»åˆ«ï¼‰ï¼Œæˆ‘ä»¬å‡è®¾å…¶ä¸­ä¸€ä¸ªéšè—å±‚å…·æœ‰10000ä¸ªè¾“å‡ºï¼š\n<ul>\n<li>å®ƒä¼šäº§ç”Ÿ10äº¿ä¸ªå¯å­¦ä¹ å‚æ•°ï¼Œè¿™å¤ªå¤§äº†ï¼</li>\n<li>å› ä¸ºå…¨è¿æ¥çš„è¾“å‡ºæ˜¯æ‰€æœ‰è¾“å…¥å…ƒç´ çš„åŠ æƒå’Œï¼Œè€Œä¸”æ¯ä¸ªè¾“å‡ºçš„æƒé‡æ˜¯ä¸ä¸€æ ·çš„ã€‚</li>\n</ul>\n</li>\n<li>è¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“ï¼š\n<ul>\n<li>å¹³ç§»ä¸å˜æ€§ï¼šæ— è®ºå¯¹è±¡åœ¨å“ªé‡Œï¼Œè¾“å‡ºéƒ½æ˜¯ç›¸ä¼¼çš„ã€‚</li>\n<li>å±€éƒ¨æ€§ï¼šåƒç´ ä¸å…¶å‘¨å›´åƒç´ çš„ç›¸å…³æ€§æ¯”è¾ƒé«˜ï¼Œå› ä¸ºå›¾åƒä¸­çš„ç‰©ä½“éƒ½æ˜¯è¿ç»­æ€§çš„ã€‚</li>\n</ul>\n</li>\n<li>å°†å…ˆéªŒçŸ¥è¯†æ„å»ºåˆ°æ¨¡å‹ç»“æ„ä¸­ï¼š\n<ul>\n<li>ç”¨æ›´å°‘çš„å‚æ•°ï¼ˆ#paramsï¼‰å®ç°ç›¸åŒçš„æ¨¡å‹å®¹é‡ã€‚</li>\n</ul>\n</li>\n</ul>\n<p><strong>å·ç§¯å±‚ï¼ˆConvolution layerï¼‰</strong></p>\n<ul>\n<li>å±€éƒ¨æ€§ï¼šä» <code>k * k</code> å¤§å°çš„è¾“å…¥çª—å£è®¡ç®—è¾“å‡ºï¼Œå³åšå±€éƒ¨çš„è®¡ç®—ã€‚</li>\n<li>å¹³ç§»ä¸å˜æ€§ï¼šè¾“å‡ºä½¿ç”¨ç›¸åŒçš„ <code>k * k</code> æƒé‡ï¼ˆæ ¸ï¼‰ã€‚</li>\n<li>å·ç§¯å±‚çš„æ¨¡å‹å‚æ•°ä¸ä¾èµ–äºè¾“å…¥/è¾“å‡ºçš„å¤§å°ã€‚</li>\n<li>ä¸€ä¸ªå·ç§¯æ ¸å¯ä»¥è¢«å­¦ä¹ æˆå»è¯†åˆ«ä¸€ä¸ªå›¾åƒé‡Œé¢çš„æ¨¡å¼ï¼Œæ¯”å¦‚è¯†åˆ«ç»¿è‰²é€šé“ä¸­çš„æŸä¸ªå—çŠ¶ç‰©ä½“ï¼Œè¯†åˆ«æŸä¸ªæ–¹å‘ä¸Šçš„çº¹ç†</li>\n</ul>\n<p>ä»£ç ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># both input `X` and weight `K` are matricesï¼ˆçŸ©é˜µï¼‰</span></span><br><span class=\"line\">h, w = K.shape  <span class=\"comment\"># ä¸€èˆ¬é•¿å’Œå®½éƒ½æ˜¯ç›¸ç­‰çš„ï¼Œä¾‹å¦‚3ã€5</span></span><br><span class=\"line\">Y = torch.zeros((X.shape[<span class=\"number\">0</span>] - h + <span class=\"number\">1</span>, X.shape[<span class=\"number\">1</span>] - w + <span class=\"number\">1</span>))  <span class=\"comment\"># å·ç§¯è¾“å‡ºçš„çŸ©é˜µ</span></span><br><span class=\"line\"><span class=\"comment\"># stride = 1</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(Y.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(Y.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">        Y[i, j] = (X[i:i + h, j:j + w] * K).<span class=\"built_in\">sum</span>()</span><br></pre></td></tr></table></figure>\n<p><strong>æ± åŒ–å±‚ï¼ˆPooling layerï¼‰</strong></p>\n<ul>\n<li>å·ç§¯å±‚å¯¹è¾“å…¥çš„ä½ç½®å¾ˆæ•æ„Ÿï¼Œå³è¾“å…¥ä¸­æ¨¡å¼çš„è½¬æ¢/æ—‹è½¬ä¼šå¯¼è‡´è¾“å‡ºä¸­æ¨¡å¼ç±»ä¼¼åœ°å˜åŒ–ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä¸€å®šçš„å¯¹æœªçŸ¥ç§»åŠ¨çš„é²æ£’æ€§ã€‚</li>\n<li>æ± åŒ–å±‚åœ¨å¤§å°ä¸º <code>k * k</code> çš„çª—å£ä¸­è®¡ç®—å¹³å‡å€¼/æœ€å¤§å€¼/æœ€å°å€¼ã€‚</li>\n</ul>\n<p>ä»£ç ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># h, w: pooling window height and width</span></span><br><span class=\"line\"><span class=\"comment\"># mode: max or avg</span></span><br><span class=\"line\">Y = torch.zeros((X.shape[<span class=\"number\">0</span>] - h + <span class=\"number\">1</span>, X.shape[<span class=\"number\">1</span>] - w + <span class=\"number\">1</span>))</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(Y.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(Y.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> mode == <span class=\"string\">&#x27;max&#x27;</span>:</span><br><span class=\"line\">            Y[i, j] = X[i:i + h, j:j + w].<span class=\"built_in\">max</span>()</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> mode == <span class=\"string\">&#x27;avg&#x27;</span>: </span><br><span class=\"line\">            Y[i, j] = X[i:i + h, j:j + w].mean() </span><br></pre></td></tr></table></figure>\n<p><strong>å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvolutional Neural Networksï¼ŒCNNï¼‰</strong></p>\n<ul>\n<li>å·ç§¯ç¥ç»ç½‘ç»œçš„åŸç†ä¸ºå åŠ å·ç§¯å±‚æ¥æå–ç‰¹å¾ã€‚\n<ul>\n<li>æ¿€æ´»å‡½æ•°åº”ç”¨äºæ¯ä¸ªå·ç§¯å±‚ä¹‹åã€‚</li>\n<li>ä½¿ç”¨æ± åŒ–æ“ä½œæ¥é™ä½ä½ç½®æ•æ„Ÿæ€§ã€‚</li>\n</ul>\n</li>\n<li>ç°ä»£ CNN æ˜¯å…·æœ‰å„ç§è¶…å‚æ•°å’Œå±‚è¿æ¥çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆAlexNet, VGG, inception, ResNet, MobileNetï¼‰ã€‚</li>\n</ul>\n<h3 id=\"2-6-å¾ªç¯ç¥ç»ç½‘ç»œ\">2.6 å¾ªç¯ç¥ç»ç½‘ç»œ</h3>\n<p><strong>å…¨è¿æ¥å±‚åˆ°å¾ªç¯ç¥ç»ç½‘ç»œ</strong></p>\n<ul>\n<li>è¯­è¨€æ¨¡å‹ï¼šç»™å‡ºä¸€ä¸ªå¥å­å‰é¢çš„ä¸€äº›è¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯æ˜¯ä»€ä¹ˆã€‚ä¾‹å¦‚ï¼š<code>hello -&gt; world</code>ã€<code>hello world -&gt; !</code>ã€‚</li>\n<li>å•çº¯ä½¿ç”¨ MLP ä¸èƒ½å¾ˆå¥½åœ°å¤„ç†åºåˆ—ä¿¡æ¯ï¼Œä¾‹å¦‚é•¿åº¦çš„å˜åŒ–å’Œæ—¶åºçš„å˜åŒ–ã€‚</li>\n</ul>\n<p>å¾ªç¯ç¥ç»ç½‘ç»œçš„åŸç†ä¸ºå°†ä¸Šä¸€ä¸ªå…¨è¿æ¥å±‚è¾“å‡ºçš„çŠ¶æ€å¤åˆ¶ä¸€ä»½ä½œä¸ºéšè—çŠ¶æ€ Hï¼Œä¸ä¸‹ä¸€ä¸ªè¾“å…¥çŠ¶æ€è¿›è¡Œæ‹¼æ¥åå†è¿›è¡Œé¢„æµ‹ã€‚å³ï¼š<code>h_t = RNN(W_hh * h' + W_hx * x_t + b_h)</code>ï¼Œå…¶ä¸­ <code>h'</code> ä¸ºéšè—çŠ¶æ€ï¼Œ<code>x_t</code> ä¸ºå½“å‰è¾“å…¥ã€‚</p>\n<p>ä»£ç ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">W_xh = nn.Parameter(torch.randn(num_inputs, num_hiddens) * <span class=\"number\">0.01</span>)</span><br><span class=\"line\">W_hh = nn.Parameter(torch.rand(num_hiddens, num_hiddens) * <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b_h = nn.Parameter(torch.zeros(num_hiddens))</span><br><span class=\"line\"></span><br><span class=\"line\">H = torch.zeros(num_hiddens)</span><br><span class=\"line\">outputs = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> X <span class=\"keyword\">in</span> inputs:  <span class=\"comment\"># `inputs` shape : (num_steps, batch_size, num_inputs)ï¼Œnum_stepsè¡¨ç¤ºæ—¶é—´ç»´åº¦</span></span><br><span class=\"line\">    H = torch.tanh(np.dot(X, W_xh) + np.dot(H, W_hh) + b_h)</span><br><span class=\"line\">    outputs.append(H)</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-æ¨¡å‹è¯„ä¼°\">3. æ¨¡å‹è¯„ä¼°</h2>\n<h3 id=\"3-1-è¯„ä¼°æŒ‡æ ‡\">3.1 è¯„ä¼°æŒ‡æ ‡</h3>\n<ul>\n<li>æŸå¤±ï¼ˆLossï¼‰è¡¡é‡æ¨¡å‹åœ¨é¢„æµ‹ç›‘ç£å­¦ä¹ ç»“æœçš„æ–¹é¢æœ‰å¤šå¥½ã€‚</li>\n<li>è¯„ä¼°æ¨¡å‹æ€§èƒ½çš„å…¶ä»–æŒ‡æ ‡ï¼š\n<ul>\n<li>æ¨¡å‹ç›¸å…³çš„æŒ‡æ ‡ï¼šä¾‹å¦‚åˆ†ç±»çš„ç²¾åº¦ï¼Œç‰©ä½“æ£€æµ‹çš„ mAPã€‚</li>\n<li>å•†ä¸šç›¸å…³çš„æŒ‡æ ‡ï¼šä¾‹å¦‚æ”¶ç›Šï¼Œæ¨ç†å»¶è¿Ÿï¼ˆå¦‚æ¨¡å‹èƒ½åœ¨100æ¯«ç§’ä¹‹å†…è¿”å›ç»“æœï¼‰ã€‚</li>\n</ul>\n</li>\n<li>æˆ‘ä»¬ä¸€èˆ¬é€šè¿‡è€ƒè™‘å¤šç§æŒ‡æ ‡æ¥é€‰æ‹©æ¨¡å‹ã€‚</li>\n</ul>\n<p><strong>äºŒåˆ†ç±»çš„è¯„ä¼°æŒ‡æ ‡</strong></p>\n<ul>\n<li>Accuracyï¼šæ­£ç¡®çš„é¢„æµ‹æ•°é‡/æ ·æœ¬æ€»æ•°</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sum</span>(y == y_hat) / y.size</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Precisionï¼šé¢„æµ‹ç»“æœä¸ºç±» <code>i</code> ä¸”å®é™…ç»“æœä¹Ÿä¸ºç±» <code>i</code> çš„æ•°é‡/é¢„æµ‹ç»“æœä¸ºç±» <code>i</code> çš„æ•°é‡</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sum</span>((y_hat == i) &amp; (y == i)) / <span class=\"built_in\">sum</span>(y_hat == i)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Recallï¼šé¢„æµ‹ç»“æœä¸ºç±» <code>i</code> ä¸”å®é™…ç»“æœä¹Ÿä¸ºç±» <code>i</code> çš„æ•°é‡/å®é™…ç»“æœä¸ºç±» <code>i</code> çš„æ•°é‡</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sum</span>((y_hat == i) &amp; (y == i)) / <span class=\"built_in\">sum</span>(y == i)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>F1ï¼šå¹³è¡¡ Precision å’Œ Recall çš„æŒ‡æ ‡ï¼Œä¸º Precision å’Œ Recall çš„è°ƒå’Œå¹³å‡å€¼ï¼š<code>2pr / (p + r)</code></li>\n</ul>\n<p><strong>äºŒåˆ†ç±»ä¸­çš„ AUC å’Œ ROC</strong></p>\n<ul>\n<li>AUC ä¸º ROC æ›²çº¿ä¸‹çš„é¢ç§¯ï¼Œå¤§å°èŒƒå›´ä¸º <code>[0.5, 1]</code>ã€‚</li>\n<li>è¡¡é‡æ¨¡å‹åˆ†ç¦»è¿™ä¸¤ä¸ªç±»çš„èƒ½åŠ›ã€‚</li>\n<li>é€‰æ‹©å†³ç­–é˜ˆå€¼ <code>x</code>ï¼Œå¦‚æœè¾“å‡º <code>y_hat &gt;= x</code> åˆ™é¢„æµ‹ä¸ºæ­£ç±»ï¼Œå¦åˆ™ä¸ºè´Ÿç±»ã€‚</li>\n</ul>\n<p><strong>å±•ç¤ºå¹¿å‘Šçš„å•†ä¸šæŒ‡æ ‡</strong></p>\n<ul>\n<li>æœ€ä¼˜åŒ–æ”¶å…¥å’Œå®¢æˆ·ä½“éªŒã€‚\n<ul>\n<li>Latencyï¼šå¹¿å‘Šåº”è¯¥ä¸å…¶ä»–å†…å®¹åŒæ—¶æ˜¾ç¤ºç»™ç”¨æˆ·ã€‚</li>\n<li>ASNï¼šå¹³å‡æ¯é¡µæ˜¾ç¤ºçš„å¹¿å‘Šæ•°é‡ã€‚</li>\n<li>CTRï¼šç”¨æˆ·å®é™…ç‚¹å‡»ç‡ã€‚</li>\n<li>ACPï¼šå¹¿å‘Šå•†æ¯æ¬¡ç‚¹å‡»æ”¯ä»˜çš„å¹³å‡ä»·æ ¼ã€‚</li>\n</ul>\n</li>\n<li>æ”¶ç›Š = é¡µé¢æµè§ˆé‡ * ASN * CTR * ACPã€‚</li>\n</ul>\n<!-- Image base64 code -->\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "https://asanosaki.github.io/posts/48394.html",
            "url": "https://asanosaki.github.io/posts/48394.html",
            "title": "PyTorchæ·±åº¦å­¦ä¹ å…¥é—¨(CIFAR10åˆ†ç±»)",
            "date_published": "2022-12-01T10:22:00.000Z",
            "content_html": "<blockquote>\n<p>é€šè¿‡ CIFAR10 æ•°æ®é›†çš„åˆ†ç±»é—®é¢˜åˆå…¥é—¨ Deep Learningï¼Œä¹Ÿæ˜¯å¼€å‘ AI ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« ã€‚<br>\nç›¸å…³ç¯å¢ƒçš„æ­å»ºå¯ä»¥è½¬è‡³ï¼š<a href=\"/posts/15428.html\">Anacondaä¸PyTorchå®‰è£…æ•™ç¨‹</a>ã€‚</p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"1-å¸¸ç”¨å‡½æ•°\">1. å¸¸ç”¨å‡½æ•°</h2>\n<p>ï¼ˆ1ï¼‰è·¯å¾„å‡½æ•°</p>\n<p>åœ¨ <code>os</code> æ¨¡å—ä¸­å¸¸ç”¨çš„è·¯å¾„ç›¸å…³å‡½æ•°æœ‰ï¼š</p>\n<ul>\n<li><code>os.listdir(path)</code>ï¼šå°† <code>path</code> ç›®å½•ä¸‹çš„å†…å®¹åˆ—æˆä¸€ä¸ª <code>list</code>ã€‚</li>\n<li><code>os.path.join(path1, path2)</code>ï¼šæ‹¼æ¥è·¯å¾„ï¼š<code>path1\\path2</code>ã€‚</li>\n</ul>\n<p>ä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\">dir_path = <span class=\"string\">&#x27;dataset/hymenoptera_data/train/ants_image&#x27;</span></span><br><span class=\"line\">img_path_list = os.listdir(dir_path)</span><br><span class=\"line\">img_full_path = os.path.join(dir_path, img_path_list[<span class=\"number\">0</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(img_path_list)  <span class=\"comment\"># [&#x27;0013035.jpg&#x27;, &#x27;1030023514_aad5c608f9.jpg&#x27;, ...]</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(img_full_path)  <span class=\"comment\"># dataset/hymenoptera_data/train/ants_image\\0013035.jpg</span></span><br></pre></td></tr></table></figure>\n<p>ï¼ˆ2ï¼‰è¾…åŠ©å‡½æ•°</p>\n<ul>\n<li><code>dir()</code>ï¼šä¸å¸¦å‚æ•°æ—¶ï¼Œè¿”å›å½“å‰èŒƒå›´å†…çš„å˜é‡ã€æ–¹æ³•å’Œå®šä¹‰çš„ç±»å‹åˆ—è¡¨ï¼›å¸¦å‚æ•°æ—¶ï¼Œè¿”å›å‚æ•°çš„å±æ€§ã€æ–¹æ³•åˆ—è¡¨ã€‚</li>\n<li><code>help(func)</code>ï¼šæŸ¥çœ‹å‡½æ•° <code>func</code> çš„ä½¿ç”¨è¯´æ˜ã€‚</li>\n</ul>\n<p>ä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">dir</span>(torch))  <span class=\"comment\"># [&#x27;AVG&#x27;, &#x27;AggregationType&#x27;, ..., &#x27;cuda&#x27;, ...]</span></span><br><span class=\"line\"><span class=\"built_in\">help</span>(torch.cuda.is_available)  <span class=\"comment\"># Help on function is_available in module torch.cuda: is_available() -&gt; bool...</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"2-æ•°æ®åŠ è½½\">2. æ•°æ®åŠ è½½</h2>\n<h3 id=\"2-1-Dataset\">2.1 Dataset</h3>\n<p>æ•°æ®è¯»å–å’Œé¢„å¤„ç†æ˜¯è¿›è¡Œæœºå™¨å­¦ä¹ çš„é¦–è¦æ“ä½œï¼ŒPyTorch æä¾›äº†å¾ˆå¤šæ–¹æ³•æ¥å®Œæˆæ•°æ®çš„è¯»å–å’Œé¢„å¤„ç†ã€‚</p>\n<p>å…¶ä¸­ Dataset è¡¨ç¤ºæ•°æ®é›†ï¼Œ<code>torch.utils.data.Dataset</code> æ˜¯ä»£è¡¨è¿™ä¸€æ•°æ®çš„æŠ½è±¡ç±»ã€‚ä½ å¯ä»¥è‡ªå·±å®šä¹‰ä½ çš„æ•°æ®ç±»ï¼Œç»§æ‰¿å’Œé‡å†™è¿™ä¸ªæŠ½è±¡ç±»ï¼Œéå¸¸ç®€å•ï¼Œåªéœ€è¦å®šä¹‰ <code>__len__</code> å’Œ <code>__getitem__</code> è¿™ä¸ªä¸¤ä¸ªå‡½æ•°å³å¯ï¼Œä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MyData</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, root_dir, label_dir</span>):</span><br><span class=\"line\">        self.root_dir = root_dir</span><br><span class=\"line\">        self.label_dir = label_dir</span><br><span class=\"line\">        self.path = os.path.join(self.root_dir, self.label_dir + <span class=\"string\">&#x27;_image&#x27;</span>)</span><br><span class=\"line\">        self.img_path_list = os.listdir(self.path)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, idx</span>):</span><br><span class=\"line\">        img_path = self.img_path_list[idx]</span><br><span class=\"line\">        img_full_path = os.path.join(self.root_dir, self.label_dir + <span class=\"string\">&#x27;_image&#x27;</span>, img_path)</span><br><span class=\"line\">        img = Image.<span class=\"built_in\">open</span>(img_full_path)</span><br><span class=\"line\">        label = self.label_dir</span><br><span class=\"line\">        <span class=\"keyword\">return</span> img, label</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(self.img_path_list)</span><br><span class=\"line\"></span><br><span class=\"line\">root_dir = <span class=\"string\">&#x27;dataset/hymenoptera_data/train&#x27;</span></span><br><span class=\"line\">ants_label_dir = <span class=\"string\">&#x27;ants&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">ants_data = MyData(root_dir, ants_label_dir)</span><br><span class=\"line\">img, label = ants_data[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(img, label)</span><br><span class=\"line\">img.show()</span><br></pre></td></tr></table></figure>\n<p>é€šè¿‡ä¸Šé¢çš„æ–¹å¼ï¼Œå¯ä»¥å®šä¹‰æˆ‘ä»¬éœ€è¦çš„æ•°æ®ç±»ï¼Œå¯ä»¥é€šè¿‡è¿­ä»£çš„æ–¹å¼æ¥è·å–æ¯ä¸€ä¸ªæ•°æ®ï¼Œä½†è¿™æ ·å¾ˆéš¾å®ç°å– batchã€shuffle æˆ–è€…æ˜¯å¤šçº¿ç¨‹å»è¯»å–æ•°æ®ã€‚</p>\n<h3 id=\"2-2-DataLoader\">2.2 DataLoader</h3>\n<p><code>torch.utils.data.DataLoader</code> æ„å»ºå¯è¿­ä»£çš„æ•°æ®è£…è½½å™¨ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œæ¯ä¸€ä¸ª <code>for</code> å¾ªç¯ï¼Œæ¯ä¸€æ¬¡ iterationï¼Œå°±æ˜¯ä» <code>DataLoader</code> ä¸­è·å–ä¸€ä¸ª <code>batch_size</code> å¤§å°çš„æ•°æ®çš„ã€‚æ‰“ä¸ªæ¯”æ–¹å¦‚æœ <code>Dataset</code> æ˜¯ä¸€å‰¯å®Œæ•´çš„æ‰‘å…‹ç‰Œï¼Œé‚£ä¹ˆ <code>DataLoader</code> å°±æ˜¯æŠ½å–å‡ å¼ ç»„æˆçš„ä¸€éƒ¨åˆ†æ‰‘å…‹ç‰Œã€‚</p>\n<p><code>DataLoader</code> çš„å‚æ•°å¾ˆå¤šï¼Œä½†æˆ‘ä»¬å¸¸ç”¨çš„ä¸»è¦æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š</p>\n<ul>\n<li><code>dataset</code>ï¼š<code>Dataset</code> ç±»ï¼Œå†³å®šä»å“ªä¸ªæ•°æ®é›†è¯»å–æ•°æ®ã€‚</li>\n<li><code>batch_size</code>ï¼šæ‰¹å¤§å°ã€‚</li>\n<li><code>num_works</code>ï¼šæ˜¯å¦å¤šè¿›ç¨‹è¯»å–æœºåˆ¶ã€‚</li>\n<li><code>shuffle</code>ï¼šæ¯ä¸ª Epoch æ˜¯å¦ä¹±åºã€‚</li>\n<li><code>drop_last</code>ï¼šå½“æ ·æœ¬æ•°ä¸èƒ½è¢« <code>batch_size</code> æ•´é™¤æ—¶ï¼Œæ˜¯å¦èˆå¼ƒæœ€åä¸€æ‰¹æ•°æ®ã€‚</li>\n</ul>\n<p>è¦ç†è§£è¿™ä¸ª <code>drop_last</code>ï¼Œé¦–å…ˆï¼Œå¾—å…ˆç†è§£ Epochã€Iteration å’Œ Batch_size çš„æ¦‚å¿µï¼š</p>\n<ul>\n<li>Epochï¼šæ‰€æœ‰è®­ç»ƒæ ·æœ¬éƒ½å·²è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œç§°ä¸ºä¸€ä¸ª Epochã€‚</li>\n<li>Iterationï¼šä¸€æ‰¹æ ·æœ¬è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œç§°ä¸ºä¸€ä¸ª Iterationã€‚</li>\n<li>Batch_sizeï¼šä¸€æ‰¹æ ·æœ¬çš„å¤§å°ï¼Œå†³å®šä¸€ä¸ª Epoch æœ‰å¤šå°‘ä¸ª Iterationã€‚</li>\n</ul>\n<p><code>DataLoader</code> çš„ä½œç”¨å°±æ˜¯æ„å»ºä¸€ä¸ªæ•°æ®è£…è½½å™¨ï¼Œæ ¹æ®æˆ‘ä»¬æä¾›çš„ <code>batch_size</code> çš„å¤§å°ï¼Œå°†æ•°æ®æ ·æœ¬åˆ†æˆä¸€ä¸ªä¸ªçš„ Batch å»è®­ç»ƒæ¨¡å‹ï¼Œè€Œè¿™ä¸ªåˆ†çš„è¿‡ç¨‹ä¸­éœ€è¦æŠŠæ•°æ®å–åˆ°ï¼Œè¿™ä¸ªå°±æ˜¯å€ŸåŠ© <code>Dataset</code> çš„ <code>__getitem__</code> æ–¹æ³•ã€‚</p>\n<p>ä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MyData</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, root_dir, label_dir, transform</span>):</span><br><span class=\"line\">        self.root_dir = root_dir</span><br><span class=\"line\">        self.label_dir = label_dir</span><br><span class=\"line\">        self.path = os.path.join(self.root_dir, self.label_dir + <span class=\"string\">&#x27;_image&#x27;</span>)</span><br><span class=\"line\">        self.img_path_list = os.listdir(self.path)</span><br><span class=\"line\">        self.transform = transform  <span class=\"comment\"># transform çš„æ–¹å¼</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, idx</span>):</span><br><span class=\"line\">        img_path = self.img_path_list[idx]</span><br><span class=\"line\">        img_full_path = os.path.join(self.root_dir, self.label_dir + <span class=\"string\">&#x27;_image&#x27;</span>, img_path)</span><br><span class=\"line\">        img = Image.<span class=\"built_in\">open</span>(img_full_path).convert(<span class=\"string\">&#x27;RGB&#x27;</span>)  <span class=\"comment\"># å…ˆå°†å›¾ç‰‡è½¬æ¢æˆä¸‰é€šé“</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.transform <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            img = self.transform(img)</span><br><span class=\"line\">        label = self.label_dir</span><br><span class=\"line\">        <span class=\"keyword\">return</span> img, label</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(self.img_path_list)</span><br><span class=\"line\"></span><br><span class=\"line\">root_dir = <span class=\"string\">&#x27;dataset/hymenoptera_data/train&#x27;</span></span><br><span class=\"line\">ants_label_dir = <span class=\"string\">&#x27;ants&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">trans_dataset = transforms.Compose([</span><br><span class=\"line\">    transforms.Resize((<span class=\"number\">83</span>, <span class=\"number\">100</span>)),  <span class=\"comment\"># tensor å¤§å°å¿…é¡»ç»Ÿä¸€</span></span><br><span class=\"line\">    transforms.ToTensor()</span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\">ants_data = MyData(root_dir, ants_label_dir, trans_dataset)</span><br><span class=\"line\"></span><br><span class=\"line\">train_loader = DataLoader(dataset=ants_data, batch_size=<span class=\"number\">10</span>, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>, drop_last=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(train_loader):</span><br><span class=\"line\">    imgs, labels = data</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"built_in\">type</span>(imgs))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(imgs[<span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(labels)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(labels[<span class=\"number\">0</span>])</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥ä½¿ç”¨ CIFAR10 æ•°æ®é›†å†å±•ç¤ºä¸€æ¬¡ <code>DataLoader</code> çš„ç”¨æ³•ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"></span><br><span class=\"line\">test_set = datasets.CIFAR10(root=<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor(), download=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">test_loader = DataLoader(dataset=test_set, batch_size=<span class=\"number\">64</span>, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>, drop_last=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&#x27;logs&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">2</span>):  <span class=\"comment\"># å¾ªç¯ä¸¤ä¸ª epoch</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(test_loader):  <span class=\"comment\"># step è¡¨ç¤ºç¬¬å‡ ä¸ª batch</span></span><br><span class=\"line\">        imgs, targets = data</span><br><span class=\"line\">        writer.add_images(<span class=\"string\">&#x27;Epoch_&#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(epoch), imgs, step)  <span class=\"comment\"># æ³¨æ„æ˜¯ add_imagesï¼Œå›¾åƒé»˜è®¤æ ¼å¼ä¸º NCHW</span></span><br><span class=\"line\"></span><br><span class=\"line\">writer.close()</span><br></pre></td></tr></table></figure>\n<p>PSï¼šéƒ¨åˆ†çœ‹ä¸æ‡‚çš„ä»£ç å¯ä»¥å…ˆå»å­¦åé¢çš„ <code>transform</code> ä»¥åŠ <code>tensorboard</code>ã€‚</p>\n<h2 id=\"3-TensorBoard\">3. TensorBoard</h2>\n<h3 id=\"3-1-add-scalar\">3.1 add_scalar</h3>\n<p>TensorBoard åŸæœ¬æ˜¯ TensorFlow çš„å¯è§†åŒ–å·¥å…·ï¼ŒPyTorch ä»1.2.0å¼€å§‹æ”¯æŒ TensorBoardã€‚ä¹‹å‰çš„ç‰ˆæœ¬ä¹Ÿå¯ä»¥ä½¿ç”¨ TensorBoardX ä»£æ›¿ã€‚</p>\n<p>å…ˆè¿›å…¥ Anaconda çš„ PyTorch ç¯å¢ƒï¼Œå®‰è£… TensorBoardï¼š</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda activate PyTorch</span><br><span class=\"line\">pip install tensorboard</span><br></pre></td></tr></table></figure>\n<p>åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ <code>logs</code>ï¼ŒTensorBoard çš„å·¥ä½œæµç¨‹ç®€å•æ¥è¯´æ˜¯å°†ä»£ç è¿è¡Œè¿‡ç¨‹ä¸­çš„ï¼ŒæŸäº›ä½ å…³å¿ƒçš„æ•°æ®ä¿å­˜åœ¨è¿™ä¸ªæ–‡ä»¶å¤¹ä¸­ï¼ˆç”±ä»£ç ä¸­çš„ <code>writer</code> å®Œæˆï¼‰ï¼Œå†è¯»å–è¿™ä¸ªæ–‡ä»¶å¤¹ä¸­çš„æ•°æ®ï¼Œç”¨æµè§ˆå™¨æ˜¾ç¤ºå‡ºæ¥ï¼ˆåœ¨å‘½ä»¤è¡Œè¿è¡Œ TensorBoard å®Œæˆï¼‰ã€‚</p>\n<p>æˆ‘ä»¬å…ˆç»˜åˆ¶ä¸€ä¸ª <code>y = x</code> çš„å›¾åƒï¼Œè¿è¡Œä»¥ä¸‹ä»£ç ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"></span><br><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&#x27;logs&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">100</span>):</span><br><span class=\"line\">    writer.add_scalar(<span class=\"string\">&#x27;y=x&#x27;</span>, x, x)  <span class=\"comment\"># tag=&#x27;y=x&#x27;, scalar_value=x, global_step=x</span></span><br><span class=\"line\"></span><br><span class=\"line\">writer.close()</span><br></pre></td></tr></table></figure>\n<p><code>add_scalar</code> å‡½æ•°ä¸»è¦æœ‰ä¸‰ä¸ªå‚æ•°ï¼š</p>\n<ul>\n<li><code>tag</code>ï¼šæ•°æ®æ ‡è¯†ç¬¦ï¼Œå¯ä»¥ç†è§£ä¸ºæ•°æ®å›¾åƒçš„æ ‡é¢˜ã€‚</li>\n<li><code>scalar_value</code>ï¼šä¿å­˜çš„å€¼ï¼Œå³çºµè½´ä¸Šçš„å€¼ã€‚</li>\n<li><code>global_step</code>ï¼šè®°å½•çš„æ­¥é•¿ï¼Œå³æ¨ªè½´çš„å€¼ï¼Œä¸€èˆ¬ä¼šè®¾ç½®ä¸€ä¸ªä¸æ–­å¢åŠ çš„ <code>step</code>ã€‚</li>\n</ul>\n<p>è¿è¡Œåä¼šçœ‹åˆ° <code>logs</code> æ–‡ä»¶å¤¹ä¸‹ç”Ÿæˆäº†ä¸€ä¸ªæ–‡ä»¶ï¼Œç„¶åæˆ‘ä»¬åœ¨ PyCharm ç»ˆç«¯çš„ PyTorch ç¯å¢ƒä¸­æ‰“å¼€ TensorBoardï¼ˆè¦åœ¨å½“å‰é¡¹ç›®ä¸­è¿›å…¥ PyTorch ç¯å¢ƒï¼Œå¦åˆ™ <code>--logdir</code> çš„è·¯å¾„å°±ä¸èƒ½ç”¨ç›¸å¯¹è·¯å¾„äº†ï¼‰ï¼š</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensorboard --logdir logs</span><br></pre></td></tr></table></figure>\n<p>æ‰“å¼€ <code>http://localhost:6006/</code> å³å¯çœ‹åˆ°ç»˜åˆ¶çš„å›¾åƒã€‚</p>\n<p>å¦‚æœå› ä¸ºæŸäº›åŸå› å¯¼è‡´ç«¯å£å†²çªå¯ä»¥æŒ‡å®šç«¯å£ï¼š</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensorboard --logdir logs --port 6007</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-2-add-image\">3.2 add_image</h3>\n<p><code>add_image</code> å‡½æ•°ä¸»è¦æœ‰ä¸‰ä¸ªå‚æ•°ï¼š</p>\n<ul>\n<li><code>tag</code>ï¼šåŒ <code>add_scalar</code>ã€‚</li>\n<li><code>img_tensor</code>ï¼šå›¾åƒæ•°æ®ï¼Œç±»å‹å¿…é¡»æ˜¯ <code>torch.Tensor</code>ã€<code>numpy.ndarry</code> æˆ– <code>string/blobname</code>ã€‚</li>\n<li><code>global_step</code>ï¼šåŒ <code>add_scalar</code>ã€‚</li>\n</ul>\n<p>å¯ä»¥çœ‹åˆ°ä¼ å…¥çš„å›¾ç‰‡æ•°æ®æœ‰ç±»å‹é™åˆ¶ï¼Œç›®å‰è¿˜æ²¡å­¦åˆ° <code>torch.Tensor</code> ç±»å‹ï¼Œä»¥ <code>numpy.ndarry</code> ä¸ºä¾‹ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å…ˆå®‰è£…ä¸€ä¸‹ NumPyï¼Œè¿˜æ˜¯åœ¨ PyTorch ç¯å¢ƒä¸­å®‰è£…ï¼š</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install numpy</span><br></pre></td></tr></table></figure>\n<p>ä½¿ç”¨ <code>PIL</code> æ‰“å¼€ä¸€ä¸ªå›¾åƒï¼Œå°†å…¶è½¬æ¢æˆ NumPy æ•°ç»„ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">img_path = <span class=\"string\">&#x27;dataset/hymenoptera_data/train/ants_image/0013035.jpg&#x27;</span></span><br><span class=\"line\">img_PIL = Image.<span class=\"built_in\">open</span>(img_path)</span><br><span class=\"line\">img_array = np.array(img_PIL)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">type</span>(img_array))  <span class=\"comment\"># &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(img_array.shape)  <span class=\"comment\"># (512, 768, 3)</span></span><br></pre></td></tr></table></figure>\n<p>å¯ä»¥çœ‹åˆ°å›¾ç‰‡çš„å½¢çŠ¶æ˜¯ä¸‰ç»´çš„æ•°æ®ï¼Œå‰ä¸¤ä¸ªæ•°æ®åˆ†åˆ«è¡¨ç¤ºé«˜åº¦å’Œå®½åº¦ï¼Œç¬¬ä¸‰ä¸ªæ•°æ®è¡¨ç¤ºé€šé“æ•°ï¼Œå¯ä»¥è®°ä¸º <code>(H, W, C)</code>ï¼Œç®€å†™ä¸º <code>HWC</code>ã€‚</p>\n<p><code>add_image</code> å‡½æ•°ä¼ å…¥å›¾ç‰‡æ—¶æ ¼å¼é»˜è®¤ä¸º <code>CHW</code>ï¼Œå¦‚æœæ ¼å¼ä¸åŒ¹é…éœ€è¦è®¾å®šå‡½æ•°ä¸­çš„ <code>dataformats</code> å‚æ•°ï¼Œä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&#x27;logs&#x27;</span>)</span><br><span class=\"line\">img_path = <span class=\"string\">&#x27;dataset/hymenoptera_data/train/ants_image/0013035.jpg&#x27;</span></span><br><span class=\"line\">img_PIL = Image.<span class=\"built_in\">open</span>(img_path)</span><br><span class=\"line\">img_array = np.array(img_PIL)</span><br><span class=\"line\"></span><br><span class=\"line\">writer.add_image(<span class=\"string\">&#x27;img_test&#x27;</span>, img_array, <span class=\"number\">1</span>, dataformats=<span class=\"string\">&#x27;HWC&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">writer.close()</span><br></pre></td></tr></table></figure>\n<p>è¿è¡Œåæ‰“å¼€ TensorBoard å³å¯åœ¨ IMAGES é¡µé¢ä¸‹çœ‹åˆ°å›¾ç‰‡ã€‚</p>\n<h2 id=\"4-Transform\">4. Transform</h2>\n<h3 id=\"4-1-Transformçš„æ¦‚å¿µä¸åŸºæœ¬ç”¨æ³•\">4.1 Transformçš„æ¦‚å¿µä¸åŸºæœ¬ç”¨æ³•</h3>\n<p><code>transforms</code> åœ¨è®¡ç®—æœºè§†è§‰å·¥å…·åŒ… <code>torchvision</code> ä¸‹ï¼ŒåŒ…å«äº†å¾ˆå¤šç§å¯¹å›¾åƒæ•°æ®è¿›è¡Œå˜æ¢çš„ç±»ï¼Œè¿™äº›éƒ½æ˜¯åœ¨æˆ‘ä»¬è¿›è¡Œå›¾åƒæ•°æ®è¯»å…¥æ­¥éª¤ä¸­å¿…ä¸å¯å°‘çš„ï¼Œé€šè¿‡å›¾åƒå˜æ¢å¯ä»¥å°†å›¾ç‰‡å˜æˆä¸åŒçš„ç±»å‹ï¼Œæˆ–è€…å¯ä»¥é€šè¿‡æ—‹è½¬ã€è£åˆ‡ç­‰æ‰‹æ®µå¯¹å›¾åƒæ•°æ®é›†çš„å›¾åƒè¿›è¡Œå˜æ¢ï¼Œèµ·åˆ°æ‰©å……æ•°æ®é›†ä¸æ•°æ®å¢å¼ºçš„ä½œç”¨ã€‚</p>\n<p><code>transforms</code> ä¸»è¦ä½¿ç”¨çš„ç±»ä¸ºï¼š<code>transforms.ToTensor</code>ï¼Œè¯¥ç±»èƒ½å¤Ÿå°† <code>PIL.Image</code> æˆ–è€… <code>ndarray</code> ç±»å‹çš„æ•°æ®è½¬æ¢ä¸º <code>tensor</code>ï¼Œå¹¶ä¸”å½’ä¸€åŒ–è‡³ <code>[0, 1]</code>ã€‚æ³¨æ„å½’ä¸€åŒ–è‡³ <code>[0, 1]</code> æ˜¯ç›´æ¥é™¤ä»¥255ï¼Œè‹¥è‡ªå·±çš„ <code>ndarray</code> æ•°æ®å°ºåº¦æœ‰å˜åŒ–ï¼Œåˆ™éœ€è¦è‡ªè¡Œä¿®æ”¹ã€‚</p>\n<p>ä¸ºä»€ä¹ˆéœ€è¦ <code>tensor</code> æ•°æ®ç±»å‹ï¼Ÿå› ä¸ºå®ƒåŒ…è£…äº†åå‘ä¼ æ’­ç¥ç»ç½‘ç»œæ‰€éœ€è¦çš„ä¸€äº›åŸºç¡€çš„å‚æ•°ï¼Œå› æ­¤åœ¨ç¥ç»ç½‘ç»œä¸­éœ€è¦å°†å›¾ç‰‡ç±»å‹è½¬æ¢ä¸º <code>tensor</code> ç±»å‹è¿›è¡Œè®­ç»ƒã€‚</p>\n<p>ä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"></span><br><span class=\"line\">img_path = <span class=\"string\">&#x27;dataset/hymenoptera_data/train/ants_image/0013035.jpg&#x27;</span></span><br><span class=\"line\">img_PIL = Image.<span class=\"built_in\">open</span>(img_path)  <span class=\"comment\"># &lt;class &#x27;PIL.JpegImagePlugin.JpegImageFile&#x27;&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">tensor_trans = transforms.ToTensor()  <span class=\"comment\"># åˆ›å»º ToTensor çš„å®ä¾‹å¯¹è±¡</span></span><br><span class=\"line\">img_tensor1 = tensor_trans(img_PIL)  <span class=\"comment\"># å°† PIL Image è½¬æ¢æˆ tensor</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">type</span>(img_tensor1))  <span class=\"comment\"># &lt;class &#x27;torch.Tensor&#x27;&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">img_cv = cv2.imread(img_path)  <span class=\"comment\"># &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class=\"line\">img_tensor2 = tensor_trans(img_cv)  <span class=\"comment\"># å°† OpenCV Image è½¬æ¢æˆ tensor</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">type</span>(img_tensor2))</span><br></pre></td></tr></table></figure>\n<h3 id=\"4-2-Transformçš„å¸¸ç”¨ç±»\">4.2 Transformçš„å¸¸ç”¨ç±»</h3>\n<ul>\n<li><code>transforms.Compose</code>ï¼š<code>Compose</code> èƒ½å¤Ÿå°†å¤šç§å˜æ¢ç»„åˆåœ¨ä¸€èµ·ã€‚ä¾‹å¦‚ä¸‹é¢çš„ä»£ç å¯ä»¥å…ˆå°† <code>PIL.Image</code> ä¸­å¿ƒè£åˆ‡ï¼Œç„¶åå†è½¬æ¢æˆ <code>tensor</code>ï¼š</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img_path = <span class=\"string\">&#x27;dataset/hymenoptera_data/train/ants_image/0013035.jpg&#x27;</span></span><br><span class=\"line\">img_PIL = Image.<span class=\"built_in\">open</span>(img_path)</span><br><span class=\"line\"></span><br><span class=\"line\">trans = transforms.Compose([</span><br><span class=\"line\">    transforms.CenterCrop(<span class=\"number\">100</span>),</span><br><span class=\"line\">    transforms.ToTensor()</span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\">img_trans = trans(img_PIL)</span><br></pre></td></tr></table></figure>\n<ul>\n<li><code>transforms.CenterCrop</code>ï¼šéœ€è¦ä¼ å…¥å‚æ•° <code>size</code>ï¼Œè¡¨ç¤ºä»¥ <code>(size, size)</code> çš„å¤§å°ä»ä¸­å¿ƒè£å‰ªï¼Œå‚æ•°ä¹Ÿå¯ä»¥ä¸º <code>(height, width)</code>ã€‚ä¾‹å¦‚ï¼š</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img_PIL.show()</span><br><span class=\"line\"></span><br><span class=\"line\">trans_centercrop = transforms.CenterCrop((<span class=\"number\">100</span>, <span class=\"number\">150</span>))</span><br><span class=\"line\">img_centercrop = trans_centercrop(img_PIL)</span><br><span class=\"line\">img_centercrop.show()</span><br></pre></td></tr></table></figure>\n<ul>\n<li><code>transforms.RandomCrop</code>ï¼šéœ€è¦ä¼ å…¥å‚æ•° <code>size</code>ï¼Œè¡¨ç¤ºä»¥ <code>(size, size)</code> çš„å¤§å°éšæœºè£å‰ªï¼Œå‚æ•°ä¹Ÿå¯ä»¥ä¸º <code>(height, width)</code>ã€‚</li>\n<li><code>transforms.Normalize(mean, std)</code>ï¼šå¯¹æ•°æ®æŒ‰é€šé“è¿›è¡Œæ ‡å‡†åŒ–ï¼Œå³å…ˆå‡å‡å€¼ <code>mean</code>ï¼Œå†é™¤ä»¥æ ‡å‡†å·® <code>std</code>ï¼Œæ³¨æ„æ˜¯ <code>HWC</code> æ ¼å¼ï¼Œå¤„ç†å…¬å¼ä¸ºï¼š<code>output[channel] = (input[channel] - mean[channel]) / std[channel]</code>ï¼Œä¾‹å¦‚ï¼š</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trans_tensor = transforms.ToTensor()</span><br><span class=\"line\">img_tensor = trans_tensor(img_PIL)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># å¦‚æœ input çš„èŒƒå›´æ˜¯[0, 1]ï¼Œé‚£ä¹ˆç”¨è¯¥å‚æ•°å½’ä¸€åŒ–åçš„èŒƒå›´å°±å˜ä¸º[-1, 1]</span></span><br><span class=\"line\">trans_norm = transforms.Normalize([<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>], [<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>])</span><br><span class=\"line\">img_norm = trans_norm(img_tensor)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(img_norm)</span><br></pre></td></tr></table></figure>\n<ul>\n<li><code>transforms.Resize</code>ï¼šéœ€è¦ä¼ å…¥å‚æ•° <code>(height, width)</code> å’Œ <code> interpolation</code>ï¼Œè¡¨ç¤ºé‡ç½®å›¾åƒçš„åˆ†è¾¨ç‡ä¸º <code>(h, w)</code>ï¼Œä¹Ÿå¯ä»¥ä¼ å…¥ä¸€ä¸ªæ•´æ•° <code>size</code>ï¼Œè¿™æ ·ä¼šå°†è¾ƒçŸ­çš„é‚£æ¡è¾¹ç¼©æ”¾è‡³ <code>size</code>ï¼Œå¦ä¸€æ¡è¾¹æŒ‰åŸå›¾å¤§å°ç­‰æ¯”ä¾‹ç¼©æ”¾ã€‚<code>interpolation</code> ä¸ºæ’å€¼æ–¹æ³•é€‰æ‹©ï¼Œé»˜è®¤ä¸º <code>PIL.Image.BILINEAR</code>ï¼Œä¾‹å¦‚ï¼š</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trans_tensor = transforms.ToTensor()</span><br><span class=\"line\">img_tensor = trans_tensor(img_PIL)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(img_tensor.size())  <span class=\"comment\"># torch.Size([3, 512, 768])ï¼Œtensor å›¾åƒä½¿ç”¨ size() è·å–å¤§å°ï¼ŒPIL å›¾åƒä½¿ç”¨ size</span></span><br><span class=\"line\"></span><br><span class=\"line\">trans_resize = transforms.Resize((<span class=\"number\">256</span>, <span class=\"number\">300</span>))</span><br><span class=\"line\">img_resize = trans_resize(img_tensor)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(img_resize.size())  <span class=\"comment\"># torch.Size([3, 256, 300])ï¼Œä¿®æ”¹æ¯”ä¾‹</span></span><br><span class=\"line\"></span><br><span class=\"line\">trans_resize = transforms.Resize(<span class=\"number\">30</span>)</span><br><span class=\"line\">img_resize = trans_resize(img_tensor)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(img_resize.size())  <span class=\"comment\"># torch.Size([3, 30, 45])ï¼Œä¸åŸå›¾ç­‰æ¯”ä¾‹</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li><code>transforms.ToPILImage</code>ï¼šï¼šå°† <code>tensor</code> æˆ–è€… <code>ndarray</code> çš„æ•°æ®è½¬æ¢ä¸º <code>PIL.Image</code> ç±»å‹æ•°æ®ï¼Œå‚æ•° <code>mode</code> é»˜è®¤ä¸º <code>None</code>ï¼Œè¡¨ç¤º1é€šé“ï¼Œ <code>mode=3</code> è¡¨ç¤º3é€šé“ï¼Œé»˜è®¤è½¬æ¢ä¸º <code>RGB</code>ï¼Œ4é€šé“é»˜è®¤è½¬æ¢ä¸º <code>RGBA</code>ã€‚</li>\n</ul>\n<h2 id=\"5-Torchvisionæ•°æ®é›†ä½¿ç”¨æ–¹æ³•\">5. Torchvisionæ•°æ®é›†ä½¿ç”¨æ–¹æ³•</h2>\n<p>Torchvision å®˜æ–¹æ–‡æ¡£ <a href=\"https://pytorch.org/vision/stable/datasets.html\">Torchvision</a> ä¸­çš„ <code>torchvision.datasets</code> å°±æ˜¯ Torchvision æä¾›çš„æ ‡å‡†æ•°æ®é›†ï¼Œå…¶ä¸­æœ‰å¾ˆå¤šå·²ç»æ„å»ºå’Œè®­ç»ƒå¥½çš„ç½‘ç»œæ¨¡å‹ï¼Œåœ¨ä¸åŒçš„é¢†åŸŸä¸‹å„è‡ªæœ‰ç€å¾ˆä¼˜ç§€çš„æ€§èƒ½ã€‚</p>\n<p>æˆ‘ä»¬ä»¥ CIFAR10 ä¸ºä¾‹ï¼Œè¯¥æ•°æ®é›†åŒ…æ‹¬äº†60000å¼ 32*32åƒç´ çš„å›¾åƒï¼Œæ€»å…±æœ‰10ä¸ªç±»åˆ«ï¼Œæ¯ä¸ªç±»åˆ«æœ‰6000å¼ å›¾åƒï¼Œå…¶ä¸­æœ‰50000å¼ å›¾åƒä¸ºè®­ç»ƒå›¾åƒï¼Œ10000å¼ ä¸ºæµ‹è¯•å›¾åƒã€‚å…¶ä½¿ç”¨è¯´æ˜å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p>\n<ul>\n<li><code>root</code>ï¼šæ•°æ®é›†å­˜æ”¾çš„è·¯å¾„ã€‚</li>\n<li><code>train</code>ï¼šå¦‚æœä¸º <code>True</code>ï¼Œåˆ›å»ºçš„æ•°æ®é›†å°±ä¸ºè®­ç»ƒé›†ï¼Œå¦åˆ™åˆ›å»ºçš„æ•°æ®é›†å°±ä¸ºæµ‹è¯•é›†ã€‚</li>\n<li><code>transform</code>ï¼šä½¿ç”¨ <code>transforms</code> ä¸­çš„å˜æ¢æ“ä½œå¯¹æ•°æ®é›†è¿›è¡Œå˜æ¢ã€‚</li>\n<li><code>target_transform</code>ï¼šå¯¹ <code>target</code> è¿›è¡Œ <code>transform</code>ã€‚</li>\n<li><code>download</code>ï¼šå¦‚æœä¸º <code>True</code>ï¼Œå°±ä¼šè‡ªåŠ¨ä»ç½‘ä¸Šä¸‹è½½è¿™ä¸ªæ•°æ®é›†ï¼Œå¦åˆ™å°±ä¸ä¼šä¸‹è½½ã€‚</li>\n</ul>\n<p>ä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"></span><br><span class=\"line\">train_data = torchvision.datasets.CIFAR10(root=<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">True</span>, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">test_data = torchvision.datasets.CIFAR10(root=<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(train_data[<span class=\"number\">0</span>])  <span class=\"comment\"># (&lt;PIL.Image.Image image mode=RGB size=32x32 at 0x24011FC4F40&gt;, 6)</span></span><br></pre></td></tr></table></figure>\n<p>åˆšå¼€å§‹è¿è¡Œæ—¶å¯ä»¥çœ‹åˆ°æ­£åœ¨ä»ç½‘ä¸Šä¸‹è½½æ•°æ®é›†ï¼Œå¦‚æœä¸‹è½½é€Ÿåº¦éå¸¸æ…¢å¯ä»¥å¤åˆ¶é“¾æ¥å»è¿…é›·ä¹‹ç±»çš„åœ°æ–¹ä¸‹è½½ï¼Œä¸‹è½½å¥½åè‡ªå·±åˆ›å»ºè®¾å®šçš„è·¯å¾„ï¼Œå°†æ•°æ®é›†æ”¾è¿‡æ¥å³å¯ã€‚</p>\n<p>ç„¶åè®¾ç½®æ–­ç‚¹ï¼Œç”¨ Debug æ¨¡å¼è¿è¡Œä¸€ä¸‹ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹ä¸€ä¸‹æ•°æ®é›†çš„å†…å®¹ï¼Œæ•°æ®é›† <code>train_data</code> ä¸­çš„ <code>classes</code> è¡¨ç¤ºå›¾åƒçš„ç§ç±»ï¼Œ<code>classes_to_idx</code> è¡¨ç¤ºå°†ç§ç±»æ˜ å°„ä¸ºæ•´æ•°ï¼Œ<code>targets</code> è¡¨ç¤ºæ¯å¼ å›¾åƒå¯¹åº”çš„ç§ç±»ç¼–å·ï¼Œè¯•ç€è¾“å‡ºä¸€ä¸‹ç¬¬ä¸€å¼ å›¾çš„ä¿¡æ¯ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img, target = train_data[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(img)  <span class=\"comment\"># &lt;PIL.Image.Image image mode=RGB size=32x32 at 0x1EEAEC32190&gt;</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(target)  <span class=\"comment\"># 6</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(train_data.classes[target])  <span class=\"comment\"># frog</span></span><br><span class=\"line\">img.show()  <span class=\"comment\"># å›¾åƒæ˜¾ç¤ºä¸ºé’è›™</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨ <code>transform</code> å‚æ•°ï¼Œå‡è®¾æˆ‘ä»¬éœ€è¦å°†æ•°æ®é›†çš„å›¾åƒéƒ½è½¬æ¢æˆ <code>tensor</code> ç±»å‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trans_dataset = torchvision.transforms.Compose([</span><br><span class=\"line\">    torchvision.transforms.ToTensor()</span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\">train_data = torchvision.datasets.CIFAR10(root=<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">True</span>, transform=trans_dataset, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">test_data = torchvision.datasets.CIFAR10(root=<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, transform=trans_dataset, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">img, target = train_data[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">type</span>(img))  <span class=\"comment\"># &lt;class &#x27;torch.Tensor&#x27;&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"6-ç¥ç»ç½‘ç»œTorch-NNåŸºæœ¬éª¨æ¶çš„ä½¿ç”¨\">6. ç¥ç»ç½‘ç»œTorch.NNåŸºæœ¬éª¨æ¶çš„ä½¿ç”¨</h2>\n<p><code>torch.nn</code> èƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬æ›´ä¼˜é›…åœ°è®­ç»ƒç¥ç»ç½‘ç»œï¼Œä½¿ç¥ç»ç½‘ç»œä»£ç æ›´åŠ ç®€æ´å’Œçµæ´»ã€‚å®˜æ–¹æ–‡æ¡£ï¼š<a href=\"https://pytorch.org/docs/stable/nn.html\">Torch.NN</a>ã€‚</p>\n<p>åœ¨æ–‡æ¡£ä¸­å¯ä»¥çœ‹åˆ°ç¬¬ä¸€å—å†…å®¹å«åš <code>Container</code>ï¼ˆå®¹å™¨ï¼‰ï¼Œè¿™å°±ç›¸å½“äºç¥ç»ç½‘ç»œçš„éª¨æ¶ï¼Œ<code>Container</code> ä¹‹åçš„ä¸œè¥¿å°±ç”¨äºå¾€éª¨æ¶é‡Œé¢å¡«å……ï¼Œå¦‚ Convolution Layersï¼ˆå·ç§¯å±‚ï¼‰ã€Pooling Layersï¼ˆæ± åŒ–å±‚ï¼‰ï¼Œæœ‰å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€çš„å°ä¼™ä¼´å¯¹è¿™äº›è¯åº”è¯¥éƒ½å¾ˆç†Ÿæ‚‰äº†ã€‚</p>\n<p><code>Container</code> ä¸­æœ‰å…­ä¸ªæ¨¡å—ï¼š<code>Module</code>ã€<code>Sequential</code>ã€<code>ModuleList</code>ã€<code>ModuleDict</code>ã€<code>ParameterList</code>ã€<code>ParameterDict</code>ï¼Œå…¶ä¸­æœ€å¸¸ç”¨çš„ä¸º <code>Module</code>ï¼Œè¿™æ˜¯æ‰€æœ‰ç¥ç»ç½‘ç»œçš„æœ€åŸºæœ¬çš„ç±»ï¼Œå…¶åŸºæœ¬çš„æ„é€ æ–¹å¼å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Model</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):  <span class=\"comment\"># åˆå§‹åŒ–</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">20</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">20</span>, <span class=\"number\">20</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):  <span class=\"comment\"># å‰å‘ä¼ æ’­</span></span><br><span class=\"line\">        x = F.relu(self.conv1(x))  <span class=\"comment\"># å°† x è¿›è¡Œç¬¬ä¸€å±‚å·ç§¯åç”¨ ReLU æ¿€æ´»å‡½æ•°è¾“å‡º</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> F.relu(self.conv2(x))  <span class=\"comment\"># å°†å¤„ç†åçš„ x å†è¿›è¡Œç¬¬äºŒå±‚å·ç§¯åç”¨ ReLU å¤„ç†åè¿”å›æœ€åç»“æœ</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æˆ‘ä»¬å°è¯•è‡ªå·±åˆ›å»ºä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼Œå¹¶è¾“å‡ºå‰å‘ä¼ æ’­çš„ç»“æœï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):  <span class=\"comment\"># åˆå§‹åŒ–</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Network, self).__init__()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = <span class=\"built_in\">input</span> + <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">network = Network()</span><br><span class=\"line\">x = torch.tensor(<span class=\"number\">1.0</span>)  <span class=\"comment\"># x ä¸º tensor ç±»å‹</span></span><br><span class=\"line\">output = network(x)  <span class=\"comment\"># Module ä¸­çš„ __call__ å‡½æ•°ä¼šè°ƒç”¨ forward å‡½æ•°</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(output)  <span class=\"comment\"># tensor(2.)</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬ä»¥ <code>Conv2d</code> å‡½æ•°ä¸ºä¾‹ï¼Œè¯¥å‡½æ•°çš„å®˜æ–¹æ–‡æ¡£ï¼š<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html#torch.nn.functional.conv2d\">TORCH.NN.FUNCTIONAL.CONV2D</a>ã€‚</p>\n<p>è¯¥å‡½æ•°æœ‰ä»¥ä¸‹å‡ ä¸ªå‚æ•°ï¼š</p>\n<ul>\n<li><code>input</code>ï¼šè¾“å…¥çš„å›¾åƒï¼Œ<code>size</code> ä¸º <code>(mini_batch, in_channels, height, width)</code>ã€‚</li>\n<li><code>weight</code>ï¼šå·ç§¯æ ¸çš„å¤§å°ï¼Œ<code>size</code> ä¸º <code>(out_channels, in_channels/groups, height, width)</code>ã€‚</li>\n<li><code>bias</code>ï¼šåç½®ï¼Œé»˜è®¤ä¸º <code>None</code>ã€‚</li>\n<li><code>stride</code>ï¼šæ­¥é•¿ï¼Œç”¨æ¥æ§åˆ¶å·ç§¯æ ¸ç§»åŠ¨é—´éš”ï¼Œå¦‚æœä¸º <code>x</code> åˆ™æ°´å¹³å’Œç«–ç›´æ–¹å‘çš„æ­¥é•¿éƒ½ä¸º <code>x</code>ï¼Œå¦‚æœä¸º <code>(x, y)</code> åˆ™ç«–ç›´æ–¹å‘æ­¥é•¿ä¸º <code>x</code>ï¼Œæ°´å¹³æ–¹å‘æ­¥é•¿ä¸º <code>y</code>ã€‚</li>\n<li><code>padding</code>ï¼šåœ¨è¾“å…¥å›¾åƒçš„è¾¹æ²¿è¿›è¡Œæ‰©è¾¹æ“ä½œï¼Œä»¥ä¿è¯å›¾åƒè¾“å…¥è¾“å‡ºå‰åçš„å°ºå¯¸å¤§å°ä¸å˜ï¼Œåœ¨ PyTorch çš„å·ç§¯å±‚å®šä¹‰ä¸­ï¼Œé»˜è®¤çš„ <code>padding</code> ä¸ºé›¶å¡«å……ï¼Œå³åœ¨è¾¹ç¼˜å¡«å……0ã€‚</li>\n<li><code>padding_mode</code>ï¼šæ‰©è¾¹çš„æ–¹å¼ã€‚</li>\n<li><code>dilation</code>ï¼šè®¾å®šäº†å–æ•°ä¹‹é—´çš„é—´éš”ã€‚</li>\n</ul>\n<p>ä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.tensor([</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">    [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>],</span><br><span class=\"line\">    [<span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>],</span><br><span class=\"line\">    [<span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\">kernel = torch.tensor([</span><br><span class=\"line\">    [<span class=\"number\">2</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">    [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>],</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">2</span>]</span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.reshape(<span class=\"built_in\">input</span>, (<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span>))  <span class=\"comment\"># batch_size = 1ï¼Œchannel = 1</span></span><br><span class=\"line\">kernel = torch.reshape(kernel, (<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">output = F.conv2d(<span class=\"built_in\">input</span>, kernel, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[[15, 16],</span></span><br><span class=\"line\"><span class=\"comment\">#           [ 6, 15]]]])</span></span><br><span class=\"line\"></span><br><span class=\"line\">output = F.conv2d(<span class=\"built_in\">input</span>, kernel, stride=<span class=\"number\">1</span>, bias=torch.tensor([<span class=\"number\">3</span>]))  <span class=\"comment\"># æ³¨æ„ bias å¿…é¡»ä¹Ÿæ˜¯çŸ©é˜µ</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(output)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[[18, 19],</span></span><br><span class=\"line\"><span class=\"comment\">#           [ 9, 18]]]])</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"7-Convolution-Layersä¸Pooling-Layers\">7. Convolution Layersä¸Pooling Layers</h2>\n<p>ç”±äºå›¾åƒæ˜¯äºŒç»´çš„ï¼Œå› æ­¤åŸºæœ¬ä¸Šæœ€å¸¸ç”¨åˆ°çš„å°±æ˜¯äºŒç»´çš„å·ç§¯å±‚å’Œæ± åŒ–å±‚ï¼š<code>torch.nn.Conv2d</code>ã€<code>torch.nn.MaxPool2d</code>ï¼Œå®˜æ–¹æ–‡æ¡£ï¼š<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\">torch.nn.Conv2d</a>ã€<a href=\"https://pytorch.org/docs/stable/nn.html#pooling-layers\">Pooling Layers</a>ã€‚</p>\n<h3 id=\"7-1-Convolution-Layers\">7.1 Convolution Layers</h3>\n<p>å·ç§¯è¿ç®—èƒ½å¤Ÿ<strong>æå–è¾“å…¥å›¾åƒçš„ä¸åŒç‰¹å¾</strong>ï¼Œç¬¬ä¸€å±‚å·ç§¯å±‚å¯èƒ½åªèƒ½æå–ä¸€äº›ä½çº§çš„ç‰¹å¾å¦‚è¾¹ç¼˜ã€çº¿æ¡å’Œè§’ç­‰å±‚çº§ï¼Œæ›´å¤šå±‚çš„ç½‘ç»œèƒ½ä»ä½çº§ç‰¹å¾ä¸­è¿­ä»£æå–æ›´å¤æ‚çš„ç‰¹å¾ã€‚</p>\n<p><code>torch.nn.Conv2d</code> çš„ä¸»è¦å‚æ•°æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š</p>\n<ul>\n<li><code>in_channels</code>ï¼šè¾“å…¥å›¾åƒçš„é€šé“æ•°ï¼Œå½©è‰²å›¾åƒä¸€èˆ¬éƒ½æ˜¯ä¸‰é€šé“ã€‚</li>\n<li><code>out_channels</code>ï¼šé€šè¿‡å·ç§¯åäº§ç”Ÿçš„è¾“å‡ºå›¾åƒçš„é€šé“æ•°ã€‚</li>\n<li><code>kernel_size</code>ï¼šå¯ä»¥æ˜¯ä¸€ä¸ªæ•°æˆ–ä¸€ä¸ªå…ƒç»„ï¼Œè¡¨ç¤ºå·ç§¯æ ¸çš„å¤§å°ï¼Œå·ç§¯æ ¸çš„å‚æ•°æ˜¯ä»æ•°æ®çš„åˆ†å¸ƒä¸­é‡‡æ ·å¾—åˆ°çš„ï¼Œè¿™äº›æ•°æ˜¯å¤šå°‘æ— æ‰€è°“ï¼Œå› ä¸ºåœ¨ç¥ç»ç½‘ç»œè®­ç»ƒçš„è¿‡ç¨‹ä¸­å°±æ˜¯å¯¹è¿™äº›å‚æ•°è¿›è¡Œä¸æ–­åœ°è°ƒæ•´ã€‚</li>\n<li><code>stride</code>ï¼šæ­¥é•¿ã€‚</li>\n<li><code>padding</code>ï¼šå¡«å……ã€‚</li>\n<li><code>padding_mode</code>ï¼šå¡«å……æ¨¡å¼ï¼Œæœ‰ <code>zeros</code>ã€<code>reflect</code>ã€<code>replicate</code>ã€<code>circular</code>ï¼Œé»˜è®¤ä¸º <code>zeros</code>ã€‚</li>\n<li><code>dilation</code>ï¼šå¯ä»¥æ˜¯ä¸€ä¸ªæ•°æˆ–ä¸€ä¸ªå…ƒç»„ï¼Œè¡¨ç¤ºå·ç§¯æ ¸å„ä¸ªå…ƒç´ é—´çš„è·ç¦»ï¼Œä¹Ÿç§°ç©ºæ´å·ç§¯ã€‚</li>\n<li><code>group</code>ï¼šä¸€èˆ¬è®¾ç½®ä¸º1ï¼ŒåŸºæœ¬ç”¨ä¸åˆ°ã€‚</li>\n<li><code>bias</code>ï¼šåç½®ï¼Œä¸€èˆ¬è®¾ç½®ä¸º <code>True</code>ã€‚</li>\n</ul>\n<p>ä¾‹å¦‚ä»¥ä¸‹ä»£ç æ„å»ºäº†ä¸€ä¸ªåªæœ‰ä¸€å±‚å·ç§¯å±‚çš„ç¥ç»ç½‘ç»œï¼Œè¯¥å·ç§¯å±‚çš„è¾“å…¥å’Œè¾“å‡ºé€šé“æ•°éƒ½ä¸ºä¸‰é€šé“ï¼Œå·ç§¯æ ¸å¤§å°ä¸º3*3ï¼Œæ­¥é•¿ä¸º1ï¼Œæ— å¡«å……ï¼Œç„¶åç”¨ CIFAR10 æµ‹è¯•æ•°æ®é›†è¿›è¡Œæµ‹è¯•ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\">test_data = datasets.CIFAR10(<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor())</span><br><span class=\"line\"></span><br><span class=\"line\">data_loader = DataLoader(test_data, batch_size=<span class=\"number\">64</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Network, self).__init__()</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(in_channels=<span class=\"number\">3</span>, out_channels=<span class=\"number\">3</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.conv1(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">network = Network()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(network)  <span class=\"comment\"># Network((conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1)))</span></span><br><span class=\"line\"></span><br><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&#x27;logs&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_loader):</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    output = network(imgs)</span><br><span class=\"line\">    writer.add_images(<span class=\"string\">&#x27;input&#x27;</span>, imgs, step)</span><br><span class=\"line\">    writer.add_images(<span class=\"string\">&#x27;output&#x27;</span>, output, step)</span><br><span class=\"line\"></span><br><span class=\"line\">writer.close()</span><br></pre></td></tr></table></figure>\n<p>è¿è¡Œåå¯ä»¥æ‰“å¼€ TensorBoard æŸ¥çœ‹ä¸€ä¸‹æ•ˆæœã€‚</p>\n<h3 id=\"7-2-Pooling-Layers\">7.2 Pooling Layers</h3>\n<p>Pooling Layers ä¸­çš„ <code>MaxPool</code> è¡¨ç¤ºæœ€å¤§æ± åŒ–ï¼Œä¹Ÿç§°ä¸Šé‡‡æ ·ï¼›<code>MaxUnpool</code> è¡¨ç¤ºæœ€å°æ± åŒ–ï¼Œä¹Ÿç§°ä¸‹é‡‡æ ·ï¼›<code>AvgPool</code> è¡¨ç¤ºå¹³å‡æ± åŒ–ã€‚å…¶ä¸­æœ€å¸¸ç”¨çš„ä¸º <code>MaxPool2d</code>ï¼Œå®˜æ–¹æ–‡æ¡£ï¼š<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d\">torch.nn.MaxPool2d</a>ã€‚</p>\n<p>æœ€å¤§æ± åŒ–çš„ç›®çš„æ˜¯<strong>ä¿ç•™è¾“å…¥æ•°æ®çš„ç‰¹å¾ï¼ŒåŒæ—¶å‡å°ç‰¹å¾çš„æ•°æ®é‡</strong>ã€‚</p>\n<p><code>torch.nn.MaxPool2d</code> çš„ä¸»è¦å‚æ•°æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š</p>\n<ul>\n<li><code>kernel_size</code>ï¼šç”¨æ¥å–æœ€å¤§å€¼çš„çª—å£ï¼ˆæ± åŒ–æ ¸ï¼‰å¤§å°ï¼Œå’Œä¹‹å‰çš„å·ç§¯æ ¸ç±»ä¼¼ã€‚</li>\n<li><code>stride</code>ï¼šæ­¥é•¿ï¼Œæ³¨æ„é»˜è®¤å€¼ä¸º <code>kernel_size</code>ã€‚</li>\n<li><code>padding</code>ï¼šå¡«å……ï¼Œå’Œ <code>Conv2d</code> ä¸€æ ·ã€‚</li>\n<li><code>dilation</code>ï¼šæ± åŒ–æ ¸ä¸­å„ä¸ªå…ƒç´ é—´çš„è·ç¦»ï¼Œå’Œ <code>Conv2d</code> ä¸€æ ·ã€‚</li>\n<li><code>return_indices</code>ï¼šå¦‚æœä¸º <code>True</code>ï¼Œè¡¨ç¤ºè¿”å›å€¼ä¸­åŒ…å«æœ€å¤§å€¼ä½ç½®çš„ç´¢å¼•ã€‚æ³¨æ„è¿™ä¸ªæœ€å¤§å€¼æŒ‡çš„æ˜¯åœ¨æ‰€æœ‰çª—å£ä¸­äº§ç”Ÿçš„æœ€å¤§å€¼ï¼Œå¦‚æœçª—å£äº§ç”Ÿçš„æœ€å¤§å€¼æ€»å…±æœ‰5ä¸ªï¼Œå°±ä¼šæœ‰5ä¸ªè¿”å›å€¼ã€‚</li>\n<li><code>ceil_mode</code>ï¼šå¦‚æœä¸º <code>True</code>ï¼Œè¡¨ç¤ºåœ¨è®¡ç®—è¾“å‡ºç»“æœå½¢çŠ¶çš„æ—¶å€™ï¼Œä½¿ç”¨å‘ä¸Šå–æ•´ï¼Œå¦åˆ™é»˜è®¤å‘ä¸‹å–æ•´ã€‚</li>\n</ul>\n<p>è¾“å‡ºå›¾åƒçš„å½¢çŠ¶çš„è®¡ç®—å…¬å¼å¯ä»¥åœ¨å®˜æ–¹æ–‡æ¡£ä¸­æŸ¥çœ‹ã€‚</p>\n<p>æ¥ä¸‹æ¥æˆ‘ä»¬ç”¨ä»£ç å®ç°è¿™ä¸ªæ± åŒ–å±‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Network, self).__init__()</span><br><span class=\"line\">        self.maxpool1 = nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.maxpool1(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.tensor([</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">    [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>],</span><br><span class=\"line\">    [<span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>],</span><br><span class=\"line\">    [<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\">], dtype=torch.float32)  <span class=\"comment\"># æ³¨æ„æ± åŒ–å±‚è¯»å…¥çš„æ•°æ®éœ€è¦ä¸ºæµ®ç‚¹å‹</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.reshape(<span class=\"built_in\">input</span>, (<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">network = Network()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(network)  <span class=\"comment\"># Network((maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))</span></span><br><span class=\"line\"></span><br><span class=\"line\">output = network(<span class=\"built_in\">input</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[[2., 3.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [4., 2.]]]])</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬ç”¨å›¾åƒæ¥è¯•è¯•æ•ˆæœï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\">test_data = datasets.CIFAR10(<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor())</span><br><span class=\"line\"></span><br><span class=\"line\">data_loader = DataLoader(test_data, batch_size=<span class=\"number\">64</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Network, self).__init__()</span><br><span class=\"line\">        self.maxpool1 = nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.maxpool1(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">network = Network()</span><br><span class=\"line\"></span><br><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&#x27;logs&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_loader):</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    output = network(imgs)</span><br><span class=\"line\">    writer.add_images(<span class=\"string\">&#x27;input&#x27;</span>, imgs, step)</span><br><span class=\"line\">    writer.add_images(<span class=\"string\">&#x27;output&#x27;</span>, output, step)</span><br><span class=\"line\"></span><br><span class=\"line\">writer.close()</span><br></pre></td></tr></table></figure>\n<p>è¿è¡Œåå¯ä»¥æ‰“å¼€ TensorBoard æŸ¥çœ‹ä¸€ä¸‹æ•ˆæœã€‚</p>\n<h2 id=\"8-Non-linear-Activationsä¸Linear-Layers\">8. Non-linear Activationsä¸Linear Layers</h2>\n<h3 id=\"8-1-Non-linear-Activations\">8.1 Non-linear Activations</h3>\n<p>éçº¿æ€§æ¿€æ´»çš„ç›®çš„æ˜¯ä¸ºäº†åœ¨ç½‘ç»œä¸­å¼•å…¥ä¸€äº›<strong>éçº¿æ€§ç‰¹å¾</strong>ï¼Œå› ä¸ºéçº¿æ€§ç‰¹å¾è¶Šå¤šæ‰èƒ½è®­ç»ƒå‡ºç¬¦åˆå„ç§æ›²çº¿ï¼ˆç‰¹å¾ï¼‰çš„æ¨¡å‹ã€‚</p>\n<p>éçº¿æ€§æ¿€æ´»å‡½æ•°å®˜æ–¹æ–‡æ¡£ï¼š<a href=\"https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\">Non-linear Activations</a>ã€‚</p>\n<p>æœ‰æ·±åº¦å­¦ä¹ åŸºç¡€çš„åŒå­¦åº”è¯¥çŸ¥é“æœ€å¸¸ç”¨çš„éçº¿æ€§æ¿€æ´»å‡½æ•°å°±æ˜¯ ReLU å’Œ Sigmoid å‡½æ•°ï¼Œå¤šåˆ†ç±»é—®é¢˜ä¼šåœ¨è¾“å‡ºå±‚ä½¿ç”¨ Softmax å‡½æ•°ï¼ˆå¦‚æœæŸå¤±å‡½æ•°ä½¿ç”¨çš„æ˜¯äº¤å‰ç†µè¯¯å·®å‡½æ•° <code>CrossEntropyLoss</code> åˆ™ä¼šè‡ªåŠ¨è®¡ç®— Softmaxï¼Œæ— éœ€åˆ›å»º Softmax å±‚ï¼‰ã€‚è¿™ä¸‰ä¸ªå‡½æ•°åœ¨ PyTorch ä¸­åˆ†åˆ«ä¸º <code>nn.ReLU</code>ã€<code>nn.Sigmoid</code> å’Œ <code>nn.Softmax</code>ã€‚</p>\n<p>è¿™ä¸¤ä¸ªå‡½æ•°çš„è¾“å…¥éƒ½æ˜¯åªéœ€æŒ‡æ˜ <code>batch_size</code> å³å¯ï¼Œåœ¨ PyTorch1.0 ä¹‹åçš„ç‰ˆæœ¬ä»»ä½•å½¢çŠ¶çš„æ•°æ®éƒ½èƒ½è¢«è®¡ç®—ï¼Œæ— éœ€æŒ‡å®š <code>batch_size</code>ã€‚</p>\n<p><code>nn.ReLU</code> åªæœ‰ä¸€ä¸ªéœ€è¦è®¾ç½®çš„å‚æ•° <code>inplace</code>ï¼Œå¦‚æœä¸º <code>True</code> è¡¨ç¤ºè®¡ç®—ç»“æœç›´æ¥æ›¿æ¢åˆ°è¾“å…¥æ•°æ®ä¸Šï¼Œä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">input</span> = -<span class=\"number\">1</span></span><br><span class=\"line\">nn.ReLU(<span class=\"built_in\">input</span>, inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\"># input = 0</span></span><br></pre></td></tr></table></figure>\n<p>æ„å»º ReLU å±‚ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Network, self).__init__()</span><br><span class=\"line\">        self.relu1 = nn.ReLU()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.relu1(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">network = Network()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.tensor([</span><br><span class=\"line\">    [<span class=\"number\">1</span>, -<span class=\"number\">0.5</span>],</span><br><span class=\"line\">    [-<span class=\"number\">1</span>, <span class=\"number\">3</span>]</span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\">output = network(<span class=\"built_in\">input</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output)</span><br><span class=\"line\"><span class=\"comment\"># tensor([[1., 0.],</span></span><br><span class=\"line\"><span class=\"comment\">#         [0., 3.]])</span></span><br></pre></td></tr></table></figure>\n<p>ç”±äº ReLU å¯¹å›¾åƒå¤„ç†çš„ç›´è§‚æ•ˆæœä¸æ˜æ˜¾ï¼Œæˆ‘ä»¬ä½¿ç”¨ Sigmoid å¯¹å›¾åƒè¿›è¡Œå¤„ç†ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Network, self).__init__()</span><br><span class=\"line\">        self.sigmoid1 = nn.Sigmoid()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.sigmoid1(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">test_data = datasets.CIFAR10(<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor())</span><br><span class=\"line\">data_loader = DataLoader(test_data, batch_size=<span class=\"number\">64</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">network = Network()</span><br><span class=\"line\"></span><br><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&#x27;logs&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_loader):</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    output = network(imgs)</span><br><span class=\"line\">    writer.add_images(<span class=\"string\">&#x27;input&#x27;</span>, imgs, step)</span><br><span class=\"line\">    writer.add_images(<span class=\"string\">&#x27;output&#x27;</span>, output, step)</span><br><span class=\"line\"></span><br><span class=\"line\">writer.close()</span><br></pre></td></tr></table></figure>\n<h3 id=\"8-2-Linear-Layers\">8.2 Linear Layers</h3>\n<p>çº¿æ€§å±‚å®˜æ–¹æ–‡æ¡£ï¼š<a href=\"https://pytorch.org/docs/stable/nn.html#linear-layers\">Linear Layers</a>ã€‚</p>\n<p>PyTorch çš„ <code>nn.Linear</code> æ˜¯ç”¨äºè®¾ç½®ç½‘ç»œä¸­çš„å…¨è¿æ¥å±‚çš„ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯å…¨è¿æ¥å±‚çš„è¾“å…¥ä¸è¾“å‡ºéƒ½æ˜¯äºŒç»´å¼ é‡ï¼Œä¸€èˆ¬å½¢çŠ¶ä¸ºï¼š<code>[batch_size, size]</code>ï¼Œä¸åŒäºå·ç§¯å±‚è¦æ±‚è¾“å…¥è¾“å‡ºæ˜¯å››ç»´å¼ é‡ï¼Œå› æ­¤åœ¨å°†å›¾åƒä¼ å…¥å…¨è¿æ¥å±‚ä¹‹å‰ä¸€èˆ¬éƒ½ä¼šå±•å¼€æˆä¸€ç»´çš„ã€‚</p>\n<p><code>nn.Linear</code> æœ‰ä¸‰ä¸ªå‚æ•°åˆ†åˆ«å¦‚ä¸‹ï¼š</p>\n<ul>\n<li><code>in_features</code>ï¼šæŒ‡çš„æ˜¯è¾“å…¥çš„äºŒç»´å¼ é‡çš„å¤§å°ï¼Œå³è¾“å…¥çš„ <code>[batch_size, size]</code> ä¸­çš„ <code>size</code>ã€‚</li>\n<li><code>out_features</code>ï¼šæŒ‡çš„æ˜¯è¾“å‡ºçš„äºŒç»´å¼ é‡çš„å¤§å°ï¼Œå³è¾“å‡ºçš„äºŒç»´å¼ é‡çš„å½¢çŠ¶ä¸º <code>[batch_size, output_size]</code>ï¼Œå½“ç„¶ï¼Œå®ƒä¹Ÿä»£è¡¨äº†è¯¥å…¨è¿æ¥å±‚çš„ç¥ç»å…ƒä¸ªæ•°ã€‚ä»è¾“å…¥è¾“å‡ºçš„å¼ é‡çš„ <code>shape</code> è§’åº¦æ¥ç†è§£ï¼Œç›¸å½“äºä¸€ä¸ªè¾“å…¥ä¸º <code>[batch_size, in_features]</code> çš„å¼ é‡å˜æ¢æˆäº† <code>[batch_size, out_features]</code> çš„è¾“å‡ºå¼ é‡ã€‚</li>\n<li><code>bias</code>ï¼šåç½®ï¼Œç›¸å½“äº <code>y = ax + b</code> ä¸­çš„ <code>b</code>ã€‚</li>\n</ul>\n<p>ä»£ç ç¤ºä¾‹å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Network, self).__init__()</span><br><span class=\"line\">        self.linear1 = nn.Linear(<span class=\"number\">24</span>, <span class=\"number\">30</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.linear1(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.tensor([</span><br><span class=\"line\">    [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">    [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>],</span><br><span class=\"line\">    [<span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>],</span><br><span class=\"line\">], dtype=torch.float32)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">input</span>.shape)  <span class=\"comment\"># torch.Size([3, 8])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.flatten(<span class=\"built_in\">input</span>)  <span class=\"comment\"># å°† input æ‹‰å¹³æˆä¸€ç»´</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">input</span>.shape)  <span class=\"comment\"># torch.Size([24])</span></span><br><span class=\"line\"></span><br><span class=\"line\">network = Network()</span><br><span class=\"line\"></span><br><span class=\"line\">output = network(<span class=\"built_in\">input</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output.shape)  <span class=\"comment\"># torch.Size([30])</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"9-ç¥ç»ç½‘ç»œæ¨¡å‹æ­å»ºå°å®æˆ˜\">9. ç¥ç»ç½‘ç»œæ¨¡å‹æ­å»ºå°å®æˆ˜</h2>\n<h3 id=\"9-1-Sequential\">9.1 Sequential</h3>\n<p><code>torch.nn.Sequential</code> æ˜¯ä¸€ä¸ª Sequential å®¹å™¨ï¼Œèƒ½å¤Ÿåœ¨å®¹å™¨ä¸­åµŒå¥—å„ç§å®ç°ç¥ç»ç½‘ç»œä¸­å…·ä½“åŠŸèƒ½ç›¸å…³çš„ç±»ï¼Œæ¥å®Œæˆå¯¹ç¥ç»ç½‘ç»œæ¨¡å‹çš„æ­å»ºã€‚æ¨¡å—çš„åŠ å…¥ä¸€èˆ¬æœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯ç›´æ¥åµŒå¥—ï¼Œå¦ä¸€ç§æ˜¯ä»¥ <code>OrderedDict</code> æœ‰åºå­—å…¸çš„æ–¹å¼è¿›è¡Œä¼ å…¥ï¼Œè¿™ä¸¤ç§æ–¹å¼çš„å”¯ä¸€åŒºåˆ«æ˜¯ï¼š</p>\n<ul>\n<li>ä½¿ç”¨ <code>OrderedDict</code> æ­å»ºçš„æ¨¡å‹çš„æ¯ä¸ªæ¨¡å—éƒ½æœ‰æˆ‘ä»¬è‡ªå®šä¹‰çš„åå­—ã€‚</li>\n<li>ç›´æ¥åµŒå¥—é»˜è®¤ä½¿ç”¨ä»é›¶å¼€å§‹çš„æ•°å­—åºåˆ—ä½œä¸ºæ¯ä¸ªæ¨¡å—çš„åå­—ã€‚</li>\n</ul>\n<p>ï¼ˆ1ï¼‰ç›´æ¥åµŒå¥—æ–¹æ³•çš„ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\">model = nn.Sequential(</span><br><span class=\"line\">    nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">20</span>, <span class=\"number\">5</span>),</span><br><span class=\"line\">    nn.ReLU(),</span><br><span class=\"line\">    nn.Conv2d(<span class=\"number\">20</span>, <span class=\"number\">64</span>, <span class=\"number\">5</span>),</span><br><span class=\"line\">    nn.ReLU()</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(model)</span><br><span class=\"line\"><span class=\"comment\"># Sequential(</span></span><br><span class=\"line\"><span class=\"comment\">#   (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))</span></span><br><span class=\"line\"><span class=\"comment\">#   (1): ReLU()</span></span><br><span class=\"line\"><span class=\"comment\">#   (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span></span><br><span class=\"line\"><span class=\"comment\">#   (3): ReLU()</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br></pre></td></tr></table></figure>\n<p>ï¼ˆ2ï¼‰ä½¿ç”¨ <code>OrderedDict</code> çš„ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> OrderedDict</span><br><span class=\"line\"></span><br><span class=\"line\">model = nn.Sequential(OrderedDict([</span><br><span class=\"line\">    (<span class=\"string\">&#x27;Conv1&#x27;</span>, nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">20</span>, <span class=\"number\">5</span>)),</span><br><span class=\"line\">    (<span class=\"string\">&#x27;ReLU1&#x27;</span>, nn.ReLU()),</span><br><span class=\"line\">    (<span class=\"string\">&#x27;Conv2&#x27;</span>, nn.Conv2d(<span class=\"number\">20</span>, <span class=\"number\">64</span>, <span class=\"number\">5</span>)),</span><br><span class=\"line\">    (<span class=\"string\">&#x27;ReLU2&#x27;</span>, nn.ReLU())</span><br><span class=\"line\">]))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(model)</span><br><span class=\"line\"><span class=\"comment\"># Sequential(</span></span><br><span class=\"line\"><span class=\"comment\">#   (Conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))</span></span><br><span class=\"line\"><span class=\"comment\">#   (ReLU1): ReLU()</span></span><br><span class=\"line\"><span class=\"comment\">#   (Conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span></span><br><span class=\"line\"><span class=\"comment\">#   (ReLU2): ReLU()</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"9-2-å°å®æˆ˜\">9.2 å°å®æˆ˜</h3>\n<p>ç”±äºä»£ç å¾ˆç®€å•ï¼Œéƒ½æ˜¯å­¦è¿‡çš„å†…å®¹è¿›è¡Œç»„è£…ï¼Œå› æ­¤ç›´æ¥çœ‹ä»£ç ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">CIFAR10_Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(CIFAR10_Network, self).__init__()</span><br><span class=\"line\">        self.model = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">3</span>, out_channels=<span class=\"number\">32</span>, kernel_size=<span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),  <span class=\"comment\"># [32, 32, 32]</span></span><br><span class=\"line\">            nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>),  <span class=\"comment\"># [32, 16, 16]</span></span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">32</span>, out_channels=<span class=\"number\">32</span>, kernel_size=<span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),  <span class=\"comment\"># [32, 16, 16]</span></span><br><span class=\"line\">            nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>),  <span class=\"comment\"># [32, 8, 8]</span></span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">32</span>, out_channels=<span class=\"number\">64</span>, kernel_size=<span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),  <span class=\"comment\"># [64, 8, 8]</span></span><br><span class=\"line\">            nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>),  <span class=\"comment\"># [64, 4, 4]</span></span><br><span class=\"line\">            nn.Flatten(),  <span class=\"comment\"># [1024]</span></span><br><span class=\"line\">            nn.Linear(in_features=<span class=\"number\">1024</span>, out_features=<span class=\"number\">64</span>),  <span class=\"comment\"># [64]</span></span><br><span class=\"line\">            nn.Linear(in_features=<span class=\"number\">64</span>, out_features=<span class=\"number\">10</span>) <span class=\"comment\"># [10]</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.model(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">network = CIFAR10_Network()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.randn(<span class=\"number\">64</span>, <span class=\"number\">3</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>)  <span class=\"comment\"># è¿”å›ä¸€ä¸ªåŒ…å«äº†ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒä¸­æŠ½å–çš„ä¸€ç»„éšæœºæ•°çš„å¼ é‡</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">input</span>.shape)  <span class=\"comment\"># torch.Size([64, 3, 32, 32])</span></span><br><span class=\"line\">output = network(<span class=\"built_in\">input</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output.shape)  <span class=\"comment\"># torch.Size([64, 10])</span></span><br><span class=\"line\"></span><br><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&#x27;logs&#x27;</span>)</span><br><span class=\"line\">writer.add_graph(network, <span class=\"built_in\">input</span>)  <span class=\"comment\"># ç”Ÿæˆè®¡ç®—å›¾</span></span><br><span class=\"line\">writer.close()</span><br></pre></td></tr></table></figure>\n<p>ä½¿ç”¨ <code>add_graph</code> å‡½æ•°å¯ä»¥åœ¨ TensorBoard ä¸­ç”Ÿæˆç¥ç»ç½‘ç»œçš„è®¡ç®—å›¾ï¼Œé€šè¿‡è®¡ç®—å›¾å¯ä»¥å¾ˆæ¸…æ™°åœ°çœ‹åˆ°æ¯ä¸€å±‚è®¡ç®—æ—¶æ•°æ®æµå…¥æµå‡ºçš„ç»“æœï¼ŒåŒå‡»ç›¸åº”çš„æ ‡ç­¾å¯ä»¥è¿›ä¸€æ­¥æ·±å…¥æŸ¥çœ‹æ›´è¯¦ç»†çš„ä¿¡æ¯ã€‚</p>\n<h2 id=\"10-æŸå¤±å‡½æ•°ä¸åå‘ä¼ æ’­\">10. æŸå¤±å‡½æ•°ä¸åå‘ä¼ æ’­</h2>\n<h3 id=\"10-1-Loss-Functions\">10.1 Loss Functions</h3>\n<p>å…·æœ‰æ·±åº¦å­¦ä¹ ç†è®ºåŸºç¡€çš„åŒå­¦å¯¹æŸå¤±å‡½æ•°å’Œåå‘ä¼ æ’­ä¸€å®šä¸é™Œç”Ÿï¼Œåœ¨æ­¤ä¸è¯¦ç»†å±•å¼€ç†è®ºä»‹ç»ã€‚æŸå¤±å‡½æ•°æ˜¯æŒ‡ç”¨äºè®¡ç®—æ ‡ç­¾å€¼å’Œé¢„æµ‹å€¼ä¹‹é—´å·®å¼‚çš„å‡½æ•°ï¼Œåœ¨æœºå™¨å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œæœ‰å¤šç§æŸå¤±å‡½æ•°å¯ä¾›é€‰æ‹©ï¼Œå…¸å‹çš„æœ‰è·ç¦»å‘é‡ï¼Œç»å¯¹å€¼å‘é‡ç­‰ã€‚ä½¿ç”¨æŸå¤±å‡½æ•°çš„æµç¨‹æ¦‚æ‹¬å¦‚ä¸‹ï¼š</p>\n<ol>\n<li>è®¡ç®—å®é™…è¾“å‡ºå’Œç›®æ ‡ä¹‹é—´çš„å·®è·ã€‚</li>\n<li>ä¸ºæˆ‘ä»¬æ›´æ–°è¾“å‡ºæä¾›ä¸€å®šçš„ä¾æ®ï¼ˆåå‘ä¼ æ’­ï¼‰ã€‚</li>\n</ol>\n<p>æŸå¤±å‡½æ•°çš„å®˜æ–¹æ–‡æ¡£ï¼š<a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\">Loss Functions</a>ã€‚</p>\n<p>ï¼ˆ1ï¼‰<code>nn.L1Loss</code>ï¼šå¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼ŒMean Absolute Errorï¼‰ï¼Œè®¡ç®—æ–¹æ³•å¾ˆç®€å•ï¼Œå–é¢„æµ‹å€¼å’ŒçœŸå®å€¼çš„ç»å¯¹è¯¯å·®çš„å¹³å‡æ•°å³å¯ã€‚</p>\n<p>PyTorch1.13ä¸­ <code>nn.L1Loss</code> æ•°æ®å½¢çŠ¶è§„å®šå¦‚ä¸‹ï¼š</p>\n<ul>\n<li><code>Input</code>ï¼š<code>(*)</code>ï¼Œmeans any number of dimensions.</li>\n<li><code>Target</code>ï¼š<code>(*)</code>ï¼Œsame shape as the input.</li>\n<li><code>Output</code>ï¼šscalar. If <code>reduction</code> is <code>none</code>, then <code>(*)</code>, same shape as the input.</li>\n</ul>\n<p>æ—©å…ˆçš„ç‰ˆæœ¬éœ€è¦æŒ‡å®š <code>batch_size</code> å¤§å°ï¼Œç°åœ¨ä¸éœ€è¦äº†ã€‚å¯ä»¥è®¾ç½®å‚æ•° <code>reduction</code>ï¼Œé»˜è®¤ä¸º <code>mean</code>ï¼Œå³å–å¹³å‡å€¼ï¼Œä¹Ÿå¯ä»¥è®¾ç½®ä¸º <code>sum</code>ï¼Œé¡¾åæ€ä¹‰å°±æ˜¯å–å’Œã€‚</p>\n<p>æµ‹è¯•ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.tensor([<span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>, <span class=\"number\">3.0</span>])</span><br><span class=\"line\">target = torch.tensor([<span class=\"number\">4.0</span>, -<span class=\"number\">2.0</span>, <span class=\"number\">5.0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">loss = nn.L1Loss()</span><br><span class=\"line\">result = loss(<span class=\"built_in\">input</span>, target)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(result)  <span class=\"comment\"># tensor(3.)</span></span><br><span class=\"line\"></span><br><span class=\"line\">loss = nn.L1Loss(reduction=<span class=\"string\">&#x27;sum&#x27;</span>)</span><br><span class=\"line\">result = loss(<span class=\"built_in\">input</span>, target)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(result)  <span class=\"comment\"># tensor(9.)</span></span><br></pre></td></tr></table></figure>\n<p>ï¼ˆ2ï¼‰<code>nn.MSELoss</code>ï¼šå‡æ–¹è¯¯å·®ï¼ˆMSEï¼ŒMean Squared Errorï¼‰ï¼Œå³é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹å·®çš„å¹³æ–¹å’Œçš„å¹³å‡æ•°ã€‚</p>\n<p>è¯¥æŸå¤±å‡½æ•°çš„ç”¨æ³•ä¸ <code>nn.L1Loss</code> ç›¸ä¼¼ï¼Œä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.tensor([<span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>, <span class=\"number\">3.0</span>])</span><br><span class=\"line\">target = torch.tensor([<span class=\"number\">4.0</span>, -<span class=\"number\">2.0</span>, <span class=\"number\">5.0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">loss = nn.MSELoss()</span><br><span class=\"line\">result = loss(<span class=\"built_in\">input</span>, target)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(result)  <span class=\"comment\"># tensor(9.6667)</span></span><br><span class=\"line\"></span><br><span class=\"line\">loss = nn.MSELoss(reduction=<span class=\"string\">&#x27;sum&#x27;</span>)</span><br><span class=\"line\">result = loss(<span class=\"built_in\">input</span>, target)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(result)  <span class=\"comment\"># tensor(29.)</span></span><br></pre></td></tr></table></figure>\n<p>ï¼ˆ3ï¼‰<code>nn.CrossEntropyLoss</code>ï¼šäº¤å‰ç†µè¯¯å·®ï¼Œè®­ç»ƒåˆ†ç±» C ä¸ªç±»åˆ«çš„æ¨¡å‹çš„æ—¶å€™è¾ƒå¸¸ç”¨è¿™ä¸ªæŸå¤±å‡½æ•°ï¼Œä¸€èˆ¬ç”¨åœ¨ Softmax å±‚åé¢ï¼Œè®¡ç®—å…¬å¼è¾ƒä¸ºå¤æ‚ï¼Œå¯ä»¥åœ¨å®˜ç½‘ä¸­æŸ¥çœ‹ã€‚</p>\n<p>æµ‹è¯•ä»£ç å¦‚ä¸‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.tensor([<span class=\"number\">0.1</span>, <span class=\"number\">0.7</span>, <span class=\"number\">0.2</span>])</span><br><span class=\"line\">target = torch.tensor(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">loss = nn.CrossEntropyLoss()</span><br><span class=\"line\">result = loss(<span class=\"built_in\">input</span>, target)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(result)  <span class=\"comment\"># tensor(0.7679)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.tensor([<span class=\"number\">0.8</span>, <span class=\"number\">0.1</span>, <span class=\"number\">0.1</span>])</span><br><span class=\"line\">result = loss(<span class=\"built_in\">input</span>, target)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(result)  <span class=\"comment\"># tensor(1.3897)</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"10-2-Backward\">10.2 Backward</h3>\n<p>æ¥ä¸‹æ¥ä»¥ CIFAR10 æ•°æ®é›†ä¸ºä¾‹ï¼Œç”¨ä¸Šä¸€èŠ‚æ­å»ºçš„ç¥ç»ç½‘ç»œå…ˆè®¾ç½® <code>batch_size</code> ä¸º1ï¼Œçœ‹ä¸€ä¸‹è¾“å‡ºç»“æœï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">CIFAR10_Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(CIFAR10_Network, self).__init__()</span><br><span class=\"line\">        self.model = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">3</span>, out_channels=<span class=\"number\">32</span>, kernel_size=<span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),  <span class=\"comment\"># [32, 32, 32]</span></span><br><span class=\"line\">            nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>),  <span class=\"comment\"># [32, 16, 16]</span></span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">32</span>, out_channels=<span class=\"number\">32</span>, kernel_size=<span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),  <span class=\"comment\"># [32, 16, 16]</span></span><br><span class=\"line\">            nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>),  <span class=\"comment\"># [32, 8, 8]</span></span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">32</span>, out_channels=<span class=\"number\">64</span>, kernel_size=<span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),  <span class=\"comment\"># [64, 8, 8]</span></span><br><span class=\"line\">            nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>),  <span class=\"comment\"># [64, 4, 4]</span></span><br><span class=\"line\">            nn.Flatten(),  <span class=\"comment\"># [1024]</span></span><br><span class=\"line\">            nn.Linear(in_features=<span class=\"number\">1024</span>, out_features=<span class=\"number\">64</span>),  <span class=\"comment\"># [64]</span></span><br><span class=\"line\">            nn.Linear(in_features=<span class=\"number\">64</span>, out_features=<span class=\"number\">10</span>) <span class=\"comment\"># [10]</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.model(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">network = CIFAR10_Network()</span><br><span class=\"line\"></span><br><span class=\"line\">test_data = datasets.CIFAR10(<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor())</span><br><span class=\"line\">data_loader = DataLoader(test_data, batch_size=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">loss = nn.CrossEntropyLoss()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_loader):</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    output = network(imgs)</span><br><span class=\"line\">    output_loss = loss(output, targets)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(output)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(targets)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(output_loss)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># tensor([[ 0.1252, -0.1069, -0.0747,  0.0232,  0.0852,  0.1019,  0.0688, -0.1068,</span></span><br><span class=\"line\"><span class=\"comment\">#           0.0854, -0.0740]], grad_fn=&lt;AddmmBackward0&gt;)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># tensor([3])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># tensor(2.2960, grad_fn=&lt;NllLossBackward0&gt;)</span></span><br></pre></td></tr></table></figure>\n<p>ç°åœ¨æˆ‘ä»¬æ¥å°è¯•è§£å†³ç¬¬äºŒä¸ªé—®é¢˜ï¼Œå³æŸå¤±å‡½æ•°å¦‚ä½•ä¸ºæˆ‘ä»¬æ›´æ–°è¾“å‡ºæä¾›ä¸€å®šçš„ä¾æ®ï¼ˆåå‘ä¼ æ’­ï¼‰ã€‚</p>\n<p>ä¾‹å¦‚å¯¹äºå·ç§¯å±‚æ¥è¯´ï¼Œå…¶ä¸­å·ç§¯æ ¸ä¸­çš„æ¯ä¸ªå‚æ•°å°±æ˜¯æˆ‘ä»¬éœ€è¦è°ƒæ•´çš„ï¼Œæ¯ä¸ªå‚æ•°å…·æœ‰ä¸€ä¸ªå±æ€§ <code>grad</code> è¡¨ç¤ºæ¢¯åº¦ï¼Œåå‘ä¼ æ’­æ—¶æ¯ä¸€ä¸ªè¦æ›´æ–°çš„å‚æ•°éƒ½ä¼šæ±‚å‡ºå¯¹åº”çš„æ¢¯åº¦ï¼Œåœ¨ä¼˜åŒ–çš„è¿‡ç¨‹ä¸­å°±å¯ä»¥æ ¹æ®è¿™ä¸ªæ¢¯åº¦å¯¹å‚æ•°è¿›è¡Œä¼˜åŒ–ï¼Œæœ€ç»ˆè¾¾åˆ°é™ä½æŸå¤±å‡½æ•°å€¼çš„ç›®çš„ã€‚</p>\n<p>PyTorch ä¸­å¯¹æŸå¤±å‡½æ•°è®¡ç®—å‡ºçš„ç»“æœä½¿ç”¨ <code>backward</code> å‡½æ•°å³å¯è®¡ç®—å‡ºæ¢¯åº¦ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">CIFAR10_Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(CIFAR10_Network, self).__init__()</span><br><span class=\"line\">        self.model = nn.Sequential(</span><br><span class=\"line\">            <span class=\"comment\"># Layers</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.model(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">network = CIFAR10_Network()</span><br><span class=\"line\"></span><br><span class=\"line\">test_data = datasets.CIFAR10(<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor())</span><br><span class=\"line\">data_loader = DataLoader(test_data, batch_size=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">loss = nn.CrossEntropyLoss()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_loader):</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    output = network(imgs)</span><br><span class=\"line\">    output_loss = loss(output, targets)</span><br><span class=\"line\">    output_loss.backward()  <span class=\"comment\"># åå‘ä¼ æ’­</span></span><br></pre></td></tr></table></figure>\n<p>æˆ‘ä»¬åœ¨è®¡ç®—åå‘ä¼ æ’­ä¹‹å‰è®¾ç½®æ–­ç‚¹ï¼Œç„¶åå¯ä»¥åœ¨ PyCharm ä¸‹æ–¹çš„å˜é‡åŒºåŸŸé€šè¿‡ç›®å½• <code>network/model/Protected Attributes/_modules/'0'/weight/grad</code> æŸ¥çœ‹åˆ°æŸä¸€å±‚å‚æ•°çš„æ¢¯åº¦ï¼Œåœ¨åå‘ä¼ æ’­ä¹‹å‰ä¸º <code>None</code>ï¼Œæ‰§è¡Œåå‘ä¼ æ’­çš„ä»£ç åå¯ä»¥çœ‹åˆ° <code>grad</code> å¤„æœ‰æ•°å€¼äº†ã€‚</p>\n<p>æˆ‘ä»¬æœ‰äº†å„ä¸ªèŠ‚ç‚¹å‚æ•°çš„æ¢¯åº¦ï¼Œæ¥ä¸‹æ¥å°±å¯ä»¥é€‰ç”¨ä¸€ä¸ªåˆé€‚çš„ä¼˜åŒ–å™¨ï¼Œæ¥å¯¹è¿™äº›å‚æ•°è¿›è¡Œä¼˜åŒ–ã€‚</p>\n<h3 id=\"10-3-Optimizer\">10.3 Optimizer</h3>\n<p>ä¼˜åŒ–å™¨ <code>torch.optim</code> çš„å®˜æ–¹æ–‡æ¡£ï¼š<a href=\"https://pytorch.org/docs/stable/optim.html\">TORCH.OPTIM</a>ã€‚</p>\n<p>ä¼˜åŒ–å™¨ä¸»è¦æ˜¯åœ¨æ¨¡å‹è®­ç»ƒé˜¶æ®µå¯¹æ¨¡å‹çš„å¯å­¦ä¹ å‚æ•°è¿›è¡Œæ›´æ–°ï¼Œå¸¸ç”¨ä¼˜åŒ–å™¨æœ‰ï¼šSGDã€RMSpropã€Adamç­‰ã€‚ä¼˜åŒ–å™¨åˆå§‹åŒ–æ—¶ä¼ å…¥ä¼ å…¥æ¨¡å‹çš„å¯å­¦ä¹ å‚æ•°ï¼Œä»¥åŠå…¶ä»–è¶…å‚æ•°å¦‚ <code>lr</code>ã€<code>momentum</code> ç­‰ï¼Œä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</span><br><span class=\"line\"></span><br><span class=\"line\">optimizer = optim.SGD(model.parameters(), lr=<span class=\"number\">0.01</span>, momentum=<span class=\"number\">0.9</span>)</span><br><span class=\"line\">optimizer = optim.Adam([var1, var2], lr=<span class=\"number\">0.0001</span>)</span><br></pre></td></tr></table></figure>\n<p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å…ˆè°ƒç”¨ <code>optimizer.zero_grad()</code> æ¸…ç©ºæ¢¯åº¦ï¼Œå†è°ƒç”¨ <code>loss.backward()</code> åå‘ä¼ æ’­ï¼Œæœ€åè°ƒç”¨ <code>optimizer.step()</code> æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_loader):</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    output = network(imgs)</span><br><span class=\"line\">    loss = loss_function(output, targets)</span><br><span class=\"line\">    optimizer.zero_grad()</span><br><span class=\"line\">    loss.backward()</span><br><span class=\"line\">    optimizer.step()</span><br></pre></td></tr></table></figure>\n<p>æ¥ä¸‹æ¥æˆ‘ä»¬æ¥è®­ç»ƒ20è½®ç¥ç»ç½‘ç»œï¼Œçœ‹çœ‹æŸå¤±å‡½æ•°å€¼çš„å˜åŒ–ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">CIFAR10_Network</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(CIFAR10_Network, self).__init__()</span><br><span class=\"line\">        self.model = nn.Sequential(</span><br><span class=\"line\">            <span class=\"comment\"># Layers</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.model(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">network = CIFAR10_Network()</span><br><span class=\"line\"></span><br><span class=\"line\">test_data = datasets.CIFAR10(<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor())</span><br><span class=\"line\">data_loader = DataLoader(test_data, batch_size=<span class=\"number\">64</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">optimizer = optim.SGD(network.parameters(), lr=<span class=\"number\">0.01</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">20</span>):  <span class=\"comment\"># å­¦ä¹ 20è½®</span></span><br><span class=\"line\">    total_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_loader):</span><br><span class=\"line\">        imgs, targets = data</span><br><span class=\"line\">        output = network(imgs)</span><br><span class=\"line\">        loss = loss_function(output, targets)</span><br><span class=\"line\">        total_loss += loss</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(total_loss)</span><br></pre></td></tr></table></figure>\n<p>å¯ä»¥çœ‹åˆ°æ¯ä¸€è½®æ‰€æœ‰ <code>batch</code> çš„æŸå¤±å‡½æ•°å€¼çš„æ€»å’Œç¡®å®åœ¨ä¸æ–­é™ä½äº†ã€‚</p>\n<h2 id=\"11-ç°æœ‰ç½‘ç»œæ¨¡å‹çš„ä½¿ç”¨åŠä¿®æ”¹\">11. ç°æœ‰ç½‘ç»œæ¨¡å‹çš„ä½¿ç”¨åŠä¿®æ”¹</h2>\n<h3 id=\"11-1-VGG16æ¨¡å‹çš„ä½¿ç”¨\">11.1 VGG16æ¨¡å‹çš„ä½¿ç”¨</h3>\n<p>æˆ‘ä»¬ä»¥ VGG16 ä¸ºä¾‹ï¼Œè¯¥ç½‘ç»œæ¨¡å‹æ˜¯ç”¨äºå¤§è§„æ¨¡å›¾åƒè¯†åˆ«çš„è¶…æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼Œå®˜æ–¹æ–‡æ¡£ï¼š<a href=\"https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.vgg16\">VGG16</a>ã€‚</p>\n<p>è¯¥ç½‘ç»œæ¨¡å‹ä¸»è¦æœ‰ä»¥ä¸‹å‚æ•°ï¼š</p>\n<ul>\n<li><code>weights</code>ï¼šå¯ä»¥è®¾ç½®æˆ <code>torchvision.models.VGG16_Weights.DEFAULT</code>ï¼Œ<code>DEFAULT</code> è¡¨ç¤ºè‡ªåŠ¨ä½¿ç”¨æœ€æ–°çš„æ•°æ®ã€‚è€ç‰ˆæœ¬ä¸º <code>pretrained</code>ï¼Œå¦‚æœä¸º <code>True</code>ï¼Œè¡¨ç¤ºä½¿ç”¨é¢„å…ˆè®­ç»ƒå¥½çš„æƒé‡ï¼Œåœ¨å®˜ç½‘å¯ä»¥çœ‹åˆ°è¿™ä¸ªæƒé‡æ˜¯åœ¨ <code>ImageNet-1K</code> æ•°æ®é›†è®­ç»ƒçš„ï¼Œé»˜è®¤ä¸ºä¸ä½¿ç”¨é¢„å…ˆè®­ç»ƒå¥½çš„æƒé‡ã€‚</li>\n<li><code>progress</code>ï¼šå¦‚æœä¸º <code>True</code>ï¼Œåˆ™æ˜¾ç¤ºä¸‹è½½çš„è¿›åº¦æ¡ï¼Œé»˜è®¤ä¸º <code>True</code>ã€‚</li>\n</ul>\n<p>æ³¨æ„ï¼Œä¸‹è½½ç½‘ç»œæ—¶é»˜è®¤çš„ä¸‹è½½è·¯å¾„æ˜¯ <code>C:\\Users\\&lt;username&gt;\\.cache</code>ï¼Œå› æ­¤åœ¨ä¸‹è½½æ¨¡å‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹è·¯å¾„ï¼šæ‰“å¼€ <code>D:\\Anaconda3_Environments\\envs\\PyTorch\\Lib\\site-packages\\torch</code> ä¸­çš„ <code>hub.py</code> æ–‡ä»¶ï¼Œæœç´¢ <code>load_state_dict_from_url</code>ï¼Œç„¶åä¿®æ”¹ <code>model_dir</code> å³å¯ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model_dir: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = <span class=\"string\">&#x27;D:\\\\Anaconda3_Environments\\\\envs\\\\PyTorch\\\\Torch-model&#x27;</span></span><br></pre></td></tr></table></figure>\n<p>ç„¶åæˆ‘ä»¬è¾“å‡ºä¸€ä¸‹è¿™ä¸ªç½‘ç»œæ¨¡å‹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"></span><br><span class=\"line\">vgg = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(vgg)</span><br><span class=\"line\"><span class=\"comment\"># VGG(</span></span><br><span class=\"line\"><span class=\"comment\">#   (features): Sequential(</span></span><br><span class=\"line\"><span class=\"comment\">#     (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span><br><span class=\"line\"><span class=\"comment\">#     (1): ReLU(inplace=True)</span></span><br><span class=\"line\"><span class=\"comment\">#     (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span><br><span class=\"line\"><span class=\"comment\">#     (3): ReLU(inplace=True)</span></span><br><span class=\"line\"><span class=\"comment\">#     (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class=\"line\"><span class=\"comment\">#     ......</span></span><br><span class=\"line\"><span class=\"comment\">#   )</span></span><br><span class=\"line\"><span class=\"comment\">#   (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))</span></span><br><span class=\"line\"><span class=\"comment\">#   (classifier): Sequential(</span></span><br><span class=\"line\"><span class=\"comment\">#     (0): Linear(in_features=25088, out_features=4096, bias=True)</span></span><br><span class=\"line\"><span class=\"comment\">#     (1): ReLU(inplace=True)</span></span><br><span class=\"line\"><span class=\"comment\">#     (2): Dropout(p=0.5, inplace=False)</span></span><br><span class=\"line\"><span class=\"comment\">#     (3): Linear(in_features=4096, out_features=4096, bias=True)</span></span><br><span class=\"line\"><span class=\"comment\">#     (4): ReLU(inplace=True)</span></span><br><span class=\"line\"><span class=\"comment\">#     (5): Dropout(p=0.5, inplace=False)</span></span><br><span class=\"line\"><span class=\"comment\">#     (6): Linear(in_features=4096, out_features=1000, bias=True)</span></span><br><span class=\"line\"><span class=\"comment\">#   )</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br></pre></td></tr></table></figure>\n<p>å¯ä»¥çœ‹åˆ°è¿™ä¸ªæ¨¡å‹çš„åˆ†ç±»ç»“æœä¸º1000ç±»ï¼Œé‚£ä¹ˆå‡å¦‚æˆ‘ä»¬éœ€è¦åˆ†ç±» CIFAR10 è¯¥å¦‚ä½•åº”ç”¨è¿™ä¸ªç½‘ç»œæ¨¡å‹å‘¢ï¼Ÿä¸€ç§æ–¹æ³•å°±æ˜¯ç›´æ¥å°†æœ€åä¸€å±‚ <code>Linear</code> çš„ <code>out_features</code> æ”¹ä¸º10ï¼Œè¿˜æœ‰ä¸€ç§æ–¹æ³•å°±æ˜¯å†æ·»åŠ ä¸€å±‚ <code>in_features=1000, out_features=10</code> çš„ <code>Linear</code>ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</span><br><span class=\"line\"></span><br><span class=\"line\">vgg = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)</span><br><span class=\"line\"></span><br><span class=\"line\">vgg.classifier.add_module(<span class=\"string\">&#x27;add_linear&#x27;</span>, nn.Linear(in_features=<span class=\"number\">1000</span>, out_features=<span class=\"number\">10</span>))  <span class=\"comment\"># åœ¨ classifier ä¸­åŠ ä¸€å±‚ Linear</span></span><br><span class=\"line\"><span class=\"comment\"># vgg.classifier[6] = nn.Linear(in_features=4096, out_features=10)  # ä¿®æ”¹ classifier çš„æœ€åä¸€å±‚ Linear</span></span><br><span class=\"line\"></span><br><span class=\"line\">test_data = datasets.CIFAR10(<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor())</span><br><span class=\"line\">data_loader = DataLoader(test_data, batch_size=<span class=\"number\">64</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">optimizer = optim.SGD(vgg.parameters(), lr=<span class=\"number\">0.01</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">20</span>):</span><br><span class=\"line\">    total_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_loader):</span><br><span class=\"line\">        imgs, targets = data</span><br><span class=\"line\">        output = vgg(imgs)</span><br><span class=\"line\">        loss = loss_function(output, targets)</span><br><span class=\"line\">        total_loss += loss</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(total_loss)</span><br></pre></td></tr></table></figure>\n<p>å¯ä»¥çœ‹åˆ°æ•ˆæœæ˜¯æ¯”ä¹‹å‰è‡ªå·±æ„å»ºçš„ç½‘ç»œæ¨¡å‹å¥½å¾ˆå¤šçš„ã€‚</p>\n<h3 id=\"11-2-æ¨¡å‹çš„ä¿å­˜ä¸è¯»å–\">11.2 æ¨¡å‹çš„ä¿å­˜ä¸è¯»å–</h3>\n<p>æˆ‘ä»¬åœ¨å¯¹æŸäº›æ¨¡å‹è¿›è¡Œä¿®æ”¹åå¯èƒ½æƒ³å°†å…¶ä¿å­˜ä¸‹æ¥ï¼Œæ–¹ä¾¿ä»¥åç”¨åˆ°æ—¶æ— éœ€å†æ„å»ºä¸€éç½‘ç»œï¼Œå¯ä»¥æŒ‰ä»¥ä¸‹çš„æ–¹å¼å°†æ•´ä¸ªæ¨¡å‹ä¿å­˜åˆ°è·¯å¾„ <code>models/CIFAR10_VGG16.pth</code>ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">model = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)</span><br><span class=\"line\">model.classifier.add_module(<span class=\"string\">&#x27;add_linear&#x27;</span>, nn.Linear(in_features=<span class=\"number\">1000</span>, out_features=<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">torch.save(model, <span class=\"string\">&#x27;models/CIFAR10_VGG16.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>å…¶å¯¹åº”çš„åŠ è½½æ¨¡å‹çš„æ–¹å¼ä¸ºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model = torch.load(<span class=\"string\">&#x27;models/CIFAR10_VGG16.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>è¿˜æœ‰ä¸€ç§ä¿å­˜æ–¹å¼æ˜¯å°†æ¨¡å‹ä¸­çš„å‚æ•°ä¿å­˜æˆå­—å…¸çš„å½¢å¼ï¼Œå®˜æ–¹å»ºè®®ä½¿ç”¨è¯¥æ–¹å¼ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.save(model.state_dict(), <span class=\"string\">&#x27;models/CIFAR10_VGG16_STATE.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>å…¶å¯¹åº”çš„åŠ è½½æ¨¡å‹çš„æ–¹å¼ä¸ºï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model = torchvision.models.vgg16()</span><br><span class=\"line\">model.load_state_dict(torch.load(<span class=\"string\">&#x27;models/CIFAR10_VGG16_STATE.pkl&#x27;</span>))</span><br></pre></td></tr></table></figure>\n<p>æ³¨æ„å¦‚æœæ˜¯ä¿å­˜è‡ªå·±æ„å»ºçš„ç½‘ç»œæ¨¡å‹ï¼Œéœ€è¦åœ¨æ¨¡å‹çš„ç±»çš„æºä»£ç ä¸­å°†è¯¥ç±»å¯¼å…¥è¿›æ¥ï¼Œä¾‹å¦‚åœ¨ <code>test_save.py</code> ä¸­ç”¨ä»¥ä¸‹ä»£ç ä¿å­˜è‡ªå·±çš„ç½‘ç»œï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MyNetwork</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(MyNetwork, self).__init__()</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">64</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.conv1(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\">model = MyNetwork()</span><br><span class=\"line\">torch.save(model, <span class=\"string\">&#x27;models/My_Network.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>åœ¨ <code>test_load.py</code> ä¸­å¯¼å…¥æ—¶éœ€è¦è¿™æ ·å†™ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> test_save <span class=\"keyword\">import</span> MyNetwork</span><br><span class=\"line\"></span><br><span class=\"line\">model = torch.load(<span class=\"string\">&#x27;models/My_Network.pth&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(model)</span><br></pre></td></tr></table></figure>\n<h2 id=\"12-å®Œæ•´è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•\">12. å®Œæ•´è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•</h2>\n<h3 id=\"12-1-è®­ç»ƒæ¨¡å‹æ—¶çš„æ³¨æ„äº‹é¡¹\">12.1 è®­ç»ƒæ¨¡å‹æ—¶çš„æ³¨æ„äº‹é¡¹</h3>\n<p>ï¼ˆ1ï¼‰é€šå¸¸æˆ‘ä»¬ä¼šå°†è¶…å‚æ•°çš„è®¾ç½®æ”¾åœ¨ä¸€èµ·ï¼Œä½¿ä»£ç æ›´åŠ ç›´è§‚ä¸”æ–¹ä¾¿ä¿®æ”¹ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BATCH_SIZE = <span class=\"number\">64</span></span><br><span class=\"line\">LEARNING_RATE = <span class=\"number\">0.01</span></span><br><span class=\"line\">EPOCH = <span class=\"number\">10</span></span><br></pre></td></tr></table></figure>\n<p>ï¼ˆ2ï¼‰æˆ‘ä»¬åœ¨æ¯ä¸€è½® epoch ä¸­ä¼šå…ˆå¯¹è®­ç»ƒé›†è¿›è¡Œè®­ç»ƒï¼Œç„¶åä½¿ç”¨æµ‹è¯•é›†è¿›è¡Œæ­£ç¡®ç‡çš„æµ‹è¯•ï¼Œå› æ­¤ä¸€èˆ¬æˆ‘ä»¬ä¼šè®°å½•æ€»å…±è®­ç»ƒçš„æ¬¡æ•° <code>total_train_step</code> ä»¥åŠæ€»å…±æµ‹è¯•çš„æ¬¡æ•° <code>total_test_step</code>ï¼Œæ–¹ä¾¿åç»­ç»˜å›¾ä½¿ç”¨ã€‚</p>\n<p>ï¼ˆ3ï¼‰åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰ä¸€èˆ¬éœ€è¦å°†æ¨¡å‹è®¾ç½®æˆè®­ç»ƒçŠ¶æ€ï¼Œåœ¨æµ‹è¯•ä¹‹å‰éœ€è¦è®¾ç½®æˆè¯„ä¼°çŠ¶æ€ï¼Œè¿™ä¸¤ç§çŠ¶æ€ä¼šå½±å“å°‘éƒ¨åˆ†çš„å±‚ä¾‹å¦‚ <code>Dropout</code> å’Œ <code>BatchNorm</code>ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model.train()</span><br><span class=\"line\">    <span class=\"comment\"># training</span></span><br><span class=\"line\"></span><br><span class=\"line\">model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">    <span class=\"comment\"># evaluation</span></span><br></pre></td></tr></table></figure>\n<p>ï¼ˆ4ï¼‰åœ¨åˆ†ç±»é—®é¢˜ä¸­è®¡ç®—å‡†ç¡®ç‡ä¸€èˆ¬ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">a = torch.tensor([</span><br><span class=\"line\">    [<span class=\"number\">0.3</span>, <span class=\"number\">0.7</span>],</span><br><span class=\"line\">    [<span class=\"number\">0.6</span>, <span class=\"number\">0.4</span>]</span><br><span class=\"line\">])  <span class=\"comment\"># å‡è®¾ä¸¤ä¸ªç‰©ä½“äºŒåˆ†ç±»çš„ç»“æœ</span></span><br><span class=\"line\"></span><br><span class=\"line\">b = torch.tensor([<span class=\"number\">0</span>, <span class=\"number\">0</span>])  <span class=\"comment\"># æ­£ç¡®çš„æ ‡ç­¾</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(a.argmax(dim=<span class=\"number\">1</span>)) <span class=\"comment\"># tensor([1, 0])ï¼Œåœ¨ç¬¬1ç»´ä¸Šå–æœ€å¤§å€¼ï¼Œå³å¯¹æ¯ä¸€è¡Œæ±‚æœ€å¤§å€¼ï¼Œå°†æœ€å¤§å€¼ä½œä¸ºåˆ†ç±»ç»“æœ</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(a.argmax(dim=<span class=\"number\">1</span>) == b)  <span class=\"comment\"># tensor([False,  True])ï¼Œä¸æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒï¼Œç¬¬ä¸€ä¸ªç‰©ä½“çš„ç»“æœä¸æ ‡ç­¾ä¸ç¬¦ï¼Œç¬¬äºŒä¸ªå’Œæ ‡ç­¾ç›¸ç¬¦</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>((a.argmax(dim=<span class=\"number\">1</span>) == b).<span class=\"built_in\">sum</span>())  <span class=\"comment\"># tensor(1)ï¼Œå°†æ‰€æœ‰ç‰©ä½“ä¸æ ‡ç­¾çš„æ¯”è¾ƒç»“æœæ±‚å’Œå°±æ˜¯ True çš„æ•°é‡ï¼Œä¹Ÿå°±æ˜¯é¢„æµ‹æ­£ç¡®çš„æ•°é‡</span></span><br></pre></td></tr></table></figure>\n<p>ï¼ˆ5ï¼‰æµ‹è¯•æ—¶ä¸èƒ½å¯¹æ¨¡å‹è¿›è¡Œä»»ä½•å¹²æ‰°ï¼Œå³åœ¨æµ‹è¯•çš„æ—¶å€™ç¥ç»ç½‘ç»œä¸èƒ½äº§ç”Ÿæ¢¯åº¦ï¼Œå› æ­¤åœ¨æ¯æ¬¡æµ‹è¯•å‰éœ€è¦åŠ ä¸Šä»¥ä¸‹ä»£ç ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    <span class=\"comment\"># evaluation</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"12-2-ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ\">12.2 ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ</h3>\n<p>å‰æï¼šç”µè„‘æœ‰ NVIDIA æ˜¾å¡ï¼Œé…ç½®å¥½äº† CUDAï¼Œå¯ä»¥ä½¿ç”¨ <code>torch.cuda.is_available()</code> æ¥æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨ã€‚</p>\n<p>ä½¿ç”¨ GPU è®­ç»ƒçš„æ—¶å€™ï¼Œéœ€è¦å°† Module å¯¹è±¡å’Œ Tensor ç±»å‹çš„æ•°æ®è½¬ç§»åˆ° GPU ä¸Šè¿›è¡Œè®¡ç®—ï¼Œä¸€èˆ¬æ¥è¯´å³ä¸ºå°†ç½‘ç»œæ¨¡å‹ã€æ•°æ®ã€æŸå¤±å‡½æ•°æ”¾åˆ° GPU ä¸Šè®¡ç®—ã€‚</p>\n<p>ä½¿ç”¨ GPU è®­ç»ƒçš„æ–¹å¼æœ‰ä¸¤ç§ï¼Œç¬¬ä¸€ç§æ˜¯ä½¿ç”¨ <code>cuda()</code> å‡½æ•°ï¼Œä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ç½‘ç»œæ¨¡å‹</span></span><br><span class=\"line\">model = MyNetwork()</span><br><span class=\"line\">model = model.cuda()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æŸå¤±å‡½æ•°</span></span><br><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">loss_function = loss_function.cuda()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æ•°æ®</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_loader):</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    imgs = imgs.cuda()</span><br><span class=\"line\">    targets = targets.cuda()</span><br></pre></td></tr></table></figure>\n<p>å¦ä¸€ç§æ˜¯ä½¿ç”¨ <code>to(device)</code>ï¼Œ<code>device</code> å°±æ˜¯æˆ‘ä»¬é€‰æ‹©ç”¨æ¥è®­ç»ƒæ¨¡å‹çš„è®¾å¤‡ï¼Œè¯¥æ–¹å¼ä¸ <code>cuda()</code> æœ‰ä¸€ç‚¹ç»†å¾®çš„å·®åˆ«å¦‚ä¸‹ï¼š</p>\n<ul>\n<li>å¯¹äº Tensor ç±»å‹çš„æ•°æ®ï¼ˆå›¾åƒã€æ ‡ç­¾ç­‰ï¼‰ï¼Œä½¿ç”¨ <code>to(device)</code> ä¹‹åï¼Œéœ€è¦æ¥æ”¶è¿”å›å€¼ï¼Œè¿”å›å€¼æ‰æ˜¯æ­£ç¡®è®¾ç½®äº† <code>device</code> çš„ Tensorã€‚</li>\n<li>å¯¹äº Module å¯¹è±¡ï¼ˆç½‘ç»œæ¨¡å‹ã€æŸå¤±å‡½æ•°ï¼‰ï¼Œåªç”¨è°ƒç”¨ <code>to(device)</code> å°±å¯ä»¥å°†æ¨¡å‹è®¾ç½®ä¸ºæŒ‡å®šçš„ <code>device</code>ï¼Œä¸å¿…æ¥æ”¶è¿”å›å€¼ï¼Œå½“ç„¶æ¥æ”¶è¿”å›å€¼ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚</li>\n</ul>\n<p>ä¾‹å¦‚ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)  <span class=\"comment\"># &#x27;cuda:0&#x27; è¡¨ç¤ºç¬¬ 0 å· GPU</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ç½‘ç»œæ¨¡å‹</span></span><br><span class=\"line\">model = MyNetwork()</span><br><span class=\"line\">model.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æŸå¤±å‡½æ•°</span></span><br><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">loss_function.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æ•°æ®</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data_loader):</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    imgs = imgs.to(device)</span><br><span class=\"line\">    targets = targets.to(device)</span><br></pre></td></tr></table></figure>\n<p>æ³¨æ„å¦‚æœåŠ è½½åœ¨ GPU ä¸Šè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œç„¶åæƒ³åœ¨ CPU ä¸Šä½¿ç”¨ï¼Œéœ€è¦æ˜ å°„å› CPUï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model = torch.load(<span class=\"string\">&#x27;models/AFTER_TRAININGS_MODEL.pth&#x27;</span>, map_location=torch.device(<span class=\"string\">&#x27;cpu&#x27;</span>))</span><br></pre></td></tr></table></figure>\n<h3 id=\"12-3-CIFAR10-Net-Simple-v3\">12.3 CIFAR10_Net_Simple_v3</h3>\n<p>æœ€åæ”¾ä¸Šç»è¿‡è‡ªå·±è°ƒå‚è¾¾åˆ°88%å·¦å³çš„æ­£ç¡®ç‡çš„æ¨¡å‹å’Œè®­ç»ƒä»£ç å§ï¼š</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">CIFAR10_Net_Simple_v3</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(CIFAR10_Net_Simple_v3, self).__init__()</span><br><span class=\"line\">        self.model = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">3</span>, out_channels=<span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),  <span class=\"comment\"># [32, 32, 32]</span></span><br><span class=\"line\">            nn.ReLU(inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">32</span>, out_channels=<span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),  <span class=\"comment\"># [32, 32, 32]</span></span><br><span class=\"line\">            nn.ReLU(inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>),  <span class=\"comment\"># [32, 16, 16]</span></span><br><span class=\"line\"></span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">32</span>, out_channels=<span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),  <span class=\"comment\"># [64, 16, 16]</span></span><br><span class=\"line\">            nn.ReLU(inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">64</span>, out_channels=<span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),  <span class=\"comment\"># [64, 16, 16]</span></span><br><span class=\"line\">            nn.ReLU(inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>),  <span class=\"comment\"># [64, 8, 8]</span></span><br><span class=\"line\"></span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">64</span>, out_channels=<span class=\"number\">128</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),  <span class=\"comment\"># [128, 16, 16]</span></span><br><span class=\"line\">            nn.ReLU(inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">128</span>),</span><br><span class=\"line\">            nn.Conv2d(in_channels=<span class=\"number\">128</span>, out_channels=<span class=\"number\">128</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),  <span class=\"comment\"># [128, 16, 16]</span></span><br><span class=\"line\">            nn.ReLU(inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">128</span>),</span><br><span class=\"line\">            nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>),  <span class=\"comment\"># [128, 4, 4]</span></span><br><span class=\"line\"></span><br><span class=\"line\">            nn.Flatten(),  <span class=\"comment\"># [2048]</span></span><br><span class=\"line\">            nn.Dropout(p=<span class=\"number\">0.4</span>, inplace=<span class=\"literal\">False</span>),</span><br><span class=\"line\"></span><br><span class=\"line\">            nn.Linear(in_features=<span class=\"number\">2048</span>, out_features=<span class=\"number\">64</span>),  <span class=\"comment\"># [64]</span></span><br><span class=\"line\">            nn.ReLU(inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\">            nn.Dropout(p=<span class=\"number\">0.4</span>, inplace=<span class=\"literal\">False</span>),</span><br><span class=\"line\"></span><br><span class=\"line\">            nn.Linear(in_features=<span class=\"number\">64</span>, out_features=<span class=\"number\">10</span>) <span class=\"comment\"># [10]</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, <span class=\"built_in\">input</span></span>):</span><br><span class=\"line\">        output = self.model(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># model = CIFAR10_Net_Simple_v3()</span></span><br><span class=\"line\"><span class=\"comment\"># torch.save(model, &#x27;../models/CIFAR10_Net_Simple_v3.pth&#x27;)</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data.dataset <span class=\"keyword\">import</span> ConcatDataset</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">from</span> util.CIFAR10_Net_Simple_v3 <span class=\"keyword\">import</span> *</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è¶…å‚æ•°</span></span><br><span class=\"line\">BATCH_SIZE = <span class=\"number\">32</span></span><br><span class=\"line\">LEARNING_RATE = <span class=\"number\">0.01</span></span><br><span class=\"line\">EPOCH = <span class=\"number\">150</span></span><br><span class=\"line\">SHOW_INFO_STEP = <span class=\"number\">200</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># è®­ç»ƒè®¾å¤‡</span></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&#x27;cuda&#x27;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&#x27;cpu&#x27;</span>)  <span class=\"comment\"># &#x27;cuda:0&#x27; è¡¨ç¤ºç¬¬ 0 å· GPU</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æ•°æ®å¢å¼º</span></span><br><span class=\"line\">trans = transforms.Compose([</span><br><span class=\"line\">    transforms.RandomCrop(<span class=\"number\">32</span>, padding=[<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>]),</span><br><span class=\"line\">    transforms.RandomHorizontalFlip(p=<span class=\"number\">0.5</span>),</span><br><span class=\"line\">    transforms.ToTensor()</span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æ•°æ®é›†</span></span><br><span class=\"line\">train_data = datasets.CIFAR10(<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">True</span>, transform=trans)</span><br><span class=\"line\">test_data = datasets.CIFAR10(<span class=\"string\">&#x27;dataset/CIFAR10&#x27;</span>, train=<span class=\"literal\">False</span>, transform=transforms.ToTensor())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># æ‰©å……è®­ç»ƒé›†</span></span><br><span class=\"line\"><span class=\"comment\"># trans_train_data = datasets.CIFAR10(&#x27;dataset/CIFAR10&#x27;, train=True, transform=trans)</span></span><br><span class=\"line\"><span class=\"comment\"># train_data = ConcatDataset([train_data, trans_train_data])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># åŠ è½½æ•°æ®</span></span><br><span class=\"line\">train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\">test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)</span><br><span class=\"line\"></span><br><span class=\"line\">train_data_len = <span class=\"built_in\">len</span>(train_data)</span><br><span class=\"line\">test_data_len = <span class=\"built_in\">len</span>(test_data)</span><br><span class=\"line\"></span><br><span class=\"line\">model = torch.load(<span class=\"string\">&#x27;models/CIFAR10_Net_Simple_v3.pth&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\"></span><br><span class=\"line\">optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=<span class=\"number\">0.9</span>)</span><br><span class=\"line\">scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[<span class=\"number\">8</span>, <span class=\"number\">16</span>, <span class=\"number\">24</span>, <span class=\"number\">32</span>], gamma=<span class=\"number\">0.5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&#x27;logs/CIFAR10_Net_Simple_v3_Aug_Mom_logs&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model.to(device)</span><br><span class=\"line\">loss_function.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\">total_train_step = <span class=\"number\">0</span></span><br><span class=\"line\">total_test_step = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(EPOCH):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;---------- The &#123;&#125; epoch of training begins ----------&#x27;</span>.<span class=\"built_in\">format</span>(epoch))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Learning rate: &#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(optimizer.state_dict()[<span class=\"string\">&#x27;param_groups&#x27;</span>][<span class=\"number\">0</span>][<span class=\"string\">&#x27;lr&#x27;</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">    train_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    train_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    model.train()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(train_dataloader):</span><br><span class=\"line\">        imgs, targets = data</span><br><span class=\"line\">        imgs = imgs.to(device)</span><br><span class=\"line\">        targets = targets.to(device)</span><br><span class=\"line\">        output = model(imgs)</span><br><span class=\"line\"></span><br><span class=\"line\">        acc = (output.argmax(dim=<span class=\"number\">1</span>)==targets).<span class=\"built_in\">float</span>().<span class=\"built_in\">sum</span>()</span><br><span class=\"line\">        loss = loss_function(output, targets)</span><br><span class=\"line\">        train_loss += loss.item()</span><br><span class=\"line\">        train_acc += acc</span><br><span class=\"line\"></span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">        total_train_step += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> total_train_step % SHOW_INFO_STEP == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The number of training: &#123;&#125;, Loss: &#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(total_train_step, loss.item()))</span><br><span class=\"line\"></span><br><span class=\"line\">    train_acc /= train_data_len</span><br><span class=\"line\"></span><br><span class=\"line\">    writer.add_scalar(<span class=\"string\">&#x27;train_loss&#x27;</span>, train_loss, epoch)</span><br><span class=\"line\">    writer.add_scalar(<span class=\"string\">&#x27;train_acc&#x27;</span>, train_acc, epoch)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The number of epoch: &#123;&#125;, train_loss: &#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(epoch, train_loss))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The number of epoch: &#123;&#125;, train_acc: &#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(epoch, train_acc))</span><br><span class=\"line\"></span><br><span class=\"line\">    test_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    test_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> step, data <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(test_dataloader):</span><br><span class=\"line\">            imgs, targets = data</span><br><span class=\"line\">            imgs = imgs.to(device)</span><br><span class=\"line\">            targets = targets.to(device)</span><br><span class=\"line\">            output = model(imgs)</span><br><span class=\"line\"></span><br><span class=\"line\">            acc = (output.argmax(dim=<span class=\"number\">1</span>) == targets).<span class=\"built_in\">float</span>().<span class=\"built_in\">sum</span>()</span><br><span class=\"line\">            loss = loss_function(output, targets)</span><br><span class=\"line\">            test_loss += loss.item()</span><br><span class=\"line\">            test_acc += acc</span><br><span class=\"line\"></span><br><span class=\"line\">            total_test_step += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">        test_acc /= test_data_len</span><br><span class=\"line\"></span><br><span class=\"line\">        writer.add_scalar(<span class=\"string\">&#x27;test_loss&#x27;</span>, test_loss, epoch)</span><br><span class=\"line\">        writer.add_scalar(<span class=\"string\">&#x27;test_acc&#x27;</span>, test_acc, epoch)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The number of epoch: &#123;&#125;, test_loss: &#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(epoch, test_loss))</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;The number of epoch: &#123;&#125;, test_acc: &#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(epoch, test_acc))</span><br><span class=\"line\"></span><br><span class=\"line\">        writer.add_scalar(<span class=\"string\">&#x27;learning_rate&#x27;</span>, optimizer.state_dict()[<span class=\"string\">&#x27;param_groups&#x27;</span>][<span class=\"number\">0</span>][<span class=\"string\">&#x27;lr&#x27;</span>], epoch)</span><br><span class=\"line\">        scheduler.step()</span><br><span class=\"line\"></span><br><span class=\"line\">torch.save(model, <span class=\"string\">&#x27;models/CIFAR10_Net_Simple_v3_Aug_Mom_150TRAININGS.pth&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># torch.save(model.state_dict(), &#x27;models/CIFAR10_Net_Simple_v3_Aug_Mom_STATE.pkl&#x27;)</span></span><br><span class=\"line\"></span><br><span class=\"line\">writer.close()</span><br></pre></td></tr></table></figure>\n<p>è‡³æ­¤å·²ç»æˆåŠŸå…¥é—¨ PyTorch å•¦ï¼å¯ä»¥æ­£å¼è¿›å…¥ Deep Learning çš„å­¦ä¹ å•¦ï¼</p>\n",
            "tags": [
                "AI"
            ]
        }
    ]
}